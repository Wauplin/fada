{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28899a2d-c30e-484c-90fd-d6c6bd9d75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nlpaug torch>=1.6.0 transformers>=4.11.3 sentencepiece sacremoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d125db4-e760-4b42-83fa-9f9991ac73ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-23 16:47:36.060394: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-23 16:47:36.749153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "from datasets import load_dataset, load_from_disk\n",
    "\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d72c7fb4-ae4e-432e-88fc-ce66bc008cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cae8f04b-abb9-4072-a0fa-9531eb65f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a9d5968-8120-498e-8e15-ce6e348bf4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-en-de and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of FSMTForConditionalGeneration were not initialized from the model checkpoint at facebook/wmt19-de-en and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The speedy brown fox leapt over the lazy dog']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'The quick brown fox jumped over the lazy dog'\n",
    "back_translation_aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de',\n",
    "    to_model_name='facebook/wmt19-de-en',\n",
    "    device=device\n",
    ")\n",
    "augmented_text = back_translation_aug.augment(text)\n",
    "augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "657f5275-bfc7-47f3-a661-10e293b7232d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['even the quick acting brown fox jumped over at the lazy dog']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_ins_aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"insert\", device=device)\n",
    "augmented_text = context_ins_aug.augment(text)\n",
    "augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "465ef8be-c60c-48f8-b35c-f5da22f7e3c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the quick tail fox variations on the lazy dog']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_sub_aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='bert-base-uncased', action=\"substitute\", device=device)\n",
    "augmented_text = context_sub_aug.augment(text)\n",
    "augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f9ac98c-8400-4b55-b07f-42bae3db025f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the quick tail fox variations on the lazy dog']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_cont_aug = nas.ContextualWordEmbsForSentenceAug(model_path='gpt2', device=device)\n",
    "augmented_texts = context_cont_aug.augment(text, n=1)\n",
    "augmented_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00bc534f-19e0-4f71-a06e-ac5e76fe42e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AugMapper:\n",
    "    def __init__(self, augmenter):\n",
    "        self.augmenter = augmenter # textattack augmenter recipe\n",
    "\n",
    "    def apply_to_batch(self, batch):\n",
    "        new_texts, new_labels = [], []\n",
    "        for text, label in zip(batch['text'], batch['label']):\n",
    "            augmented_text = self.augmenter.augment(text)\n",
    "            new_texts.extend(augmented_text)\n",
    "            new_labels.extend([label] * len(augmented_text))\n",
    "\n",
    "        return {\n",
    "            \"text\": new_texts,\n",
    "            \"label\": new_labels,\n",
    "            \"idx\": list(range(len(new_labels))),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def7b9f4-42ec-452f-939d-bf68d6892e86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./fada/fadata/datasets/ag_news.default.original.10\n",
      "./fada/fadata/datasets/ag_news.default.backtranslate.10\n",
      "found existing dataset ./fada/fadata/datasets/ag_news.default.backtranslate.10... skipping...\n",
      "./fada/fadata/datasets/ag_news.default.context_ins.10\n",
      "found existing dataset ./fada/fadata/datasets/ag_news.default.context_ins.10... skipping...\n",
      "./fada/fadata/datasets/ag_news.default.context_sub.10\n",
      "found existing dataset ./fada/fadata/datasets/ag_news.default.context_sub.10... skipping...\n",
      "./fada/fadata/datasets/ag_news.default.context_cont.10\n",
      "found existing dataset ./fada/fadata/datasets/ag_news.default.context_cont.10... skipping...\n",
      "./fada/fadata/datasets/ag_news.default.original.200\n",
      "./fada/fadata/datasets/ag_news.default.backtranslate.200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9db6914ce744c8abb5d84d7bb46606d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augs = [\n",
    "    (\"backtranslate\", AugMapper(back_translation_aug)),\n",
    "    (\"context_ins\", AugMapper(context_ins_aug)), \n",
    "    (\"context_sub\", AugMapper(context_sub_aug)), \n",
    "    (\"context_cont\", AugMapper(context_cont_aug))\n",
    "]\n",
    "\n",
    "dataset_paths = glob.glob(\"./fada/fadata/datasets/*original.*\")\n",
    "dataset_paths.sort()\n",
    "\n",
    "for dataset_path in dataset_paths:\n",
    "\n",
    "    print(dataset_path)\n",
    "\n",
    "    dataset = load_from_disk(dataset_path)\n",
    "    \n",
    "    for aug_name, aug_fn in augs:\n",
    "\n",
    "        aug_save_path = dataset_path.replace(\"original\", aug_name)\n",
    "        \n",
    "        print(aug_save_path)\n",
    "        \n",
    "        if os.path.exists(aug_save_path):\n",
    "            print(f\"found existing dataset {aug_save_path}... skipping...\") \n",
    "        else:\n",
    "            aug_dataset = dataset.map(aug_fn.apply_to_batch, batched=True, batch_size=10)\n",
    "            aug_dataset.save_to_disk(aug_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc42ae60-e9e6-4a18-839e-60bee87fee7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
