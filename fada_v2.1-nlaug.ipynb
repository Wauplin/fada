{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e616ab",
   "metadata": {},
   "source": [
    "# Feature-Aware Data Augmentation\n",
    "\n",
    "Augmentation policies to consider:\n",
    "- Simple policy randomly sampling of n transforms \n",
    "- Constrained sampling policy with a blacklist of transforms to avoid \n",
    "- Feature-aware augmentation policy where transforms are picked based on their (transform, feature) behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0cdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "\n",
    "# amrs\n",
    "import amrlib\n",
    "import penman\n",
    "\n",
    "# transform\n",
    "# import sibyl\n",
    "import time\n",
    "import torch\n",
    "import inspect\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "# eval pipeline\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import HfApi, ModelFilter\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from scipy.special import softmax\n",
    "\n",
    "# train pipeline\n",
    "import shutil\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# cleanlab pipeline\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8870c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\huggingface_hub\\utils\\_hf_folder.py:92: UserWarning: A token has been found in `C:\\Users\\Fabrice\\.huggingface\\token`. This is the old path where tokens were stored. The new location is `C:\\Users\\Fabrice\\.cache\\huggingface\\token` which is configurable using `HF_HOME` environment variable. Your token has been copied to this new location. You can now safely delete the old token file manually or use `huggingface-cli logout`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0953833c2e42eca2c9ffef4fa4673e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbad517ac654d3ea6eb35eb12a70d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d39795028d942ff9c2943b44a8dce24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24d920e6a5c41328bed336874e07c8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b386d9fe184998a9f9f7adc2a7a05f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0380ccd35e4572a1a2401edc601804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nlaugmenter.transformations.emojify                                   import EmojifyTransformation\n",
    "from nlaugmenter.transformations.synonym_insertion                         import SynonymInsertion\n",
    "from nlaugmenter.transformations.back_translation                          import BackTranslation\n",
    "from nlaugmenter.transformations.noun_compound_paraphraser                 import NounCompoundParaphraser\n",
    "from nlaugmenter.transformations.diacritic_removal                         import DiacriticRemoval\n",
    "from nlaugmenter.transformations.azerty_qwerty_chars_swap                  import AzertyQwertyCharsSwap\n",
    "from nlaugmenter.transformations.add_hashtags                              import HashtagGeneration\n",
    "from nlaugmenter.transformations.replace_spelling                          import SpellingTransformation\n",
    "from nlaugmenter.transformations.token_replacement                         import TokenReplacement\n",
    "from nlaugmenter.transformations.auxiliary_negation_removal                import SentenceAuxiliaryNegationRemoval\n",
    "from nlaugmenter.transformations.use_acronyms                              import UseAcronyms\n",
    "from nlaugmenter.transformations.yoda_transform                            import YodaPerturbation\n",
    "from nlaugmenter.transformations.factive_verb_transformation               import FactiveVerbTransformation\n",
    "from nlaugmenter.transformations.protaugment_diverse_paraphrase            import ProtaugmentDiverseParaphrase\n",
    "from nlaugmenter.transformations.replace_financial_amounts                 import ReplaceFinancialAmount\n",
    "from nlaugmenter.transformations.americanize_britishize_english            import AmericanizeBritishizeEnglish\n",
    "from nlaugmenter.transformations.punctuation                               import PunctuationWithRules\n",
    "from nlaugmenter.transformations.urban_dict_swap                           import UrbanThesaurusSwap\n",
    "from nlaugmenter.transformations.filler_word_augmentation                  import FillerWordAugmentation\n",
    "from nlaugmenter.transformations.synonym_substitution                      import SynonymSubstitution\n",
    "from nlaugmenter.transformations.style_paraphraser                         import StyleTransferParaphraser\n",
    "from nlaugmenter.transformations.random_upper_transformation               import RandomUpperPerturbation\n",
    "from nlaugmenter.transformations.weekday_month_abbreviation                import WeekdayMonthAbbreviation\n",
    "from nlaugmenter.transformations.city_names_transformation                 import CityNamesTransformation\n",
    "from nlaugmenter.transformations.sentence_additions                        import SentenceAdditions\n",
    "from nlaugmenter.transformations.change_date_format                        import ChangeDateFormat\n",
    "from nlaugmenter.transformations.tense                                     import TenseTransformation\n",
    "from nlaugmenter.transformations.dyslexia_words_swap                       import DyslexiaWordsSwap\n",
    "from nlaugmenter.transformations.gender_culture_diverse_name               import GenderCultureDiverseName\n",
    "from nlaugmenter.transformations.gender_neutral_rewrite                    import GenderNeutralRewrite\n",
    "from nlaugmenter.transformations.lost_in_translation                       import LostInTranslation\n",
    "from nlaugmenter.transformations.insert_abbreviation                       import AbbreviationInsertionEN\n",
    "from nlaugmenter.transformations.random_deletion                           import RandomDeletion\n",
    "from nlaugmenter.transformations.transformer_fill                          import TransformerFill\n",
    "from nlaugmenter.transformations.concat_monolingual                        import ConcatMonolingual\n",
    "from nlaugmenter.transformations.country_state_abbreviation_transformation import CountryStateAbbreviation\n",
    "from nlaugmenter.transformations.butter_fingers_perturbation               import ButterFingersPerturbation\n",
    "from nlaugmenter.transformations.replace_abbreviation_and_acronyms         import ReplaceAbbreviations\n",
    "from nlaugmenter.transformations.slangificator                             import Slangificator\n",
    "from nlaugmenter.transformations.yes_no_question                           import YesNoQuestionPerturbation\n",
    "from nlaugmenter.transformations.gender_swap                               import GenderSwap\n",
    "from nlaugmenter.transformations.close_homophones_swap                     import CloseHomophonesSwap\n",
    "from nlaugmenter.transformations.simple_ciphers                            import SimpleCiphers\n",
    "from nlaugmenter.transformations.change_person_named_entities              import ChangePersonNamedEntities\n",
    "from nlaugmenter.transformations.greetings_and_farewells                   import GreetingsAndFarewells\n",
    "from nlaugmenter.transformations.discourse_marker_substitution             import DiscourseMarkerSubstitution\n",
    "from nlaugmenter.transformations.summarization_transformation              import Summarization\n",
    "from nlaugmenter.transformations.visual_attack_letters                     import VisualAttackLetters\n",
    "from nlaugmenter.transformations.sentence_reordering                       import SentenceReordering\n",
    "from nlaugmenter.transformations.change_char_case                          import ChangeCharCase\n",
    "from nlaugmenter.transformations.antonyms_substitute                       import AntonymsSubstitute\n",
    "from nlaugmenter.transformations.mix_transliteration                       import MixTransliteration\n",
    "from nlaugmenter.transformations.disability_transformation                 import DifferentAbilityTransformation\n",
    "from nlaugmenter.transformations.abbreviation_transformation               import Abbreviate\n",
    "from nlaugmenter.transformations.replace_with_hyponyms_hypernyms           import ReplaceHypernyms\n",
    "from nlaugmenter.transformations.replace_with_hyponyms_hypernyms           import ReplaceHyponyms\n",
    "from nlaugmenter.transformations.grapheme_to_phoneme_transformation        import PhonemeSubstitution\n",
    "from nlaugmenter.transformations.multilingual_lexicon_perturbation         import MultilingualLexiconPerturbation\n",
    "from nlaugmenter.transformations.multilingual_back_translation             import MultilingualBackTranslation\n",
    "from nlaugmenter.transformations.unit_converter                            import UnitConverter\n",
    "from nlaugmenter.transformations.adjectives_antonyms_switch                import SentenceAdjectivesAntonymsSwitch\n",
    "from nlaugmenter.transformations.correct_common_misspellings               import CorrectCommonMisspellings\n",
    "from nlaugmenter.transformations.neural_question_paraphraser               import NeuralParaphaserPerturbation\n",
    "from nlaugmenter.transformations.subject_object_switch                     import SentenceSubjectObjectSwitch\n",
    "from nlaugmenter.transformations.numeric_to_word                           import NumericToWord\n",
    "from nlaugmenter.transformations.multilingual_dictionary_based_code_switch import MultilingualDictionaryBasedCodeSwitch\n",
    "from nlaugmenter.transformations.diverse_paraphrase                        import DiverseParaphrase\n",
    "from nlaugmenter.transformations.english_inflectional_variation            import EnglishInflectionalVariation\n",
    "from nlaugmenter.transformations.replace_numerical_values                  import ReplaceNumericalValues\n",
    "from nlaugmenter.transformations.speech_disfluency_perturbation            import SpeechDisfluencyPerturbation\n",
    "from nlaugmenter.transformations.whitespace_perturbation                   import WhitespacePerturbation\n",
    "from nlaugmenter.transformations.contraction_expansions                    import ContractionExpansions\n",
    "from nlaugmenter.transformations.color_transformation                      import ColorTransformation\n",
    "from nlaugmenter.transformations.contextual_meaning_perturbation           import ContextualMeaningPerturbation\n",
    "from nlaugmenter.transformations.pig_latin                                 import PigLatin\n",
    "from nlaugmenter.transformations.leet_letters                              import LeetLetters\n",
    "from nlaugmenter.transformations.hashtagify                                import HashtagifyTransformation\n",
    "from nlaugmenter.transformations.propbank_srl_roles                        import CheckSrl\n",
    "from nlaugmenter.transformations.geo_names_transformation                  import GeoNamesTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0408a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cec473e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(False)\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b61f4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def normalize_minmax(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())  \n",
    "    return df\n",
    "\n",
    "def normalize_sum(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column] / df[column].sum()\n",
    "    return df\n",
    "\n",
    "def augment_data(batch, transform, keep_originals=True):\n",
    "    new_texts, new_labels = [], []\n",
    "    for text, label in zip(batch['text'], batch['label']):\n",
    "        new_text, new_label = transform.apply([text], [label])\n",
    "        new_texts.extend(new_text)\n",
    "        new_labels.extend(new_label)\n",
    "    if keep_originals:\n",
    "        return {\"text\": batch['text'] + new_texts, \"label\": batch['label'] + new_labels}\n",
    "    else:\n",
    "        return {\"text\": new_texts, \"label\": new_labels}\n",
    "    \n",
    "def percent_dataset_changed(d1, d2):\n",
    "    return sum([t1['text'] != t2['text'] for t1, t2 in zip(d1, d2)]) / len(d1) \n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    acc = accuracy_score(labels, predictions.argmax(-1))\n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(\n",
    "        y_true=labels, \n",
    "        y_pred=predictions.argmax(-1), \n",
    "        average=\"weighted\", \n",
    "        zero_division=0)\n",
    "    return { 'accuracy': acc , \n",
    "             'precision': precision, \n",
    "             'recall': recall, \n",
    "             'fbeta_score': fbeta_score} \n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    if not isinstance(labels, np.ndarray):\n",
    "        labels = np.array(labels)\n",
    "    if len(labels.shape) > 1:\n",
    "        acc = acc_at_k(labels, predictions, k=2)       \n",
    "    else:\n",
    "        acc = accuracy_score(labels, np.argmax(predictions, -1))\n",
    "    return acc\n",
    "\n",
    "def vectorize(output):\n",
    "    sorted_output = sorted(output, key=lambda d: d['label']) \n",
    "    probs = torch.tensor([d['score'] for d in sorted_output])\n",
    "    return probs\n",
    "\n",
    "def sample_transforms(transforms, p, n=2, replace=False):\n",
    "    return np.random.choice(transforms, size=n, p=p, replace=replace).tolist()\n",
    "\n",
    "def transforms_to_ids(sampled_transforms, all_transforms):\n",
    "    transforms_ids = [all_transforms.index(i) for i in sampled_transforms]\n",
    "    transforms_applied = np.zeros(len(all_transforms), dtype=np.int32)\n",
    "    transforms_applied[transforms_ids] = 1\n",
    "    return transforms_applied\n",
    "\n",
    "def policy_heatmap(policy, transforms, featurizers):\n",
    "    t_names = [t.transform_class.__name__ for t in transforms]\n",
    "    f_names = [f.__name__ for f in featurizers]\n",
    "    df = pd.DataFrame(policy)\n",
    "    df.columns = f_names\n",
    "    df.index = t_names\n",
    "    sns.heatmap(df)\n",
    "    plt.show()\n",
    "    \n",
    "def implement_policy_probabilities(policy, features):\n",
    "    default_probability = policy.mean(axis=1)\n",
    "    policy_probs = []\n",
    "    for f in features:\n",
    "        available_features = np.nonzero(f)[0]\n",
    "        if len(available_features) == 0:\n",
    "            probs = default_probability\n",
    "        else:\n",
    "            probs = policy[:, available_features].mean(axis=1)\n",
    "        policy_probs.append(probs)\n",
    "    return np.array(policy_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af0516f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self, transform_class, num_outputs=1, task_name=\"sentiment\"):\n",
    "        self.transform_class = transform_class\n",
    "        self.num_outputs = num_outputs\n",
    "        self.task_name = task_name\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.intakes_target = False\n",
    "        self.is_batched = False\n",
    "        \n",
    "        # setting class attributes\n",
    "        if 'to_tense' in inspect.signature(self.transform_class).parameters:\n",
    "            print(f\"initializing {self.transform_class.__name__} with to_tense='past'\") # future & random don't work\n",
    "            self.transform_instance = self.transform_class(to_tense=\"past\")\n",
    "        elif 'source_lang' in inspect.signature(self.transform_class).parameters:\n",
    "            print(f\"initializing {self.transform_class.__name__} with source_lang='es'\") \n",
    "            self.transform_instance = self.transform_class(source_lang=\"es\")\n",
    "        elif 'task_name' in inspect.signature(self.transform_class).parameters:\n",
    "            print(f\"initializing {self.transform_class.__name__} with task_name='{task_name}', return_metadata=True\") \n",
    "            self.transform_instance = self.transform_class(task_name=self.task_name, return_metadata=True)\n",
    "        elif isinstance(self.transform_class, LostInTranslation):\n",
    "            print(f\"initializing {self.transform_class.__name__} with device=0\")\n",
    "            self.transform_instance = self.transform_class(device=0)\n",
    "        else:\n",
    "            print(f\"initializing {self.transform_class.__name__}\")\n",
    "            self.transform_instance = self.transform_class()\n",
    "        \n",
    "        # setting instance attributes\n",
    "        if hasattr(self.transform_instance, \"max_outputs\"):\n",
    "            print(f\"setting max_outputs={self.num_outputs}\")\n",
    "            self.transform_instance.max_outputs = self.num_outputs\n",
    "        if hasattr(self.transform_instance, \"max_paraphrases\"):\n",
    "            print(f\"setting max_paraphrases={self.num_outputs}\")\n",
    "            self.transform_instance.max_paraphrases = self.num_outputs\n",
    "        if hasattr(self.transform_instance, \"device\"):\n",
    "            if self.transform_instance.device is None or self.transform_instance.device == 'cpu':\n",
    "                print(f\"setting device={self.device}\")\n",
    "                self.transform_instance.device = self.device\n",
    "        \n",
    "        # selecting the transformation function\n",
    "        if hasattr(self.transform_class, \"generate\"):\n",
    "            self.transform_fn = self.transform_instance.generate\n",
    "        if hasattr(self.transform_class, \"augment\"):\n",
    "            self.transform_fn = self.transform_instance.augment\n",
    "        if hasattr(self.transform_class, \"transform_batch\"):\n",
    "            self.transform_fn = self.transform_instance.transform_batch\n",
    "            self.intakes_target = True\n",
    "            self.is_batched = True\n",
    "            \n",
    "    def synced_shuffle(self, list1, list2):\n",
    "        # Shuffle two lists with same order\n",
    "        # Using zip() + * operator + shuffle()\n",
    "        temp = list(zip(list1, list2))\n",
    "        random.shuffle(temp)\n",
    "        res1, res2 = zip(*temp)\n",
    "        # res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "        res1, res2 = list(res1), list(res2)\n",
    "        return res1, res2\n",
    "            \n",
    "    def apply(self, texts, labels=None):\n",
    "        if self.intakes_target:\n",
    "            if self.is_batched:\n",
    "                new_texts, new_labels = self.transform_fn((texts, labels))\n",
    "            else:\n",
    "                new_texts, new_labels = [], []\n",
    "                for t, l in zip(texts, labels):\n",
    "                    new_t, new_l = self.transform_fn(t, l)\n",
    "                    new_texts.append(new_t)\n",
    "                    new_labels.extend([new_l] * len(new_t))\n",
    "        else:\n",
    "            if self.is_batched:\n",
    "                new_texts = self.transform_fn((texts))\n",
    "                new_texts = labels\n",
    "            else:\n",
    "                new_texts, new_labels = [], []\n",
    "                for t, l in zip(texts, labels):\n",
    "                    new_t = self.transform_fn(t)\n",
    "                    if len(new_t) > self.num_outputs:\n",
    "                        new_t = new_t[:self.num_outputs]\n",
    "                    new_texts.extend(new_t)\n",
    "                    new_labels.extend([l] * len(new_t))\n",
    "                    \n",
    "        # post processing since some transformations add/remove more new outputs than expected\n",
    "        if len(new_texts) == 0:\n",
    "            print(\"no new_texts, substituting original texts...\")\n",
    "            new_texts = texts\n",
    "        if len(new_labels) == 0:\n",
    "            print(\"no new_labels, substituting original labels...\")\n",
    "            new_labels = labels\n",
    "        new_texts, new_labels = self.synced_shuffle(new_texts, new_labels)\n",
    "        \n",
    "        expected_len = len(texts) * self.num_outputs\n",
    "        new_texts = new_texts[:expected_len]\n",
    "        new_labels = new_labels[:expected_len]\n",
    "        \n",
    "        return new_texts, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c7635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRGraph:\n",
    "    def __init__(self, amr):\n",
    "        self.graph = penman.decode(amr) if not isinstance(amr, penman.graph.Graph) else amr\n",
    "        self.amr_text = penman.encode(self.graph)\n",
    "\n",
    "    def contains_concept(self, concepts):\n",
    "        \"\"\"\n",
    "        Concepts are nodes / instances in the AMR graph.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(concepts, list): concepts = [concepts]\n",
    "            graph_concepts = [t.target for t in self.graph.instances()]\n",
    "            return any(c for c in graph_concepts if c in concepts)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.graph, self.amr_text)\n",
    "\n",
    "    def contains_role(self, roles):\n",
    "        \"\"\"\n",
    "        Roles are edges in the AMR graph.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(roles, list): roles = [roles]\n",
    "            graph_roles = [e.role for e in self.graph.edges()]\n",
    "            return any(r for r in graph_roles if r in roles)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.graph, self.amr_text)\n",
    "\n",
    "    def contains_attribute(self, attributes):\n",
    "        \"\"\"\n",
    "        Attributes are properties of concept nodes, i.e. relationships to \n",
    "        constant values.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(attributes, list): attributes = [attributes]\n",
    "            graph_attrs = [a.target for a in self.graph.attributes()]\n",
    "            return any(a for a in graph_attrs if a in attributes)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.graph, self.amr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d81c17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes =============================================================\n",
    "\n",
    "def contains_imperative(g): return g.contains_attribute(\"imperative\")\n",
    "def contains_exlamation(g): return g.contains_attribute(\"expressive\")\n",
    "def contains_negation(g):   return g.contains_attribute(\"-\")\n",
    "\n",
    "# concepts ===============================================================\n",
    "\n",
    "def contains_conjunctions(g):         return g.contains_concept([\"and\", \"or\", \"contrast-01\", \"either\", \"neither\"])\n",
    "def contains_interrogative_clause(g): return g.contains_concept(\"truth-value\")\n",
    "def contains_question(g):             return g.contains_concept([\"amr-unknown\", \"amr-choice\"])\n",
    "\n",
    "# roles ==================================================================\n",
    "\n",
    "def contains_coreferences(g): return any(r for r in g.amr_text.split() if r in ['i', 'you', 'he', 'she', 'it', 'we', 'they'])\n",
    "def contains_number(g):       return any(a for a in g.graph.attributes() if a.target.isnumeric())\n",
    "\n",
    "def contains_accompanier(g):  return g.contains_role(':accompanier')\n",
    "def contains_age(g):          return g.contains_role(':age')\n",
    "def contains_beneficiary(g):  return g.contains_role(':beneficiary')\n",
    "def contains_concession(g):   return g.contains_role(':concession')\n",
    "def contains_condition(g):    return g.contains_role(':condition')\n",
    "def contains_consist_of(g):   return any(r for r in g.amr_text.split() if r in [':consist-of'])\n",
    "def contains_degree(g):       return g.contains_role(':degree')\n",
    "def contains_destination(g):  return g.contains_role(':destination')\n",
    "def contains_direction(g):    return g.contains_role(':direction')\n",
    "def contains_domain(g):       return g.contains_role(':domain')\n",
    "def contains_duration(g):     return g.contains_role(':duration')\n",
    "def contains_example(g):      return g.contains_role(':example')\n",
    "def contains_extent(g):       return g.contains_role(':extent')\n",
    "def contains_frequency(g):    return g.contains_role(':frequency')\n",
    "def contains_instrument(g):   return g.contains_role(':instrument')\n",
    "# def contains_li(g):           return g.contains_role(':li')\n",
    "def contains_location(g):     return g.contains_role(':location')\n",
    "def contains_manner(g):       return g.contains_role(':manner')\n",
    "def contains_medium(g):       return g.contains_role(':medium')\n",
    "def contains_mod(g):          return g.contains_role(':mod')\n",
    "def contains_mode(g):         return any(a for a in g.graph.attributes() if \":mode\" in a.role)\n",
    "def contains_name(g):         return g.contains_role(':name')\n",
    "def contains_ord(g):          return g.contains_role(':ord')\n",
    "def contains_part(g):         return g.contains_role(':part')\n",
    "def contains_path(g):         return g.contains_role(':path')\n",
    "def contains_polarity(g):     return g.contains_role(':polarity')\n",
    "def contains_polite(g):       return any(r for r in g.amr_text.split() if r in [':polite'])\n",
    "def contains_poss(g):         return g.contains_role(':poss')\n",
    "def contains_purpose(g):      return g.contains_role(':purpose')\n",
    "def contains_quant(g):        return g.contains_role(':quant')\n",
    "def contains_range(g):        return g.contains_role(':range')\n",
    "def contains_scale(g):        return g.contains_role(':scale')\n",
    "def contains_source(g):       return g.contains_role(':source')\n",
    "def contains_subevent(g):     return g.contains_role(':subevent')\n",
    "def contains_time(g):         return g.contains_role(':time')\n",
    "def contains_topic(g):        return g.contains_role(':topic')\n",
    "def contains_unit(g):         return g.contains_role(':unit')\n",
    "# def contains_value(g):        return g.contains_role(':value')\n",
    "def contains_wiki(g):         return g.contains_role(':wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "363516ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRFeatureExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.featurizers = featurizers = [    \n",
    "            contains_accompanier,\n",
    "            contains_age,\n",
    "            contains_beneficiary,\n",
    "            contains_concession,\n",
    "            contains_condition,\n",
    "            contains_conjunctions,\n",
    "            contains_consist_of,\n",
    "            contains_coreferences,\n",
    "            contains_degree,\n",
    "            contains_destination,\n",
    "            contains_direction,\n",
    "            contains_domain,\n",
    "            contains_duration,\n",
    "            contains_example,\n",
    "            contains_exlamation,\n",
    "            contains_extent,\n",
    "            contains_frequency,\n",
    "            contains_imperative,\n",
    "            contains_instrument,\n",
    "            contains_interrogative_clause,\n",
    "            contains_location,\n",
    "            contains_manner,\n",
    "            contains_medium,\n",
    "            contains_mod,\n",
    "            contains_mode,\n",
    "            contains_name,\n",
    "            contains_negation,\n",
    "            contains_number,\n",
    "            contains_ord,\n",
    "            contains_part,\n",
    "            contains_path,\n",
    "            contains_polarity,\n",
    "            contains_polite,\n",
    "            contains_poss,\n",
    "            contains_purpose,\n",
    "            contains_quant,\n",
    "            contains_question,\n",
    "            contains_range,\n",
    "            contains_scale,\n",
    "            contains_source,\n",
    "            contains_subevent,\n",
    "            contains_time,\n",
    "            contains_topic,\n",
    "            contains_unit\n",
    "        ]\n",
    "        self.featurizers = sorted(featurizers, key=lambda f: f.__name__)\n",
    "        self.amr_model   = None\n",
    "        \n",
    "    def load_amr_model(self, max_sent_len=128):\n",
    "        self.amr_model = amrlib.load_stog_model(max_sent_len=max_sent_len)\n",
    "        \n",
    "    def text_to_amr(self, texts):\n",
    "        if self.amr_model is None:\n",
    "            self.load_amr_model()\n",
    "        amr_penmans = self.amr_model.parse_sents(texts, add_metadata=False, disable_progress=True)\n",
    "        amr_graphs = []\n",
    "        for p in amr_penmans:\n",
    "            try:\n",
    "                amr_graphs.append(AMRGraph(p))\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "                print(p)\n",
    "                amr_graphs.append(AMRGraph(p))\n",
    "        return amr_graphs\n",
    "    \n",
    "    def generate_feature_matrix(self, graphs):\n",
    "        feature_matrix = []\n",
    "        for g in graphs:\n",
    "            feature_vector = []\n",
    "            for f in self.featurizers:\n",
    "                feature_vector.append(f(g))\n",
    "            feature_matrix.append(feature_vector)\n",
    "        feature_matrix = np.array(feature_matrix, dtype=np.int32)\n",
    "        return feature_matrix\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        graphs = self.text_to_amr(texts)\n",
    "        return self.generate_feature_matrix(graphs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85172943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmenter:\n",
    "    def __init__(self, \n",
    "                 dataset,\n",
    "                 transforms,\n",
    "                 transform_probabilities = None, \n",
    "                 num_augmentations_per_record = 5,\n",
    "                 num_transforms_to_apply = 2,\n",
    "                 batch_size = 10,\n",
    "                 allow_resampling = False,\n",
    "                 keep_originals = False,\n",
    "                 feature_extractor = None,\n",
    "                 perf_extractor = None):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        self.transform_probabilities = transform_probabilities\n",
    "        self.num_augmentations_per_record = num_augmentations_per_record\n",
    "        self.num_transforms_to_apply = num_transforms_to_apply\n",
    "        self.batch_size = batch_size\n",
    "        self.allow_resampling = allow_resampling\n",
    "        self.keep_originals = keep_originals\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.perf_extractor = perf_extractor\n",
    "        \n",
    "        # initializations\n",
    "        self.dataset = dataset.remove_columns(\"idx\")\n",
    "        self.add_idx_to_dataset()\n",
    "        self.num_transforms_available = len(self.transforms)\n",
    "        \n",
    "        if self.transform_probabilities is None:\n",
    "            # set to uniform\n",
    "            num_examples = len(self.dataset)\n",
    "            num_transforms = len(self.transforms)\n",
    "            uniform_policy = np.full((num_examples, num_transforms), fill_value=1/num_transforms)\n",
    "            self.transform_probabilities = uniform_policy\n",
    "        \n",
    "    def add_idx_to_dataset(self):\n",
    "        if 'idx' not in self.dataset.features:\n",
    "            self.dataset = self.dataset.add_column(\"idx\", range(len(self.dataset)))\n",
    "        \n",
    "    def apply_to_batch(self, batch):\n",
    "        new_texts, new_labels, transforms_applied, is_changed = [], [], [], []\n",
    "        for idx, text, label in zip(batch['idx'], batch['text'], batch['label']):\n",
    "            actual_batch_size = len(batch['idx'])\n",
    "            original_text, original_label = text, label\n",
    "            for _ in range(self.num_augmentations_per_record):\n",
    "                sampled_transforms = sample_transforms(self.transforms, \n",
    "                                                       p=self.transform_probabilities[idx], \n",
    "                                                       n=self.num_transforms_to_apply, \n",
    "                                                       replace=self.allow_resampling)\n",
    "                transforms_applied.append(transforms_to_ids(sampled_transforms, self.transforms))\n",
    "                for t in sampled_transforms:\n",
    "                    try:\n",
    "                        text, label = t.apply([text], [label])\n",
    "                        text, label = text[0], label[0]\n",
    "                    except Exception as e: \n",
    "                        print(e)\n",
    "                        print(f\"[Augmenter]: skipping augmentation from {t.transform_class.__name__} on text:'{text}' and label: {label}\")\n",
    "\n",
    "                # avoid adding records with empty text\n",
    "                if text:\n",
    "                    new_texts.append(text)\n",
    "                    new_labels.append(label)\n",
    "                    is_changed.append(int(original_text != text))\n",
    "\n",
    "        if self.keep_originals:\n",
    "            new_texts = batch['text'] + new_texts\n",
    "            new_labels = batch['label'] + new_labels\n",
    "            realized_batch_size = len(new_labels)\n",
    "            transforms_applied = transforms_applied + np.zeros((actual_batch_size, len(self.transforms)), dtype=np.int32).tolist()\n",
    "            is_changed = is_changed + [0] * actual_batch_size\n",
    "            out = {\n",
    "                \"text\": new_texts, \n",
    "                \"label\": new_labels,\n",
    "                \"idx\": list(range(realized_batch_size)),\n",
    "                \"transforms_applied\": [t for t in transforms_applied],\n",
    "                \"is_changed\": is_changed\n",
    "            }\n",
    "        else:\n",
    "            out = {\n",
    "                \"text\": new_texts, \n",
    "                \"label\": new_labels, \n",
    "                \"idx\": list(range(len(new_labels))),\n",
    "                \"transforms_applied\": transforms_applied,\n",
    "                \"is_changed\": is_changed\n",
    "            }\n",
    "\n",
    "        return out\n",
    "            \n",
    "                                                   \n",
    "    def augment(self):\n",
    "        dataset = self.dataset.map(self.apply_to_batch, batched=True, batch_size=self.batch_size)\n",
    "        dataset = dataset.remove_columns(\"idx\")\n",
    "    \n",
    "        # feature extraction\n",
    "        if self.feature_extractor is not None:\n",
    "            features = self.feature_extractor(dataset[\"text\"])\n",
    "            dataset = dataset.add_column(\"features\", [f for f in features])\n",
    "                \n",
    "        # performance scoring    \n",
    "        if self.perf_extractor is not None:\n",
    "            performances = self.perf_extractor(dataset[\"text\"], dataset[\"label\"])\n",
    "            dataset = dataset.add_column(\"performance\", [p for p in performances])\n",
    "                \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76aa080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood:\n",
    "    def __init__(self):\n",
    "        self.scorer = torch.nn.NLLLoss(reduction=\"none\")\n",
    "    \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        return -self.scorer(probs, targets).numpy()\n",
    "    \n",
    "class InverseLikelihood:\n",
    "    def __init__(self):\n",
    "        self.scorer = torch.nn.NLLLoss(reduction=\"none\")\n",
    "    \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        return 1+self.scorer(probs, targets).numpy()\n",
    "    \n",
    "class CleanLabSafe:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        probs = probs.numpy()\n",
    "        targets = targets.numpy()\n",
    "        scores = ~find_label_issues(\n",
    "            labels=targets,\n",
    "            pred_probs=probs,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        return scores.astype(np.int32).tolist()\n",
    "    \n",
    "class LikelihoodShift:\n",
    "    def __init__(self, original_dataset, direction=\"positive\"):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.direction = direction\n",
    "        self.scorer = torch.nn.NLLLoss(reduction=\"none\")\n",
    "        \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        new_scores  = -self.scorer(probs, targets).numpy()\n",
    "        \n",
    "        old_probs   = torch.tensor(self.original_dataset.select(indices)[\"preds\"])\n",
    "        old_targets = torch.tensor(self.original_dataset.select(indices)['label'])\n",
    "        old_scores  = -self.scorer(old_probs, old_targets).numpy()\n",
    "            \n",
    "        if self.direction in \"positive\":\n",
    "            scores = (new_scores - old_scores).clip(0, 1)\n",
    "        elif self.direction in \"negative\":\n",
    "            scores = (old_scores - new_scores).clip(0, 1)\n",
    "        else:\n",
    "            scores = new_scores\n",
    "        return scores\n",
    "        \n",
    "class PerformanceExtractor:\n",
    "    def __init__(self, dataset_name, scorer, model_id=None):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.scorer = scorer\n",
    "        self.model_id = model_id\n",
    "        self.api = HfApi()\n",
    "        self.pipe = None\n",
    "        self.device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "        if self.model_id and not self.pipe:\n",
    "            self.create_pipe(self.model_id)\n",
    "\n",
    "        if not self.pipe:\n",
    "            self.find_model_for_dataset()\n",
    "\n",
    "    def create_pipe(self, model_id):\n",
    "        self.pipe = pipeline(\"text-classification\", \n",
    "                            model=model_id, \n",
    "                            device=self.device, \n",
    "                            padding=True, \n",
    "                            truncation=True,\n",
    "                            top_k=None)\n",
    "        return self.pipe\n",
    "\n",
    "    def find_model_for_dataset(self):\n",
    "        model_filter = ModelFilter(\n",
    "            task=\"text-classification\",\n",
    "            library=\"pytorch\",\n",
    "            # model_name=dataset_name,\n",
    "            trained_dataset=self.dataset_name)\n",
    "        model_id = next(iter(self.api.list_models(filter=model_filter)))\n",
    "        if model_id:\n",
    "            model_id = getattr(model_id, 'modelId')\n",
    "            print('Using ' + model_id + ' to support evaluation.')\n",
    "            self.create_pipe(model_id)\n",
    "\n",
    "    def extract_prediction_probabilities(self, inputs):\n",
    "        output = self.pipe(inputs)\n",
    "        return torch.stack([vectorize(o) for o in output])\n",
    "    \n",
    "    def extract_prediction_classes(self, inputs):\n",
    "        return torch.argmax(self.extract_prediction_probabilities(inputs), axis=1)\n",
    "\n",
    "    def __call__(self, inputs, targets, indices=None):\n",
    "        probs   = self.extract_prediction_probabilities(inputs)\n",
    "        targets = torch.tensor(targets)\n",
    "        return self.scorer(probs, targets, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c6532",
   "metadata": {},
   "source": [
    "## FADA v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7de8febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = (\"glue\", \"sst2\")\n",
    "task_name = \"sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c3f69f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-21 20:25:32,974 | datasets.builder | WARNING | Found cached dataset glue (C:/Users/Fabrice/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(*dataset_config, split=\"train\")\n",
    "dataset = dataset.rename_column(\"sentence\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "484683e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing Abbreviate\n",
      "setting max_outputs=1\n",
      "initializing AbbreviationInsertionEN\n",
      "setting max_outputs=1\n",
      "initializing AmericanizeBritishizeEnglish\n",
      "setting max_outputs=1\n",
      "initializing AntonymsSubstitute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting max_outputs=1\n",
      "initializing AzertyQwertyCharsSwap\n",
      "setting max_outputs=1\n",
      "initializing ButterFingersPerturbation\n",
      "setting max_outputs=1\n",
      "initializing ChangeCharCase\n",
      "setting max_outputs=1\n",
      "initializing ChangeDateFormat\n",
      "setting max_outputs=1\n",
      "initializing CityNamesTransformation\n",
      "setting max_outputs=1\n",
      "initializing ColorTransformation\n",
      "setting max_outputs=1\n",
      "initializing ConcatMonolingual\n",
      "setting max_outputs=1\n",
      "initializing ContractionExpansions\n",
      "setting max_outputs=1\n",
      "initializing CorrectCommonMisspellings\n",
      "setting max_outputs=1\n",
      "initializing CountryStateAbbreviation\n",
      "setting max_outputs=1\n",
      "initializing DiacriticRemoval\n",
      "setting max_outputs=1\n",
      "initializing DiscourseMarkerSubstitution\n",
      "setting max_outputs=1\n",
      "initializing DyslexiaWordsSwap\n",
      "setting max_outputs=1\n",
      "initializing EnglishInflectionalVariation\n",
      "setting max_outputs=1\n",
      "initializing FillerWordAugmentation\n",
      "setting max_outputs=1\n",
      "initializing GenderSwap\n",
      "Loading Operation GenderSwap\n",
      "setting max_outputs=1\n",
      "initializing GreetingsAndFarewells\n",
      "setting max_outputs=1\n",
      "initializing HashtagGeneration\n",
      "setting max_outputs=1\n",
      "initializing LeetLetters\n",
      "setting max_outputs=1\n",
      "initializing MultilingualDictionaryBasedCodeSwitch\n",
      "setting max_outputs=1\n",
      "initializing PigLatin\n",
      "setting max_outputs=1\n",
      "initializing RandomDeletion\n",
      "setting max_outputs=1\n",
      "initializing RandomUpperPerturbation\n",
      "setting max_outputs=1\n",
      "initializing ReplaceNumericalValues\n",
      "setting max_outputs=1\n",
      "initializing SentenceAdjectivesAntonymsSwitch\n",
      "setting max_outputs=1\n",
      "initializing SentenceAuxiliaryNegationRemoval\n",
      "setting max_outputs=1\n",
      "initializing SentenceSubjectObjectSwitch\n",
      "setting max_outputs=1\n",
      "initializing SimpleCiphers\n",
      "setting max_outputs=1\n",
      "initializing Slangificator\n",
      "setting max_outputs=1\n",
      "initializing SpeechDisfluencyPerturbation\n",
      "setting max_outputs=1\n",
      "initializing SpellingTransformation\n",
      "setting max_outputs=1\n",
      "initializing SynonymInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting max_outputs=1\n",
      "initializing SynonymSubstitution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting max_outputs=1\n",
      "initializing TokenReplacement\n",
      "setting max_outputs=1\n",
      "initializing TransformerFill\n",
      "setting max_outputs=1\n",
      "initializing UnitConverter\n",
      "setting max_outputs=1\n",
      "initializing UseAcronyms\n",
      "setting max_outputs=1\n",
      "initializing VisualAttackLetters\n",
      "setting max_outputs=1\n",
      "initializing WeekdayMonthAbbreviation\n",
      "setting max_outputs=1\n",
      "initializing WhitespacePerturbation\n",
      "setting max_outputs=1\n",
      "initializing YesNoQuestionPerturbation\n",
      "setting max_outputs=1\n",
      "initializing YodaPerturbation\n",
      "setting max_outputs=1\n"
     ]
    }
   ],
   "source": [
    "nlaug_transforms = [\n",
    "    # EmojifyTransformation, # UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 220: character maps to <undefined>\n",
    "    SynonymInsertion,\n",
    "    # BackTranslation, # runtime too long (does not attempt to use gpu) (50.15s/ba w gpu)\n",
    "    # NounCompoundParaphraser, # does not return anything\n",
    "    DiacriticRemoval,\n",
    "    AzertyQwertyCharsSwap,\n",
    "    HashtagGeneration,\n",
    "    SpellingTransformation,\n",
    "    TokenReplacement,\n",
    "    SentenceAuxiliaryNegationRemoval,\n",
    "    UseAcronyms,\n",
    "    YodaPerturbation,\n",
    "    # FactiveVerbTransformation, # cannot find gender.male.names\n",
    "    # ProtaugmentDiverseParaphrase, # somewhat long runtime (29.63s/ba)\n",
    "    # ReplaceFinancialAmount,\n",
    "    AmericanizeBritishizeEnglish,\n",
    "    # PunctuationWithRules,  # runtime too long (does not appear to be gpu compatible)\n",
    "    # UrbanThesaurusSwap, # runtime too long (195.74s/ba)\n",
    "    FillerWordAugmentation,\n",
    "    SynonymSubstitution,\n",
    "    # StyleTransferParaphraser, # runtime too long (192.32s/ba)\n",
    "    RandomUpperPerturbation,\n",
    "    WeekdayMonthAbbreviation,\n",
    "    CityNamesTransformation,\n",
    "    # SentenceAdditions, # runtime too long (does not attempt to use gpu) # RuntimeError: CUDA out of memory. even at batch_size=1\n",
    "    ChangeDateFormat,\n",
    "    # TenseTransformation, # index out of range errors / NoneType errors if not using to_tense='past'\n",
    "    DyslexiaWordsSwap,\n",
    "    # GenderCultureDiverseName, # does not return anything\n",
    "    # GenderNeutralRewrite, # index out of range errors\n",
    "    # LostInTranslation, # IndexError: index out of range in self\n",
    "    AbbreviationInsertionEN,\n",
    "    RandomDeletion,\n",
    "    TransformerFill, # (3.20s/ba)\n",
    "    ConcatMonolingual,\n",
    "    CountryStateAbbreviation,\n",
    "    ButterFingersPerturbation,\n",
    "    # ReplaceAbbreviations, # (4.52s/ba)\n",
    "    Slangificator,\n",
    "    YesNoQuestionPerturbation,\n",
    "    GenderSwap,\n",
    "    # CloseHomophonesSwap, # runs slow, no gpu (221.04s/ba)\n",
    "    SimpleCiphers,\n",
    "    # ChangePersonNamedEntities, # does not return anything\n",
    "    GreetingsAndFarewells,\n",
    "    DiscourseMarkerSubstitution,\n",
    "    # Summarization,\n",
    "    VisualAttackLetters,\n",
    "    # SentenceReordering, # somwhat slow (41.14s/ba)\n",
    "    ChangeCharCase,\n",
    "    AntonymsSubstitute,\n",
    "    # MixTransliteration, # IndexError: list index out of range\n",
    "    # DifferentAbilityTransformation, UnboundLocalError: local variable 'text' referenced before assignment\n",
    "    Abbreviate,\n",
    "    # ReplaceHypernyms, # RuntimeError: CUDA out of memory. even at batch_size=1\n",
    "    # ReplaceHyponyms, # RuntimeError: CUDA out of memory. even at batch_size=1\n",
    "    # PhonemeSubstitution, # IndexError: list index out of range\n",
    "    # MultilingualLexiconPerturbation, FileNotFoundError: [Errno 2] No such file or directory: '/multilingual_lexicon_uncased.xz'\n",
    "    # MultilingualBackTranslation, # runtime too long (does not attempt to use gpu) (98.04s/ba w gpu)\n",
    "    UnitConverter,\n",
    "    SentenceAdjectivesAntonymsSwitch,\n",
    "    CorrectCommonMisspellings,\n",
    "    # NeuralParaphaserPerturbation, # somewhat slow (4.03s/ba)\n",
    "    SentenceSubjectObjectSwitch,\n",
    "    # NumericToWord, # InvalidOperation: [<class 'decimal.ConversionSyntax'>]\n",
    "    MultilingualDictionaryBasedCodeSwitch,\n",
    "    # DiverseParaphrase, # runtime too long (does not attempt to use gpu)\n",
    "    EnglishInflectionalVariation,\n",
    "    ReplaceNumericalValues,\n",
    "    SpeechDisfluencyPerturbation,\n",
    "    WhitespacePerturbation,\n",
    "    ContractionExpansions,\n",
    "    ColorTransformation,\n",
    "    # ContextualMeaningPerturbation, # runtime too long (not gpu compatible)\n",
    "    PigLatin,\n",
    "    LeetLetters,\n",
    "    # HashtagifyTransformation, # error: nothing to repeat at position 0\n",
    "    # CheckSrl, # RuntimeError: The size of tensor a (1127) must match the size of tensor b (512) at non-singleton dimension 1\n",
    "    # GeoNamesTransformation, # does not return anything\n",
    "]\n",
    "transforms = [t for t in nlaug_transforms]\n",
    "transforms = sorted(transforms, key=lambda t: t.__name__)\n",
    "transforms = [Transform(t, task_name=task_name) for t in transforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c953bbdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c77b2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviate\n",
      "Some sample txt to transform as a test 0 runtime: 0.009000301361083984\n",
      "AbbreviationInsertionEN\n",
      "Some sample text 2 transform as a test 0 runtime: 0.0\n",
      "AmericanizeBritishizeEnglish\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "AntonymsSubstitute\n",
      "Some sample text to transform as a test 0 runtime: 0.006001472473144531\n",
      "AzertyQwertyCharsSwap\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "ButterFingersPerturbation\n",
      "Somf sample text to transform as a test 0 runtime: 0.0\n",
      "ChangeCharCase\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "ChangeDateFormat\n",
      "Some sample text to transform as a test 0 runtime: 0.005998849868774414\n",
      "CityNamesTransformation\n",
      "Some sample text to transform as a test 0 runtime: 0.005040645599365234\n",
      "ColorTransformation\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "ConcatMonolingual\n",
      "Some sample text to transform as a test  0 runtime: 0.0\n",
      "ContractionExpansions\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "CorrectCommonMisspellings\n",
      "Some sample text to transform as a test 0 runtime: 0.004999876022338867\n",
      "CountryStateAbbreviation\n",
      "Some sample text to transform as a test 0 runtime: 0.005983114242553711\n",
      "DiacriticRemoval\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "DiscourseMarkerSubstitution\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "DyslexiaWordsSwap\n",
      "sum sample text too transform as a test 0 runtime: 0.005972862243652344\n",
      "EnglishInflectionalVariation\n",
      "Some sample texts to transforms as a tests 0 runtime: 0.0\n",
      "FillerWordAugmentation\n",
      "Some sample text obviously to transform as a test 0 runtime: 0.0\n",
      "GenderSwap\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "GreetingsAndFarewells\n",
      "Some sample text to transform as a test 0 runtime: 0.0010912418365478516\n",
      "HashtagGeneration\n",
      "Some sample text to transform as a test#SomeSampleText #Text 0 runtime: 0.005953073501586914\n",
      "LeetLetters\n",
      "So33 sa3pl3 t3xt to transf0r3 as a t3st 0 runtime: 0.0\n",
      "MultilingualDictionaryBasedCodeSwitch\n",
      "Some عينة text to रूपांतरण as a test 0 runtime: 0.0\n",
      "PigLatin\n",
      "omesay amplesay exttay otay ansformtray asay aay esttay 0 runtime: 0.0\n",
      "RandomDeletion\n",
      "Some sample text to transform as a 0 runtime: 0.0010063648223876953\n",
      "RandomUpperPerturbation\n",
      "Some sample text to transforM as a test 0 runtime: 0.0\n",
      "ReplaceNumericalValues\n",
      "Some sample text to transform as a test 0 runtime: 0.0049495697021484375\n",
      "SentenceAdjectivesAntonymsSwitch\n",
      "Some sample text to transform as a test 0 runtime: 0.00504755973815918\n",
      "SentenceAuxiliaryNegationRemoval\n",
      "Some sample text to transform as a test 0 runtime: 0.004997730255126953\n",
      "SentenceSubjectObjectSwitch\n",
      "Some sample text to transform as a test 0 runtime: 0.004999399185180664\n",
      "SimpleCiphers\n",
      "SSoommee  ssaammppllee  tteexxtt  ttoo  ttrraannssffoorrmm  aass  aa  tteesstt 0 runtime: 0.0\n",
      "Slangificator\n",
      "Some sample text to transform as a test 0 runtime: 0.005049943923950195\n",
      "SpeechDisfluencyPerturbation\n",
      "Some sample text to transform uh as a test 0 runtime: 0.0\n",
      "SpellingTransformation\n",
      "Some sample text to transform as a test 0 runtime: 0.012038230895996094\n",
      "SynonymInsertion\n",
      "Some sample text to transform translate as a test 0 runtime: 0.005533695220947266\n",
      "SynonymSubstitution\n",
      "Some sample distribution text to transform as a test 0 runtime: 0.005013227462768555\n",
      "TokenReplacement\n",
      "Some sample text to transform as a tekt 0 runtime: 0.0049550533294677734\n",
      "TransformerFill\n",
      "Some sample text to transform as regression test 0 runtime: 0.029995441436767578\n",
      "UnitConverter\n",
      "Some sample text to transform as a test 0 runtime: 0.007999897003173828\n",
      "UseAcronyms\n",
      "Some sample text to transform as a test 0 runtime: 0.002999544143676758\n",
      "VisualAttackLetters\n",
      "Soⴇe ṩaḿpⱡḙ text ṭo trḁἠsfoɼⅿ ⍺ṥ a teʂt 0 runtime: 0.0\n",
      "WeekdayMonthAbbreviation\n",
      "Some sample text to transform as a test 0 runtime: 0.0\n",
      "WhitespacePerturbation\n",
      "Some sample text to transform as a t est 0 runtime: 0.0\n",
      "YesNoQuestionPerturbation\n",
      "Some sample text to transform as a test 0 runtime: 0.008001327514648438\n",
      "YodaPerturbation\n",
      "To transform as a test, some sample text 0 runtime: 0.0069997310638427734\n"
     ]
    }
   ],
   "source": [
    "# test to see what works and what doesn't\n",
    "text, label = (\"Some sample text to transform as a test\", 0)\n",
    "\n",
    "for t in transforms:\n",
    "    print(t.transform_class.__name__)\n",
    "    start_time = time.time()\n",
    "    new_text, new_label = t.apply([text], [label])\n",
    "    new_text, new_label = new_text[0], new_label[0]\n",
    "    print(new_text, new_label, f\"runtime: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c2e0160",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorers = [\n",
    "    (CleanLabSafe(), \"CleanLabSafe\"),\n",
    "    (LikelihoodShift(dataset, direction=\"positive\"), \"LikelihoodShiftPos\"),\n",
    "    (LikelihoodShift(dataset, direction=\"negative\"), \"LikelihoodShiftNeg\"),\n",
    "    (Likelihood(), \"Likelihood\"),\n",
    "    (InverseLikelihood(), \"InverseLikelihood\"),\n",
    "]\n",
    "\n",
    "aggregations = [\"sum\", \"avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28b4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 09:16:13,075 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-e456697cf2686baa.arrow\n",
      "2023-02-23 09:16:53,236 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-da90f534a23d4c9d.arrow\n",
      "2023-02-23 09:17:39,676 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-21e150949efee464.arrow\n",
      "2023-02-23 09:18:21,010 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4f6fa985b732d46f.arrow\n",
      "2023-02-23 09:19:05,754 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-bf9cc545635518f7.arrow\n",
      "2023-02-23 09:19:53,069 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d432f8db6a174c1c.arrow\n",
      "2023-02-23 09:20:36,527 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-14aa451ca69cfb85.arrow\n",
      "2023-02-23 09:21:22,191 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-983631890063e42f.arrow\n",
      "2023-02-23 09:22:05,085 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-b2d650af313b32b7.arrow\n",
      "2023-02-23 09:22:46,543 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-28fafd04559b5975.arrow\n",
      "2023-02-23 09:23:31,366 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-391cf0463d4a5d51.arrow\n",
      "2023-02-23 09:24:19,206 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-72b8ff39a32c9b6f.arrow\n",
      "2023-02-23 09:25:03,733 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-b5d97ef760ef1471.arrow\n",
      "2023-02-23 09:25:47,873 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ac7c8803e01bbf50.arrow\n",
      "2023-02-23 09:26:30,405 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-dfe1b30791725f0a.arrow\n",
      "2023-02-23 09:27:13,449 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-08135d586a1689ad.arrow\n",
      "2023-02-23 09:27:56,789 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-df26f51766faf989.arrow\n",
      "2023-02-23 09:28:45,185 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-9145de05b3ab1b2c.arrow\n",
      "2023-02-23 09:29:27,892 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-c5adf6816b10e53a.arrow\n",
      "2023-02-23 09:30:10,529 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-b5816b74a985ab61.arrow\n",
      "2023-02-23 09:30:57,167 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2a69acc70bf9c0ef.arrow\n",
      "2023-02-23 09:31:40,420 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-105ada6b720299e3.arrow\n",
      "2023-02-23 09:32:23,872 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-b3969057425cb200.arrow\n",
      "2023-02-23 09:33:04,959 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-7244f536285e25b4.arrow\n",
      "2023-02-23 09:33:47,718 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-e28bc9ff870f084c.arrow\n",
      "2023-02-23 09:34:29,907 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-e8754cd37cbd7025.arrow\n",
      "2023-02-23 09:35:13,463 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-9a9e43108fb83bab.arrow\n",
      "2023-02-23 09:35:55,890 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-0004884cc167733f.arrow\n",
      "2023-02-23 09:36:37,767 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-09f6048fe245a460.arrow\n",
      "2023-02-23 09:37:19,065 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-53710f577e9cf84f.arrow\n",
      "2023-02-23 09:38:01,725 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d675ebf74fe30c9a.arrow\n",
      "2023-02-23 09:38:42,215 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-0cc36d8c77863fe5.arrow\n",
      "2023-02-23 09:39:24,818 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d29dc5dfcf1da110.arrow\n",
      "2023-02-23 09:40:14,244 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-f963a7efe00111e5.arrow\n",
      "2023-02-23 09:40:56,499 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-6a46721acffa6cdd.arrow\n",
      "2023-02-23 09:41:39,411 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-8c6e90373020da5c.arrow\n",
      "2023-02-23 09:42:21,630 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-f689a4a5ffda0336.arrow\n",
      "2023-02-23 09:43:02,815 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-fa83ada4a2121ac5.arrow\n",
      "2023-02-23 09:43:44,565 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d663049d155e18b1.arrow\n",
      "2023-02-23 09:44:26,635 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2169df82b9bdee2d.arrow\n",
      "2023-02-23 09:45:07,110 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-03c54c71fca05536.arrow\n",
      "2023-02-23 09:45:49,320 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-f3158c0c66dd7794.arrow\n",
      "2023-02-23 09:46:30,734 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-6ae04d52adb328cb.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 09:47:12,524 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-00de59f550f0fc2b.arrow\n",
      "2023-02-23 09:47:54,320 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-03a8987936a98d74.arrow\n",
      "2023-02-23 09:48:36,272 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-c1378be5b7a28e0a.arrow\n",
      "2023-02-23 09:49:20,063 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-faf1501b009a815b.arrow\n",
      "2023-02-23 09:50:01,788 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-acfebb4bd29e8693.arrow\n",
      "2023-02-23 09:50:43,739 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-9cb017c18741ae91.arrow\n",
      "2023-02-23 09:51:26,250 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-30c1fb6a19086515.arrow\n",
      "2023-02-23 09:52:09,114 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-9bbd750d1e707c52.arrow\n",
      "2023-02-23 09:52:52,503 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-32d1f81ba636425c.arrow\n",
      "2023-02-23 09:53:35,559 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4d6b234fdfa7c6ed.arrow\n",
      "2023-02-23 09:54:18,634 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-b044284a47acf2f6.arrow\n",
      "2023-02-23 09:55:00,557 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2ea60b99fa7ff8bf.arrow\n",
      "2023-02-23 09:55:42,420 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-79c147c719a5711b.arrow\n",
      "2023-02-23 09:56:23,633 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ec3aa314da9bb017.arrow\n",
      "2023-02-23 09:57:05,354 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-a0acf4c9658de17e.arrow\n",
      "2023-02-23 09:57:47,942 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-0597aab614d30dbc.arrow\n",
      "2023-02-23 09:58:29,543 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-e9f41cc04653a560.arrow\n",
      "2023-02-23 09:59:12,175 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ccc14d5173f660d8.arrow\n",
      "2023-02-23 09:59:54,651 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1da3b7e2cad6e514.arrow\n",
      "2023-02-23 10:00:36,801 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-41a93f90dc821527.arrow\n",
      "2023-02-23 10:01:19,596 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-a7502a812227d96d.arrow\n",
      "2023-02-23 10:02:02,729 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d138d1508557716a.arrow\n",
      "2023-02-23 10:02:44,412 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-a51ad4f3a699bae0.arrow\n",
      "2023-02-23 10:03:25,914 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1d77ce4058d87776.arrow\n",
      "2023-02-23 10:04:07,654 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-27896389df3277fd.arrow\n",
      "2023-02-23 10:04:50,563 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d9ead9264745dd9e.arrow\n",
      "2023-02-23 10:05:32,212 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-0ad4041504c14982.arrow\n",
      "2023-02-23 10:06:12,694 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-34ab18fd0a68e88e.arrow\n",
      "2023-02-23 10:06:55,915 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4279b14dae55cdff.arrow\n",
      "2023-02-23 10:07:42,081 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-50910bdc8ef066d4.arrow\n",
      "2023-02-23 10:08:27,199 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-5decc06af24dfdd8.arrow\n",
      "2023-02-23 10:09:12,204 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-914591aef03d866a.arrow\n",
      "2023-02-23 10:09:56,452 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d974c146e8ec01b3.arrow\n",
      "2023-02-23 10:10:39,303 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d8ab0b300ac0cf0d.arrow\n",
      "2023-02-23 10:11:22,047 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-f61164cebfc74ca9.arrow\n",
      "2023-02-23 10:12:03,400 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-9b8b71a1b38a05fb.arrow\n",
      "2023-02-23 10:12:44,542 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-7e969cf3a7c5cb87.arrow\n",
      "2023-02-23 10:13:27,195 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-a4e695c9b65d1226.arrow\n",
      "2023-02-23 10:14:08,555 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-756b0715e7180322.arrow\n",
      "2023-02-23 10:14:51,447 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-6f790959a3e04b3b.arrow\n",
      "2023-02-23 10:15:34,357 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-df14c6125f58d5b5.arrow\n",
      "2023-02-23 10:16:15,012 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2da44da189b5b368.arrow\n",
      "2023-02-23 10:16:57,153 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-6025f0ae35354579.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 10:17:39,578 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4a814d53964ddb77.arrow\n",
      "2023-02-23 10:18:21,481 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2371ea2c0247145f.arrow\n",
      "2023-02-23 10:19:05,138 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4578bab326a97465.arrow\n",
      "2023-02-23 10:19:48,648 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-56672017555a4085.arrow\n",
      "2023-02-23 10:20:29,325 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-5e00ea6dca24be4d.arrow\n",
      "2023-02-23 10:21:11,520 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-17fd3736b7ef941c.arrow\n",
      "2023-02-23 10:21:53,021 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-c787ddfb5697f17c.arrow\n",
      "2023-02-23 10:22:35,445 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-09215f4f9edb95f2.arrow\n",
      "2023-02-23 10:23:20,725 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4505f4f60a8c46c7.arrow\n",
      "2023-02-23 10:24:12,315 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2640211e29f2c3c7.arrow\n",
      "2023-02-23 10:24:57,976 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-955d0e77fb5eb866.arrow\n",
      "2023-02-23 10:25:42,411 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-5c6460364a1eb1b7.arrow\n",
      "2023-02-23 10:26:24,026 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-fd42f69765111656.arrow\n",
      "2023-02-23 10:27:05,364 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2130260c8c69778f.arrow\n",
      "2023-02-23 10:27:46,635 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1d69d9fc4b1cb8bd.arrow\n",
      "2023-02-23 10:28:27,807 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-bb0378eb7a62722e.arrow\n",
      "2023-02-23 10:29:09,156 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ef0a81ed3d5d60bc.arrow\n",
      "2023-02-23 10:29:50,871 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4ed135530c5a876f.arrow\n",
      "2023-02-23 10:30:31,497 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-db66bfda2df96747.arrow\n",
      "2023-02-23 10:31:12,592 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ba8982dd85e69ea9.arrow\n",
      "2023-02-23 10:31:55,126 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4d7bd307122411e6.arrow\n",
      "2023-02-23 10:32:35,996 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d5e73e3f673617d9.arrow\n",
      "2023-02-23 10:32:36,544 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-8d40391d40e212e5.arrow\n",
      "2023-02-23 10:33:17,778 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4c9a0ae15419eefc.arrow\n",
      "2023-02-23 10:33:57,825 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1bd094486a2b3200.arrow\n",
      "2023-02-23 10:34:38,768 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-8f928dc519724ce3.arrow\n",
      "2023-02-23 10:35:20,185 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-7b2e1b82e89dc815.arrow\n",
      "2023-02-23 10:36:02,539 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-564ae90979585e69.arrow\n",
      "2023-02-23 10:36:44,144 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-cc417e7cd741d609.arrow\n",
      "2023-02-23 10:37:26,319 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-cff4c56bf9ea2c64.arrow\n",
      "2023-02-23 10:38:07,475 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1fd3c01757f98d1e.arrow\n",
      "2023-02-23 10:38:50,858 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1db2b4527aa56a18.arrow\n",
      "2023-02-23 10:39:31,473 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-7f6b8793b318ad4c.arrow\n",
      "2023-02-23 10:40:12,757 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-09aedbd06d316b4a.arrow\n",
      "2023-02-23 10:40:55,017 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-55c7ed9d4d4985dc.arrow\n",
      "2023-02-23 10:41:36,824 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-afe6790abc18a40b.arrow\n",
      "2023-02-23 10:42:18,570 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-27d99a23e4f7625e.arrow\n",
      "2023-02-23 10:43:01,998 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2aa36cf7eb70ba65.arrow\n",
      "2023-02-23 10:43:44,958 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-90823edaa0722aa0.arrow\n",
      "2023-02-23 10:44:26,607 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ce5dc80760257199.arrow\n",
      "2023-02-23 10:45:08,425 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-fdd2ed7af97ccc57.arrow\n",
      "2023-02-23 10:45:49,676 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-16408169a38d8afc.arrow\n",
      "2023-02-23 10:46:32,648 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ceca2ee310da8a95.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 10:47:13,998 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-32b2c49215ace7a1.arrow\n",
      "2023-02-23 10:47:55,860 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-38974df5bff773ce.arrow\n",
      "2023-02-23 10:48:37,847 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-628308690fa7ee05.arrow\n",
      "2023-02-23 10:49:14,493 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-191b8adf0202861c.arrow\n",
      "2023-02-23 10:49:51,930 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-8e751eb764d09913.arrow\n",
      "2023-02-23 10:50:28,206 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-4a31b24384dd6da6.arrow\n",
      "2023-02-23 10:51:04,261 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-eb8f205672d3cc5d.arrow\n",
      "2023-02-23 10:51:39,123 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-c9cd4af97d161f29.arrow\n",
      "2023-02-23 10:52:11,220 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-b6e355f695bb440d.arrow\n",
      "2023-02-23 10:52:43,490 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-379deda1ade6c5e9.arrow\n",
      "2023-02-23 10:53:16,025 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-156af4586c4c3935.arrow\n",
      "2023-02-23 10:53:49,013 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-385af4635e4af862.arrow\n",
      "2023-02-23 10:54:20,961 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ffc573d5fd0ba70e.arrow\n",
      "2023-02-23 10:54:52,609 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-95d1805142cb6d1d.arrow\n",
      "2023-02-23 10:55:25,521 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-2aa50f4ec6f00933.arrow\n",
      "2023-02-23 10:55:56,621 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-31234efe6e648043.arrow\n",
      "2023-02-23 10:56:29,159 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1d7173e55bc7fdeb.arrow\n",
      "2023-02-23 10:57:01,027 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d26d53961058fe8c.arrow\n",
      "2023-02-23 10:57:34,053 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-da54f267dd138266.arrow\n",
      "2023-02-23 10:58:06,361 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-07120911b3b68b57.arrow\n",
      "2023-02-23 10:58:38,077 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-869bdbd2e72bb5b7.arrow\n",
      "2023-02-23 10:59:09,902 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-c09fcd8f739cd488.arrow\n",
      "2023-02-23 10:59:43,191 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-33a1d1c2ad4ab155.arrow\n",
      "2023-02-23 11:00:14,614 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-7f411fed1e70e799.arrow\n",
      "2023-02-23 11:00:47,091 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-41a8a6e165e04993.arrow\n",
      "2023-02-23 11:01:19,033 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-a41865bf350d278d.arrow\n",
      "2023-02-23 11:01:52,032 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ff3e0ba10ac728b4.arrow\n",
      "2023-02-23 11:02:23,143 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-cc249558f2ad985f.arrow\n",
      "2023-02-23 11:02:55,345 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-9f9821883744da64.arrow\n",
      "2023-02-23 11:03:27,391 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1ac902ee25777cf0.arrow\n",
      "2023-02-23 11:03:58,919 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-755a3ac132ae2a20.arrow\n",
      "2023-02-23 11:04:33,375 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-5c94938160c6b3ed.arrow\n",
      "2023-02-23 11:05:09,490 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d3b564b08be04c3e.arrow\n",
      "2023-02-23 11:05:42,625 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-1ad0a6f226bdd974.arrow\n",
      "2023-02-23 11:06:14,964 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-98a33736fd1ac7ce.arrow\n",
      "2023-02-23 11:06:46,523 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-7ce71b48fba52e59.arrow\n",
      "2023-02-23 11:07:17,823 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-905c053b25fdacbe.arrow\n",
      "2023-02-23 11:07:49,363 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-a36bcb0167e98363.arrow\n",
      "2023-02-23 11:08:20,321 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-6c596216ae0fdbc8.arrow\n",
      "2023-02-23 11:08:50,386 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-856f3d95e0ae1a1b.arrow\n",
      "2023-02-23 11:09:22,283 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ade7cef37ed2ec2f.arrow\n",
      "2023-02-23 11:09:53,026 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-e345ac72eac39204.arrow\n",
      "2023-02-23 11:10:24,648 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-d5627386528cc241.arrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-23 11:11:11,557 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-ff88ec827f99d273.arrow\n",
      "2023-02-23 11:12:05,973 | datasets.arrow_dataset | WARNING | Loading cached processed dataset at C:\\Users\\Fabrice\\Documents\\GitHub\\fada\\datasets\\glue.sst2.annotated\\cache-a2939b3b7fa74d8a.arrow\n"
     ]
    }
   ],
   "source": [
    "dataset_config = (\"glue\", \"sst2\")\n",
    "task_name = \"sentiment\"\n",
    "\n",
    "for agg in aggregations:\n",
    "    for scorer, scorer_name in scorers:\n",
    "\n",
    "        print(f\"running fada-v2 policy search using {scorer_name}-{agg}\")\n",
    "\n",
    "        dataset = load_dataset(*dataset_config, split=\"train\")\n",
    "        dataset = dataset.rename_column(\"sentence\", \"text\")\n",
    "\n",
    "        # initialize extractors\n",
    "        feature_extractor = AMRFeatureExtractor()\n",
    "        perf_extractor = PerformanceExtractor(dataset.builder_name, Likelihood())\n",
    "\n",
    "        # initialize dataset + annotations\n",
    "        if os.path.exists(\"./datasets/glue.sst2.annotated\"):\n",
    "            dataset = load_from_disk(\"./datasets/glue.sst2.annotated\")\n",
    "            features = np.array(dataset[\"features\"])\n",
    "        else:\n",
    "            features = feature_extractor(dataset[\"text\"])\n",
    "            preds = perf_extractor.extract_prediction_probabilities(dataset[\"text\"])\n",
    "            dataset = dataset.add_column(\"features\", [f for f in features])\n",
    "            dataset = dataset.add_column(\"preds\", [p.numpy() for p in preds])\n",
    "            dataset.save_to_disk(\"./datasets/glue.sst2.annotated\")\n",
    "\n",
    "        # initialize save directory\n",
    "        save_dir       = f\"./fadata/nlaug/v2-{scorer_name}-{agg}/\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "        # initialize fadata arrays\n",
    "        num_rows       = len(dataset)\n",
    "        num_transforms = len(transforms)\n",
    "        num_features   = len(feature_extractor.featurizers)\n",
    "\n",
    "        performances   = np.zeros((num_transforms, num_features))\n",
    "        counts         = np.zeros((num_transforms, num_features))\n",
    "        changes        = np.zeros((num_transforms, num_features))\n",
    "        policy         = np.full((num_transforms, num_features), fill_value=1/num_transforms)\n",
    "\n",
    "        min_coverage = 128\n",
    "        num_to_transform_per_step = 16\n",
    "\n",
    "        policy_difference = np.inf\n",
    "        convergence_threshold = 1 / (num_transforms + num_features)\n",
    "\n",
    "        # run fada-v2 convergence loop\n",
    "\n",
    "        i = 0\n",
    "        while policy_difference > convergence_threshold:\n",
    "\n",
    "            # find low coverage (t,f) pairs\n",
    "            ts, fs   = np.where(changes < min_coverage)\n",
    "            tf_pairs = list(zip(ts, fs))\n",
    "\n",
    "            for t, f in tqdm(tf_pairs):\n",
    "\n",
    "                f_candidates  = np.where(features[:,f] == 1)[0]\n",
    "\n",
    "                # feature missing in dataset\n",
    "                if not f_candidates.size:\n",
    "                    continue\n",
    "\n",
    "                num_to_sample = num_to_transform_per_step if len(f_candidates) > num_to_transform_per_step else len(f_candidates)\n",
    "                f_indices     = np.random.choice(f_candidates, num_to_sample, replace=False)\n",
    "                f_dataset     = dataset.select(f_indices)\n",
    "\n",
    "                t_prob = np.zeros(num_transforms)\n",
    "                t_prob[t] = 1\n",
    "                transform_probabilities = np.array([t_prob for _ in range(f_dataset.num_rows)])\n",
    "\n",
    "                augmenter = Augmenter(dataset=f_dataset, \n",
    "                              transforms=transforms,  \n",
    "                              transform_probabilities=transform_probabilities,\n",
    "                              num_augmentations_per_record=1,\n",
    "                              num_transforms_to_apply=1,\n",
    "                              batch_size=10, \n",
    "                              keep_originals=False)\n",
    "                aug_dataset = augmenter.augment()\n",
    "\n",
    "                try:\n",
    "                    performance = perf_extractor(aug_dataset[\"text\"], aug_dataset[\"label\"], indices=f_indices)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    performance = [1] * f_dataset.num_rows\n",
    "                aug_dataset = aug_dataset.add_column(\"performance\", [p for p in performance])\n",
    "\n",
    "                performance = np.array(aug_dataset[\"performance\"]).sum()\n",
    "                num_changes = np.array(aug_dataset[\"is_changed\"]).sum()\n",
    "\n",
    "                counts[t,f]       += f_dataset.num_rows\n",
    "                changes[t,f]      += num_changes  \n",
    "                performances[t,f] += performance   \n",
    "\n",
    "            # compute augmentation policy\n",
    "            if agg == \"sum\":\n",
    "                aggregated_performance = performances \n",
    "            elif agg == \"avg\":\n",
    "                aggregated_performance = np.nan_to_num(performances / counts, 0)\n",
    "            applicability_rate         = np.nan_to_num(changes / counts, 0)\n",
    "            new_policy                 = softmax(aggregated_performance * applicability_rate, axis=0)\n",
    "\n",
    "            policy_difference          = np.linalg.norm(new_policy - policy)\n",
    "            policy                     = new_policy\n",
    "\n",
    "            print(f\"policy_difference: {policy_difference} (convergence_threshold: {convergence_threshold})\")\n",
    "\n",
    "            policy_heatmap(policy, transforms, feature_extractor.featurizers)\n",
    "\n",
    "            print(\"Saving intermediate matrices...\")\n",
    "            np.save(os.path.join(save_dir, f\"glue.sst2.fada.v2.counts-step-{i}\"), counts)\n",
    "            np.save(os.path.join(save_dir, f\"glue.sst2.fada.v2.changes-step-{i}\"), changes)\n",
    "            np.save(os.path.join(save_dir, f\"glue.sst2.fada.v2.performances-step-{i}\"), performances)\n",
    "            np.save(os.path.join(save_dir, f\"glue.sst2.fada.v2.policy-step-{i}\"), policy)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # augment original dataset with newly converged policy\n",
    "        dataset = load_dataset(*dataset_config, split=\"train\")\n",
    "        dataset = dataset.rename_column(\"sentence\", \"text\")\n",
    "\n",
    "        policy_probabilities = implement_policy_probabilities(policy, features)\n",
    "\n",
    "        augmenter = Augmenter(dataset=dataset, \n",
    "                              transforms=transforms, \n",
    "                              transform_probabilities=policy_probabilities, \n",
    "                              num_augmentations_per_record=1,\n",
    "                              num_transforms_to_apply=1,\n",
    "                              keep_originals=True)\n",
    "        aug_dataset = augmenter.augment()\n",
    "        aug_dataset.save_to_disk(f\"./datasets/glue.sst2.nlaug.fada_v2_{scorer_name}_{agg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64244f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
