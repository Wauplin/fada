{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e616ab",
   "metadata": {},
   "source": [
    "# Feature-Aware Data Augmentation\n",
    "\n",
    "Augmentation policies to consider:\n",
    "- Simple policy randomly sampling of n transforms \n",
    "- Constrained sampling policy with a blacklist of transforms to avoid \n",
    "- Feature-aware augmentation policy where transforms are picked based on their (transform, feature) behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf807a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install codecarbon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "259af696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Welcome to CodeCarbon, here is your experiment id:\n",
      "87abc9a8-d71c-4913-a654-80a754736084 (from ./.codecarbon.config)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!codecarbon init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be0cdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets.utils.logging import disable_progress_bar\n",
    "\n",
    "# amrs\n",
    "import amrlib\n",
    "import penman\n",
    "\n",
    "# transform\n",
    "import sibyl\n",
    "import time\n",
    "import torch\n",
    "import inspect\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "# eval pipeline\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import HfApi, ModelFilter\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from scipy.special import softmax\n",
    "\n",
    "# train pipeline\n",
    "import shutil\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification, \n",
    "    AutoTokenizer, \n",
    "    Trainer, \n",
    "    TrainingArguments, \n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# cleanlab pipeline\n",
    "from cleanlab.filter import find_label_issues\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from codecarbon import EmissionsTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8870c2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlaugmenter.transformations.emojify                                   import EmojifyTransformation\n",
    "from nlaugmenter.transformations.synonym_insertion                         import SynonymInsertion\n",
    "from nlaugmenter.transformations.back_translation                          import BackTranslation\n",
    "from nlaugmenter.transformations.noun_compound_paraphraser                 import NounCompoundParaphraser\n",
    "from nlaugmenter.transformations.diacritic_removal                         import DiacriticRemoval\n",
    "from nlaugmenter.transformations.azerty_qwerty_chars_swap                  import AzertyQwertyCharsSwap\n",
    "from nlaugmenter.transformations.add_hashtags                              import HashtagGeneration\n",
    "from nlaugmenter.transformations.replace_spelling                          import SpellingTransformation\n",
    "from nlaugmenter.transformations.token_replacement                         import TokenReplacement\n",
    "from nlaugmenter.transformations.auxiliary_negation_removal                import SentenceAuxiliaryNegationRemoval\n",
    "from nlaugmenter.transformations.use_acronyms                              import UseAcronyms\n",
    "from nlaugmenter.transformations.yoda_transform                            import YodaPerturbation\n",
    "from nlaugmenter.transformations.factive_verb_transformation               import FactiveVerbTransformation\n",
    "from nlaugmenter.transformations.protaugment_diverse_paraphrase            import ProtaugmentDiverseParaphrase\n",
    "from nlaugmenter.transformations.replace_financial_amounts                 import ReplaceFinancialAmount\n",
    "from nlaugmenter.transformations.americanize_britishize_english            import AmericanizeBritishizeEnglish\n",
    "from nlaugmenter.transformations.punctuation                               import PunctuationWithRules\n",
    "from nlaugmenter.transformations.urban_dict_swap                           import UrbanThesaurusSwap\n",
    "from nlaugmenter.transformations.filler_word_augmentation                  import FillerWordAugmentation\n",
    "from nlaugmenter.transformations.synonym_substitution                      import SynonymSubstitution\n",
    "from nlaugmenter.transformations.style_paraphraser                         import StyleTransferParaphraser\n",
    "from nlaugmenter.transformations.random_upper_transformation               import RandomUpperPerturbation\n",
    "from nlaugmenter.transformations.weekday_month_abbreviation                import WeekdayMonthAbbreviation\n",
    "from nlaugmenter.transformations.city_names_transformation                 import CityNamesTransformation\n",
    "from nlaugmenter.transformations.sentence_additions                        import SentenceAdditions\n",
    "from nlaugmenter.transformations.change_date_format                        import ChangeDateFormat\n",
    "from nlaugmenter.transformations.tense                                     import TenseTransformation\n",
    "from nlaugmenter.transformations.dyslexia_words_swap                       import DyslexiaWordsSwap\n",
    "from nlaugmenter.transformations.gender_culture_diverse_name               import GenderCultureDiverseName\n",
    "from nlaugmenter.transformations.gender_neutral_rewrite                    import GenderNeutralRewrite\n",
    "from nlaugmenter.transformations.lost_in_translation                       import LostInTranslation\n",
    "from nlaugmenter.transformations.insert_abbreviation                       import AbbreviationInsertionEN\n",
    "from nlaugmenter.transformations.random_deletion                           import RandomDeletion\n",
    "from nlaugmenter.transformations.transformer_fill                          import TransformerFill\n",
    "from nlaugmenter.transformations.concat_monolingual                        import ConcatMonolingual\n",
    "from nlaugmenter.transformations.country_state_abbreviation_transformation import CountryStateAbbreviation\n",
    "from nlaugmenter.transformations.butter_fingers_perturbation               import ButterFingersPerturbation\n",
    "from nlaugmenter.transformations.replace_abbreviation_and_acronyms         import ReplaceAbbreviations\n",
    "from nlaugmenter.transformations.slangificator                             import Slangificator\n",
    "from nlaugmenter.transformations.yes_no_question                           import YesNoQuestionPerturbation\n",
    "from nlaugmenter.transformations.gender_swap                               import GenderSwap\n",
    "from nlaugmenter.transformations.close_homophones_swap                     import CloseHomophonesSwap\n",
    "from nlaugmenter.transformations.simple_ciphers                            import SimpleCiphers\n",
    "from nlaugmenter.transformations.change_person_named_entities              import ChangePersonNamedEntities\n",
    "from nlaugmenter.transformations.greetings_and_farewells                   import GreetingsAndFarewells\n",
    "from nlaugmenter.transformations.discourse_marker_substitution             import DiscourseMarkerSubstitution\n",
    "from nlaugmenter.transformations.summarization_transformation              import Summarization\n",
    "from nlaugmenter.transformations.visual_attack_letters                     import VisualAttackLetters\n",
    "# from nlaugmenter.transformations.sentence_reordering                       import SentenceReordering\n",
    "from nlaugmenter.transformations.change_char_case                          import ChangeCharCase\n",
    "from nlaugmenter.transformations.antonyms_substitute                       import AntonymsSubstitute\n",
    "from nlaugmenter.transformations.mix_transliteration                       import MixTransliteration\n",
    "from nlaugmenter.transformations.disability_transformation                 import DifferentAbilityTransformation\n",
    "from nlaugmenter.transformations.abbreviation_transformation               import Abbreviate\n",
    "from nlaugmenter.transformations.replace_with_hyponyms_hypernyms           import ReplaceHypernyms\n",
    "from nlaugmenter.transformations.replace_with_hyponyms_hypernyms           import ReplaceHyponyms\n",
    "from nlaugmenter.transformations.grapheme_to_phoneme_transformation        import PhonemeSubstitution\n",
    "from nlaugmenter.transformations.multilingual_lexicon_perturbation         import MultilingualLexiconPerturbation\n",
    "from nlaugmenter.transformations.multilingual_back_translation             import MultilingualBackTranslation\n",
    "from nlaugmenter.transformations.unit_converter                            import UnitConverter\n",
    "from nlaugmenter.transformations.adjectives_antonyms_switch                import SentenceAdjectivesAntonymsSwitch\n",
    "from nlaugmenter.transformations.correct_common_misspellings               import CorrectCommonMisspellings\n",
    "from nlaugmenter.transformations.neural_question_paraphraser               import NeuralParaphaserPerturbation\n",
    "from nlaugmenter.transformations.subject_object_switch                     import SentenceSubjectObjectSwitch\n",
    "from nlaugmenter.transformations.numeric_to_word                           import NumericToWord\n",
    "from nlaugmenter.transformations.multilingual_dictionary_based_code_switch import MultilingualDictionaryBasedCodeSwitch\n",
    "from nlaugmenter.transformations.diverse_paraphrase                        import DiverseParaphrase\n",
    "from nlaugmenter.transformations.english_inflectional_variation            import EnglishInflectionalVariation\n",
    "from nlaugmenter.transformations.replace_numerical_values                  import ReplaceNumericalValues\n",
    "from nlaugmenter.transformations.speech_disfluency_perturbation            import SpeechDisfluencyPerturbation\n",
    "from nlaugmenter.transformations.whitespace_perturbation                   import WhitespacePerturbation\n",
    "from nlaugmenter.transformations.contraction_expansions                    import ContractionExpansions\n",
    "from nlaugmenter.transformations.color_transformation                      import ColorTransformation\n",
    "from nlaugmenter.transformations.contextual_meaning_perturbation           import ContextualMeaningPerturbation\n",
    "from nlaugmenter.transformations.pig_latin                                 import PigLatin\n",
    "from nlaugmenter.transformations.leet_letters                              import LeetLetters\n",
    "from nlaugmenter.transformations.hashtagify                                import HashtagifyTransformation\n",
    "# from nlaugmenter.transformations.propbank_srl_roles                        import CheckSrl\n",
    "from nlaugmenter.transformations.geo_names_transformation                  import GeoNamesTransformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0408a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cec473e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(False)\n",
    "disable_progress_bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b61f4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def normalize_minmax(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = (df[column] - df[column].min()) / (df[column].max() - df[column].min())  \n",
    "    return df\n",
    "\n",
    "def normalize_sum(df):\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column] / df[column].sum()\n",
    "    return df\n",
    "\n",
    "def augment_data(batch, transform, keep_originals=True):\n",
    "    new_texts, new_labels = [], []\n",
    "    for text, label in zip(batch['text'], batch['label']):\n",
    "        new_text, new_label = transform.apply([text], [label])\n",
    "        new_texts.extend(new_text)\n",
    "        new_labels.extend(new_label)\n",
    "    if keep_originals:\n",
    "        return {\"text\": batch['text'] + new_texts, \"label\": batch['label'] + new_labels}\n",
    "    else:\n",
    "        return {\"text\": new_texts, \"label\": new_labels}\n",
    "    \n",
    "def percent_dataset_changed(d1, d2):\n",
    "    return sum([t1['text'] != t2['text'] for t1, t2 in zip(d1, d2)]) / len(d1) \n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    acc = accuracy_score(labels, predictions.argmax(-1))\n",
    "    precision, recall, fbeta_score, support = precision_recall_fscore_support(\n",
    "        y_true=labels, \n",
    "        y_pred=predictions.argmax(-1), \n",
    "        average=\"weighted\", \n",
    "        zero_division=0)\n",
    "    return { 'accuracy': acc , \n",
    "             'precision': precision, \n",
    "             'recall': recall, \n",
    "             'fbeta_score': fbeta_score} \n",
    "\n",
    "def compute_accuracy(predictions, labels):\n",
    "    if not isinstance(labels, np.ndarray):\n",
    "        labels = np.array(labels)\n",
    "    if len(labels.shape) > 1:\n",
    "        acc = acc_at_k(labels, predictions, k=2)       \n",
    "    else:\n",
    "        acc = accuracy_score(labels, np.argmax(predictions, -1))\n",
    "    return acc\n",
    "\n",
    "def vectorize(output):\n",
    "    sorted_output = sorted(output, key=lambda d: d['label']) \n",
    "    probs = torch.tensor([d['score'] for d in sorted_output])\n",
    "    return probs\n",
    "\n",
    "def sample_transforms(transforms, p, n=2, replace=False):\n",
    "    return np.random.choice(transforms, size=n, p=p, replace=replace).tolist()\n",
    "\n",
    "def transforms_to_ids(sampled_transforms, all_transforms):\n",
    "    transforms_ids = [all_transforms.index(i) for i in sampled_transforms]\n",
    "    transforms_applied = np.zeros(len(all_transforms), dtype=np.int32)\n",
    "    transforms_applied[transforms_ids] = 1\n",
    "    return transforms_applied\n",
    "\n",
    "def policy_heatmap(policy, transforms, featurizers):\n",
    "    t_names = [t.transform_class.__name__ for t in transforms]\n",
    "    f_names = [f.__name__ for f in featurizers]\n",
    "    df = pd.DataFrame(policy)\n",
    "    df.columns = f_names\n",
    "    df.index = t_names\n",
    "    sns.heatmap(df)\n",
    "    plt.show()\n",
    "    \n",
    "def implement_policy_probabilities(policy, features):\n",
    "    default_probability = policy.mean(axis=1)\n",
    "    policy_probs = []\n",
    "    for f in features:\n",
    "        available_features = np.nonzero(f)[0]\n",
    "        if len(available_features) == 0:\n",
    "            probs = default_probability\n",
    "        else:\n",
    "            probs = policy[:, available_features].mean(axis=1)\n",
    "        policy_probs.append(probs)\n",
    "    return np.array(policy_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af0516f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self, transform_class, num_outputs=1, task_name=\"sentiment\"):\n",
    "        self.transform_class = transform_class\n",
    "        self.num_outputs = num_outputs\n",
    "        self.task_name = task_name\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.intakes_target = False\n",
    "        self.is_batched = False\n",
    "        \n",
    "        # setting class attributes\n",
    "        if 'to_tense' in inspect.signature(self.transform_class).parameters:\n",
    "            print(f\"initializing {self.transform_class.__name__} with to_tense='past'\") # future & random don't work\n",
    "            self.transform_instance = self.transform_class(to_tense=\"past\")\n",
    "        elif 'source_lang' in inspect.signature(self.transform_class).parameters:\n",
    "            print(f\"initializing {self.transform_class.__name__} with source_lang='es'\") \n",
    "            self.transform_instance = self.transform_class(source_lang=\"es\")\n",
    "        elif 'task_name' in inspect.signature(self.transform_class).parameters:\n",
    "            print(f\"initializing {self.transform_class.__name__} with task_name='{task_name}', return_metadata=True\") \n",
    "            self.transform_instance = self.transform_class(task_name=self.task_name, return_metadata=True)\n",
    "        elif isinstance(self.transform_class, LostInTranslation):\n",
    "            print(f\"initializing {self.transform_class.__name__} with device=0\")\n",
    "            self.transform_instance = self.transform_class(device=0)\n",
    "        else:\n",
    "            print(f\"initializing {self.transform_class.__name__}\")\n",
    "            self.transform_instance = self.transform_class()\n",
    "        \n",
    "        # setting instance attributes\n",
    "        if hasattr(self.transform_instance, \"max_outputs\"):\n",
    "            print(f\"setting max_outputs={self.num_outputs}\")\n",
    "            self.transform_instance.max_outputs = self.num_outputs\n",
    "        if hasattr(self.transform_instance, \"max_paraphrases\"):\n",
    "            print(f\"setting max_paraphrases={self.num_outputs}\")\n",
    "            self.transform_instance.max_paraphrases = self.num_outputs\n",
    "        if hasattr(self.transform_instance, \"device\"):\n",
    "            if self.transform_instance.device is None or self.transform_instance.device == 'cpu':\n",
    "                print(f\"setting device={self.device}\")\n",
    "                self.transform_instance.device = self.device\n",
    "        \n",
    "        # selecting the transformation function\n",
    "        if hasattr(self.transform_class, \"generate\"):\n",
    "            self.transform_fn = self.transform_instance.generate\n",
    "        if hasattr(self.transform_class, \"augment\"):\n",
    "            self.transform_fn = self.transform_instance.augment\n",
    "        if hasattr(self.transform_class, \"transform_batch\"):\n",
    "            self.transform_fn = self.transform_instance.transform_batch\n",
    "            self.intakes_target = True\n",
    "            self.is_batched = True\n",
    "            \n",
    "    def synced_shuffle(self, list1, list2):\n",
    "        # Shuffle two lists with same order\n",
    "        # Using zip() + * operator + shuffle()\n",
    "        temp = list(zip(list1, list2))\n",
    "        random.shuffle(temp)\n",
    "        res1, res2 = zip(*temp)\n",
    "        # res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "        res1, res2 = list(res1), list(res2)\n",
    "        return res1, res2\n",
    "            \n",
    "    def apply(self, texts, labels=None):\n",
    "        if self.intakes_target:\n",
    "            if self.is_batched:\n",
    "                new_texts, new_labels = self.transform_fn((texts, labels))\n",
    "            else:\n",
    "                new_texts, new_labels = [], []\n",
    "                for t, l in zip(texts, labels):\n",
    "                    new_t, new_l = self.transform_fn(t, l)\n",
    "                    new_texts.append(new_t)\n",
    "                    new_labels.extend([new_l] * len(new_t))\n",
    "        else:\n",
    "            if self.is_batched:\n",
    "                new_texts = self.transform_fn((texts))\n",
    "                new_texts = labels\n",
    "            else:\n",
    "                new_texts, new_labels = [], []\n",
    "                for t, l in zip(texts, labels):\n",
    "                    new_t = self.transform_fn(t)\n",
    "                    if len(new_t) > self.num_outputs:\n",
    "                        new_t = new_t[:self.num_outputs]\n",
    "                    new_texts.extend(new_t)\n",
    "                    new_labels.extend([l] * len(new_t))\n",
    "                    \n",
    "        # post processing since some transformations add/remove more new outputs than expected\n",
    "        if len(new_texts) == 0:\n",
    "            print(\"no new_texts, substituting original texts...\")\n",
    "            new_texts = texts\n",
    "        if len(new_labels) == 0:\n",
    "            print(\"no new_labels, substituting original labels...\")\n",
    "            new_labels = labels\n",
    "        new_texts, new_labels = self.synced_shuffle(new_texts, new_labels)\n",
    "        \n",
    "        expected_len = len(texts) * self.num_outputs\n",
    "        new_texts = new_texts[:expected_len]\n",
    "        new_labels = new_labels[:expected_len]\n",
    "        \n",
    "        return new_texts, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79c7635d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRGraph:\n",
    "    def __init__(self, amr):\n",
    "        self.graph = penman.decode(amr) if not isinstance(amr, penman.graph.Graph) else amr\n",
    "        self.amr_text = penman.encode(self.graph)\n",
    "\n",
    "    def contains_concept(self, concepts):\n",
    "        \"\"\"\n",
    "        Concepts are nodes / instances in the AMR graph.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(concepts, list): concepts = [concepts]\n",
    "            graph_concepts = [t.target for t in self.graph.instances()]\n",
    "            return any(c for c in graph_concepts if c in concepts)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.graph, self.amr_text)\n",
    "\n",
    "    def contains_role(self, roles):\n",
    "        \"\"\"\n",
    "        Roles are edges in the AMR graph.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(roles, list): roles = [roles]\n",
    "            graph_roles = [e.role for e in self.graph.edges()]\n",
    "            return any(r for r in graph_roles if r in roles)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.graph, self.amr_text)\n",
    "\n",
    "    def contains_attribute(self, attributes):\n",
    "        \"\"\"\n",
    "        Attributes are properties of concept nodes, i.e. relationships to \n",
    "        constant values.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if not isinstance(attributes, list): attributes = [attributes]\n",
    "            graph_attrs = [a.target for a in self.graph.attributes()]\n",
    "            return any(a for a in graph_attrs if a in attributes)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(self.graph, self.amr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d81c17bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes =============================================================\n",
    "\n",
    "def contains_imperative(g): return g.contains_attribute(\"imperative\")\n",
    "def contains_exlamation(g): return g.contains_attribute(\"expressive\")\n",
    "def contains_negation(g):   return g.contains_attribute(\"-\")\n",
    "\n",
    "# concepts ===============================================================\n",
    "\n",
    "def contains_conjunctions(g):         return g.contains_concept([\"and\", \"or\", \"contrast-01\", \"either\", \"neither\"])\n",
    "def contains_interrogative_clause(g): return g.contains_concept(\"truth-value\")\n",
    "def contains_question(g):             return g.contains_concept([\"amr-unknown\", \"amr-choice\"])\n",
    "\n",
    "# roles ==================================================================\n",
    "\n",
    "def contains_coreferences(g): return any(r for r in g.amr_text.split() if r in ['i', 'you', 'he', 'she', 'it', 'we', 'they'])\n",
    "def contains_number(g):       return any(a for a in g.graph.attributes() if a.target.isnumeric())\n",
    "\n",
    "def contains_accompanier(g):  return g.contains_role(':accompanier')\n",
    "def contains_age(g):          return g.contains_role(':age')\n",
    "def contains_beneficiary(g):  return g.contains_role(':beneficiary')\n",
    "def contains_concession(g):   return g.contains_role(':concession')\n",
    "def contains_condition(g):    return g.contains_role(':condition')\n",
    "def contains_consist_of(g):   return any(r for r in g.amr_text.split() if r in [':consist-of'])\n",
    "def contains_degree(g):       return g.contains_role(':degree')\n",
    "def contains_destination(g):  return g.contains_role(':destination')\n",
    "def contains_direction(g):    return g.contains_role(':direction')\n",
    "def contains_domain(g):       return g.contains_role(':domain')\n",
    "def contains_duration(g):     return g.contains_role(':duration')\n",
    "def contains_example(g):      return g.contains_role(':example')\n",
    "def contains_extent(g):       return g.contains_role(':extent')\n",
    "def contains_frequency(g):    return g.contains_role(':frequency')\n",
    "def contains_instrument(g):   return g.contains_role(':instrument')\n",
    "# def contains_li(g):           return g.contains_role(':li')\n",
    "def contains_location(g):     return g.contains_role(':location')\n",
    "def contains_manner(g):       return g.contains_role(':manner')\n",
    "def contains_medium(g):       return g.contains_role(':medium')\n",
    "def contains_mod(g):          return g.contains_role(':mod')\n",
    "def contains_mode(g):         return any(a for a in g.graph.attributes() if \":mode\" in a.role)\n",
    "def contains_name(g):         return g.contains_role(':name')\n",
    "def contains_ord(g):          return g.contains_role(':ord')\n",
    "def contains_part(g):         return g.contains_role(':part')\n",
    "def contains_path(g):         return g.contains_role(':path')\n",
    "def contains_polarity(g):     return g.contains_role(':polarity')\n",
    "def contains_polite(g):       return any(r for r in g.amr_text.split() if r in [':polite'])\n",
    "def contains_poss(g):         return g.contains_role(':poss')\n",
    "def contains_purpose(g):      return g.contains_role(':purpose')\n",
    "def contains_quant(g):        return g.contains_role(':quant')\n",
    "def contains_range(g):        return g.contains_role(':range')\n",
    "def contains_scale(g):        return g.contains_role(':scale')\n",
    "def contains_source(g):       return g.contains_role(':source')\n",
    "def contains_subevent(g):     return g.contains_role(':subevent')\n",
    "def contains_time(g):         return g.contains_role(':time')\n",
    "def contains_topic(g):        return g.contains_role(':topic')\n",
    "def contains_unit(g):         return g.contains_role(':unit')\n",
    "# def contains_value(g):        return g.contains_role(':value')\n",
    "def contains_wiki(g):         return g.contains_role(':wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "363516ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRFeatureExtractor:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.featurizers = featurizers = [    \n",
    "            contains_accompanier,\n",
    "            contains_age,\n",
    "            contains_beneficiary,\n",
    "            contains_concession,\n",
    "            contains_condition,\n",
    "            contains_conjunctions,\n",
    "            contains_consist_of,\n",
    "            contains_coreferences,\n",
    "            contains_degree,\n",
    "            contains_destination,\n",
    "            contains_direction,\n",
    "            contains_domain,\n",
    "            contains_duration,\n",
    "            contains_example,\n",
    "            contains_exlamation,\n",
    "            contains_extent,\n",
    "            contains_frequency,\n",
    "            contains_imperative,\n",
    "            contains_instrument,\n",
    "            contains_interrogative_clause,\n",
    "            contains_location,\n",
    "            contains_manner,\n",
    "            contains_medium,\n",
    "            contains_mod,\n",
    "            contains_mode,\n",
    "            contains_name,\n",
    "            contains_negation,\n",
    "            contains_number,\n",
    "            contains_ord,\n",
    "            contains_part,\n",
    "            contains_path,\n",
    "            contains_polarity,\n",
    "            contains_polite,\n",
    "            contains_poss,\n",
    "            contains_purpose,\n",
    "            contains_quant,\n",
    "            contains_question,\n",
    "            contains_range,\n",
    "            contains_scale,\n",
    "            contains_source,\n",
    "            contains_subevent,\n",
    "            contains_time,\n",
    "            contains_topic,\n",
    "            contains_unit\n",
    "        ]\n",
    "        self.featurizers = sorted(featurizers, key=lambda f: f.__name__)\n",
    "        self.amr_model   = None\n",
    "        \n",
    "    def load_amr_model(self, max_sent_len=128):\n",
    "        self.amr_model = amrlib.load_stog_model(max_sent_len=max_sent_len)\n",
    "        \n",
    "    def text_to_amr(self, texts):\n",
    "        if self.amr_model is None:\n",
    "            self.load_amr_model()\n",
    "        amr_penmans = self.amr_model.parse_sents(texts, add_metadata=False, disable_progress=True)\n",
    "        amr_graphs = []\n",
    "        for p in amr_penmans:\n",
    "            try:\n",
    "                amr_graphs.append(AMRGraph(p))\n",
    "            except Exception as e: \n",
    "                print(e)\n",
    "                print(p)\n",
    "                amr_graphs.append(AMRGraph(p))\n",
    "        return amr_graphs\n",
    "    \n",
    "    def generate_feature_matrix(self, graphs):\n",
    "        feature_matrix = []\n",
    "        for g in graphs:\n",
    "            feature_vector = []\n",
    "            for f in self.featurizers:\n",
    "                feature_vector.append(f(g))\n",
    "            feature_matrix.append(feature_vector)\n",
    "        feature_matrix = np.array(feature_matrix, dtype=np.int32)\n",
    "        return feature_matrix\n",
    "    \n",
    "    def __call__(self, texts):\n",
    "        graphs = self.text_to_amr(texts)\n",
    "        return self.generate_feature_matrix(graphs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85172943",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmenter:\n",
    "    def __init__(self, \n",
    "                 dataset,\n",
    "                 transforms,\n",
    "                 transform_probabilities = None, \n",
    "                 num_augmentations_per_record = 5,\n",
    "                 num_transforms_to_apply = 2,\n",
    "                 batch_size = 10,\n",
    "                 allow_resampling = False,\n",
    "                 keep_originals = False,\n",
    "                 feature_extractor = None,\n",
    "                 perf_extractor = None):\n",
    "        \n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        self.transform_probabilities = transform_probabilities\n",
    "        self.num_augmentations_per_record = num_augmentations_per_record\n",
    "        self.num_transforms_to_apply = num_transforms_to_apply\n",
    "        self.batch_size = batch_size\n",
    "        self.allow_resampling = allow_resampling\n",
    "        self.keep_originals = keep_originals\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.perf_extractor = perf_extractor\n",
    "        \n",
    "        # initializations\n",
    "        self.dataset = dataset.remove_columns(\"idx\")\n",
    "        self.add_idx_to_dataset()\n",
    "        self.num_transforms_available = len(self.transforms)\n",
    "        \n",
    "        if self.transform_probabilities is None:\n",
    "            # set to uniform\n",
    "            num_examples = len(self.dataset)\n",
    "            num_transforms = len(self.transforms)\n",
    "            uniform_policy = np.full((num_examples, num_transforms), fill_value=1/num_transforms)\n",
    "            self.transform_probabilities = uniform_policy\n",
    "        \n",
    "    def add_idx_to_dataset(self):\n",
    "        if 'idx' not in self.dataset.features:\n",
    "            self.dataset = self.dataset.add_column(\"idx\", range(len(self.dataset)))\n",
    "        \n",
    "    def apply_to_batch(self, batch):\n",
    "        new_texts, new_labels, transforms_applied, is_changed = [], [], [], []\n",
    "        for idx, text, label in zip(batch['idx'], batch['text'], batch['label']):\n",
    "            actual_batch_size = len(batch['idx'])\n",
    "            original_text, original_label = text, label\n",
    "            for _ in range(self.num_augmentations_per_record):\n",
    "                sampled_transforms = sample_transforms(self.transforms, \n",
    "                                                       p=self.transform_probabilities[idx], \n",
    "                                                       n=self.num_transforms_to_apply, \n",
    "                                                       replace=self.allow_resampling)\n",
    "                transforms_applied.append(transforms_to_ids(sampled_transforms, self.transforms))\n",
    "                for t in sampled_transforms:\n",
    "                    try:\n",
    "                        text, label = t.apply([text], [label])\n",
    "                        text, label = text[0], label[0]\n",
    "                    except Exception as e: \n",
    "                        print(e)\n",
    "                        print(f\"[Augmenter]: skipping augmentation from {t.transform_class.__name__} on text:'{text}' and label: {label}\")\n",
    "\n",
    "                # avoid adding records with empty text\n",
    "                if text:\n",
    "                    new_texts.append(text)\n",
    "                    new_labels.append(label)\n",
    "                    is_changed.append(int(original_text != text))\n",
    "\n",
    "        if self.keep_originals:\n",
    "            new_texts = batch['text'] + new_texts\n",
    "            new_labels = batch['label'] + new_labels\n",
    "            realized_batch_size = len(new_labels)\n",
    "            transforms_applied = transforms_applied + np.zeros((actual_batch_size, len(self.transforms)), dtype=np.int32).tolist()\n",
    "            is_changed = is_changed + [0] * actual_batch_size\n",
    "            out = {\n",
    "                \"text\": new_texts, \n",
    "                \"label\": new_labels,\n",
    "                \"idx\": list(range(realized_batch_size)),\n",
    "                \"transforms_applied\": [t for t in transforms_applied],\n",
    "                \"is_changed\": is_changed\n",
    "            }\n",
    "        else:\n",
    "            out = {\n",
    "                \"text\": new_texts, \n",
    "                \"label\": new_labels, \n",
    "                \"idx\": list(range(len(new_labels))),\n",
    "                \"transforms_applied\": transforms_applied,\n",
    "                \"is_changed\": is_changed\n",
    "            }\n",
    "\n",
    "        return out\n",
    "            \n",
    "                                                   \n",
    "    def augment(self):\n",
    "        dataset = self.dataset.map(self.apply_to_batch, batched=True, batch_size=self.batch_size)\n",
    "        dataset = dataset.remove_columns(\"idx\")\n",
    "    \n",
    "        # feature extraction\n",
    "        if self.feature_extractor is not None:\n",
    "            features = self.feature_extractor(dataset[\"text\"])\n",
    "            dataset = dataset.add_column(\"features\", [f for f in features])\n",
    "                \n",
    "        # performance scoring    \n",
    "        if self.perf_extractor is not None:\n",
    "            performances = self.perf_extractor(dataset[\"text\"], dataset[\"label\"])\n",
    "            dataset = dataset.add_column(\"performance\", [p for p in performances])\n",
    "                \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76aa080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood:\n",
    "    def __init__(self):\n",
    "        self.scorer = torch.nn.NLLLoss(reduction=\"none\")\n",
    "    \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        return -self.scorer(probs, targets).numpy()\n",
    "    \n",
    "class InverseLikelihood:\n",
    "    def __init__(self):\n",
    "        self.scorer = torch.nn.NLLLoss(reduction=\"none\")\n",
    "    \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        return 1+self.scorer(probs, targets).numpy()\n",
    "    \n",
    "class CleanLabSafe:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        probs = probs.numpy()\n",
    "        targets = targets.numpy()\n",
    "        scores = ~find_label_issues(\n",
    "            labels=targets,\n",
    "            pred_probs=probs,\n",
    "            n_jobs=1\n",
    "        )\n",
    "        return scores.astype(np.int32).tolist()\n",
    "    \n",
    "class LikelihoodShift:\n",
    "    def __init__(self, original_dataset, direction=\"positive\"):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.direction = direction\n",
    "        self.scorer = torch.nn.NLLLoss(reduction=\"none\")\n",
    "        \n",
    "    def __call__(self, probs, targets, indices=None):\n",
    "        new_scores  = -self.scorer(probs, targets).numpy()\n",
    "        \n",
    "        old_probs   = torch.tensor(self.original_dataset.select(indices)[\"preds\"])\n",
    "        old_targets = torch.tensor(self.original_dataset.select(indices)['label'])\n",
    "        old_scores  = -self.scorer(old_probs, old_targets).numpy()\n",
    "            \n",
    "        if self.direction in \"positive\":\n",
    "            scores = (new_scores - old_scores).clip(0, 1)\n",
    "        elif self.direction in \"negative\":\n",
    "            scores = (old_scores - new_scores).clip(0, 1)\n",
    "        else:\n",
    "            scores = new_scores\n",
    "        return scores\n",
    "        \n",
    "class PerformanceExtractor:\n",
    "    def __init__(self, dataset_name, scorer, model_id=None):\n",
    "        self.dataset_name = dataset_name\n",
    "        self.scorer = scorer\n",
    "        self.model_id = model_id\n",
    "        self.api = HfApi()\n",
    "        self.pipe = None\n",
    "        self.device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "        if self.model_id and not self.pipe:\n",
    "            self.create_pipe(self.model_id)\n",
    "\n",
    "        if not self.pipe:\n",
    "            self.find_model_for_dataset()\n",
    "\n",
    "    def create_pipe(self, model_id):\n",
    "        self.pipe = pipeline(\"text-classification\", \n",
    "                            model=model_id, \n",
    "                            device=self.device, \n",
    "                            padding=True, \n",
    "                            truncation=True,\n",
    "                            top_k=None)\n",
    "        return self.pipe\n",
    "\n",
    "    def find_model_for_dataset(self):\n",
    "        model_filter = ModelFilter(\n",
    "            task=\"text-classification\",\n",
    "            library=\"pytorch\",\n",
    "            # model_name=dataset_name,\n",
    "            trained_dataset=self.dataset_name)\n",
    "        model_id = next(iter(self.api.list_models(filter=model_filter)))\n",
    "        if model_id:\n",
    "            model_id = getattr(model_id, 'modelId')\n",
    "            print('Using ' + model_id + ' to support evaluation.')\n",
    "            self.create_pipe(model_id)\n",
    "\n",
    "    def extract_prediction_probabilities(self, inputs):\n",
    "        output = self.pipe(inputs)\n",
    "        return torch.stack([vectorize(o) for o in output])\n",
    "    \n",
    "    def extract_prediction_classes(self, inputs):\n",
    "        return torch.argmax(self.extract_prediction_probabilities(inputs), axis=1)\n",
    "\n",
    "    def __call__(self, inputs, targets, indices=None):\n",
    "        probs   = self.extract_prediction_probabilities(inputs)\n",
    "        targets = torch.tensor(targets)\n",
    "        return self.scorer(probs, targets, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71c6532",
   "metadata": {},
   "source": [
    "## FADA v2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7de8febd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_builder, dataset_config = \"glue\", \"sst2\"\n",
    "task_name = \"sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c3f69f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-11 21:32:14,776 | datasets.builder | WARNING | Found cached dataset glue (C:/Users/Fabrice/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(*dataset_config, split=\"train\")\n",
    "dataset = dataset.rename_column(\"sentence\", \"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "484683e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing Abbreviate\n",
      "setting max_outputs=1\n",
      "initializing AbbreviationInsertionEN\n",
      "setting max_outputs=1\n",
      "initializing AmericanizeBritishizeEnglish\n",
      "setting max_outputs=1\n",
      "initializing AntonymsSubstitute\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting max_outputs=1\n",
      "initializing AzertyQwertyCharsSwap\n",
      "setting max_outputs=1\n",
      "initializing ButterFingersPerturbation\n",
      "setting max_outputs=1\n",
      "initializing ChangeCharCase\n",
      "setting max_outputs=1\n",
      "initializing ChangeDateFormat\n",
      "setting max_outputs=1\n",
      "initializing CityNamesTransformation\n",
      "setting max_outputs=1\n",
      "initializing ColorTransformation\n",
      "setting max_outputs=1\n",
      "initializing ConcatMonolingual\n",
      "setting max_outputs=1\n",
      "initializing ContractionExpansions\n",
      "setting max_outputs=1\n",
      "initializing CorrectCommonMisspellings\n",
      "setting max_outputs=1\n",
      "initializing CountryStateAbbreviation\n",
      "setting max_outputs=1\n",
      "initializing DiacriticRemoval\n",
      "setting max_outputs=1\n",
      "initializing DiscourseMarkerSubstitution\n",
      "setting max_outputs=1\n",
      "initializing DyslexiaWordsSwap\n",
      "setting max_outputs=1\n",
      "initializing EnglishInflectionalVariation\n",
      "setting max_outputs=1\n",
      "initializing FillerWordAugmentation\n",
      "setting max_outputs=1\n",
      "initializing GenderSwap\n",
      "Loading Operation GenderSwap\n",
      "setting max_outputs=1\n",
      "initializing GreetingsAndFarewells\n",
      "setting max_outputs=1\n",
      "initializing HashtagGeneration\n",
      "setting max_outputs=1\n",
      "initializing LeetLetters\n",
      "setting max_outputs=1\n",
      "initializing MultilingualDictionaryBasedCodeSwitch\n",
      "setting max_outputs=1\n",
      "initializing PigLatin\n",
      "setting max_outputs=1\n",
      "initializing RandomDeletion\n",
      "setting max_outputs=1\n",
      "initializing RandomUpperPerturbation\n",
      "setting max_outputs=1\n",
      "initializing ReplaceNumericalValues\n",
      "setting max_outputs=1\n",
      "initializing SentenceAdjectivesAntonymsSwitch\n",
      "setting max_outputs=1\n",
      "initializing SentenceAuxiliaryNegationRemoval\n",
      "setting max_outputs=1\n",
      "initializing SentenceSubjectObjectSwitch\n",
      "setting max_outputs=1\n",
      "initializing SimpleCiphers\n",
      "setting max_outputs=1\n",
      "initializing Slangificator\n",
      "setting max_outputs=1\n",
      "initializing SpeechDisfluencyPerturbation\n",
      "setting max_outputs=1\n",
      "initializing SpellingTransformation\n",
      "setting max_outputs=1\n",
      "initializing SynonymInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting max_outputs=1\n",
      "initializing SynonymSubstitution\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Fabrice\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting max_outputs=1\n",
      "initializing TokenReplacement\n",
      "setting max_outputs=1\n",
      "initializing TransformerFill\n",
      "setting max_outputs=1\n",
      "initializing UnitConverter\n",
      "setting max_outputs=1\n",
      "initializing UseAcronyms\n",
      "setting max_outputs=1\n",
      "initializing VisualAttackLetters\n",
      "setting max_outputs=1\n",
      "initializing WeekdayMonthAbbreviation\n",
      "setting max_outputs=1\n",
      "initializing WhitespacePerturbation\n",
      "setting max_outputs=1\n",
      "initializing YesNoQuestionPerturbation\n",
      "setting max_outputs=1\n",
      "initializing YodaPerturbation\n",
      "setting max_outputs=1\n"
     ]
    }
   ],
   "source": [
    "nlaug_transforms = [\n",
    "    # EmojifyTransformation, # UnicodeDecodeError: 'charmap' codec can't decode byte 0x81 in position 220: character maps to <undefined>\n",
    "    SynonymInsertion,\n",
    "    # BackTranslation, # runtime too long (does not attempt to use gpu) (50.15s/ba w gpu)\n",
    "    # NounCompoundParaphraser, # does not return anything\n",
    "    DiacriticRemoval,\n",
    "    AzertyQwertyCharsSwap,\n",
    "    HashtagGeneration,\n",
    "    SpellingTransformation,\n",
    "    TokenReplacement,\n",
    "    SentenceAuxiliaryNegationRemoval,\n",
    "    UseAcronyms,\n",
    "    YodaPerturbation,\n",
    "    # FactiveVerbTransformation, # cannot find gender.male.names\n",
    "    # ProtaugmentDiverseParaphrase, # somewhat long runtime (29.63s/ba)\n",
    "    # ReplaceFinancialAmount,\n",
    "    AmericanizeBritishizeEnglish,\n",
    "    # PunctuationWithRules,  # runtime too long (does not appear to be gpu compatible)\n",
    "    # UrbanThesaurusSwap, # runtime too long (195.74s/ba)\n",
    "    FillerWordAugmentation,\n",
    "    SynonymSubstitution,\n",
    "    # StyleTransferParaphraser, # runtime too long (192.32s/ba)\n",
    "    RandomUpperPerturbation,\n",
    "    WeekdayMonthAbbreviation,\n",
    "    CityNamesTransformation,\n",
    "    # SentenceAdditions, # runtime too long (does not attempt to use gpu) # RuntimeError: CUDA out of memory. even at batch_size=1\n",
    "    ChangeDateFormat,\n",
    "    # TenseTransformation, # index out of range errors / NoneType errors if not using to_tense='past'\n",
    "    DyslexiaWordsSwap,\n",
    "    # GenderCultureDiverseName, # does not return anything\n",
    "    # GenderNeutralRewrite, # index out of range errors\n",
    "    # LostInTranslation, # IndexError: index out of range in self\n",
    "    AbbreviationInsertionEN,\n",
    "    RandomDeletion,\n",
    "    TransformerFill, # (3.20s/ba)\n",
    "    ConcatMonolingual,\n",
    "    CountryStateAbbreviation,\n",
    "    ButterFingersPerturbation,\n",
    "    # ReplaceAbbreviations, # (4.52s/ba)\n",
    "    Slangificator,\n",
    "    YesNoQuestionPerturbation,\n",
    "    GenderSwap,\n",
    "    # CloseHomophonesSwap, # runs slow, no gpu (221.04s/ba)\n",
    "    SimpleCiphers,\n",
    "    # ChangePersonNamedEntities, # does not return anything\n",
    "    GreetingsAndFarewells,\n",
    "    DiscourseMarkerSubstitution,\n",
    "    # Summarization,\n",
    "    VisualAttackLetters,\n",
    "    # SentenceReordering, # somwhat slow (41.14s/ba)\n",
    "    ChangeCharCase,\n",
    "    AntonymsSubstitute,\n",
    "    # MixTransliteration, # IndexError: list index out of range\n",
    "    # DifferentAbilityTransformation, UnboundLocalError: local variable 'text' referenced before assignment\n",
    "    Abbreviate,\n",
    "    # ReplaceHypernyms, # RuntimeError: CUDA out of memory. even at batch_size=1\n",
    "    # ReplaceHyponyms, # RuntimeError: CUDA out of memory. even at batch_size=1\n",
    "    # PhonemeSubstitution, # IndexError: list index out of range\n",
    "    # MultilingualLexiconPerturbation, FileNotFoundError: [Errno 2] No such file or directory: '/multilingual_lexicon_uncased.xz'\n",
    "    # MultilingualBackTranslation, # runtime too long (does not attempt to use gpu) (98.04s/ba w gpu)\n",
    "    UnitConverter,\n",
    "    SentenceAdjectivesAntonymsSwitch,\n",
    "    CorrectCommonMisspellings,\n",
    "    # NeuralParaphaserPerturbation, # somewhat slow (4.03s/ba)\n",
    "    SentenceSubjectObjectSwitch,\n",
    "    # NumericToWord, # InvalidOperation: [<class 'decimal.ConversionSyntax'>]\n",
    "    MultilingualDictionaryBasedCodeSwitch,\n",
    "    # DiverseParaphrase, # runtime too long (does not attempt to use gpu)\n",
    "    EnglishInflectionalVariation,\n",
    "    ReplaceNumericalValues,\n",
    "    SpeechDisfluencyPerturbation,\n",
    "    WhitespacePerturbation,\n",
    "    ContractionExpansions,\n",
    "    ColorTransformation,\n",
    "    # ContextualMeaningPerturbation, # runtime too long (not gpu compatible)\n",
    "    PigLatin,\n",
    "    LeetLetters,\n",
    "    # HashtagifyTransformation, # error: nothing to repeat at position 0\n",
    "    # CheckSrl, # RuntimeError: The size of tensor a (1127) must match the size of tensor b (512) at non-singleton dimension 1\n",
    "    # GeoNamesTransformation, # does not return anything\n",
    "]\n",
    "nlaug_transforms = [t for t in nlaug_transforms]\n",
    "nlaug_transforms = sorted(nlaug_transforms, key=lambda t: t.__name__)\n",
    "nlaug_transforms = [Transform(t, task_name=task_name) for t in nlaug_transforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e78098d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing AddNeutralEmoji with task_name='sentiment', return_metadata=True\n",
      "initializing ChangeHypernym with task_name='sentiment', return_metadata=True\n",
      "initializing ChangeHyponym with task_name='sentiment', return_metadata=True\n",
      "initializing ChangeLocation with task_name='sentiment', return_metadata=True\n",
      "initializing ChangeName with task_name='sentiment', return_metadata=True\n",
      "initializing ChangeNumber with task_name='sentiment', return_metadata=True\n",
      "initializing ChangeSynonym with task_name='sentiment', return_metadata=True\n",
      "initializing ContractContractions with task_name='sentiment', return_metadata=True\n",
      "initializing ExpandContractions with task_name='sentiment', return_metadata=True\n",
      "initializing HomoglyphSwap with task_name='sentiment', return_metadata=True\n",
      "initializing InsertPunctuationMarks with task_name='sentiment', return_metadata=True\n",
      "initializing RandomCharDel with task_name='sentiment', return_metadata=True\n",
      "initializing RandomCharInsert with task_name='sentiment', return_metadata=True\n",
      "initializing RandomCharSubst with task_name='sentiment', return_metadata=True\n",
      "initializing RandomCharSwap with task_name='sentiment', return_metadata=True\n",
      "initializing RandomInsertion with task_name='sentiment', return_metadata=True\n",
      "initializing RandomSwap with task_name='sentiment', return_metadata=True\n",
      "initializing RandomSwapQwerty with task_name='sentiment', return_metadata=True\n",
      "initializing RemoveNeutralEmoji with task_name='sentiment', return_metadata=True\n",
      "initializing WordDeletion with task_name='sentiment', return_metadata=True\n"
     ]
    }
   ],
   "source": [
    "blacklist = [\n",
    "    sibyl.Emojify,\n",
    "    sibyl.AddPositiveEmoji,\n",
    "    sibyl.AddNegativeEmoji,\n",
    "    sibyl.Demojify,\n",
    "    sibyl.RemovePositiveEmoji,\n",
    "    sibyl.RemoveNegativeEmoji,\n",
    "    sibyl.AddPositiveEmoji,\n",
    "    sibyl.AddNegativeEmoji,\n",
    "    sibyl.InsertPositivePhrase,\n",
    "    sibyl.InsertNegativePhrase,\n",
    "    sibyl.AddPositiveLink,\n",
    "    sibyl.AddNegativeLink,\n",
    "    sibyl.ImportLinkText,\n",
    "    sibyl.AddNegation,\n",
    "    sibyl.RemoveNegation,\n",
    "    sibyl.ChangeAntonym,\n",
    "    sibyl.ConceptMix,\n",
    "    sibyl.TextMix,\n",
    "    sibyl.SentMix,\n",
    "    sibyl.WordMix,\n",
    "    sibyl.Concept2Sentence\n",
    "]\n",
    "sibyl_transforms = [t for t in sibyl.TRANSFORMATIONS if t not in blacklist]\n",
    "sibyl_transforms = sorted(sibyl_transforms, key=lambda t: t.__name__)\n",
    "sibyl_transforms = [Transform(t, task_name=task_name) for t in sibyl_transforms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9d8f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = nlaug_transforms + sibyl_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06f96e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8fceb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_array_with_one_column(N, M, column_idx):\n",
    "    arr = np.zeros((N, M))\n",
    "    arr[:, column_idx] = 1\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85f3de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7be2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 09:11:20] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 09:11:20] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 09:11:20] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 09:11:20] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 09:11:20] No CPU tracking mode found. Falling back on CPU constant mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abbreviate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 09:11:22] CPU Model on constant consumption mode: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n",
      "[codecarbon INFO @ 09:11:22] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 09:11:22]   Platform system: Windows-10-10.0.22621-SP0\n",
      "[codecarbon INFO @ 09:11:22]   Python version: 3.8.16\n",
      "[codecarbon INFO @ 09:11:22]   CodeCarbon version: 2.2.3\n",
      "[codecarbon INFO @ 09:11:22]   Available RAM : 15.912 GB\n",
      "[codecarbon INFO @ 09:11:22]   CPU count: 12\n",
      "[codecarbon INFO @ 09:11:22]   CPU model: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz\n",
      "[codecarbon INFO @ 09:11:22]   GPU count: 1\n",
      "[codecarbon INFO @ 09:11:22]   GPU model: 1 x NVIDIA GeForce RTX 2060\n",
      "[codecarbon INFO @ 09:11:37] Energy consumed for RAM : 0.000025 kWh. RAM Power : 5.967082500457764 W\n",
      "[codecarbon INFO @ 09:11:37] Energy consumed for all GPUs : 0.000126 kWh. Total GPU Power : 30.078 W\n",
      "[codecarbon INFO @ 09:11:38] Energy consumed for all CPUs : 0.000101 kWh. Total CPU Power : 22.5 W\n",
      "[codecarbon INFO @ 09:11:38] 0.000252 kWh of electricity used since the beginning.\n"
     ]
    }
   ],
   "source": [
    "num_examples = len(dataset)\n",
    "num_transforms = len(transforms)\n",
    "\n",
    "results = {}\n",
    "for i, t in enumerate(transforms):\n",
    "    \n",
    "    t_name = t.transform_class.__name__\n",
    "    print(t_name)\n",
    "    \n",
    "    policy = generate_array_with_one_column(num_examples, num_transforms, i)\n",
    "    \n",
    "    tracker = EmissionsTracker(project_name=f\"{dataset_builder}.{dataset_config}.{t_name}.num_rows={len(test_dataset)}\")\n",
    "\n",
    "    tracker.start()\n",
    "    start_time = time.time()\n",
    "    augmenter = Augmenter(dataset=test_dataset, \n",
    "                          transforms=transforms, \n",
    "                          transform_probabilities=policy, \n",
    "                          num_augmentations_per_record=1,\n",
    "                          num_transforms_to_apply=1,\n",
    "                          batch_size=10, \n",
    "                          keep_originals=True)\n",
    "    aug_dataset = augmenter.augment()\n",
    "    run_time = time.time() - start_time\n",
    "    emissions = tracker.stop()\n",
    "    \n",
    "    out = {\"run_time\":run_time, \"applicability_rate\":np.mean(aug_dataset[\"is_changed\"]), \"emissions\": emissions}\n",
    "    \n",
    "    print(out)\n",
    "    \n",
    "    results[t.transform_class.__name__] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fbd8140e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2383116014076\n",
      "20.45435383029056\n",
      "0.7243476210267108\n"
     ]
    }
   ],
   "source": [
    "augmenter_df = pd.DataFrame(results).T.reset_index().rename(columns={\"index\":\"transform\"})\n",
    "augmenter_df[\"wasted_time\"] = augmenter_df[\"run_time\"] * (1-augmenter_df[\"applicability_rate\"])\n",
    "print(augmenter_df[\"run_time\"].mean())\n",
    "print(augmenter_df[\"wasted_time\"].mean())\n",
    "print(augmenter_df[\"wasted_time\"].mean() / augmenter_df[\"run_time\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "93b41b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "emissions_df = pd.read_csv(\"./emissions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "28b69440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transform</th>\n",
       "      <th>applicability_rate</th>\n",
       "      <th>wasted_time</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>project_name</th>\n",
       "      <th>run_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>emissions</th>\n",
       "      <th>emissions_rate</th>\n",
       "      <th>cpu_power</th>\n",
       "      <th>...</th>\n",
       "      <th>cpu_count</th>\n",
       "      <th>cpu_model</th>\n",
       "      <th>gpu_count</th>\n",
       "      <th>gpu_model</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>ram_total_size</th>\n",
       "      <th>tracking_mode</th>\n",
       "      <th>on_cloud</th>\n",
       "      <th>pue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbreviate</td>\n",
       "      <td>0.500</td>\n",
       "      <td>14.435126</td>\n",
       "      <td>2023-06-12T01:24:30</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>c88609b6-586c-4a6c-b0a8-93c387e50cd0</td>\n",
       "      <td>28.921270</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AbbreviationInsertionEN</td>\n",
       "      <td>0.270</td>\n",
       "      <td>20.188816</td>\n",
       "      <td>2023-06-12T01:24:59</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>b6a6137d-31e1-4080-82cc-14379ca7c449</td>\n",
       "      <td>27.714384</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AmericanizeBritishizeEnglish</td>\n",
       "      <td>0.500</td>\n",
       "      <td>14.763894</td>\n",
       "      <td>2023-06-12T01:25:31</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>dc8a40a0-27b9-4852-b666-a1161c706b36</td>\n",
       "      <td>29.575989</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AntonymsSubstitute</td>\n",
       "      <td>0.500</td>\n",
       "      <td>14.462993</td>\n",
       "      <td>2023-06-12T01:26:02</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>cb6fc5ac-47b8-4fdd-b5da-945266602c86</td>\n",
       "      <td>28.970264</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AzertyQwertyCharsSwap</td>\n",
       "      <td>0.045</td>\n",
       "      <td>27.971924</td>\n",
       "      <td>2023-06-12T01:26:33</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>135c2936-9f84-493b-9018-e50946a46930</td>\n",
       "      <td>29.338117</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>RandomInsertion</td>\n",
       "      <td>0.480</td>\n",
       "      <td>14.279255</td>\n",
       "      <td>2023-06-12T01:55:25</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>0b06b309-159f-441e-afd8-49734d4f3263</td>\n",
       "      <td>27.506217</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>RandomSwap</td>\n",
       "      <td>0.500</td>\n",
       "      <td>13.459566</td>\n",
       "      <td>2023-06-12T01:55:54</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>0df8f044-4502-4983-a30d-c7c1c4ab8616</td>\n",
       "      <td>26.962872</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RandomSwapQwerty</td>\n",
       "      <td>0.395</td>\n",
       "      <td>16.672739</td>\n",
       "      <td>2023-06-12T01:56:24</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>b8558d6a-db95-415e-85b0-ca4f746e9ea2</td>\n",
       "      <td>27.598097</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>RemoveNeutralEmoji</td>\n",
       "      <td>0.000</td>\n",
       "      <td>26.419902</td>\n",
       "      <td>2023-06-12T01:56:52</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>8d546762-4919-440a-869b-70b6431ff968</td>\n",
       "      <td>26.462041</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>WordDeletion</td>\n",
       "      <td>0.480</td>\n",
       "      <td>14.154684</td>\n",
       "      <td>2023-06-12T01:57:22</td>\n",
       "      <td>codecarbon</td>\n",
       "      <td>d1932d33-e543-46ad-9a0e-206120ff0db2</td>\n",
       "      <td>27.265930</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>22.5</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz</td>\n",
       "      <td>1</td>\n",
       "      <td>1 x NVIDIA GeForce RTX 2060</td>\n",
       "      <td>-97.822</td>\n",
       "      <td>37.751</td>\n",
       "      <td>15.91222</td>\n",
       "      <td>machine</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows  34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       transform  applicability_rate  wasted_time  \\\n",
       "0                     Abbreviate               0.500    14.435126   \n",
       "1        AbbreviationInsertionEN               0.270    20.188816   \n",
       "2   AmericanizeBritishizeEnglish               0.500    14.763894   \n",
       "3             AntonymsSubstitute               0.500    14.462993   \n",
       "4          AzertyQwertyCharsSwap               0.045    27.971924   \n",
       "..                           ...                 ...          ...   \n",
       "61               RandomInsertion               0.480    14.279255   \n",
       "62                    RandomSwap               0.500    13.459566   \n",
       "63              RandomSwapQwerty               0.395    16.672739   \n",
       "64            RemoveNeutralEmoji               0.000    26.419902   \n",
       "65                  WordDeletion               0.480    14.154684   \n",
       "\n",
       "              timestamp project_name                                run_id  \\\n",
       "0   2023-06-12T01:24:30   codecarbon  c88609b6-586c-4a6c-b0a8-93c387e50cd0   \n",
       "1   2023-06-12T01:24:59   codecarbon  b6a6137d-31e1-4080-82cc-14379ca7c449   \n",
       "2   2023-06-12T01:25:31   codecarbon  dc8a40a0-27b9-4852-b666-a1161c706b36   \n",
       "3   2023-06-12T01:26:02   codecarbon  cb6fc5ac-47b8-4fdd-b5da-945266602c86   \n",
       "4   2023-06-12T01:26:33   codecarbon  135c2936-9f84-493b-9018-e50946a46930   \n",
       "..                  ...          ...                                   ...   \n",
       "61  2023-06-12T01:55:25   codecarbon  0b06b309-159f-441e-afd8-49734d4f3263   \n",
       "62  2023-06-12T01:55:54   codecarbon  0df8f044-4502-4983-a30d-c7c1c4ab8616   \n",
       "63  2023-06-12T01:56:24   codecarbon  b8558d6a-db95-415e-85b0-ca4f746e9ea2   \n",
       "64  2023-06-12T01:56:52   codecarbon  8d546762-4919-440a-869b-70b6431ff968   \n",
       "65  2023-06-12T01:57:22   codecarbon  d1932d33-e543-46ad-9a0e-206120ff0db2   \n",
       "\n",
       "     duration  emissions  emissions_rate  cpu_power  ...  cpu_count  \\\n",
       "0   28.921270   0.000174        0.000006       22.5  ...         12   \n",
       "1   27.714384   0.000166        0.000006       22.5  ...         12   \n",
       "2   29.575989   0.000180        0.000006       22.5  ...         12   \n",
       "3   28.970264   0.000177        0.000006       22.5  ...         12   \n",
       "4   29.338117   0.000179        0.000006       22.5  ...         12   \n",
       "..        ...        ...             ...        ...  ...        ...   \n",
       "61  27.506217   0.000107        0.000004       22.5  ...         12   \n",
       "62  26.962872   0.000103        0.000004       22.5  ...         12   \n",
       "63  27.598097   0.000107        0.000004       22.5  ...         12   \n",
       "64  26.462041   0.000102        0.000004       22.5  ...         12   \n",
       "65  27.265930   0.000105        0.000004       22.5  ...         12   \n",
       "\n",
       "                                   cpu_model  gpu_count  \\\n",
       "0   Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "1   Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "2   Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "3   Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "4   Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "..                                       ...        ...   \n",
       "61  Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "62  Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "63  Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "64  Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "65  Intel(R) Core(TM) i7-9750H CPU @ 2.60GHz          1   \n",
       "\n",
       "                      gpu_model  longitude  latitude ram_total_size  \\\n",
       "0   1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "1   1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "2   1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "3   1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "4   1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "..                          ...        ...       ...            ...   \n",
       "61  1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "62  1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "63  1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "64  1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "65  1 x NVIDIA GeForce RTX 2060    -97.822    37.751       15.91222   \n",
       "\n",
       "   tracking_mode  on_cloud  pue  \n",
       "0        machine         N  1.0  \n",
       "1        machine         N  1.0  \n",
       "2        machine         N  1.0  \n",
       "3        machine         N  1.0  \n",
       "4        machine         N  1.0  \n",
       "..           ...       ...  ...  \n",
       "61       machine         N  1.0  \n",
       "62       machine         N  1.0  \n",
       "63       machine         N  1.0  \n",
       "64       machine         N  1.0  \n",
       "65       machine         N  1.0  \n",
       "\n",
       "[66 rows x 34 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([augmenter_df[[\"transform\", \"applicability_rate\", \"wasted_time\"]], emissions_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98439eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
