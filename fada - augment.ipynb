{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1e616ab",
   "metadata": {},
   "source": [
    "# Feature-Aware Data Augmentation\n",
    "\n",
    "Augmentation policies to consider:\n",
    "- Simple policy randomly sampling of n transforms \n",
    "- Constrained sampling policy with a blacklist of transforms to avoid \n",
    "- Feature-aware augmentation policy where transforms are picked based on their (transform, feature) behavior\n",
    "\n",
    "Feature-Aware Data Augmentation (FADA)\n",
    "1. Extract AMRs for all examples in the dataset\n",
    "2. Create feature matrix by checking for the presence of different features in the text\n",
    "3. Create sampling probabilities based on the feature vector\n",
    "    - Select subsets of the dataset based on the presence / absence of the feature\n",
    "    - Test a model already fine-tuned on the target dataset\n",
    "    - Calculate disparate impact of each (feature, transform) pair\n",
    "    - Normalize disparate impact into a probability vector for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be0cdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "# amrs\n",
    "import amrlib\n",
    "import penman\n",
    "\n",
    "# transform\n",
    "import sibyl\n",
    "import torch\n",
    "import inspect\n",
    "import random\n",
    "from functools import partial\n",
    "\n",
    "# eval pipeline\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from huggingface_hub import HfApi, ModelFilter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sibyl import acc_at_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52274480",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.use_deterministic_algorithms(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbc3deeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self, transform_class, num_outputs=1, task_name=\"sentiment\"):\n",
    "        self.transform_class = transform_class\n",
    "        self.num_outputs = num_outputs\n",
    "        self.task_name = task_name\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.intakes_target = False\n",
    "        self.is_batched = False\n",
    "        \n",
    "        # setting class attributes\n",
    "        if 'to_tense' in inspect.signature(self.transform_class).parameters:\n",
    "            print(\"initializing class with to_tense='past'\") # future & random don't work\n",
    "            self.transform_instance = self.transform_class(to_tense=\"past\")\n",
    "        elif 'source_lang' in inspect.signature(self.transform_class).parameters:\n",
    "            print(\"initializing class with source_lang='es'\") \n",
    "            self.transform_instance = self.transform_class(source_lang=\"es\")\n",
    "        elif 'task_name' in inspect.signature(self.transform_class).parameters:\n",
    "            print(f\"initializing class with task_name='{task_name}', return_metadata=True\") \n",
    "            self.transform_instance = self.transform_class(task_name=self.task_name, return_metadata=True)\n",
    "        # elif isinstance(self.transform_class, LostInTranslation):\n",
    "        #     self.transform_instance = self.transform_class(device=0)\n",
    "        else:\n",
    "            self.transform_instance = self.transform_class()\n",
    "        \n",
    "        # setting instance attributes\n",
    "        if hasattr(self.transform_instance, \"max_outputs\"):\n",
    "            print(f\"setting max_outputs={self.num_outputs}\")\n",
    "            self.transform_instance.max_outputs = self.num_outputs\n",
    "        if hasattr(self.transform_instance, \"max_paraphrases\"):\n",
    "            print(f\"setting max_paraphrases={self.num_outputs}\")\n",
    "            self.transform_instance.max_paraphrases = self.num_outputs\n",
    "        if hasattr(self.transform_instance, \"device\"):\n",
    "            if self.transform_instance.device is None or self.transform_instance.device == 'cpu':\n",
    "                print(f\"setting device={self.device}\")\n",
    "                self.transform_instance.device = self.device\n",
    "        \n",
    "        # selecting the transformation function\n",
    "        if hasattr(self.transform_class, \"generate\"):\n",
    "            self.transform_fn = self.transform_instance.generate\n",
    "        if hasattr(self.transform_class, \"augment\"):\n",
    "            self.transform_fn = self.transform_instance.augment\n",
    "        if hasattr(self.transform_class, \"transform_batch\"):\n",
    "            self.transform_fn = self.transform_instance.transform_batch\n",
    "            self.intakes_target = True\n",
    "            self.is_batched = True\n",
    "            \n",
    "    def synced_shuffle(self, list1, list2):\n",
    "        # Shuffle two lists with same order\n",
    "        # Using zip() + * operator + shuffle()\n",
    "        temp = list(zip(list1, list2))\n",
    "        random.shuffle(temp)\n",
    "        res1, res2 = zip(*temp)\n",
    "        # res1 and res2 come out as tuples, and so must be converted to lists.\n",
    "        res1, res2 = list(res1), list(res2)\n",
    "        return res1, res2\n",
    "            \n",
    "    def apply(self, texts, labels=None):\n",
    "        if self.intakes_target:\n",
    "            if self.is_batched:\n",
    "                new_texts, new_labels = self.transform_fn((texts, labels))\n",
    "            else:\n",
    "                new_texts, new_labels = [], []\n",
    "                for t, l in zip(texts, labels):\n",
    "                    new_t, new_l = self.transform_fn(t, l)\n",
    "                    new_texts.append(new_t)\n",
    "                    new_labels.extend([new_l] * len(new_t))\n",
    "        else:\n",
    "            if self.is_batched:\n",
    "                new_texts = self.transform_fn((texts))\n",
    "                new_texts = labels\n",
    "            else:\n",
    "                new_texts, new_labels = [], []\n",
    "                for t, l in zip(texts, labels):\n",
    "                    new_t = self.transform_fn(t)\n",
    "                    if len(new_t) > self.num_outputs:\n",
    "                        new_t = new_t[:self.num_outputs]\n",
    "                    new_texts.extend(new_t)\n",
    "                    new_labels.extend([l] * len(new_t))\n",
    "                    \n",
    "        # post processing since some transformations add/remove more new outputs than expected\n",
    "        if len(new_texts) == 0:\n",
    "            print(\"no new_texts, substituting original texts...\")\n",
    "            new_texts = texts\n",
    "        if len(new_labels) == 0:\n",
    "            print(\"no new_labels, substituting original labels...\")\n",
    "            new_labels = labels\n",
    "        new_texts, new_labels = self.synced_shuffle(new_texts, new_labels)\n",
    "        \n",
    "        expected_len = len(texts) * self.num_outputs\n",
    "        new_texts = new_texts[:expected_len]\n",
    "        new_labels = new_labels[:expected_len]\n",
    "        \n",
    "        return new_texts, new_labels\n",
    "    \n",
    "def augment_data(batch, transform, keep_originals=True):\n",
    "    new_texts, new_labels = [], []\n",
    "    for text, label in zip(batch['text'], batch['label']):\n",
    "        new_text, new_label = transform.apply([text], [label])\n",
    "        new_texts.extend(new_text)\n",
    "        new_labels.extend(new_label)\n",
    "    if keep_originals:\n",
    "        return {\"text\": batch['text'] + new_texts, \"label\": batch['label'] + new_labels}\n",
    "    else:\n",
    "        return {\"text\": new_texts, \"label\": new_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2b9029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes =============================================================\n",
    "\n",
    "def contains_imperative(g): return g.contains_attribute(\"imperative\")\n",
    "def contains_exlamation(g): return g.contains_attribute(\"expressive\")\n",
    "def contains_negation(g):   return g.contains_attribute(\"-\")\n",
    "\n",
    "# concepts ===============================================================\n",
    "\n",
    "def contains_conjunctions(g):         return g.contains_concept([\"and\", \"or\", \"contrast-01\", \"either\", \"neither\"])\n",
    "def contains_interrogative_clause(g): return g.contains_concept(\"truth-value\")\n",
    "def contains_question(g):             return g.contains_concept([\"amr-unknown\", \"amr-choice\"])\n",
    "\n",
    "# roles ==================================================================\n",
    "\n",
    "def contains_coreferences(g): return any(r for r in g.amr_text.split() if r in ['i', 'you', 'he', 'she', 'it', 'we', 'they'])\n",
    "def contains_number(g):       return any(a for a in g.graph.attributes() if a.target.isnumeric())\n",
    "\n",
    "def contains_accompanier(g):  return g.contains_role(':accompanier')\n",
    "def contains_age(g):          return g.contains_role(':age')\n",
    "def contains_beneficiary(g):  return g.contains_role(':beneficiary')\n",
    "def contains_concession(g):   return g.contains_role(':concession')\n",
    "def contains_condition(g):    return g.contains_role(':condition')\n",
    "def contains_consist_of(g):   return any(r for r in g.amr_text.split() if r in [':consist-of'])\n",
    "def contains_degree(g):       return g.contains_role(':degree')\n",
    "def contains_destination(g):  return g.contains_role(':destination')\n",
    "def contains_direction(g):    return g.contains_role(':direction')\n",
    "def contains_domain(g):       return g.contains_role(':domain')\n",
    "def contains_duration(g):     return g.contains_role(':duration')\n",
    "def contains_example(g):      return g.contains_role(':example')\n",
    "def contains_extent(g):       return g.contains_role(':extent')\n",
    "def contains_frequency(g):    return g.contains_role(':frequency')\n",
    "def contains_instrument(g):   return g.contains_role(':instrument')\n",
    "# def contains_li(g):           return g.contains_role(':li')\n",
    "def contains_location(g):     return g.contains_role(':location')\n",
    "def contains_manner(g):       return g.contains_role(':manner')\n",
    "def contains_medium(g):       return g.contains_role(':medium')\n",
    "def contains_mod(g):          return g.contains_role(':mod')\n",
    "def contains_mode(g):         return any(a for a in g.graph.attributes() if \":mode\" in a.role)\n",
    "def contains_name(g):         return g.contains_role(':name')\n",
    "def contains_ord(g):          return g.contains_role(':ord')\n",
    "def contains_part(g):         return g.contains_role(':part')\n",
    "def contains_path(g):         return g.contains_role(':path')\n",
    "def contains_polarity(g):     return g.contains_role(':polarity')\n",
    "def contains_polite(g):       return any(r for r in g.amr_text.split() if r in [':polite'])\n",
    "def contains_poss(g):         return g.contains_role(':poss')\n",
    "def contains_purpose(g):      return g.contains_role(':purpose')\n",
    "def contains_quant(g):        return g.contains_role(':quant')\n",
    "def contains_range(g):        return g.contains_role(':range')\n",
    "def contains_scale(g):        return g.contains_role(':scale')\n",
    "def contains_source(g):       return g.contains_role(':source')\n",
    "def contains_subevent(g):     return g.contains_role(':subevent')\n",
    "def contains_time(g):         return g.contains_role(':time')\n",
    "def contains_topic(g):        return g.contains_role(':topic')\n",
    "def contains_unit(g):         return g.contains_role(':unit')\n",
    "# def contains_value(g):        return g.contains_role(':value')\n",
    "def contains_wiki(g):         return g.contains_role(':wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52b32030",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMRGraph:\n",
    "    def __init__(self, amr):\n",
    "        self.graph = penman.decode(amr) if not isinstance(amr, penman.graph.Graph) else amr\n",
    "        self.amr_text = penman.encode(self.graph)\n",
    "\n",
    "    def contains_concept(self, concepts):\n",
    "        \"\"\"\n",
    "        Concepts are nodes / instances in the AMR graph.\n",
    "        \"\"\"\n",
    "        if not isinstance(concepts, list): concepts = [concepts]\n",
    "        graph_concepts = [t.target for t in self.graph.instances()]\n",
    "        return any(c for c in graph_concepts if c in concepts)\n",
    "\n",
    "    def contains_role(self, roles):\n",
    "        \"\"\"\n",
    "        Roles are edges in the AMR graph.\n",
    "        \"\"\"\n",
    "        if not isinstance(roles, list): roles = [roles]\n",
    "        graph_roles = [e.role for e in self.graph.edges()]\n",
    "        return any(r for r in graph_roles if r in roles)\n",
    "\n",
    "    def contains_attribute(self, attributes):\n",
    "        \"\"\"\n",
    "        Attributes are properties of concept nodes, i.e. relationships to \n",
    "        constant values.\n",
    "        \"\"\"\n",
    "        if not isinstance(attributes, list): attributes = [attributes]\n",
    "        graph_attrs = [a.target for a in self.graph.attributes()]\n",
    "        return any(a for a in graph_attrs if a in attributes)\n",
    "    \n",
    "class AMRGraphManager:\n",
    "    def __init__(self):\n",
    "        self.graphs_save_path = \"amr_graphs.pkl\"\n",
    "        self.feature_matrix_save_path = \"feature_matrix.npy\"\n",
    "        \n",
    "        if os.path.exists(self.graphs_save_path):\n",
    "            self.load_graphs()\n",
    "        else:\n",
    "            self.graphs = None\n",
    "            self.model = None\n",
    "            \n",
    "        if os.path.exists(self.feature_matrix_save_path):\n",
    "            self.load_feature_matrix()\n",
    "        else:\n",
    "            self.feature_matrix = None\n",
    "        \n",
    "        self.featurizers = [    \n",
    "            contains_imperative,contains_exlamation,contains_negation,\n",
    "            contains_conjunctions,contains_interrogative_clause,contains_question,\n",
    "            contains_coreferences,contains_number,contains_accompanier,\n",
    "            contains_age,contains_beneficiary,contains_concession,\n",
    "            contains_condition,contains_consist_of,contains_degree,\n",
    "            contains_destination,contains_direction,contains_domain,\n",
    "            contains_duration,contains_example,contains_extent,\n",
    "            contains_frequency,contains_instrument,contains_location,\n",
    "            contains_manner,contains_medium,contains_mod,\n",
    "            contains_mode,contains_name,contains_ord,\n",
    "            contains_part,contains_path,contains_polarity,\n",
    "            contains_polite,contains_poss,contains_purpose,\n",
    "            contains_quant,contains_range,contains_scale,\n",
    "            contains_source,contains_subevent,contains_time,\n",
    "            contains_topic,contains_unit,contains_wiki\n",
    "        ]\n",
    "    \n",
    "    def load_model(self, max_sent_len=128):\n",
    "        self.model = amrlib.load_stog_model(max_sent_len=max_sent_len)\n",
    "    \n",
    "    def text_to_amr(self, texts):\n",
    "        if self.model is None:\n",
    "            self.load_model()\n",
    "        if self.graphs is None:\n",
    "            amr_penmans = self.model.parse_sents(texts, add_metadata=False, disable_progress=False)\n",
    "            amr_graphs  = [AMRGraph(p) for p in amr_penmans]\n",
    "            self.graphs = amr_graphs\n",
    "        return self.graphs\n",
    "    \n",
    "    def generate_feature_matrix(self, graphs):\n",
    "        if self.feature_matrix is None:\n",
    "            feature_matrix = []\n",
    "            for g in graphs:\n",
    "                feature_vector = []\n",
    "                for f in self.featurizers:\n",
    "                    feature_vector.append(f(g))\n",
    "                feature_matrix.append(feature_vector)\n",
    "            self.feature_matrix = np.array(feature_matrix, dtype=np.bool_)\n",
    "        return self.feature_matrix\n",
    "\n",
    "    def save_graphs(self):\n",
    "        with open(self.graphs_save_path, \"wb\") as f:\n",
    "            pickle.dump(self.graphs, f)\n",
    "            \n",
    "    def load_graphs(self):\n",
    "        with open(self.graphs_save_path, \"rb\") as f:\n",
    "            self.graphs = pickle.load(f)\n",
    "\n",
    "    def save_feature_matrix(self):\n",
    "        np.save(self.feature_matrix_save_path, self.feature_matrix)\n",
    "            \n",
    "    def load_feature_matrix(self):\n",
    "        self.feature_matrix = np.load(self.feature_matrix_save_path)\n",
    "        \n",
    "    def locate_feature_idx(self, featurizer_id, top_n=3, has_feature=True):\n",
    "    \n",
    "        feature_column = self.feature_matrix[:, featurizer_id]\n",
    "        if not has_feature:\n",
    "            feature_column = np.invert(feature_column)\n",
    "        targets = np.where(feature_column)[0]\n",
    "\n",
    "        num_examples = len(targets)\n",
    "        if num_examples == 0:\n",
    "            print(f\"0 (not {top_n}) \\t : {self.featurizers[featurizer_id].__name__}.\")\n",
    "            return []\n",
    "        elif num_examples < top_n:\n",
    "            print(f\"{num_examples} (not {top_n}) \\t : {self.featurizers[featurizer_id].__name__}.\")\n",
    "            top_n = num_examples\n",
    "\n",
    "        # trying to find texts that don't have a lot of other \n",
    "        # competing features which may confound our results\n",
    "        competing_features = self.feature_matrix[targets].sum(axis=1)\n",
    "        sorted_idx = np.argsort(competing_features)\n",
    "\n",
    "        return targets[sorted_idx][:top_n]\n",
    "    \n",
    "    def construct_feature_datasets(self, dataset, dataset_size=1000):\n",
    "        feature_datasets = {}\n",
    "        for i, featurizer in enumerate(graph_manager.featurizers):\n",
    "\n",
    "            feature_present_idx = graph_manager.locate_feature_idx(i, dataset_size, has_feature=True)\n",
    "            feature_absent_idx  = graph_manager.locate_feature_idx(i, len(feature_present_idx), has_feature=False)\n",
    "\n",
    "            feature_present_dataset = dataset.select(feature_present_idx)\n",
    "            feature_absent_dataset  = dataset.select(feature_absent_idx)\n",
    "\n",
    "            feature_datasets[featurizer.__name__] = {\n",
    "                \"feature_present_idx\"     : feature_present_idx,\n",
    "                \"feature_absent_idx\"      : feature_absent_idx,\n",
    "                \"feature_present_dataset\" : feature_present_dataset,\n",
    "                \"feature_absent_dataset\"  : feature_absent_dataset,\n",
    "            }\n",
    "        return feature_datasets\n",
    "            \n",
    "def percent_dataset_changed(d1, d2):\n",
    "    return sum([t1['text'] != t2['text'] for t1, t2 in zip(d1, d2)]) / len(d1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a1af8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(predictions, labels):\n",
    "    if not isinstance(labels, np.ndarray):\n",
    "        labels = np.array(labels)\n",
    "    if len(labels.shape) > 1:\n",
    "        acc = acc_at_k(labels, predictions, k=2)       \n",
    "    else:\n",
    "        acc = accuracy_score(labels, np.argmax(predictions, -1))\n",
    "    return acc\n",
    "\n",
    "def vectorize(output):\n",
    "    sorted_output = sorted(output, key=lambda d: d['label']) \n",
    "    probs = np.array([d['score'] for d in sorted_output])\n",
    "    return probs\n",
    "\n",
    "class EvalPipeline:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.api = HfApi()\n",
    "        self.pipe = None\n",
    "        self.device = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "    def find_model_for_dataset(self, dataset_name):\n",
    "        \n",
    "        model_filter = ModelFilter(\n",
    "            task=\"text-classification\",\n",
    "            library=\"pytorch\",\n",
    "            # model_name=dataset_name,\n",
    "            trained_dataset=dataset_name)\n",
    "\n",
    "        model_id = next(iter(self.api.list_models(filter=model_filter)))\n",
    "\n",
    "        if model_id:\n",
    "            model_id = getattr(model_id, 'modelId')\n",
    "            print('Using ' + model_id + ' to support evaluation.')\n",
    "            self.pipe = pipeline(\"text-classification\", \n",
    "                                 model=model_id, \n",
    "                                 device=self.device, \n",
    "                                 padding=True, \n",
    "                                 truncation=True,\n",
    "                                 top_k=None)\n",
    "\n",
    "    def extract_prediction_probabilities(self, dataset):\n",
    "        output = self.pipe(dataset['text'])\n",
    "        return np.stack([vectorize(o) for o in output])\n",
    "    \n",
    "    def extract_prediction_classes(self, dataset):\n",
    "        return np.argmax(self.extract_prediction_probabilities(dataset), axis=1)\n",
    "    \n",
    "    def calculate_accuracy(self, dataset):\n",
    "        preds = self.extract_prediction_probabilities(dataset)\n",
    "        acc = compute_accuracy(preds, dataset[\"label\"])\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9984dcaa",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f36fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (C:/Users/Fabrice/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"glue\", \"sst2\", split=\"train\") # .select(range(100))\n",
    "dataset = dataset.rename_column(\"sentence\", \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381afb8f",
   "metadata": {},
   "source": [
    "## Extract AMRs + Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9989be6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_manager = AMRGraphManager()\n",
    "\n",
    "# extract amr graphs\n",
    "if graph_manager.graphs is None:\n",
    "    graphs = graph_manager.text_to_amr(dataset[\"sentence\"])\n",
    "    graph_manager.save_graphs()\n",
    "\n",
    "# compute boolean feature matrix\n",
    "if graph_manager.feature_matrix is None:\n",
    "    feature_matrix = graph_manager.generate_feature_matrix(graphs)\n",
    "    graph_manager.save_feature_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d868ed",
   "metadata": {},
   "source": [
    "## Construct datasets with / without features present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a9ab588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557 (not 1000) \t : contains_exlamation.\n",
      "78 (not 1000) \t : contains_interrogative_clause.\n",
      "709 (not 1000) \t : contains_question.\n",
      "622 (not 1000) \t : contains_coreferences.\n",
      "330 (not 1000) \t : contains_accompanier.\n",
      "200 (not 1000) \t : contains_age.\n",
      "532 (not 1000) \t : contains_beneficiary.\n",
      "742 (not 1000) \t : contains_concession.\n",
      "608 (not 1000) \t : contains_condition.\n",
      "888 (not 1000) \t : contains_consist_of.\n",
      "132 (not 1000) \t : contains_destination.\n",
      "577 (not 1000) \t : contains_direction.\n",
      "924 (not 1000) \t : contains_duration.\n",
      "251 (not 1000) \t : contains_example.\n",
      "92 (not 1000) \t : contains_extent.\n",
      "205 (not 1000) \t : contains_instrument.\n",
      "288 (not 1000) \t : contains_medium.\n",
      "650 (not 1000) \t : contains_ord.\n",
      "238 (not 1000) \t : contains_path.\n",
      "247 (not 1000) \t : contains_polarity.\n",
      "10 (not 1000) \t : contains_polite.\n",
      "7 (not 1000) \t : contains_range.\n",
      "1 (not 1000) \t : contains_scale.\n",
      "446 (not 1000) \t : contains_source.\n",
      "89 (not 1000) \t : contains_subevent.\n",
      "0 (not 1000) \t : contains_wiki.\n"
     ]
    }
   ],
   "source": [
    "dataset_size = 1000\n",
    "\n",
    "feature_datasets = {}\n",
    "for i, featurizer in enumerate(graph_manager.featurizers):\n",
    "    \n",
    "    feature_present_idx = graph_manager.locate_feature_idx(i, dataset_size, has_feature=True)\n",
    "    feature_absent_idx  = graph_manager.locate_feature_idx(i, len(feature_present_idx), has_feature=False)\n",
    "    \n",
    "    feature_present_dataset = dataset.select(feature_present_idx)\n",
    "    feature_absent_dataset  = dataset.select(feature_absent_idx)\n",
    "    \n",
    "    feature_datasets[featurizer.__name__] = {\n",
    "        \"feature_present_idx\"     : feature_present_idx,\n",
    "        \"feature_absent_idx\"      : feature_absent_idx,\n",
    "        \"feature_present_dataset\" : feature_present_dataset,\n",
    "        \"feature_absent_dataset\"  : feature_absent_dataset,\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afde78c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains_imperative': {'feature_present_idx': array([    0, 37052, 37166, 63623, 37169, 19311, 59715, 63680, 10356,\n",
       "         10324, 37512, 37564, 52061, 10175, 51849, 37589, 63782, 37658,\n",
       "          9933, 64067, 37737, 28958, 19471,  9748, 55875, 63725, 59905,\n",
       "         10805, 36871, 36271, 11942, 29172, 11918, 29081, 11859, 63050,\n",
       "         36426, 29070, 11631, 23682, 11552, 63208, 55863, 11316, 36727,\n",
       "         11090, 63440, 11060, 11034, 11031, 52135, 11007, 36776, 10950,\n",
       "          9708, 52179, 59438, 64190, 39316, 28143, 39468, 28130, 20241,\n",
       "         59341, 27976, 39812, 20329, 54979, 64563, 56161,  8024, 51100,\n",
       "         20511, 40234, 40412, 64685,  7724, 56389, 27566, 40555, 56475,\n",
       "         40668, 40037, 28186, 51399, 56031, 38109, 19605,  9279, 28755,\n",
       "          9196, 51645,  9167, 38430, 64234,  8971, 19703, 38545, 19718,\n",
       "         51561, 51501, 51476, 28662, 28611, 64424, 28511,  8655, 51410,\n",
       "          8538,  8492,  8489,  9644, 12002, 36246, 52196, 15752, 54142,\n",
       "         32646, 17840, 15526, 61383, 54110, 17893, 32873, 33008, 33033,\n",
       "         30302, 33113, 60583, 33319, 55285, 30260, 15208, 33357, 33410,\n",
       "         53789, 33477, 18197, 33651, 33210, 30310, 15793, 54328, 31154,\n",
       "         30970, 30933, 60620, 55045, 16831, 16577, 54534, 16535, 60925,\n",
       "         16375, 16323, 60593, 60948, 31769, 17548, 30587, 16202, 32073,\n",
       "         54411, 30548, 55173, 32155, 15874, 61148, 53546, 33719, 61951,\n",
       "         30056, 13439, 53043, 35389, 62573, 35516, 13303, 18713, 35570,\n",
       "         35609, 18863, 52865, 29546, 18949, 35761, 62887, 35823, 12590,\n",
       "         18975, 35907, 52737, 29409, 12304, 59983, 12124, 12096, 62340,\n",
       "         20678, 53052, 34993, 14538, 34010, 34167, 53505, 34211, 53467,\n",
       "         60519, 14196, 14155, 14153, 60471, 34419, 18259, 53416, 13994,\n",
       "         62157, 13928, 29973, 13847, 18528, 13714, 34934, 34961, 62324,\n",
       "         55494, 35287, 27485, 27964, 43932, 22086, 47212, 65764, 40880,\n",
       "          3479,   801,  3437, 58025, 44545, 25661,  3584,  3248, 25594,\n",
       "         65925, 25505, 47105, 44818, 49945, 44935,   856,   865, 48724,\n",
       "         44619, 44988, 50063, 44289,  4214,  4189, 43964, 26012, 57307,\n",
       "         44044, 25911,  4092,  4007,  3959,  3605,  3957, 57326, 66775,\n",
       "           767,  3794, 22063,  3760, 57372,  3732, 44223,  3644,  3930,\n",
       "          4228, 47021,  2840, 48941, 49612, 49599,  2200, 66275,  2062,\n",
       "         45893, 45931, 45947, 22659,  1235, 57877, 46178,  1605,  1286,\n",
       "         49064, 24706,  1579,  1507,  1482,  1380, 22770, 57886, 45000,\n",
       "         45571, 49697, 23017, 22332,   925, 66039, 66051,  2754, 58640,\n",
       "         45091, 58453, 66094, 22618, 45093,  1020, 46937, 49788, 48773,\n",
       "         57608, 25365, 66105, 25077, 45361, 66433,  2669,  4285,  1374,\n",
       "         50697, 58362, 26944,  6095, 67102, 50870, 50868, 47906, 26834,\n",
       "         42250, 42285,  5869, 47893,  5867, 58368, 26587,   727, 66939,\n",
       "           345, 47855,   124,  6248, 48593, 51015, 20955,  6748, 48209,\n",
       "          6725, 41316, 56609, 64876, 56642, 59148,  5619, 41579, 65010,\n",
       "         58326,  6561,  6970, 27139, 65080,  6475,  6977, 41821,    34,\n",
       "         42507, 21318,  5479, 23180, 65417, 27302, 65442, 21799, 43540,\n",
       "         23987, 26055, 43609, 43643, 58077, 23059, 65523, 43808, 43809,\n",
       "         43870, 50272,  4374, 43906, 50321, 59136, 20892, 43189, 65259,\n",
       "         47818,  5255, 47727, 26336, 42673, 23844,  5055,   520, 50549,\n",
       "         50472, 66842, 42832,  4968,  4947,  4938, 21555, 20868, 43108,\n",
       "         26196, 66838, 23715, 55365, 30253, 30927, 23837, 55076, 24507,\n",
       "         55120, 55132, 55279, 30388, 30321, 23792, 56539, 57390, 30128,\n",
       "         26183, 29002, 26270, 55894, 26331, 28766, 26417, 57215, 57211,\n",
       "         55927, 28701, 26763, 28586, 56011, 26891, 56034, 56074, 27103,\n",
       "         56772, 28112, 27158, 27263, 27889, 27794, 56285, 56424, 27321,\n",
       "         26164, 55411, 57246, 57258, 30058, 24667, 55417, 57935, 30008,\n",
       "         30006, 24983, 29960, 57555, 57497, 55554, 29768, 29685, 29684,\n",
       "         55560, 25483, 57462, 29579, 29537, 55579, 29374, 29283, 25734,\n",
       "         25742, 26022, 26037, 29030, 29003, 31179, 36531, 31315, 50891,\n",
       "         50876, 42074, 50782, 42343, 42396, 42442, 42583, 42593, 41881,\n",
       "         50551, 42691, 50444, 43001, 43160, 50440, 43340, 50317, 43538,\n",
       "         43546, 42625, 43547, 50913, 50932, 51196, 51116, 40172, 40207,\n",
       "         40434, 40503, 40542, 40652, 51063, 41792, 40821, 40912, 40930,\n",
       "         40941, 41273, 41393, 41396, 50948, 41439, 41459, 51054, 43802,\n",
       "         50240, 44034, 49556, 49514, 49300, 49292, 49119, 48913, 46948,\n",
       "         46989, 47119, 46017, 47237, 47399, 47412, 48671, 48598, 47942,\n",
       "         48042, 48570, 48196, 48505, 47383, 45981, 45537, 45424, 44041,\n",
       "         44085, 44096, 44106, 50111, 44122, 44169, 44382, 44529, 50034,\n",
       "         44707, 44756, 44936, 44981, 49900, 49894, 49811, 45144, 45227,\n",
       "         45277, 45330, 39993, 31216, 51203, 39686, 53734, 33534, 33588,\n",
       "         53693, 33610, 33929, 33940, 34277, 53449, 33452, 34458, 34767,\n",
       "         53315, 53298, 34932, 34971, 35054, 35343, 35522, 35551, 34698,\n",
       "         52988, 33347, 33220, 31378, 31437, 54919, 31505, 31514, 31560,\n",
       "         54798, 54531, 31779, 67249, 31939, 32107, 32119, 54362, 32160,\n",
       "         54333, 32489, 32591, 32659, 32736, 32103, 35586, 35632, 35665,\n",
       "         51728, 38281, 38452, 51596, 38622, 51525, 51465, 38874, 38884,\n",
       "         51764, 51444, 39119, 51347, 39266, 39272, 39283, 39364, 51281,\n",
       "         39616, 39647, 39089, 38098, 37908, 37874, 35696, 35709, 52812,\n",
       "         52758, 52656, 36007, 52554, 36104, 52204, 36289, 36419, 36460,\n",
       "         36633, 52067, 37203, 37373, 51967, 37558, 37722, 51780, 37830,\n",
       "         51251, 23611, 48337, 66258, 16570, 16632, 16795, 60779, 60775,\n",
       "          6837, 16304, 60669, 17051, 60630,  6637, 17119,  6566, 66760,\n",
       "          6767, 16269, 60952,   821, 15332,  7933, 15358, 64587,  7712,\n",
       "         61273, 64689, 61194,  7644,  7569,  7455, 66652,   883,   839,\n",
       "         61002,  6503,  7962,  6342, 65098, 65241,  5489,  5313,  5169,\n",
       "         65272, 18918,  5805, 60175,  5033,   599, 19065, 59940,  1742,\n",
       "         19275, 18966, 18351, 60437,  5838, 17464, 66432, 60592, 65125,\n",
       "         17610, 17635, 17700,  6066, 60570, 18027,  1739, 18055, 65140,\n",
       "         18183, 65201, 17358,  7969,  8057,  8158, 62872, 12836, 62863,\n",
       "         13071, 13107, 62827, 58244, 13252,  9253, 62563, 64245, 64286,\n",
       "          8876,  8871,  1582, 12337, 12147, 12076,  1355, 10683, 63483,\n",
       "         10979, 11122, 10421, 11364, 11583, 10294, 11714, 10227, 11930,\n",
       "         10222, 11986, 12019,  8863, 13710,  2278, 13712, 61988, 14831,\n",
       "         14881, 64471, 14949,  8346, 61778, 15076, 64533, 15087,  8249,\n",
       "         61685, 61605,  8208, 64544, 14734, 59596,  8365, 62144,  1238,\n",
       "          8809,  8798, 13858, 64398, 14000,  8740, 14022, 14108, 66437,\n",
       "          8698,  8646,  8568, 14128,  8440, 14472, 19364, 17573, 66834,\n",
       "         21873, 67161, 21740,  3679,  3737, 59004, 65760, 21396, 21312,\n",
       "          2219,  4102,  2204,   113, 66395, 59042,  4144, 67072,   242,\n",
       "          4335, 21090,  4337,  4383, 20962, 59131, 20957, 59228, 20750,\n",
       "            77,   383, 21935, 22045, 23444, 66239, 66126,  2497,  2519,\n",
       "          2622, 58396, 58484,  2682, 58549, 66087, 22742, 66079, 22548,\n",
       "          2829, 66038, 65962,    46,  3085, 22515, 22438,  2226,  3177,\n",
       "         65900,  3288, 58793, 58807, 21943, 20722, 10598,   511, 65409,\n",
       "         19588,  4818,  4814,   388, 59418, 20382, 19965,   395, 59355,\n",
       "          4752, 65446, 19851, 19723, 20243, 59332, 20114,  4513, 20223,\n",
       "         20537, 20567,  4415, 59442,  4549, 20013,  4842, 20719, 59429,\n",
       "         59256, 38124,  5485,  9170,  4735,  9506, 38229, 43496, 44623,\n",
       "          9247, 65862, 44898, 64215, 38453, 44941,  4643, 65232,  3094,\n",
       "          9600, 50007, 50763,  8827, 44807,  4710,  3111,  3160, 38377,\n",
       "         50026, 46078, 38083,  2580, 45194, 65378, 37517, 49762,  2420,\n",
       "         37489, 10157, 10387,  4987, 37336, 10456, 49193, 45433, 45434,\n",
       "         45445, 45341,  5086,  1429,  2656, 38053,  9670, 49826, 45075,\n",
       "          9737,  9767, 37791,  9954, 64182, 51835, 64168, 37734, 63902,\n",
       "         65278], dtype=int64),\n",
       "  'feature_absent_idx': array([33689, 60248, 60249, 18898, 60253, 18894, 42450, 18889, 51358,\n",
       "         18887, 42454, 18880, 60256, 60258, 42459, 60260, 18911, 42460,\n",
       "         18912, 42440, 42430, 60235, 18954, 18953, 18952, 18951, 18948,\n",
       "         18947, 18946, 18942, 60238, 18938, 42437, 42439, 60243, 18919,\n",
       "         18960, 18867, 18864, 51352, 51351, 18808, 60300, 42483, 18796,\n",
       "         18794, 18791, 42489, 60305, 42490, 18783, 18778, 42492, 42493,\n",
       "         60292, 51356, 42475, 60287, 42462, 18860, 60270, 18856, 18855,\n",
       "         18850, 60274, 18847, 60275, 18841, 42470, 60280, 42472, 18832,\n",
       "         18830, 18826, 18773, 42428, 18973, 42382, 19127, 19124, 19123,\n",
       "         19119, 60178, 51377, 51376, 60180, 51375, 60183, 19103, 42392,\n",
       "         19088, 19087, 19132, 19086, 19135, 19149, 19187, 19184, 19181,\n",
       "         42363, 60154, 19173, 60160, 42368, 51384, 60164, 51382, 19159,\n",
       "         42372, 60168, 42374, 42377, 42424, 19085, 19083, 42411, 42412,\n",
       "         19001, 18998, 42415, 42416, 42418, 18993, 18992, 60228, 18989,\n",
       "         51370, 18980, 18979, 18977, 42410, 19084, 42409, 60210, 19080,\n",
       "         19079, 60188, 60189, 19074, 60191, 19052, 19051, 19045, 60206,\n",
       "         19040, 19038, 19036, 19031, 60209, 19021, 42495, 18765, 42496,\n",
       "         60421, 42592, 60428, 18469, 60430, 42597, 42600, 60435, 51303,\n",
       "         18451, 42604, 60436, 60438, 60440, 18426, 60420, 18423, 18487,\n",
       "         42585, 18531, 18529, 18521, 18520, 42573, 18518, 51317, 18516,\n",
       "         42576, 60410, 18511, 18501, 42582, 18494, 42584, 42586, 18535,\n",
       "         18422, 42612, 18361, 60464, 18355, 18344, 18343, 42644, 42646,\n",
       "         18337, 18336, 18334, 18332, 51286, 18330, 60469, 60472, 18369,\n",
       "         18420, 18370, 42632, 18412, 51300, 42618, 51299, 18402, 60453,\n",
       "         18400, 18392, 18391, 42624, 18389, 18383, 51295, 18376, 42631,\n",
       "         18371, 18536, 18542, 60401, 60338, 18694, 42521, 18691, 60340,\n",
       "         60342, 60344, 60345, 42522, 42524, 18678, 42525, 18670, 18668,\n",
       "         18665, 18700, 51337, 18707, 18714, 18761, 42497, 18750, 42500,\n",
       "         51348, 51344, 42509, 18733, 18732, 42511, 18727, 60329, 60332,\n",
       "         18718, 18715, 18712, 18661, 18660, 18656, 18596, 60386, 18592,\n",
       "         60387, 18589, 42559, 42560, 18584, 60390, 18578, 42564, 42565,\n",
       "         60394, 18551, 18550, 42554, 60382, 18610, 18616, 18650, 18648,\n",
       "         60367, 42536, 42537, 18640, 51333, 19189, 60373, 18630, 42541,\n",
       "         18624, 18623, 18622, 18619, 18617, 60374, 51389, 19192, 19194,\n",
       "         59950, 19739, 42174, 59953, 42176, 19726, 19725, 59956, 59958,\n",
       "         19719, 19717, 42177, 59959, 19714, 59960, 42171, 19709, 19745,\n",
       "         19750, 59934, 59935, 42160, 19779, 59936, 51469, 19770, 19765,\n",
       "         19763, 59942, 42168, 19758, 59943, 59944, 59945, 19748, 19791,\n",
       "         59963, 19701, 59987, 19646, 42194, 19640, 19639, 19636, 59992,\n",
       "         51459, 59993, 19630, 59995, 59996, 42204, 19621, 19615, 19651,\n",
       "         19706, 59986, 51463, 59964, 19697, 19696, 19695, 19691, 42182,\n",
       "         19687, 59971, 42184, 19677, 42187, 19663, 19661, 19660, 59984,\n",
       "         19654, 59933, 51473, 51474, 19956, 59877, 59883, 19943, 42102,\n",
       "         59885, 19933, 19930, 42109, 19928, 42110, 42112, 19915, 59892,\n",
       "         19902, 19972, 19899, 42091, 19989, 20028, 20026, 42070, 20022,\n",
       "         20019, 20011, 59864, 42078, 59866, 42081, 59868, 19999, 19996,\n",
       "         19994, 59870, 19983, 51489, 42121, 42123, 19841, 19839, 59914,\n",
       "         19833, 19832, 19831, 59915, 19825, 59917, 59920, 59921, 59922,\n",
       "         59930, 42153, 19802, 59911, 51482, 59909, 42137, 19893, 42126,\n",
       "         19889, 19886, 19885, 19882, 19880, 42206, 59899, 59901, 19868,\n",
       "         59903, 19866, 59904, 51485, 51484, 19875, 18324, 51453, 42210,\n",
       "         60093, 19339, 42304, 19335, 60100, 51415, 19319, 19318, 60104,\n",
       "         60107, 42313, 19310, 60113, 19297, 19294, 51419, 19293, 19350,\n",
       "         60083, 51427, 19405, 19402, 19400, 19396, 60073, 51425, 19386,\n",
       "         19385, 19379, 19369, 42293, 19362, 42295, 60082, 19355, 19410,\n",
       "         19290, 19287, 60139, 60140, 42341, 19221, 19216, 51392, 60143,\n",
       "         51391, 19211, 19209, 19207, 42351, 19201, 19199, 19197, 60138,\n",
       "         19288, 19228, 51402, 42318, 51411, 19273, 19271, 42326, 19266,\n",
       "         60124, 60128, 19257, 19256, 60129, 60130, 51403, 19251, 19248,\n",
       "         19234, 42280, 51428, 19419, 19560, 19555, 42223, 19552, 19550,\n",
       "         19549, 42226, 19541, 19540, 19539, 19538, 19537, 60024, 51446,\n",
       "         19523, 60020, 19521, 19562, 19565, 19602, 60006, 51452, 42215,\n",
       "         19590, 19584, 60013, 19581, 60015, 19578, 19577, 19576, 19570,\n",
       "         60018, 19566, 19564, 51440, 60028, 19512, 19459, 19454, 60053,\n",
       "         60056, 19445, 42269, 19439, 60065, 19431, 19430, 42274, 42276,\n",
       "         19423, 19422, 19420, 60047, 19466, 42257, 42256, 19511, 60031,\n",
       "         19507, 19506, 19505, 51439, 19502, 19606, 51436, 42249, 60039,\n",
       "         60041, 42252, 19479, 19477, 19475, 60038, 20029, 42652, 42653,\n",
       "         17241, 17240, 60864, 17235, 17228, 17227, 51136, 43024, 60871,\n",
       "         60872, 51135, 17216, 17215, 60877, 17209, 17244, 17208, 17247,\n",
       "         17252, 17296, 17293, 17288, 17287, 17286, 51148, 17278, 43009,\n",
       "         60852, 17266, 17265, 60856, 43012, 60859, 17254, 17248, 60842,\n",
       "         43029, 17204, 17159, 17156, 17154, 43051, 17152, 43053, 17148,\n",
       "         17146, 60891, 51127, 60892, 43055, 60894, 17139, 60895, 60888,\n",
       "         60878, 17161, 17163, 60880, 17201, 43034, 60881, 43036, 17184,\n",
       "         17179, 17177, 43041, 17173, 43044, 17169, 43047, 17165, 43048,\n",
       "         17162, 60899, 51151, 42991, 60788, 17449, 42953, 17439, 17438,\n",
       "         17437, 17435, 51159, 17429, 17428, 17424, 17423, 17421, 17420,\n",
       "         42958, 60786, 17417, 17458, 17465, 60764, 42933, 17502, 51167,\n",
       "         17497, 17492, 17491, 60772, 17478, 60777, 17475, 60781, 17471,\n",
       "         17469, 17466, 17462, 60837, 17415, 17408, 60817, 17353, 17344,\n",
       "         17343, 60820, 17338, 60822, 17330, 17324, 17322, 17321, 17319,\n",
       "         17318, 42987, 42990, 17355, 42960, 60816, 17369, 60803, 17402,\n",
       "         17401, 17399, 17396, 17392, 17389, 42968, 60806, 60807, 17384,\n",
       "         42971, 60812, 42972, 42973, 17367, 17132, 17125, 43061, 16830,\n",
       "         43177, 16827, 16824, 61011, 16813, 16812, 16808, 16807, 61016,\n",
       "         16802, 16797, 16794, 16792, 16788, 16835, 16786, 51079, 16847,\n",
       "         51091, 60991, 43157, 43159, 43161, 16876, 16874, 16873, 43164,\n",
       "         16871, 16867, 51086, 16856, 16855, 16849, 16844, 16889, 16785,\n",
       "         43192, 16748, 16747, 43204, 43205, 43206, 16736, 16732, 16725,\n",
       "         16721, 16719, 61046, 16715, 16712, 16711, 16709, 16750, 16782,\n",
       "         16752, 43203, 16778, 16776, 16775, 51068, 16771, 16770, 16766,\n",
       "         43197, 43198, 61026, 61027, 16760, 61028, 51066, 43201, 16755,\n",
       "         43149, 16893, 60986, 60924, 17056, 17055, 17053, 17050, 17037,\n",
       "         43094, 17027, 43095, 17019, 43097, 51112, 60937, 17006, 17001,\n",
       "         43081, 60939, 60921, 60920, 17118, 60906, 17116, 17113, 17111,\n",
       "         43066, 17105, 43069, 17090, 60913, 43073, 17080, 43076, 17077,\n",
       "         17072, 17070, 16996, 43103, 16991, 60968, 51101, 43132, 43133,\n",
       "         51098, 43138, 43139, 16919, 43143, 60982, 43144, 16905, 16901,\n",
       "         16898, 16897, 16935, 16937, 16943, 60965, 16989, 16986, 43107,\n",
       "         16981, 43112, 16973, 43114, 42932, 16970, 43115, 43116, 43117,\n",
       "         43118, 51108, 60961, 16955, 60953, 17512, 17513, 42931, 18077,\n",
       "         18073, 18067, 60571, 60572, 60574, 18061, 60577, 18056, 18054,\n",
       "         42745, 60579, 51248, 18042, 18037, 18084, 60587, 18086, 18090,\n",
       "         42723, 51260, 60558, 18119, 42726, 18115, 60559, 18112, 18110,\n",
       "         18109, 18108, 18107, 18105, 18096, 42735, 18088, 18126, 18031,\n",
       "         60595, 17971, 60611, 42769, 42770, 60613, 17958, 60619, 51234,\n",
       "         60625, 17948, 17947, 42776, 17940, 60632, 17936, 17977, 18023,\n",
       "         17978, 42766, 18013, 18012, 18011, 18010, 60598, 18006, 42758,\n",
       "         42759, 17996, 42760, 42761, 42764, 17984, 42765, 60608, 42767,\n",
       "         18127, 60552, 18137, 18255, 18254, 18253, 42679, 60498, 18247,\n",
       "         51274], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_exlamation': {'feature_present_idx': array([24600, 66290, 45167, 35890, 35721, 35621, 34876, 33272, 33245,\n",
       "         33213, 32441, 36036, 32418, 32207, 32102, 31717, 31625, 31600,\n",
       "         32837, 36480, 34257, 36514, 42056, 41152, 40927, 40818, 38974,\n",
       "         38894, 38416, 38179, 38007, 37688, 37604, 37250, 37205, 36976,\n",
       "         36969, 31080, 30422, 30351, 30301, 24296, 24269, 24240, 24182,\n",
       "         23947, 23739, 23435, 22978, 22911, 22613, 22575, 22276, 22220,\n",
       "         21856, 21822, 24396, 42148, 24493, 24711, 30294, 30261, 29812,\n",
       "         29714, 29415, 29267, 28802, 28028, 28001, 27481, 27193, 26255,\n",
       "         25926, 25278, 24958, 24606, 42303, 44110, 21336, 58732, 57987,\n",
       "         57324, 57273, 57104, 57033, 56730, 56662, 56412, 56339, 56330,\n",
       "         56175, 55902, 55525, 55361, 58927, 54662, 59049, 59653, 67038,\n",
       "         66923, 66260, 66181, 65449, 65135, 65006, 63428, 63196, 62785,\n",
       "         62688, 61831, 60483, 60416, 59835, 59461, 54407, 54103, 53976,\n",
       "         47908, 47787, 47700, 47439, 47318, 46590, 46471, 46346, 46190,\n",
       "         46167, 45950, 45303, 44842, 44788, 44504, 48051, 48054, 48107,\n",
       "         48827, 53533, 53327, 52719, 52555, 52425, 52041, 51892, 43512,\n",
       "         51342, 50772, 50510, 50332, 49914, 49763, 49285, 48915, 51328,\n",
       "         21162, 67243, 20956, 14639,  8061, 14725,  7686,  7387,  7363,\n",
       "         14758,  7124, 15169,  6780, 14595,  6544, 15938,  5982, 16169,\n",
       "         16218,  5286,  5121,  4941, 17121,  4860,  4357, 15924,  8119,\n",
       "          8222,  8456, 12220, 12336, 12219, 12150, 12066, 13297, 11728,\n",
       "         11690, 13447, 11604, 13528, 11577, 11345, 13691, 13700, 10794,\n",
       "         13733, 13979, 10741,  9643,  8719,  8676, 14460,  4163,  3521,\n",
       "         16105, 12312,  1083,  2803,  2841, 19772, 19357,  2709, 18181,\n",
       "         18523, 19392, 20137, 17561, 19122, 18874,   396,  3140, 18813,\n",
       "         20235, 46539,  9921, 46596, 46300, 63870, 47900, 63834, 63620,\n",
       "         48014, 63589,  8269, 48069,  1271, 48631,  8142,  1348, 46837,\n",
       "         46085, 64516, 64201, 39011, 66986, 39653, 40313, 40632,   413,\n",
       "         40873, 40916,   487, 41810, 41885,   747,   807, 66133, 42936,\n",
       "         66122, 44304,   878, 44539, 64972, 10797, 64255, 45624, 64038,\n",
       "          8084, 58869,  1728, 54091,  5853,  5704, 54516, 54531, 55041,\n",
       "          5559, 55486,  5307, 59371, 56367, 60052, 59149, 56551, 59054,\n",
       "          3068, 56780, 56838,  4089,  3918, 57458, 57936,  3580, 58119,\n",
       "          4904,  1480, 60310, 53727, 49861, 49913, 58892, 50172, 62163,\n",
       "          7591, 51172,  7242, 51682, 51884,  1973, 38961, 61380, 52083,\n",
       "         52156, 52293, 52326, 61152, 52504, 60782, 53450, 60656,  2198,\n",
       "         53525,  7093,  8060, 11778,   151, 18066, 14775, 14752, 32461,\n",
       "         25174, 25120, 32906, 32940, 33027, 24794, 33115, 27595, 67220,\n",
       "         34361, 34469, 35045, 35069, 35091, 18939, 35661, 35746, 25340,\n",
       "         31464, 15512, 30603, 27821, 28023, 28181, 27269, 28242, 17155,\n",
       "         29125, 29156, 27157, 27043, 19265, 29259, 26713, 26494, 29468,\n",
       "         29631, 30102, 26422, 38744, 26293, 15587, 17699, 16240, 35767,\n",
       "         34203, 27301, 36972, 23981, 37627, 12686, 37988, 37741, 36944,\n",
       "         19414, 19995, 22649, 22208, 20245, 36008, 20067, 13392, 36907,\n",
       "         22471, 38425, 36087, 38319, 36576, 21500, 36425, 20765, 38340,\n",
       "         41089, 25977,  6694, 20569, 54756, 15680, 38492, 37660, 31102,\n",
       "         27651, 25930, 16933,  6494, 53676, 39490, 29791, 26479, 16255,\n",
       "         38083, 55323, 54428, 55280, 66458, 20600, 40698, 40326, 30105,\n",
       "         26520, 46149, 32021, 35719,  9713, 36517, 46657, 45286, 14459,\n",
       "         46960, 35375, 62122, 34476, 44750, 31989, 61775, 48635, 61460,\n",
       "         48466, 14814, 32500, 50832, 14743, 25242, 59862, 63964, 42645,\n",
       "         32608, 43901, 11683, 13393, 24279, 63518, 27180, 63158, 62928,\n",
       "         61442, 24716,  3939, 26305, 19316, 24713, 66365, 21843, 19452,\n",
       "         61448, 66637, 21844, 38624,  5182, 34132,  8535, 17130, 46204,\n",
       "         45902, 11380, 44186, 51488, 43593, 12783, 41751, 41597, 12587,\n",
       "         40205, 39019, 38485, 37331, 15511, 53112, 54897, 54332, 52420,\n",
       "         29458, 52908, 53362, 30449,  6500,  5654, 54674, 12148, 24305,\n",
       "         46814, 41048, 21018, 40772, 28734, 39807, 49573, 66665, 66730,\n",
       "         50682,  2379, 21809, 56933, 15667, 25783, 42025, 25848, 57720,\n",
       "         66752, 55549,   960, 22660, 53985, 44443, 25193, 14289, 62812,\n",
       "         62686, 14631, 33850, 34109, 52031, 51380, 18171, 24530,  8686,\n",
       "         42322, 22757, 49830, 32656, 54489, 37540, 10185, 10700],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([52728, 57594, 57591, 28378, 12768, 12769, 12770, 12771, 12773,\n",
       "         28374, 45634, 12777, 45635, 28371, 12763, 28370, 45638, 45639,\n",
       "         57579, 57578, 28361, 57571, 12799, 57570, 57568, 57567, 57566,\n",
       "         12805, 12807, 12782, 45643, 12762, 28382, 28416, 12714, 12717,\n",
       "         12721, 28410, 12723, 45615, 28408, 28407, 57629, 45616, 57628,\n",
       "         57626, 57596, 45618, 28398, 28397, 12739, 12742, 57611, 57609,\n",
       "         45626, 57605, 45628, 28388, 57601, 28383, 57599, 45619, 28350,\n",
       "         12811, 12812, 28299, 12877, 12878, 45695, 12880, 45696, 57502,\n",
       "         57501, 45699, 57493, 45701, 12892, 12894, 57511, 45704, 12898,\n",
       "         12901, 45711, 45713, 28274, 45716, 45717, 28267, 12915, 28265,\n",
       "         57480, 28264, 45722, 45705, 57513, 57516, 57518, 12813, 45652,\n",
       "         28341, 28337, 12824, 45664, 12826, 57550, 12829, 28333, 28331,\n",
       "         12835, 57544, 45671, 45672, 45674, 28316, 45683, 12851, 12852,\n",
       "         12854, 28310, 57526, 12858, 57525, 57524, 12862, 12865, 28304,\n",
       "         12711, 45725, 12710, 57641, 28529, 12562, 28525, 57753, 57750,\n",
       "         12568, 45535, 28521, 28520, 28519, 12574, 57745, 57741, 28530,\n",
       "         12581, 57736, 57735, 12586, 45542, 57731, 57730, 45544, 12592,\n",
       "         12595, 12596, 12597, 12598, 45553, 12583, 28504, 12557, 28536,\n",
       "         57807, 57801, 57796, 12506, 57795, 45509, 45511, 12510, 12512,\n",
       "         28562, 57782, 28558, 12527, 28534, 12530, 45520, 57772, 12534,\n",
       "         57770, 28548, 28544, 12544, 57768, 12546, 57766, 12550, 57762,\n",
       "         28537, 28552, 45557, 57725, 28501, 12667, 28447, 57676, 28445,\n",
       "         28441, 45598, 12675, 12676, 28439, 57670, 57667, 57666, 57665,\n",
       "         28448, 28436, 45600, 57662, 57656, 12693, 28429, 12696, 45603,\n",
       "         57650, 28421, 45609, 57643, 57642, 12707, 45599, 12664, 12663,\n",
       "         28450, 57723, 28500, 28498, 28494, 57718, 57717, 28493, 57715,\n",
       "         45565, 45567, 28487, 28482, 45573, 28478, 28476, 12633, 12634,\n",
       "         28473, 45576, 57699, 12644, 45583, 57688, 12653, 45592, 57683,\n",
       "         45594, 28452, 12661, 45611, 57811, 45726, 45731, 45856, 57257,\n",
       "         13173, 57256, 13176, 45863, 45864, 45865, 57254, 57252, 13183,\n",
       "         57251, 28064, 57261, 28063, 57247, 13190, 28056, 13193, 45874,\n",
       "         28051, 13201, 28047, 45879, 57237, 28042, 13209, 57232, 45872,\n",
       "         13214, 13167, 28078, 57303, 57301, 57299, 57297, 28097, 45843,\n",
       "         28093, 28091, 45846, 57283, 28088, 45847, 13146, 28076, 45849,\n",
       "         13149, 28085, 13151, 28084, 57271, 13154, 28082, 57266, 57265,\n",
       "         13160, 13161, 28080, 28079, 13148, 57230, 28034, 13217, 13280,\n",
       "         45935, 45939, 13288, 13290, 13292, 13293, 45945, 13295, 27967,\n",
       "         45948, 27963, 13301, 45929, 57156, 27958, 13307, 27957, 27955,\n",
       "         13311, 13317, 27946, 57133, 57131, 13322, 57130, 45968, 13328,\n",
       "         45953, 45927, 13274, 13273, 57227, 13219, 13221, 57224, 57221,\n",
       "         45892, 28026, 57218, 45895, 13233, 28018, 45899, 57209, 57208,\n",
       "         13243, 28013, 13247, 45900, 13249, 45903, 45904, 13255, 57188,\n",
       "         13259, 27994, 27992, 45923, 13269, 13271, 57305, 57468, 57306,\n",
       "         28109, 45758, 12973, 57430, 57429, 57428, 57427, 28213, 57425,\n",
       "         57423, 12983, 45761, 28209, 57422, 12971, 12987, 12989, 28207,\n",
       "         57420, 28205, 57415, 57413, 13002, 13003, 57405, 57403, 57401,\n",
       "         57399, 28191, 28208, 57395, 12970, 28218, 45732, 12930, 28248,\n",
       "         28247, 45736, 28241, 28240, 28238, 45740, 12943, 57450, 28233,\n",
       "         57447, 12969, 12947, 28232, 45743, 12951, 12952, 57442, 57441,\n",
       "         45747, 28225, 28224, 57437, 12960, 57433, 12964, 12948, 45769,\n",
       "         13014, 13016, 28140, 13079, 28136, 13081, 28135, 13084, 57336,\n",
       "         57334, 28128, 28126, 13095, 13096, 28124, 57339, 13098, 45824,\n",
       "         13101, 57329, 13103, 57325, 13106, 45826, 13108, 28117, 45828,\n",
       "         13112, 28114, 28113, 45823, 57341, 57344, 45809, 28188, 57392,\n",
       "         57391, 13020, 57389, 28182, 45779, 57386, 13028, 13029, 45786,\n",
       "         57381, 28173, 13037, 13040, 28167, 57367, 57366, 57365, 13052,\n",
       "         57362, 45800, 57359, 45803, 28150, 45807, 57352, 13065, 57350,\n",
       "         28108, 12495, 12494, 45504, 58239, 58237, 58236, 45172, 28994,\n",
       "         11952, 28993, 45178, 28986, 11959, 28983, 28982, 28981, 58240,\n",
       "         28976, 58221, 11975, 11976, 45188, 58215, 28964, 58208, 11984,\n",
       "         11985, 58207, 11987, 28957, 58203, 11968, 11994, 58242, 11939,\n",
       "         29032, 58283, 29029, 29028, 11902, 45148, 58277, 58274],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 557\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 557\n",
       "  })},\n",
       " 'contains_negation': {'feature_present_idx': array([25342,  8916, 44753, 56681, 56714, 19156,  8887,  8865, 19165,\n",
       "          8835, 56809, 56825,  8921, 28965, 56855, 44693, 56876, 44692,\n",
       "          8735, 34027, 44677, 19230, 44660, 34018, 57007, 19166, 33979,\n",
       "         19130, 44771,  9189,  9188, 56300, 56326, 18943, 44875, 18982,\n",
       "         56404, 56409,  9115, 44865, 26666, 37090,  9094,  9078, 19013,\n",
       "         56517, 19035,  9045, 19068, 37101, 44828, 56575, 56613, 56507,\n",
       "          9210, 57050, 19277, 57322,  8367, 19470, 19472, 44428, 57421,\n",
       "         57440, 33924,  8323, 29157, 57490, 44474, 44415, 33895, 44390,\n",
       "         57542, 57546, 57573, 57602, 44336, 33874, 44329, 19587, 44309,\n",
       "          8290, 44601, 57300, 57291, 57070, 57081, 44594, 33959,  8621,\n",
       "          8619, 37171, 44568, 57118, 44556, 29060, 19461, 19368,  8499,\n",
       "         33945,  8471, 26605, 44519, 19446, 26598,  8427,  8424,  8411,\n",
       "         33944, 19376, 57726, 44916, 56244, 10151, 18248, 55223, 45581,\n",
       "         55289, 26816, 55313, 10093, 10070, 34381, 28679, 55193,  9972,\n",
       "         18444, 18453, 26792, 45420, 28692, 55642, 18471, 45394, 55666,\n",
       "         34371, 18524, 45450, 18526, 55174, 18240, 54832, 36842, 45906,\n",
       "         18053, 36881, 10449, 54931, 45817, 18082, 28614, 10425, 18242,\n",
       "         45798, 28619, 45721, 45694, 36887, 18172, 10307, 55095, 18179,\n",
       "         28673, 55144, 45662, 55005, 44918, 28707, 55757,  9526, 45099,\n",
       "          9489, 26751, 34263, 56063, 28807, 56081, 34245,  9419,  9418,\n",
       "         56009,  9379, 34216,  9351,  9339, 34193, 44990, 26727, 56157,\n",
       "         56216,  9256, 18910,  9230, 34219, 34364, 56000, 45143, 45312,\n",
       "         55792,  9799, 34354, 18559, 34308,  9741, 37004,  9735,  9734,\n",
       "          9725, 18731, 18599, 28741, 55845, 18628, 18634, 26771, 55905,\n",
       "         55910,  9609, 45176, 45173,  9588, 18607, 44298,  8167, 19629,\n",
       "         59250, 26437, 20653, 43301, 20679, 37403, 59308, 59314,  6531,\n",
       "         20688, 29642, 43339, 43275, 59367, 33615, 43230, 26413,  6437,\n",
       "         43185, 59458, 59507, 59524, 20830,  6360, 43265, 33513,  6583,\n",
       "         59225, 20539, 20543, 20549,  6812, 43408,  6794, 20562, 43404,\n",
       "         67339, 59118, 59125, 43354,  6730, 59135, 29590, 59152,  6646,\n",
       "          6641,  6639, 59177, 29596, 37355, 43358, 29613, 20581, 37341,\n",
       "          6354,  6337,  6010,  5990, 60037, 33402, 21153, 42775, 26314,\n",
       "         21183,  5906, 42751, 37649, 42794, 26294, 60198, 26288, 33372,\n",
       "         60241, 60269, 37664, 26277,  5770, 21256, 42611,  5759,  5857,\n",
       "          6341,  6039,  6045, 20853, 33486, 59688, 43071,  6270,  6267,\n",
       "         37534,  6250,  6249, 20925,  6240, 21126, 42996, 33454,  6169,\n",
       "         59860,  6136, 26341, 42906, 26339,  6073,  6064,  6062, 33416,\n",
       "          6217, 20527, 59082, 29551, 58162, 43910, 29282, 58190,  7822,\n",
       "          7812, 58225, 43890, 19903, 33777, 58257, 29279, 58264, 58345,\n",
       "         19916, 29298,  7708, 43868,  7679, 43867, 43861, 19925, 58390,\n",
       "         43841, 29291, 58408, 58150, 43927, 26586, 44216, 44161, 19662,\n",
       "         44138, 44086, 44083, 44061,  8032, 29222, 57944,  7857, 19767,\n",
       "         19784, 58015, 43977, 58062,  7905, 19844,  7876, 58100, 58123,\n",
       "         43934, 58137, 57984, 29318,  7550, 58447, 33703, 37291, 20312,\n",
       "          7183,  7172, 43489, 58777, 43482, 20368, 20375, 58854, 20279,\n",
       "         20383, 29501, 43442,  7057, 20400,  7049, 58916,  7011, 58968,\n",
       "         20460, 59051, 59074, 43449, 29464, 20207, 58722, 19946, 19952,\n",
       "          7517, 58477, 49652,  7504,  7478, 58500,  7476,  7463,  7427,\n",
       "          7403, 29371,  7391, 43610, 37287, 58641, 20159, 20160,  7324,\n",
       "         20173,  7311, 29439, 58705, 58716, 18028, 42606, 45944, 34565,\n",
       "         13461, 51340, 13436, 48244, 48233, 15932, 48226, 15949, 15951,\n",
       "         48212, 15973, 13478, 51420, 15977, 16008, 13310, 48170, 51544,\n",
       "         51556, 51569, 13232, 51582, 16096, 36133, 13360, 27940, 13486,\n",
       "         13496, 48612, 36071, 13721, 48576, 51089, 13694, 35432, 15720,\n",
       "         13648, 35431, 27324, 36112, 13628, 48545, 36076, 51161, 36101,\n",
       "         48483, 15759, 27311, 15804, 15830, 13506, 35368, 51140, 48618,\n",
       "         27942, 13155, 51889, 12843, 16368, 51902, 36192, 47723, 47706,\n",
       "         12787, 47675, 47650, 47605, 28027, 27197, 47589, 47584, 12713,\n",
       "         28048, 36216, 12699, 28057, 12660, 47532, 52062, 16472, 51979,\n",
       "         51676, 35245, 12874, 13120, 13080, 51733, 13057, 48074, 47983,\n",
       "         47979, 27241, 13017, 51775, 12993, 51863, 47923, 47856, 51839,\n",
       "         35259, 27240, 12923, 27984, 47807, 47790, 47789, 36185, 47780,\n",
       "         47862, 16478, 48643, 15691, 15055, 49407, 50072, 14509, 27668,\n",
       "         49384, 14485, 15095, 15096, 15101, 50175, 14569, 50185, 35889,\n",
       "         35636, 49364, 50208, 50229, 35902, 15147, 49338, 49336, 15177,\n",
       "         49326, 15114, 14364, 35672, 35683, 35738, 14816, 14852, 14861,\n",
       "         14868, 49585, 14787, 49702, 27540, 27588, 35708, 49951, 49533,\n",
       "         27615, 35697, 27632, 49494, 14660, 35814, 14652, 14648, 49902,\n",
       "         27640, 49473, 14934, 13755, 15201, 14339, 48944, 48942, 50671,\n",
       "         36000, 35562, 50754, 15552, 50755, 50756, 13914, 15562, 14036,\n",
       "         13902, 50810, 48797, 50846, 48782, 15580, 13832, 15605, 27781,\n",
       "         15638, 13789, 13781, 27774, 35909, 27752, 50519, 15230, 49297,\n",
       "         14274, 49265, 49261, 49245, 50325, 14234, 50331, 49236, 49229,\n",
       "         35573, 49188, 35599, 49103, 50387, 35969, 49002, 14060, 14057,\n",
       "         35984, 50473, 50486, 50487, 50337, 47480, 12627, 35219, 46619,\n",
       "         17285, 11277, 46594, 11251, 53776, 17323, 28369, 11229, 11213,\n",
       "         17346, 11305, 17349, 34791, 53867, 17372, 26961, 11153, 46504,\n",
       "         17425, 11088, 46464, 54004, 54052, 11201, 11030, 11327, 46629,\n",
       "         53334, 34921, 53396, 27017, 53437, 17120, 46734, 11509, 46723,\n",
       "         46676, 53460, 46620, 11458, 11433, 11426, 53554, 11404, 46650,\n",
       "         46649, 53624, 17243, 28329, 17256, 34856, 53500, 53307, 17516,\n",
       "         46420, 17829, 17855, 54421, 54440, 54459, 54514, 10672, 34596,\n",
       "         54610, 10656, 54630, 28528, 17908, 10612, 10604, 54660, 28591,\n",
       "         10545, 10535, 10534, 45992, 54740, 10493, 54749, 10620, 17552,\n",
       "         36754, 17780, 54132, 34726, 10985, 17594, 54157, 46371, 46363,\n",
       "         54186, 10940, 54212, 10936, 17787, 46345, 34687, 54247, 46264,\n",
       "         17695, 10857, 34675, 17703, 17723, 26929, 46238, 46224, 26942,\n",
       "         34924, 46786, 53269, 28129, 36385, 52407, 52412, 16730, 52477,\n",
       "         12237, 52497, 16768, 36413, 52557, 47268, 52561, 27100, 12154,\n",
       "         52598, 12137, 52612, 12117, 36437, 16840, 27090, 12107, 36470,\n",
       "         35155, 12091, 52332, 52327, 47425, 12614, 27176, 36239, 47389,\n",
       "         16520, 36279, 16542, 25349, 16545, 28104, 12343, 16563, 12508,\n",
       "         36288, 52242, 35180, 52250, 47324, 12429, 52268, 47302, 52300,\n",
       "         12400, 52213, 52681, 47071, 52694, 17010, 53016, 11840, 17039,\n",
       "         11808, 53041, 35026, 11753, 46859, 53088, 11735, 46925, 11725,\n",
       "         11719, 53098, 53108, 34962, 34952, 46807, 17078, 17082, 53206,\n",
       "         11621, 53262, 11723, 35038, 53000, 52960, 52699, 35130, 52726,\n",
       "         35128, 52762, 28170, 16921, 36521, 12005, 52781, 11988, 16953,\n",
       "         11955, 36552, 52850, 46947, 52851, 52874, 35053, 16985, 36564,\n",
       "         11901, 35046, 52954, 11889, 54773,  5755, 58480,  5741, 30667,\n",
       "         23211,  2866, 64128, 64146,  2844, 64186,  2820,  2786, 23175,\n",
       "         25815, 23294,  2745, 23312, 23323,  2722,  2719, 40391, 40375,\n",
       "         32269, 23268, 23353, 30653, 64046, 63733, 63775, 40612, 23032,\n",
       "         23041, 23050, 63807, 40566, 23053,  5753, 38142, 63878,  3053,\n",
       "          3047, 63909,  3016, 63945, 30632, 40497, 23140,  3062,  3157,\n",
       "         40362, 32253, 25740, 32136, 64626,  2383, 64633, 40050,  2346,\n",
       "         40048, 40022, 32166, 40008, 64709,  2251, 64743, 64759, 64771,\n",
       "          2207, 64807, 31991, 64843, 23548, 40299, 25763, 64510, 64355,\n",
       "         32223, 64367, 32222, 30749, 40279,  2601, 23406,  2588,  2441,\n",
       "          2578, 40266,  2563, 40245, 23459, 64467, 40214, 64502, 30753,\n",
       "         40208,  2573,  2130, 40659,  3169,  3926, 41161,  3884, 62977,\n",
       "         41149], dtype=int64),\n",
       "  'feature_absent_idx': array([52160, 60143, 11668, 11669, 33114, 60140, 11672, 11673, 60139,\n",
       "         11676, 60138, 54655, 11679, 33112, 33111, 20302, 33109, 20301,\n",
       "         20300, 46712, 20299, 60130, 33104, 11695, 33117, 50448, 33120,\n",
       "         11659, 11630, 20316, 33136, 33135, 20315, 54646, 11636, 33130,\n",
       "         11638, 33129, 20313, 11696, 11641, 11644, 11647, 54650, 11649,\n",
       "         54651, 11651, 11653, 50450, 46703, 11656, 54653, 60154, 60129,\n",
       "         11699, 11700, 33079, 33077, 46729, 46730, 33073, 46731, 60107,\n",
       "         27111, 60104, 11749, 33070, 11739, 54666, 60100, 33067, 11758,\n",
       "         46737, 50434, 27113, 27114, 33059, 11765, 11766, 33057, 46735,\n",
       "         11629, 11738, 11736, 33100, 11704, 20294, 11706, 11707, 11708,\n",
       "         60128, 50446, 11711, 50442, 60124, 11737, 27104, 33093, 33092,\n",
       "         11722, 54665, 33086, 33082, 20281, 11731, 60113, 11733, 11734,\n",
       "         20290, 11628, 60160, 11626, 20350, 60235, 46609, 11530, 27066,\n",
       "         50462, 46617, 11534, 11535, 33209, 11538, 33218, 11539, 33203,\n",
       "         60228, 46632, 11546, 11549, 33196, 46638, 50460, 54629, 11557,\n",
       "         33191, 33207, 11559, 50463, 11520, 46588, 60258, 46589, 60256,\n",
       "         33241, 11493, 33239, 33238, 11498, 60253, 11501, 20352, 11502,\n",
       "         60248, 46591, 54623, 27061, 54625, 50465, 11513, 60243, 46602,\n",
       "         46603, 60238, 60249, 60093, 33187, 27075, 11598, 33162, 60183,\n",
       "         46671, 33158, 60180, 54639, 11607, 60178, 20321, 33152, 11597,\n",
       "         11611, 54641, 11615, 50452, 33143, 60168, 33142, 46688, 20317,\n",
       "         60164, 33139, 33138, 46679, 46647, 46670, 50457, 60210, 11565,\n",
       "         27076, 11567, 60209, 60206, 33181, 50459, 50458, 11573, 33178,\n",
       "         11591, 11575, 27080, 20331, 60191, 27081, 60189, 11584, 60188,\n",
       "         11586, 27082, 20327, 11589, 54632, 11486, 54670, 20267, 54723,\n",
       "         59971, 46832, 11975, 11976, 50406, 50405, 59964, 59963, 32914,\n",
       "         11984, 11985, 59960, 11987, 20197, 59959, 59958, 59956, 11994,\n",
       "         11995, 46835, 20196, 59953, 27171, 54719, 54718, 11968, 11931,\n",
       "         59992, 46812, 46815, 54705, 46816, 11939, 11940, 27160, 59987,\n",
       "         59986, 46844, 59984, 54712, 11952, 46818, 32936, 32935, 27166,\n",
       "         11959, 32931, 54715, 32926, 32925, 27164, 59950, 32899, 50403,\n",
       "         12045, 12046, 12047, 27183, 50400, 59922, 32876, 59921, 12056,\n",
       "         32875, 59920, 32880, 12059, 12062, 54735, 12064, 20181, 59917,\n",
       "         54736, 59915, 20179, 59914, 32867, 59911, 46863, 59993, 59930,\n",
       "         59933, 32896, 46851, 12013, 12014, 12015, 12017, 59945, 20191,\n",
       "         59944, 12022, 59943, 46862, 59942, 46852, 12029, 32891, 32890,\n",
       "         12033, 27181, 59936, 59935, 46860, 59934, 54734, 54730, 59995,\n",
       "         59996, 20219, 33025, 46759, 20252, 11817, 60065, 11821, 20249,\n",
       "         20248, 11826, 11827, 11828, 11811, 60056, 33014, 11832, 20246,\n",
       "         11834, 60053, 50427, 46769, 20244, 54688, 20242, 33007, 11830,\n",
       "         60047, 27129, 11806, 60083, 11777, 60082, 11779, 27121, 11781,\n",
       "         50432, 11784, 11785, 54675, 27123, 11809, 46747, 46749, 27126,\n",
       "         60073, 50430, 33036, 33035, 46755, 11802, 54678, 11804, 11805,\n",
       "         20261, 20268, 33004, 11850, 27156, 32974, 32971, 60015, 60013,\n",
       "         11902, 20224, 54700, 11906, 32965, 20222, 60018, 60006, 46802,\n",
       "         11914, 32959, 20221, 46804, 32956, 32955, 11922, 11923, 54702,\n",
       "         32953, 32963, 11848, 46787, 11885, 60041, 60039, 60038, 27143,\n",
       "         27144, 60031, 60028, 54694, 11861, 32998, 32996, 60020, 46783,\n",
       "         50424, 60024, 11874, 46784, 11876, 27147, 32986, 27148, 32983,\n",
       "         11882, 50422, 32993, 12075, 11484, 11482, 33555, 11065, 33553,\n",
       "         11069, 11071, 26936, 46406, 50555, 26940, 60478, 60477, 11080,\n",
       "         60475, 20501, 60472, 50554, 50553, 60469, 54542, 33537, 46417,\n",
       "         11094, 50552, 33556, 46402, 60489, 11059, 33575, 20520, 20519,\n",
       "         20518, 46389, 33570, 50558, 46390, 11036, 11037, 60498, 33532,\n",
       "         46393, 11044, 11045, 26932, 60495, 60494, 11052, 11053, 60492,\n",
       "         11055, 46399, 20508, 11042, 54546, 33530, 33528, 11139, 60438,\n",
       "         60436, 11142, 33497, 60435, 60430, 20475, 11150, 46434, 20474,\n",
       "         20478, 60428, 33485, 11159, 46439, 20472, 46442, 11164, 20471,\n",
       "         60421, 60420, 46446, 46447, 33489, 33577, 46428, 60440, 60464,\n",
       "         54547, 26948, 33523, 11110, 20488, 50541, 33516, 11116, 33515,\n",
       "         33514, 46427, 11119, 26965, 54550, 11123, 11124, 20482, 50535,\n",
       "         33507, 33506, 33505, 46426, 33501, 60453, 33578, 60515, 60517,\n",
       "         20559, 60579, 10905, 26905, 26906, 10910, 10911, 50564, 10913,\n",
       "         60577, 33637, 50566, 60574, 10922, 60572, 54503, 60571, 46361,\n",
       "         33633, 10928, 10931, 10932, 20552, 20551, 10921, 26910, 10900,\n",
       "         54499, 10866, 54495, 46341, 46342, 33679, 20575, 46343, 10874,\n",
       "         46344, 60587, 26897, 46353, 10879, 10882, 10883, 33664, 33663,\n",
       "         46349, 46350, 54497, 10889, 33653, 10893, 10894, 26899, 46449,\n",
       "         10938, 10943, 10986, 10987, 60535, 60533, 10991, 60531, 33594,\n",
       "         33593, 20530, 60529, 60526, 33596, 60524, 33590, 60523, 11006,\n",
       "         46382, 11010, 20525, 46383, 33583, 54525, 33581, 11018, 54520,\n",
       "         54509, 10982, 20533, 60559, 10947, 60558, 46372, 60552, 60551,\n",
       "         26915, 10958, 20540, 10960, 46374, 26920, 33609, 33608, 10967,\n",
       "         20538, 26918, 50561, 54518, 54519, 33601, 46377, 10978, 60547,\n",
       "         10963, 60260, 33471, 20469, 11371, 33330, 20396, 33327, 46546,\n",
       "         11378, 33324, 54587, 50493, 33315, 11390, 27037, 11392, 33306,\n",
       "         33305, 33304, 11397, 60305, 46558, 11400, 33302, 33300, 60300,\n",
       "         33334, 46542, 27022, 11366, 33363, 60338, 33362, 20411, 11340,\n",
       "         20409, 33356, 50498, 27013, 46530, 60332, 11409, 11350, 11353,\n",
       "         11354, 11355, 20403, 60329, 27018, 46536, 11361, 11363, 46538,\n",
       "         50496, 11352, 11410, 33295, 50479, 46573, 33269, 11455, 46575,\n",
       "         50475, 11459, 33266, 33265, 11462, 33263, 54614, 50476, 11465,\n",
       "         54616, 60275, 60274, 11471, 33256, 46582, 11476, 60270, 33249,\n",
       "         33248, 33246, 60280, 20412, 60287, 33276, 11417, 60292, 11419,\n",
       "         46563, 33290, 11422, 11423, 46564, 33288, 11427, 11428, 46572,\n",
       "         11429, 11432, 11434, 33287, 11437, 33283, 20374, 33280, 27046,\n",
       "         33278, 20372, 11447, 11430, 11331, 60340, 60342, 26982, 26983,\n",
       "         11217, 11219, 11220, 54562, 33438, 11223, 50523, 11226, 54564,\n",
       "         11214, 11230, 11233, 60394, 46480, 33429, 54566, 33426, 20439,\n",
       "         46482, 11244, 33421, 46486, 26987, 11248, 46475, 20452, 11176,\n",
       "         11177, 26974, 20465, 46458, 54558, 50527, 60410, 54559, 54560,\n",
       "         50526, 11211, 11191, 20456, 11194, 33453, 11196, 46462, 33451,\n",
       "         11202, 20454, 46472, 46473, 60401, 33456, 33470, 60390, 11254,\n",
       "         20426, 33387, 54571, 46510, 33384, 54573, 20423, 11303, 50507,\n",
       "         11306, 11307, 60367, 33380, 46513, 20420, 20419, 11314, 20418,\n",
       "         50506, 33367, 11321, 60345, 60344, 46518, 46511, 33418, 33390,\n",
       "         33394, 60387, 60386, 46487, 46488, 11259, 46489, 46490, 46493,\n",
       "         60382, 46494, 33407, 27000, 50515, 11274, 50512, 11276, 60374,\n",
       "         60373, 11281, 20430, 11285, 33396, 11287, 54568, 46495, 33689,\n",
       "         59909, 12079, 12877, 12878, 32328, 12880, 47238, 59426, 19899,\n",
       "         47240, 47244, 54922, 32316, 12892, 47249, 12894, 47251, 32312,\n",
       "         12898, 32311, 47253, 12901, 32309, 27401, 32306, 27399, 59435,\n",
       "         27398, 19902, 32348, 54907, 47218, 27394, 54909, 54912, 59456,\n",
       "         59454, 27395, 59452, 12851, 27402, 12852, 12854, 59449, 47227,\n",
       "         12858, 32338, 47229, 12862, 59444, 12865, 54915, 59441, 32340,\n",
       "         47264, 59412, 59411, 59387, 12951, 12952, 32278, 59385, 59384,\n",
       "         59383, 12960, 32276, 27413, 12964, 47282, 19875, 12969, 12970,\n",
       "         12971, 47286, 12973, 59368, 59363, 47289, 59358, 59357, 27417,\n",
       "         32270, 59460, 12948, 59389, 19893, 47269, 32297, 12915, 59406,\n",
       "         19889, 32293, 47274, 19886, 19885, 32287, 12947, 12930, 50273,\n",
       "         32284, 27408, 59395, 59393, 19882, 59392, 19880, 59391, 27409,\n",
       "         12943], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_conjunctions': {'feature_present_idx': array([26169, 41912, 16226, 41918, 16212, 16211, 55436, 16244, 16200,\n",
       "         16177, 16174, 16168, 41966, 41967, 41977, 16193, 16249, 16258,\n",
       "         62494, 41760, 16400, 55465, 41801, 16337, 41824, 16324, 41829,\n",
       "         41833, 41846, 55457, 16309, 41864, 41865, 41869, 16145, 16144,\n",
       "         16124, 62519, 15854, 15847, 15807, 15797, 31721, 15770, 42255,\n",
       "         62626, 15726, 62631, 15708, 15706, 42290, 15663, 15659, 42186,\n",
       "         41754, 42167, 15911, 55421, 62525, 42007, 62527, 16062, 42021,\n",
       "         42030, 16029, 42072, 15993, 42079, 42090, 62571, 15928, 42141,\n",
       "         15889, 16433, 16439, 62419, 41363, 16960, 41381, 16949, 16942,\n",
       "         41411, 16917, 62259, 16904, 16899, 62270, 16864, 16862, 62285,\n",
       "         62291, 41357, 16833, 16965, 62223, 41251, 17109, 17102, 17095,\n",
       "         17083, 17058, 17054, 55606, 17025, 17018, 41323, 41325, 16995,\n",
       "         41353, 16983, 16975, 15642, 16815, 16789, 16550, 41648, 62371,\n",
       "         62382, 16527, 62384, 41677, 41683, 41690, 16475, 55473, 41712,\n",
       "         16467, 62411, 16451, 55489, 41463, 16608, 41590, 16773, 62319,\n",
       "         41491, 41508, 41514, 55553, 41519, 41527, 16704, 55551, 41547,\n",
       "         16688, 16678, 16659, 41588, 55518, 17150, 15608, 15601, 62960,\n",
       "         43067, 14777, 14776, 55092, 43085, 14795, 62973, 14736, 43124,\n",
       "         14724, 14720, 43129, 63006, 43090, 43064, 43060, 62953, 42980,\n",
       "         62933, 42989, 14913, 14902, 62938, 14880, 14876, 62945, 55109,\n",
       "         43017, 43021, 14841, 43040, 43050, 14699, 14683, 14682, 14676,\n",
       "         14519, 55044, 14516, 43299, 14475, 55034, 14456, 14450, 63068,\n",
       "         63071, 43325, 14391, 14375, 43363, 55027, 14520, 42977, 43261,\n",
       "         14556, 14672, 14666, 14650, 14646, 43172, 14618, 43174, 43175,\n",
       "         43179, 14597, 14591, 14588, 14579, 43207, 43218, 14532, 14939,\n",
       "         42959, 14955, 15427, 42540, 15420, 42542, 15403, 42587, 42599,\n",
       "         42609, 62746, 15350, 15349, 62756, 42662, 42675, 42695, 42529,\n",
       "         42700, 15449, 42478, 42355, 15581, 15574, 62646, 15570, 62659,\n",
       "         15548, 55283, 42405, 42419, 62665, 15522, 15503, 15496, 15471,\n",
       "         15455, 62645, 15278, 15268, 55130, 42904, 62876, 15035, 15022,\n",
       "         62880, 42927, 15001, 62886, 62891, 14984, 42947, 14970, 62897,\n",
       "         42954, 55136, 55191, 15079, 55150, 15237, 15232, 15231, 15222,\n",
       "         15203, 62800, 62819, 42736, 42744, 42803, 42839, 15123, 15117,\n",
       "         42848, 15110, 42876, 14300, 17151, 17183, 40026, 40035, 19063,\n",
       "         40049, 19048, 19024, 19081, 40079, 55907, 18987, 18983, 61784,\n",
       "         18957, 55891, 40082, 40006, 19095, 19097, 39897, 39911, 55941,\n",
       "         55940, 19219, 39950, 19203, 19186, 39953, 55935, 39959, 39982,\n",
       "         19153, 19136, 19126, 18935, 61797, 61805, 55889, 18747, 18739,\n",
       "         40291, 40295, 18709, 40332, 61843, 40376, 40383, 18633, 40395,\n",
       "         40399, 18625, 18618, 40417, 40286, 39896, 18757, 18766, 18895,\n",
       "         18882, 18878, 40164, 18845, 18837, 40224, 55869, 18822, 40231,\n",
       "         18804, 18793, 40242, 18781, 40281, 18762, 19276, 39893, 61691,\n",
       "         19749, 19738, 19728, 39662, 55990, 61551, 19705, 61552, 39695,\n",
       "         19682, 61555, 61556, 19653, 61564, 39722, 39635, 19628, 19761,\n",
       "         19769, 39565, 39568, 39579, 39581, 39584, 39604, 19845, 19843,\n",
       "         19822, 56021, 56008, 61524, 19797, 19789, 19781, 39634, 55838,\n",
       "         55985, 61574, 19388, 19387, 19384, 39841, 19382, 19378, 19372,\n",
       "         61670, 39871, 61680, 61681, 19307, 55957, 39891, 19292, 19397,\n",
       "         61571, 19424, 61652, 39742, 61580, 39755, 61593, 19536, 61600,\n",
       "         19508, 19503, 39794, 19497, 19496, 19492, 19483, 39815, 39833,\n",
       "         39836, 17166, 18577, 61875, 40908, 55714, 55711, 17662, 17644,\n",
       "         17641, 17706, 17639, 62063, 17628, 17622, 17621, 17604, 40983,\n",
       "         40955, 17712, 17717, 17738, 17890, 55745, 55743, 17877, 62036,\n",
       "         17860, 40800, 55724, 17843, 17811, 40845, 17801, 17795, 17760,\n",
       "         55719, 40985, 55693, 62071, 41026, 17304, 62135, 41182, 17290,\n",
       "         17284, 41191, 17250, 17249, 41221, 55640, 41230, 55629, 17200,\n",
       "         17188, 17186, 17305, 62014, 17332, 41148, 17565, 17551, 17501,\n",
       "         17496, 17479, 17463, 17451, 17436, 41111, 62097, 17403, 17390,\n",
       "         17374, 62115, 41136, 41162, 17907, 17917, 17930, 55821, 40494,\n",
       "         18382, 40512, 18360, 40514, 18347, 18338, 40524, 40526, 18317,\n",
       "         18312, 40541, 18286, 18285, 40487, 18268, 18416, 55825, 40420,\n",
       "         18556, 18555, 40422, 40423, 18500, 61900, 40442, 18467, 18463,\n",
       "         40456, 40464, 18456, 40471, 18430, 18418, 55830, 40556, 18231,\n",
       "         18034, 55767, 55761, 18020, 18016, 40669, 18000, 61993, 61994,\n",
       "         55756, 17975, 40695, 40701, 40703, 40728, 18035, 18245, 61987,\n",
       "         55789, 40572, 18219, 40579, 18192, 61971, 40608, 18162, 18148,\n",
       "         40615, 18134, 40631, 18099, 18092, 18079, 40645, 40651, 14299,\n",
       "         14282, 63094, 54324, 54307, 10360, 10322, 10315, 54305, 45797,\n",
       "         54304, 10269, 10261, 10254, 10247, 10246, 45861, 10276, 10407,\n",
       "         10410, 45794, 64193, 10551, 54356, 45702, 45707, 54352, 10512,\n",
       "         54345, 64210, 10483, 10471, 10470, 45745, 45764, 45782, 10221,\n",
       "         10208, 45881, 10201, 46033, 46057,  9984, 64371,  9968, 46064,\n",
       "          9958, 46094,  9922,  9914, 64387,  9911,  9910, 46112, 46127,\n",
       "         10036, 54358, 10052, 10079, 45889, 45890, 45891, 45894, 10179,\n",
       "         10165, 64317, 45910, 54292, 45925, 45937, 45958, 45973, 45978,\n",
       "         45979, 45991, 10566, 45668, 10573, 64048, 10983, 10969, 10968,\n",
       "         10965, 45472, 64059, 10907, 45492, 10899, 10890, 10881, 10880,\n",
       "         10875, 10868, 45412, 10860, 45408, 11009, 11165, 45314, 11133,\n",
       "         11106, 11104, 45325, 45336, 11083, 45362, 45380, 45392, 11028,\n",
       "         45399, 11017, 11014, 64031, 46139, 10851, 45519, 64156, 64158,\n",
       "         45617, 64167, 64173, 45623, 45627, 45633, 10600, 10596, 10594,\n",
       "         10586, 45656, 10581, 64179, 45614, 45514, 45585, 64147, 64087,\n",
       "         10826, 10823, 10816, 10814, 64095, 45534, 10783, 10781, 45539,\n",
       "         10751, 10748, 10731, 64144, 45559, 45569, 54427, 46142, 46157,\n",
       "         46715,  8868, 46722,  8841, 64772,  8831,  8877, 46750,  8804,\n",
       "         46776,  8786,  8783,  8780, 46788,  8826,  8906,  8909,  8910,\n",
       "         46600,  9065, 64698,  9039, 64702,  9013,  9000,  8988, 46645,\n",
       "         64711,  8957,  8955,  8944,  8943, 46681, 46797,  8761,  8759,\n",
       "         46801, 46915, 46918,  8570,  8564,  8562,  8561, 64865, 46920,\n",
       "          8533,  8521,  8509, 46950, 46951, 53998,  8477,  8576, 54119,\n",
       "          8587,  8631, 54034,  8753, 64804, 54028,  8713,  8710, 46824,\n",
       "         46834, 46839, 64825, 46848,  8652, 54023, 54008, 64837,  8600,\n",
       "          9110, 54121,  9139, 46240,  9663,  9660, 54201,  9652,  9636,\n",
       "         64519, 46275, 46281, 46310,  9548,  9545, 46327,  9534,  9531,\n",
       "         64495, 46328,  9690,  9722, 64436, 46161,  9854, 46170,  9830,\n",
       "          9814,  9809,  9798, 54236, 54234, 64470,  9757,  9740, 64484,\n",
       "         46213,  9720, 46147,  9516,  9484, 54177, 46461, 46465, 64624,\n",
       "          9264, 54151, 46477,  9248, 54126, 46527, 46535, 46541, 64661,\n",
       "          9142, 46554,  9318,  9501,  9336, 46443, 64559,  9465,  9452,\n",
       "         46357, 46362, 64571,  9427, 46369, 46376,  9415, 46378,  9396,\n",
       "         46392, 46418,  9349,  9337, 11184, 54431, 45289, 13200, 13196,\n",
       "         13177, 13169, 63434, 54803, 13203, 44114, 13100, 13085, 13077,\n",
       "         54790, 44172, 63470, 54797, 13212, 44057, 13227, 13373, 43973,\n",
       "         13363, 43991, 43998, 13318, 44003, 13306, 54818, 63395, 44037,\n",
       "         44048, 44054, 13239, 44055, 44182, 13023, 13021, 54771, 44290,\n",
       "         54728, 12830, 63531, 44319, 54725, 44354, 12775, 12766, 44358,\n",
       "         12754, 12740, 12736, 63553, 44367, 12893, 63351, 12895, 44268,\n",
       "         44191, 12995, 44194, 12984, 12981, 44200, 44209, 44221, 44226,\n",
       "         63507, 44229, 12938, 12933, 12932, 12925, 44283, 54841, 13419,\n",
       "         13442, 43514, 14061, 43517, 14048, 13966, 13959, 63187, 43574,\n",
       "         13931, 43595, 13906, 13893, 43608, 13876, 13874, 43511, 13865,\n",
       "         43510], dtype=int64),\n",
       "  'feature_absent_idx': array([13565, 58941, 33888, 58937, 16458, 58935, 16462, 33887, 33885,\n",
       "         58933, 33883, 16474, 33880, 16477, 33878, 58928, 33875, 58925,\n",
       "         16490, 50016, 33867, 16493, 16494, 16496, 50021, 58919, 16504,\n",
       "         33860, 16453, 50024, 33889, 16444, 33932, 16378, 16380, 16382,\n",
       "         49999, 33927, 50000, 16393, 16394, 16397, 58966, 16401, 16407,\n",
       "         33916, 33914, 16414, 16415, 16420, 16422, 16424, 33904, 16428,\n",
       "         33903, 33902, 58951, 58950, 16443, 33892, 16376, 58915, 58914,\n",
       "         16579, 33817, 50046, 16585, 16586, 16588, 50049, 33808, 33804,\n",
       "         33802, 58865, 33798, 33797, 16607, 58859, 50055, 33792, 33790,\n",
       "         33788, 16626, 16627, 33787, 58851, 50058, 50060, 33783, 58842,\n",
       "         16578, 16510, 16575, 58884, 58912, 16517, 33855, 58907, 16522,\n",
       "         16532, 16533, 16534, 33840, 16537, 58897, 16539, 58894, 16543,\n",
       "         16544, 33836, 16551, 33835, 33834, 16560, 33827, 33825, 16564,\n",
       "         16566, 33821, 33820, 58885, 58882, 50062, 49994, 58974, 16173,\n",
       "         49931, 16178, 34066, 34065, 16182, 34064, 34054, 59073, 16196,\n",
       "         34053, 34050, 16201, 49941, 16203, 34047, 34046, 34043, 16216,\n",
       "         34040, 16219, 59058, 34033, 16222, 16223, 16227, 34029, 59087,\n",
       "         34026, 59088, 16165, 16117, 49891, 49897, 49898, 16122, 16123,\n",
       "         16125, 16126, 16129, 49901, 59112, 59110, 16135, 16136, 16138,\n",
       "         34093, 34092, 59106, 16142, 49923, 16151, 59104, 16155, 34077,\n",
       "         59093, 59092, 16164, 59089, 16373, 49948, 59045, 33970, 49976,\n",
       "         16321, 49978, 33966, 33961, 16332, 33960, 58992, 16339, 16340,\n",
       "         16343, 49985, 49988, 16347, 33954, 58987, 16350, 16356, 58982,\n",
       "         16358, 58981, 16360, 16364, 33939, 33937, 16369, 16316, 34022,\n",
       "         16313, 33975, 16241, 16242, 59043, 34013, 16250, 16252, 59040,\n",
       "         49954, 59038, 16260, 59037, 34009, 34005, 16266, 59032, 49960,\n",
       "         16278, 59016, 33996, 33995, 16285, 33989, 16294, 59006, 16300,\n",
       "         59003, 49973, 16308, 16640, 33779, 16644, 33577, 16991, 33575,\n",
       "         16996, 50165, 58672, 58671, 17001, 33570, 17006, 50176, 58666,\n",
       "         50180, 17019, 33556, 33555, 33553, 17027, 50184, 50194, 33537,\n",
       "         17037, 58657, 50200, 33532, 33530, 33528, 16989, 17050, 33578,\n",
       "         16981, 58714, 50154, 58713, 16919, 58712, 58708, 33609, 33608,\n",
       "         16935, 16937, 33601, 16943, 58697, 33596, 33594, 33593, 16955,\n",
       "         58694, 33590, 50161, 16970, 58687, 58684, 16973, 58680, 33583,\n",
       "         33581, 16986, 58718, 33523, 17055, 17116, 17118, 33471, 33470,\n",
       "         17125, 50232, 17132, 58601, 33456, 17139, 33453, 33451, 17146,\n",
       "         50241, 17148, 17152, 17154, 17156, 33438, 17159, 17161, 17162,\n",
       "         17163, 17165, 17169, 58573, 58572, 17113, 17053, 58615, 50223,\n",
       "         17056, 50203, 50205, 33516, 58643, 33515, 33514, 17070, 33507,\n",
       "         17072, 33506, 58635, 33505, 58632, 17077, 58631, 17080, 33501,\n",
       "         33497, 58628, 17090, 33489, 58621, 33485, 50215, 17105, 50218,\n",
       "         17111, 50151, 16905, 16901, 16719, 16721, 16725, 50084, 58799,\n",
       "         58797, 58796, 50087, 16732, 33727, 33726, 16736, 50092, 16747,\n",
       "         16748, 16750, 16752, 50103, 16755, 16760, 33710, 58781, 16766,\n",
       "         58780, 50104, 16770, 16771, 16715, 58779, 33734, 16711, 33772,\n",
       "         16654, 50070, 58827, 16661, 50074, 58821, 16668, 58820, 33751,\n",
       "         16675, 33748, 16681, 58814, 33747, 16685, 16692, 16694, 33739,\n",
       "         58809, 16697, 16698, 16699, 16702, 33737, 33736, 16709, 16712,\n",
       "         16775, 16776, 33706, 16847, 50139, 16849, 33653, 50141, 16855,\n",
       "         16856, 58747, 16867, 58746, 16871, 16873, 16874, 58744, 16876,\n",
       "         33637, 58741, 58740, 58739, 50142, 16889, 33633, 16893, 50143,\n",
       "         16897, 16898, 50145, 16844, 50131, 33663, 33664, 16778, 58776,\n",
       "         16782, 16785, 16786, 16788, 16792, 16794, 33700, 58770, 16797,\n",
       "         58769, 33693, 49890, 16802, 50112, 16807, 16808, 33689, 16812,\n",
       "         16813, 33679, 50122, 16824, 16827, 58754, 16830, 16835, 33692,\n",
       "         17173, 34116, 16108, 15433, 34543, 34541, 15437, 15440, 49661,\n",
       "         59486, 59484, 59479, 59473, 15459, 15462, 49666, 59467, 34526,\n",
       "         34524, 59460, 49667, 34522, 49668, 49677, 15485, 59456, 49678,\n",
       "         49679, 59454, 15490, 34546, 15493, 15429, 59499, 15364, 15365,\n",
       "         15370, 15372, 15376, 34583, 59519, 15383, 34579, 49648, 59515,\n",
       "         34573, 15392, 34572, 34570, 49649, 59509, 59508, 15406, 49654,\n",
       "         15410, 34556, 59500, 15417, 34554, 34553, 34552, 34547, 34587,\n",
       "         59452, 59449, 15576, 15577, 49703, 59395, 15586, 59393, 34462,\n",
       "         15590, 34457, 15592, 15594, 49707, 15598, 49708, 59392, 15602,\n",
       "         59391, 59389, 34445, 34441, 34440, 59387, 59385, 59384, 15619,\n",
       "         49712, 49713, 34468, 34512, 15571, 15563, 59444, 15509, 49686,\n",
       "         59441, 15514, 15516, 15519, 34500, 59435, 15524, 34498, 59426,\n",
       "         15530, 34495, 34493, 15534, 15535, 49691, 34488, 15541, 59412,\n",
       "         15547, 59411, 34483, 59406, 15560, 49696, 15566, 59383, 59529,\n",
       "         15354, 15172, 34703, 15176, 34702, 34701, 59618, 15182, 15188,\n",
       "         59612, 15190, 15195, 59609, 15198, 34691, 59603, 34688, 15205,\n",
       "         49586, 34685, 49588, 15212, 34679, 49590, 49594, 15217, 15220,\n",
       "         15226, 15171, 15227, 15170, 49578, 34740, 34738, 34727, 34725,\n",
       "         15134, 15136, 34722, 49570, 59643, 15144, 59641, 49572, 34714,\n",
       "         15149, 59639, 15151, 59638, 15154, 34710, 15157, 15159, 59636,\n",
       "         15161, 49574, 15165, 15166, 59635, 49579, 49642, 15228, 15235,\n",
       "         15299, 15300, 34628, 59570, 59565, 59564, 15315, 15316, 15320,\n",
       "         34612, 59560, 59555, 34611, 15326, 34607, 15330, 34605, 59547,\n",
       "         15336, 15337, 34600, 59544, 34598, 49639, 34593, 59537, 15353,\n",
       "         34634, 59594, 15290, 15284, 15236, 15239, 59593, 59592, 59590,\n",
       "         15246, 34664, 59587, 15250, 15251, 34663, 34661, 34659, 15255,\n",
       "         15256, 15257, 15260, 15263, 49605, 49606, 15266, 15267, 34650,\n",
       "         49609, 15279, 49610, 15281, 59573, 15624, 34434, 59368, 15931,\n",
       "         34235, 59198, 34227, 59195, 59191, 15942, 15943, 34218, 34214,\n",
       "         34212, 15957, 59183, 34207, 34205, 34204, 15964, 49825, 15968,\n",
       "         59179, 49831, 15972, 34198, 59178, 49837, 15984, 15988, 59199,\n",
       "         49847, 59206, 15922, 59243, 34274, 49800, 15872, 59241, 59240,\n",
       "         59237, 59236, 15881, 15882, 34269, 59235, 15887, 15891, 34262,\n",
       "         49803, 15898, 15901, 34253, 49809, 59212, 15908, 59211, 34243,\n",
       "         59210, 34241, 15921, 15925, 15863, 15994, 15997, 16070, 16071,\n",
       "         16072, 34139, 34138, 59134, 16078, 34136, 16081, 34134, 34133,\n",
       "         34131, 49885, 16088, 34128, 16091, 16092, 34127, 59128, 34126,\n",
       "         34123, 16098, 16099, 16103, 16104, 34120, 59123, 16067, 34179,\n",
       "         59139, 34147, 49851, 59170, 59168, 34174, 34173, 49854, 49855,\n",
       "         16016, 49856, 34168, 59163, 34164, 34162, 59158, 59154, 16033,\n",
       "         16036, 49865, 16040, 16042, 16044, 34153, 59147, 16050, 34149,\n",
       "         16056, 16057, 34145, 15862, 49796, 34282, 59326, 15688, 34393,\n",
       "         59323, 15694, 49732, 59320, 34382, 15704, 15705, 34380, 15709,\n",
       "         34378, 49739, 49742, 15722, 15723, 15724, 15727, 34366, 15730,\n",
       "         15731, 15732, 15733, 15737, 34362, 59301, 15686, 49752, 34395,\n",
       "         34399, 34433, 15630, 15632, 15634, 59363, 15637, 34427, 34426,\n",
       "         15641, 34422, 34420, 59358, 34417, 59357, 15652, 49725, 34413,\n",
       "         15656, 15657, 15660, 59349, 59348, 15670, 15676, 59339, 15679,\n",
       "         59330, 49729, 59299, 34359, 34357, 15802, 15803, 34316, 15808,\n",
       "         15812, 15813, 34314, 15815, 59265, 59264, 15823, 59262, 59261,\n",
       "         15826, 15827, 15829, 34304, 34302, 15834, 15835, 34298, 15837,\n",
       "         15843, 15848, 34285, 59249, 34283, 15800, 59268, 59270, 34319,\n",
       "         34353, 15750, 59293, 15754, 15756, 49760, 59286, 49761, 59283,\n",
       "         15766, 15768, 34338, 34335, 34119, 15773, 34334, 15777, 15780,\n",
       "         49767, 49768, 34328, 34326, 34325, 15787, 34324, 59274, 59273,\n",
       "         49771, 15774, 34741, 50245, 17177, 57898, 50672, 32590, 57887,\n",
       "         32585], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_interrogative_clause': {'feature_present_idx': array([66745, 38631, 39392, 49591, 16437, 54056, 57672, 58691, 26559,\n",
       "         60865,  8777,  8428, 10297, 64994, 64338, 16314, 31518, 12393,\n",
       "         15689, 22089, 52727, 66371, 45297, 33603, 60061, 41905, 62732,\n",
       "         29772, 57729, 39724, 45905, 32055,  6030, 11246, 10918, 24382,\n",
       "         21348, 20969,  9262, 18476, 20515, 20039, 19411, 13094, 52459,\n",
       "         59404, 16972, 43557, 49394, 37986, 36296, 35521, 32788, 65185,\n",
       "         30237, 57155, 12352,  2917, 46668, 48561, 57872, 30146, 29990,\n",
       "         56445,  9141,   169, 53349, 51146, 16541, 60695, 19330, 38408,\n",
       "         54238, 30862, 16502, 25048, 26565,  1533], dtype=int64),\n",
       "  'feature_absent_idx': array([38026, 57568, 57567, 57566, 28248, 12707, 28247, 12710, 12711,\n",
       "         45576, 12714, 28241, 28240, 12717, 57570, 28238, 12723, 28233,\n",
       "         28232, 57550, 45583, 28225, 57544, 28224, 45592, 12739, 45594,\n",
       "         28218, 12742, 12721, 28213, 45573, 12696, 57609, 45535, 57605,\n",
       "         12653, 57601, 45542, 12661, 57599, 12663, 12664, 45544, 12667,\n",
       "         57596, 57571, 28274, 57591, 45553, 12675, 12676, 45557, 28267,\n",
       "         28265, 28264, 57579, 57578, 45565, 45567, 12693, 57594, 45598,\n",
       "         45599, 28209, 12799, 28173, 12805, 12807, 28167, 12811, 12812,\n",
       "         12813, 45626, 45628, 57480, 12824, 12826], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 78\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 78\n",
       "  })},\n",
       " 'contains_question': {'feature_present_idx': array([67304, 30335,  8182, 17677,  7867, 17730, 45181, 17377, 18354,\n",
       "         25737, 61799, 28326, 20561, 51808, 41298,  6213,  8421, 59876,\n",
       "         35393, 32552, 13483, 56966, 11768, 11633, 42474, 11341, 43286,\n",
       "         58230, 41988, 10121, 34482,  9733, 31593, 55548, 20820,  3529,\n",
       "         57289, 23512, 23649, 65462,   535,  2201, 26590, 48472, 48832,\n",
       "         64955, 66383, 46867, 24654, 43450, 31821, 56247, 55919, 44496,\n",
       "         16804, 31043, 16886, 48918, 30947, 55055, 48943, 44891, 46795,\n",
       "         44906, 30456, 44723, 15506, 48705, 27286, 13387, 48121, 26224,\n",
       "         13547, 57197, 13596, 57057, 57018, 26290, 14272, 48443, 14318,\n",
       "         25390, 14523, 32302, 56925, 56741, 14632, 42966, 47291, 32065,\n",
       "         56250, 44952, 50971, 17654, 28596, 46026, 50266, 19960, 20015,\n",
       "         20147, 20153, 20528, 28038, 22889, 20799, 22583, 51801, 28087,\n",
       "         46549, 51206, 21852, 22565, 21963, 21979, 21985, 51022, 22258,\n",
       "         52139, 50500, 19694, 52920, 27648, 27902, 27966, 45029, 17781,\n",
       "         23330, 17882, 54033, 18278, 53751, 23289, 45485, 53580, 18696,\n",
       "         28010, 18854, 28992, 23173, 53173, 19182, 19235, 52999, 45933,\n",
       "         52858, 38879, 47911,  5691,  5361, 36443,  5548, 36414, 36356,\n",
       "          5664, 57541,  5803, 36325, 36314,  5229, 36242, 37429, 36074,\n",
       "          6654,  2293, 61054, 35951, 60815,  6959,  7206, 60627,  2449,\n",
       "          2766, 61871, 62035, 40199,  3042, 40311, 64266, 64101, 36787,\n",
       "         36723, 36679, 37113, 40899,  2459, 63219,  2569,  4029, 41092,\n",
       "         62940, 62890, 62842, 62528,  4669,  4823, 36448, 63105, 37582,\n",
       "         65187,  7382, 41682, 10106,   784,   628, 58085, 37984,   248,\n",
       "         11132, 11547, 11726, 11800, 66406, 33329, 12043, 38070, 12353,\n",
       "         33189, 12609, 12615, 42504, 57545, 10008, 65981, 34208,  8848,\n",
       "         59645, 41980, 35572, 35133, 60177, 35610, 34978,  1551,  8358,\n",
       "          9239,  8113, 65646, 58792, 58755, 60353, 40179, 47709, 46626,\n",
       "         37913, 37618, 39630, 26272, 37748, 39955, 26651, 47309, 47183,\n",
       "         39250, 40116, 37552, 42528, 28044, 67232, 32490, 42783, 42233,\n",
       "         33535, 33619, 33823, 33861, 34158, 32003, 31827, 34514, 31510,\n",
       "         34673, 36970, 34937, 35316, 35490, 35649, 30083, 41479, 45456,\n",
       "         45665, 29136, 36161, 28330, 46216, 40902, 36648, 36655, 34987,\n",
       "         32666, 53289, 38459, 58875, 65576,  9304, 58586,  9992, 10092,\n",
       "         58570, 10543, 10718, 57931, 25671, 10997, 11579, 11872, 12414,\n",
       "         12624, 12764, 13181, 13391, 13634, 14067, 14544, 63996, 59008,\n",
       "          2499,  8889, 59220,  2933,  3360, 63674, 63400, 63035,  4110,\n",
       "          4133, 62080,  5379,  2685,  5645, 56299,  5942,  2600,  6069,\n",
       "          6224,  2585,  7270,  7380, 60626,  8258,  8345,  8389, 59259,\n",
       "         61642, 14961, 56486,  1305, 19377, 52086, 51934, 51865, 19909,\n",
       "         20444, 51795, 51288, 50485, 23278,   456, 23485, 23566, 49328,\n",
       "         23979, 24579,   144, 24821, 25036, 25197, 48275, 25482, 25537,\n",
       "         16031, 66315,  3090, 55931,  1004, 16513, 16345, 16679, 16759,\n",
       "         55445, 54954, 17221,   922, 65784, 55778, 17555, 56069, 54417,\n",
       "         54312, 17846, 53768, 53702, 18605, 53470, 17477, 64503, 39215,\n",
       "         38959, 39715, 39405, 65519, 39158, 65621, 38931, 40005, 47353,\n",
       "         63698, 48772, 48783, 49600, 50250, 50707, 53459, 45848, 54733,\n",
       "         55686, 44326, 43941, 43367, 57816, 58521, 41834, 58948, 59095,\n",
       "         41783, 61041, 61174, 61703, 63735, 57823,    63, 32881, 22388,\n",
       "         30186, 22330, 30586, 30863,  3791, 22008, 10842, 30025, 21658,\n",
       "         31403, 31517,  3344, 20980, 17281,  3165,  8978, 32231, 21466,\n",
       "         22527, 23081,  8586, 24719,  6785, 24869, 25400,  6714, 25664,\n",
       "          6793,  6024, 26221,  5555,  7236, 26403, 10919, 26668,  5167,\n",
       "         28074,  4654, 17968, 12680, 32243,  2855,  9037, 32874, 36890,\n",
       "         32555, 36929, 13187, 37211, 37367, 18955,   916, 37699,   441,\n",
       "         37782, 10236, 18078, 37930, 38023, 38119, 18819,  1027, 24694,\n",
       "         33442, 36542,  1755, 35040,  9137,  1979, 35886, 19731,  2783,\n",
       "         17844,  9426, 10171, 17773, 52049, 10918, 24483, 54225, 19856,\n",
       "         18480, 52264, 49368, 52420, 23474, 53308, 49670,  9907, 59408,\n",
       "         52668,  8535, 23065, 58619, 58789, 19328, 23639, 38676, 28490,\n",
       "         24713, 55988, 33481, 42041, 65157, 34209, 16326, 41751, 36508,\n",
       "         40898, 65652, 40390, 40205, 13549, 40075, 37614,   815, 37762,\n",
       "         39369,   157, 56378, 38990, 64386, 24666, 64345, 64058, 25862,\n",
       "         25945, 55123, 47245, 46998, 27244, 46523, 57615,  3866, 31733,\n",
       "         29154, 29612, 45085, 30199, 16558,  3671, 31300, 16334,  3320,\n",
       "         29187, 54097, 57364, 58001, 57456, 61786,  9368, 66863, 66163,\n",
       "         66109,  2301,  2717, 64589,  3657, 63544, 58250,  3788, 62689,\n",
       "          5554, 13809, 60783,  8114, 59549,  8879,  9175,  4412, 13905,\n",
       "         38371, 34073, 19449, 47299, 42101, 42242, 31923, 51864, 43652,\n",
       "         51782, 21849, 43818, 50080, 43824, 44366, 44717, 44824, 48695,\n",
       "         45723, 28734, 27245, 19152, 19139, 14571, 18310, 14702, 37788,\n",
       "         15696, 16348, 39402, 39446, 18657, 37028, 16972, 37062, 17076,\n",
       "         53844, 36459, 35882, 17206, 64358,  3397, 40785,  2236, 44779,\n",
       "         43734, 65956, 66564,  4629,  2771, 28318,  4973, 39164, 26634,\n",
       "         53189, 19888, 19598, 58402, 57473, 10375, 20779,  8690, 54876,\n",
       "         49850,  7456, 52625, 17110, 49298, 24420, 25473, 57720, 16622,\n",
       "         61085, 47421, 12886, 26320, 14631, 19768, 40664, 58016, 65516,\n",
       "         12864, 14222, 14762,  5983,  4280, 31245, 61783, 23425, 15448,\n",
       "         64174, 52031,  8282,  3091, 34564, 62926, 40611, 62554, 65556,\n",
       "         36644, 67055,  4985, 49206, 29057, 32378, 43054], dtype=int64),\n",
       "  'feature_absent_idx': array([29915, 12813, 57611, 57609, 28436, 45674, 57605, 12824, 57601,\n",
       "         12826, 28429, 57599, 12829, 45683, 12812, 57596, 57594, 28421,\n",
       "         28416, 57591, 28410, 45695, 28408, 12851, 12852, 57579, 12854,\n",
       "         57578, 28407, 12835, 45696, 12811, 12807, 57650, 12762, 12763,\n",
       "         45652, 12768, 12769, 12770, 12771, 12773, 12777, 12782, 57643,\n",
       "         57642, 28439, 57641, 28452, 28450, 57629, 57628, 28448, 57626,\n",
       "         28447, 12799, 28445, 45671, 45672, 12805, 28441, 45664, 12858,\n",
       "         45699, 12862, 45726, 12915, 28361, 57526, 57525, 57524, 45731,\n",
       "         45732, 57518, 12930, 28350, 45736, 57516, 45725, 45740, 57513,\n",
       "         28341, 57511, 28337, 12943, 45747, 28333, 12947, 12948, 28331,\n",
       "         12951, 12952, 57502, 45743, 28370, 28371, 45722, 45701, 12865,\n",
       "         45704, 57571, 57570, 57568, 57567, 57566, 28398, 28397, 45705,\n",
       "         12877, 12878, 12880, 45711, 28388, 57550, 28383, 12892, 28382,\n",
       "         12894, 45713, 12898, 28378, 12901, 45716, 45717, 28374, 57544,\n",
       "         28473, 57501, 57656, 28478, 28592, 28589, 57772, 45592, 28583,\n",
       "         57770, 28580, 57768, 45594, 57766, 57762, 45598, 45599, 45583,\n",
       "         45600, 12634, 28562, 45603, 57753, 57750, 28558, 12644, 28552,\n",
       "         57745, 12653, 28548, 57741, 45609, 12633, 57736, 12598, 12596,\n",
       "         12550, 28630, 45565, 57811, 12557, 45567, 28624, 28622, 12562,\n",
       "         28621, 57807, 57801, 12568, 12597, 57796, 12574, 28612, 45573,\n",
       "         45576, 12581, 28605, 12583, 12586, 57782, 28602, 12592, 28595,\n",
       "         12595, 57795, 57735, 28544, 12661, 45628, 12714, 57688, 12717,\n",
       "         28504, 12721, 12723, 57683, 28501, 28500, 28498, 28494, 28493,\n",
       "         12711, 57676, 45635, 45638, 12739, 28487, 45639, 12742, 57670,\n",
       "         57667, 57666, 57665, 28482, 57662, 45643, 45634, 12710, 45626,\n",
       "         12707, 12663, 12664, 57731, 12667, 57730, 45611, 57725, 28537,\n",
       "         12675, 12676, 28536, 57723, 28534, 45615, 45616, 28530, 28529,\n",
       "         57718, 57717, 57715, 12693, 28525, 45618, 12696, 45619, 28521,\n",
       "         28520, 28519, 57699, 28476, 12546, 57493, 12960, 28124, 28117,\n",
       "         28114, 28113, 13233, 57271, 45923, 28109, 28108, 57266, 57265,\n",
       "         45927, 13243, 28126, 57261, 45929, 13249, 57257, 57256, 57254,\n",
       "         13255, 57252, 57251, 13259, 28097, 57247, 45935, 28093, 13247,\n",
       "         28091, 13221, 13219, 13167, 45879, 13173, 13176, 13183, 28150,\n",
       "         57306, 57305, 13190, 45892, 13193, 57303, 45895, 57283, 57301,\n",
       "         28140, 13201, 57299, 45900, 28136, 57297, 28135, 13209, 45903,\n",
       "         45904, 13214, 13217, 28128, 45899, 45939, 13269, 13271, 13317,\n",
       "         28056, 13322, 28051, 57188, 13328, 13329, 28047, 45968, 13333,\n",
       "         45969, 28042, 13338, 57208, 28034, 13345, 13347, 45976, 28026,\n",
       "         45984, 45986, 28018, 13362, 13364, 13365, 28013, 57156, 45990,\n",
       "         13344, 13311, 28063, 28064, 57237, 13273, 13274, 28088, 28085,\n",
       "         57232, 28084, 13280, 57230, 57227, 28082, 57224, 57221, 13288,\n",
       "         28080, 13290, 28079, 13292, 13293, 28078, 13295, 57218, 28076,\n",
       "         13301, 45945, 45948, 45953, 13307, 57209, 28167, 45758, 45874,\n",
       "         13160, 28264, 57437, 13028, 13029, 45807, 57433, 45809, 13037,\n",
       "         57430, 13040, 57429, 57428, 57427, 28265, 57425, 57423, 28247,\n",
       "         13052, 57422, 57420, 28241, 28240, 28238, 45823, 57415, 57413,\n",
       "         13065, 45824, 28248, 28233, 45803, 13020, 45761, 12964, 28316,\n",
       "         12969, 12970, 12971, 28310, 12973, 57480, 28304, 45769, 12983,\n",
       "         28299, 28267, 12987, 45779, 57468, 45786, 13002, 13003, 57450,\n",
       "         28274, 57447, 13014, 57442, 13016, 45800, 57441, 12989, 57405,\n",
       "         57403, 28232, 57362, 45846, 45847, 57359, 45849, 28191, 57352,\n",
       "         57350, 28188, 57344, 45856, 57341, 57339, 57365, 28182, 13146,\n",
       "         57336, 13148, 13149, 45864, 13151, 57334, 45865, 13154, 45872,\n",
       "         57329, 28173, 57325, 45863, 57366, 57367, 45843, 57401, 57399,\n",
       "         45826, 57395, 45828, 13079, 13081, 28225, 28224, 13084, 57392,\n",
       "         57391, 28218, 57389, 13095, 13096, 13098, 28213, 13101, 57386,\n",
       "         13103, 13106, 13108, 57381, 28209, 28208, 13112, 28207, 28205,\n",
       "         13161, 57821, 12544, 28634, 29041, 58243, 29040, 58242, 29039,\n",
       "         12013, 12014, 12015, 45233, 12017, 58240, 58239, 58237, 29042,\n",
       "         12022, 29035, 29033, 29032, 45236, 12029, 45237, 29029, 29028,\n",
       "         12033, 45239, 45243, 58221, 29020, 58236, 45247, 58246, 45223,\n",
       "         58301, 58297, 58294, 58292, 29086, 11952, 45197, 11959, 58286,\n",
       "         45199, 58285, 11968, 58283, 45232, 29071, 58274, 11975, 11976,\n",
       "         58267, 45212, 11984, 11985, 11987, 29058, 11994, 11995, 45220,\n",
       "         58254, 58277, 45248, 58215, 12045, 28986, 28983, 28982, 28981,\n",
       "         45281, 45282, 28976, 12104, 12106, 12108, 12109, 45292, 58163,\n",
       "         58178, 58158, 45299, 58152, 58151, 28957, 45304, 28954, 45305,\n",
       "         45310, 12132, 12134, 28942, 28940, 58132, 28964, 58179, 12087,\n",
       "         45275, 12046, 12047, 45249, 45250, 45252, 58208, 58207, 45253,\n",
       "         29012, 12056, 45255, 12059, 58203, 12062, 29008, 12064, 29007,\n",
       "         58200, 29004, 58197, 58195, 45258, 12075, 58191, 45266, 12079,\n",
       "         45271, 28994, 28993, 11940, 58130, 11939, 29094, 29200, 58416,\n",
       "         58415, 58413, 58411, 29199, 29196, 29194, 11802, 11804, 11805,\n",
       "         11806, 45135, 11785, 29191, 11811, 29184, 11817, 11821, 58389,\n",
       "         58388, 11826, 11827, 11828, 29177, 11830, 58385, 11832, 11809,\n",
       "         11834, 11784, 29205, 11739, 58465, 45111, 45113, 29229, 58460,\n",
       "         11749, 29226, 45117, 58450, 29219, 11758, 29214, 58428, 58444,\n",
       "         58443, 11765, 11766, 58442, 58439, 58438, 45122, 58434, 11777,\n",
       "         58429, 11779, 45128, 11781, 29213, 58380, 29175], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 709\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 709\n",
       "  })},\n",
       " 'contains_coreferences': {'feature_present_idx': array([20751, 45961, 59415, 58102, 22240, 40621, 58742, 56156, 52691,\n",
       "         50136, 25990, 49557, 60565,  8758, 49248, 26309,  8504, 61001,\n",
       "         26411, 26584, 26946, 48744, 27352, 27915, 48102, 47872,  7123,\n",
       "          6963, 25116, 20658, 59826, 15357, 52307, 57354, 57434, 14404,\n",
       "         21815, 57995, 56292, 58024, 12516, 24584, 52161, 11383, 20170,\n",
       "         58445, 10980, 10975, 58646, 10727,  6891,  9639, 11384, 62290,\n",
       "          8270, 36785,  4299, 32856, 33038, 64098, 33862, 34379, 44612,\n",
       "         62386, 32320, 37338, 65903,  2252,  1997, 42814, 66815, 41202,\n",
       "         41619, 42156, 37391,  4400, 55301, 63631, 31415, 46974, 46686,\n",
       "          5653,  5587, 55178, 52516, 52460, 21287, 42265, 21534, 40644,\n",
       "         42212, 21862, 21899, 43137, 28991, 21398, 41892, 41241, 43361,\n",
       "         54397, 54198, 17894, 41735, 29367, 53761, 53603, 19807, 19819,\n",
       "         20107, 29176, 20406, 41291, 20455, 52951, 29023, 22407, 30122,\n",
       "         26501, 35283, 34674, 24627, 44711, 50410, 44742, 50778, 25528,\n",
       "         27598, 31330, 33172, 27093, 45658, 32210, 25753, 38918, 28234,\n",
       "         50834, 51906, 47391, 38459, 51855, 37916, 23151, 24025, 30271,\n",
       "         23290, 28332, 35732, 44540, 51519, 23525, 43819, 29463, 32260,\n",
       "         41946, 60133, 60125,  9091,  9098, 59630,  9432,  1328, 61275,\n",
       "          9668, 10169,  1325, 11349, 58101, 12786, 13320, 13366, 58875,\n",
       "         61562,  8199,  7736,  2763,  2827,  2832, 65133, 64513,  3510,\n",
       "          2030,  4771, 63294,  6685,  6695,  6888,  7048, 66328,  7404,\n",
       "          7520,  7715, 13724, 66957, 65541,   103, 14444, 56493, 56723,\n",
       "         56170, 15160, 67135, 56278, 56792, 15824, 56035, 31562, 31868,\n",
       "         31895, 30852, 39482,  1872, 31281, 45778, 31029, 30916,  5214,\n",
       "         63708, 13884, 39639, 46034, 54453, 47257, 29900,  5788, 30012,\n",
       "         54638, 30538, 46360, 30204, 46313,  5618, 30419, 30523, 45637,\n",
       "         30201, 43188, 39219, 32236, 17044,  3063,  2127, 44374, 44276,\n",
       "         44118, 65094, 43451, 16918, 37147, 15917,  2581, 37864,  2556,\n",
       "         16945, 44688, 17115, 34657,  4325, 32648, 45075,  4292, 63958,\n",
       "         45043, 39079,  3670, 44898, 44863, 34156, 17292, 15876, 34450,\n",
       "          3460, 45552, 29285, 17830,  6819, 23935, 23999,  9656, 24092,\n",
       "         56242, 50774, 23930, 24537, 14985, 53183, 50297, 53254, 66568,\n",
       "         25208, 14755, 29262, 20381, 14614, 20980, 21581, 21594, 41367,\n",
       "         57559, 57669, 51418, 22039, 41469, 66909, 22418, 11542, 23138,\n",
       "         11004, 22200, 50026, 59829, 42192, 29171, 56976, 28990, 62088,\n",
       "         47859, 54174, 28720, 28395, 18063,  7585, 28148, 28138, 48519,\n",
       "         53300, 48555, 40180,   518, 60293,  8963,  1726, 60959, 49228,\n",
       "         53926, 49222, 18256, 66547,  7964, 43496, 48783,  7845, 49126,\n",
       "         42672, 43015, 43491, 42711, 42199, 55303, 44029, 54969, 56062,\n",
       "         53858, 53318, 56774, 52754, 56982, 57223, 58050, 58610, 59307,\n",
       "         50285, 60594, 61584, 49100, 48625, 61970, 56027, 63234, 46059,\n",
       "         45719, 63462, 63894, 45219, 64021, 64429, 65424, 43624, 62078,\n",
       "            48, 28812, 26740, 26867, 12884, 27180, 12599, 11747, 10762,\n",
       "         10450,  9620, 19356,  9089, 29659,  9053, 30533, 30876, 26317,\n",
       "         26225, 13400, 25418, 19625, 19649, 20466, 20937, 17316, 21192,\n",
       "         22528, 31181, 22662, 14492, 14425, 24382, 13985, 24878, 24976,\n",
       "         25191, 14704,  8277, 18138, 40453, 36002, 36654,  4238,  4907,\n",
       "         35407, 37076, 35025,  5712,  1411,  5874, 40019, 40507,  3511,\n",
       "         33915,  1833,  7269,   967, 37719, 40705,  1804,  7357,  8176,\n",
       "          7685, 38608, 38020, 15363, 14643, 55370, 15710, 61057, 17220,\n",
       "         16664, 55253, 14346, 66665, 54895, 66863, 54469, 41709, 17870,\n",
       "         17923,  1054, 18133, 55330, 14325, 57249, 64978,  8526, 60954,\n",
       "         60644, 61712,  8751,  8825, 60555,  8966, 60086,  6444, 59373,\n",
       "         59361,  5799, 10848, 63408, 12619, 57982,  3940, 57767, 57527,\n",
       "         64658, 13809, 13843, 57205, 57088,  2980, 41535, 67310, 33098,\n",
       "         28734, 44273, 50602, 35918, 43845, 50599, 39613, 50286, 27879,\n",
       "         25361, 42301, 47121, 23572, 29932, 44420, 38681, 67183, 32715,\n",
       "         48686, 51781, 49915, 32162, 50080, 21062, 21329, 34480, 46653,\n",
       "         11329, 58314, 27234, 11064, 47267, 58622, 58752,  4491,  9433,\n",
       "          9224, 59728, 29586, 30265, 63243, 31742,  8318, 45439, 45110,\n",
       "         64282, 27137, 28793, 16224, 19003, 53386, 19582,   291, 66981,\n",
       "         17410, 20815, 17311, 55038, 40920, 51765, 16448,  1499, 51573,\n",
       "         15178,  3348, 12957, 49773,  3306, 50179, 39426, 50981, 24239,\n",
       "         14055, 51550, 63896, 34109, 44804, 38993, 65475, 34294,  2487,\n",
       "          2361, 40108,  4620,  3403, 66422, 41274, 36262, 17809, 32212,\n",
       "         53160, 53085, 52889, 22757, 51609, 15875, 51575, 23343, 23393,\n",
       "         56482, 56603, 56845, 13930, 57538, 45015, 13261, 27115, 28030,\n",
       "         30526, 10162, 30163, 53427,  8984, 57621, 31324, 51745, 19109,\n",
       "         28851,  4344,  4278, 57382, 47894,  8342, 26291, 35310, 42748,\n",
       "          9117], dtype=int64),\n",
       "  'feature_absent_idx': array([19123, 30459, 10137, 10139, 17905, 53687, 53688, 44250, 48583,\n",
       "         48581, 59643, 59641, 30460, 17899, 53694, 10153, 48580, 59639,\n",
       "         30446, 59638, 59636, 59635, 44262, 24612, 30442, 10150, 53700,\n",
       "         44248, 10132, 53679, 10105, 44236, 10107, 10108, 48600, 24595,\n",
       "         59678, 59676, 24598, 59673, 48592, 44239, 10119, 59670, 44242,\n",
       "         59668, 17912, 17911, 10125, 59665, 10127, 53684, 10130, 44241,\n",
       "         30438, 30436, 44267, 10203, 59593, 10205, 59592, 59590, 44285,\n",
       "         53718, 30404, 30403, 10212, 59587, 48573, 53719, 10218, 10220,\n",
       "         53726, 44295, 10224, 53730, 30389, 10228, 30387, 10231, 30385,\n",
       "         30398, 24622, 59594, 53712, 24616, 17888, 59618, 53703, 59612,\n",
       "         10177, 30429, 30428, 48574, 53705, 59609, 44272, 24618, 30420,\n",
       "         24619, 10187, 59603, 10189, 10190, 10191, 44277, 53708, 44279,\n",
       "         30414, 24620, 10102, 48603, 17921, 10099, 10004, 44193, 59764,\n",
       "         48633, 53660, 30546, 48630, 30543, 30542, 10015, 59756, 10003,\n",
       "         10017, 10019, 59754, 44198, 53662, 10024, 59749, 44203, 48628,\n",
       "         30535, 30534, 44204, 59755, 30552, 10001, 59767, 30576, 17971,\n",
       "         24550, 24552,  9973, 59783,  9975, 53652, 59780,  9978, 24553,\n",
       "          9980, 59779,  9982, 48641, 59774,  9987,  9988, 44189, 30559,\n",
       "         30558,  9994, 53657, 59771, 17958, 17948, 48564, 17947, 10034,\n",
       "         30506, 17934, 10071, 10073, 44222, 30499, 59714, 17932, 10080,\n",
       "         59710, 10083, 17936, 17928, 10087, 30489, 30488, 24589, 59698,\n",
       "         17924, 24590, 59691, 44230, 10097, 30483, 10085, 30508, 10064,\n",
       "         30510, 53664, 30527, 10038, 24569, 10040, 10041, 10042, 10043,\n",
       "         30524, 59739, 10046, 59738, 59737, 59736, 59734, 44212, 48624,\n",
       "         10055, 44214, 17940, 24576, 30513, 24577, 30511, 59725, 59744,\n",
       "         59786, 59573, 44303, 59435, 44405, 17799, 24689, 30248, 59426,\n",
       "         30247, 30246, 44410, 44411, 53800, 17800, 30241, 24693, 30236,\n",
       "         17792, 59412, 59411, 48514, 17790, 59406, 30232, 44418, 53808,\n",
       "         24690, 17788, 30255, 48517, 30276, 59456, 10383, 59454, 30272,\n",
       "         53783, 59452, 10388, 30269, 10390, 10391, 10408, 10392, 10394,\n",
       "         10395, 24684, 53786, 59444, 53788, 59441, 10402, 53792, 53795,\n",
       "         30257, 59449, 24696, 48513, 59395, 30209, 30208, 53811, 10474,\n",
       "         24699, 59363, 17775, 10478, 30203, 17774, 30200, 53810, 44431,\n",
       "         59358, 59357, 17772, 53814, 44432, 10490, 59349, 59348, 30191,\n",
       "         44438, 44439, 48511, 17779, 10468, 59368, 10441, 10442, 17785,\n",
       "         30224, 59393, 44425, 30222, 59392, 30221, 10451, 59391, 17784,\n",
       "         17783, 59389, 17782, 59387, 59385, 59384, 59383, 30217, 30216,\n",
       "         53809, 48512, 30213, 30212, 44380, 10377, 10376, 59460, 10271,\n",
       "         30352, 44320, 59547, 59544, 10280, 10281, 10282, 30346, 30345,\n",
       "         30344, 59555, 30343, 59537, 10289, 59529, 24652, 30334, 44331,\n",
       "         10299, 10300, 44333, 10304, 17838, 53754, 24643, 10268, 44317,\n",
       "         44305, 10239, 17862, 53735, 10242, 30375, 59570, 30373, 30371,\n",
       "         10249, 10250, 44311, 30367, 30366, 59565, 59564, 10257, 44312,\n",
       "         44313, 59560, 53741, 17856, 48560, 53743, 30358, 44335, 30383,\n",
       "         24656, 10309, 30300, 10346, 59486, 59484, 10349, 44361, 30297,\n",
       "         24669, 59479, 10355, 44363, 10343, 10357, 59473, 24675, 10363,\n",
       "         53777, 10366, 44372, 53780, 10370, 59467, 24678, 44376, 30292,\n",
       "         10342, 44353, 10339, 59519, 44337, 30325, 59515, 53771, 44339,\n",
       "         44340, 53772, 59509, 10321, 24659, 59508, 24660, 44347, 10326,\n",
       "         17828, 30312, 10330, 30311, 48548, 59500, 59499, 44350, 10336,\n",
       "         30306, 10308, 10496, 30577,  9963, 60053, 44014,  9616, 53570,\n",
       "          9618, 18088, 30804,  9623, 60047, 30803, 30801, 30810, 18086,\n",
       "         44023, 60041, 60039, 60038, 53571,  9634, 30797, 30796, 30795,\n",
       "         18084,  9640,  9628,  9641, 18090, 44012, 30834, 44002, 53561,\n",
       "         53562,  9585,  9587,  9589, 44006,  9591, 30826,  9593, 60056,\n",
       "         53565,  9596, 53566, 30823, 18096, 44007, 60065, 24464, 44009,\n",
       "         30816,  9608, 53568, 60073, 44026, 30792, 60031, 48697, 53582,\n",
       "         53584, 30762, 59996, 44047, 59995, 30760, 59993,  9689, 30759,\n",
       "         30768, 59992, 30756, 30755, 53590, 59987, 59986,  9702, 18061,\n",
       "         59984, 53591, 53592,  9709, 18067, 18073, 60006, 24477, 44030,\n",
       "         24469, 24470, 60028, 44031, 24471, 60024, 30786, 30784, 44035,\n",
       "         24472, 60020, 60018, 30780, 48702, 60015, 30778, 18077, 30776,\n",
       "          9666,  9667, 60013, 44038,  9672, 44042, 44001, 53560, 60082,\n",
       "         30837,  9487, 60143, 24438, 60140, 60139, 60138,  9494,  9495,\n",
       "         48727, 43956,  9498, 30907, 30901, 18127, 43961,  9503, 43962,\n",
       "          9505, 18126, 60130, 60129, 53547, 24444, 43966, 30898, 48728,\n",
       "         24436,  9483, 24423,  9453,  9456,  9457,  9458, 60168, 24426,\n",
       "          9461, 30930, 43933, 60164, 18143, 60160,  9467, 30926,  9469,\n",
       "         24431, 18137,  9475, 60154, 30917, 43947, 48731, 48730, 43951,\n",
       "         30889], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 622\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 622\n",
       "  })},\n",
       " 'contains_number': {'feature_present_idx': array([32942, 37010, 32408,  5274, 21268, 43757, 16605,  7396, 57308,\n",
       "         12038, 32396, 62679, 52830, 43098, 57103, 11795, 53037, 30349,\n",
       "         43925,  1651,  1407, 57739, 65065, 12741, 53368, 22914, 10719,\n",
       "         11782, 12629, 49243,  4291, 34762,  7264, 64717,  3301,  5327,\n",
       "          9847, 19975, 57045, 57032, 52151, 20593, 31753, 51126, 17445,\n",
       "         60884, 38327, 10973, 25204, 41460, 17688, 33893, 51534, 51917,\n",
       "         33897, 41345, 38171, 17347,  4783, 21025, 31052, 25867, 25790,\n",
       "         10211, 42929, 31189, 25895, 25707, 23314, 23325, 52505,  4919,\n",
       "         11369, 32239, 50964, 31195, 29764, 49081, 53621, 28451, 58248,\n",
       "         55383,   494, 61569, 35486,  8679, 15080, 47656, 27436, 15204,\n",
       "         29744,  5826,  6683, 19905, 45306, 27441,  8729, 35802, 27584,\n",
       "         58614, 22265, 46748, 67250, 58598, 22329, 46999, 46077, 28103,\n",
       "         58575, 14168, 58511, 61794, 35784, 66952, 66947, 54980, 22557,\n",
       "         45226, 39978, 61048, 27072, 44424, 39257, 48665, 53918, 19961,\n",
       "         48741, 46699, 48482, 35203, 19921, 33259, 59536, 21707, 16128,\n",
       "         21791, 23945, 48056, 48831, 35468, 35402, 48222, 36433,  4175,\n",
       "         44932, 24047, 29240, 56072, 39252,  8584, 55506,  8578,  8056,\n",
       "          8515, 56087, 19800,  8400, 19804, 39231, 55453,  8648, 20044,\n",
       "         39144, 55728, 19901, 56064, 55873, 55702, 39312,  8317, 55787,\n",
       "         38865, 38634, 55580, 39280, 39088, 21606,  7995, 36728, 21469,\n",
       "         57747, 57755, 36649, 57771,  6988, 57773, 36612,  6946,  6922,\n",
       "         36411, 36328, 58041,  6706, 58063, 58087, 36140,  6632,  6618,\n",
       "         58088, 36066,  6495, 35929,  6417,  6416,  6398,  6370, 22238,\n",
       "         21457, 21404,  7204, 36940, 38478, 20371,  7936, 56206, 38348,\n",
       "         38255, 38237, 56511,  7771, 20813, 37668, 37644, 20897, 56770,\n",
       "         56128, 56935, 37522, 55188, 21114, 21243, 57287,  7424, 37268,\n",
       "         57340, 37093, 57412, 57448, 21351,  7317,  7255,  7634, 57198,\n",
       "         18497, 55006, 49208, 49183, 44163, 49075, 49022, 49008, 44213,\n",
       "         44270, 48900, 44351, 48815, 48733, 44383, 48589, 48578, 49221,\n",
       "         49256, 49318, 12548, 49873, 16846, 49755, 43594, 49587, 49559,\n",
       "         49482, 44452, 49465, 16483, 12380, 49447, 43976, 43985, 12499,\n",
       "         44063, 16501, 49899, 13224, 48458, 47407, 15064, 47363, 15047,\n",
       "         45733, 14115, 15002, 45770, 14166, 45928, 14313, 46292, 14330,\n",
       "         46502, 46587, 45729, 13938, 15121, 45605, 13276, 48373, 44906,\n",
       "         15674, 15585, 13574, 48104, 48460, 45155, 47819, 45425, 47792,\n",
       "         15274, 47725, 13837, 47601, 48044, 11928, 43154, 43088, 40838,\n",
       "         53466, 53322, 53223, 18671, 18580, 53154, 18569, 41059, 41091,\n",
       "         58629, 41192, 41217, 18340, 41261, 40812, 53651, 53815, 18893,\n",
       "         54997, 19734, 54960, 39658, 19591, 19525,  9041, 18147, 54589,\n",
       "         40115, 40235,  9299, 40637,  9416, 40660,  9449,  9145, 52200,\n",
       "         52195, 10431, 17328, 42376, 11309, 17312, 42469, 42581, 50745,\n",
       "         17371, 50700, 50428, 50366, 50261, 11568, 17021, 50128, 50090,\n",
       "         50641, 55063, 11187, 42188, 41387, 52029, 17989, 41840, 51604,\n",
       "         51598, 51595, 11171, 51535, 17674, 17664, 51184, 10955, 11050,\n",
       "         42143, 51119, 41958, 58662, 14551, 58725, 63303, 25277, 32066,\n",
       "         63199, 32075, 32087, 63306, 32176,  3011, 32183, 62795, 62726,\n",
       "          6233, 24888, 25032, 24866, 25280, 63358,  2386, 63796,  2411,\n",
       "         31422, 31428, 31431, 63340,  2545, 63592,  2589, 25403, 31819,\n",
       "          2704, 32020, 63628, 24859, 62567,  3304, 24281, 32957, 24237,\n",
       "         24202, 33075, 61671,  3971, 61669, 24168,  4190, 23994, 23977,\n",
       "         23852, 23832, 61616,  3969,  3872, 32868,  3342,  3347, 32410,\n",
       "         32504,  3456, 32565, 24554, 62044, 24515,  3682, 24514, 61894,\n",
       "         24402, 61821, 24383, 25668,  4309, 64124,  2180, 28819, 27475,\n",
       "         28969, 27420,   754, 27350, 66587,   786, 66132, 27276, 29186,\n",
       "         65974, 65970, 65952, 66201, 65915, 66628, 28427, 28039, 67244,\n",
       "         27788, 67163, 27741, 66992, 66642, 66966,   207,   250, 66859,\n",
       "           319, 28387,   419, 28282, 27110, 27098, 65575, 30364, 64595,\n",
       "          1792, 64591, 30617, 30676, 26497, 30902, 64395, 31004, 25936,\n",
       "          2120,  2129, 25886,  1942, 26505, 30287, 64829, 27005, 29454,\n",
       "         26895, 65145, 65136,  1384, 29912, 30003, 65022, 26625, 26608,\n",
       "         64939, 64880,  1528, 30096, 64225, 33544, 32352, 22936, 59175,\n",
       "         34163, 34379,  5156, 34157, 34944,  5159,  5140,  5537, 60717,\n",
       "         34396, 59144, 34537, 60279, 59719, 59070, 34877, 23414, 23253,\n",
       "          5069, 59401,  5748, 60701, 22544, 60728, 23280, 60738, 60792,\n",
       "          5054, 60818, 35473,  5056, 59306,  5858, 60858,  5893, 35215,\n",
       "          5263, 34839, 59686, 22637,  4523, 58917, 22317, 61076, 61059,\n",
       "         33907,  6126,  6031, 22982, 22256,  5441, 22303, 60105, 23036,\n",
       "         34635,  6215, 61184, 23680, 35491, 59069, 23668, 34796, 35243,\n",
       "         26620, 43145, 21666, 16276, 44199, 21677, 22648, 25944, 36740,\n",
       "         43083, 36896, 21709, 29770, 31048, 36213, 16184, 16969, 22685,\n",
       "         16684, 35162, 16630, 26105, 30611, 36718, 21527, 43554, 34829,\n",
       "         26219, 16829, 16505, 43864, 30522, 30914, 35084, 43318, 26558,\n",
       "         22868, 30228, 30181, 44043, 30176, 30124, 16307, 22712, 36429,\n",
       "         16906, 26607, 26021, 34812, 20012, 35430, 22203, 22367, 22452,\n",
       "         28685, 35853, 27493, 45546, 28321, 35949, 15196, 22462, 22475,\n",
       "         35974, 29030, 36099, 45418, 22016, 21949, 45754, 45757, 27844,\n",
       "         27794, 14621, 14625, 46403, 46300, 35691, 35575, 28046, 27767,\n",
       "         14782, 14835, 14926, 45775, 35754, 14957, 46084, 29733, 27343,\n",
       "         21924, 44541, 27150, 15918, 44520, 27106, 27092, 15974, 44576,\n",
       "         43018, 16041, 27023, 44396, 27002, 29429, 16111, 26966, 29418,\n",
       "         15474, 29338, 15833, 45251, 27313, 21915, 21885, 29126, 22499,\n",
       "         27232, 44667, 15604, 27212, 21845, 45055, 44950, 36129, 15739,\n",
       "         44747, 45069, 29366, 42627, 17071, 32637, 19065, 40322, 40292,\n",
       "         19169, 23438, 19193, 38460, 34072, 40230, 40174, 40150, 19280,\n",
       "         24512, 40099, 32682, 19242, 40097, 38385, 24583, 18682, 18697,\n",
       "         40914, 24791, 34171, 40850, 40844, 40702, 32528, 32551, 18769,\n",
       "         24667, 18859, 40747, 32581, 24628, 18753, 40917, 40096, 24434,\n",
       "         38686, 38785, 24170, 39015, 33133, 33145, 24036, 19869, 33695,\n",
       "         23971, 33483, 33495, 33519, 23857, 23779, 33549, 33654, 40059,\n",
       "         20225, 20276, 34039, 19484, 24405, 20306, 34012, 39858, 39824,\n",
       "         39334, 39767, 38584, 24324, 32815, 38625, 39488, 33819, 23634,\n",
       "         19686, 22953, 23381, 40940, 31432, 17357, 31516, 25486, 31659,\n",
       "         34455, 31776, 25546, 17543, 42107, 42096, 17624, 31949, 32007,\n",
       "         25317, 32025, 23156, 41938, 34555, 42506, 17073, 34724, 42941,\n",
       "         25784, 25755, 42874, 42862, 34575, 42809, 31345, 42733, 25605,\n",
       "         23799, 34642, 25598, 42539, 25660, 34259, 41928, 17749, 32271,\n",
       "         32327, 41219, 24920, 32344, 18385, 18443, 24985, 20861, 37817,\n",
       "         37831, 41014, 24833, 24831, 40966, 18654, 18475, 41909, 18144,\n",
       "         34275, 37404, 23204, 41841, 32052, 21061, 41713, 41525, 18142,\n",
       "         41512, 25261, 37493, 41422, 34360, 25079, 41348, 37531, 41473,\n",
       "         13759, 27949,  6613, 56014, 63336,  8261, 63400, 55946,  8306,\n",
       "         55849, 63509,  8540, 55482,  8592, 55472,  2628, 55409, 55350,\n",
       "         55275,  2568,  8760, 55238, 63654, 63669,  8202, 63334,  8151,\n",
       "          2883, 57074,  7580, 62762, 56962, 62766, 62769, 56664,  3031,\n",
       "          7740, 62803, 54964, 56602,  7796, 62835, 56479,  7863, 56392,\n",
       "         56240, 63088, 56203, 56197, 56177,  7783, 62740,  2455, 63747,\n",
       "         64296,  9592,  2020,  9758,  1941,  9794, 53275, 53273,  9867,\n",
       "         53213,  9940, 53174, 53077, 53066, 52936, 10078, 52921, 64493,\n",
       "         10195, 10210, 52732, 53915, 53957, 53972,  9403, 54788, 54716,\n",
       "          9023, 63749, 63883, 64044, 64132, 64214, 54425, 61040, 63718,\n",
       "          2230,  9229,  9251, 54136,  2185, 54095, 64283, 53999,  2148,\n",
       "          9387], dtype=int64),\n",
       "  'feature_absent_idx': array([25272, 31258, 11164, 43418, 43416, 60018, 11176, 11177, 60020,\n",
       "         43397, 43395, 31272, 20452, 43393, 31276, 43386, 20439, 60024,\n",
       "         43380, 11191, 31277, 11194, 31279, 11196, 43372, 31274, 31257,\n",
       "         20454, 11159, 11123, 11124, 65527, 43476, 43475, 43472, 43470,\n",
       "         20465, 60006, 43456, 43454, 11139, 65524, 11142, 31250, 31251,\n",
       "         60013, 31254, 65522, 11150, 43437, 20456, 43435, 43433, 60015,\n",
       "         43370, 43368, 11202, 31282, 20423, 43311, 62073, 43305, 11244,\n",
       "         20420, 20419, 20418, 11248, 43297, 43296, 31301, 31302, 43288,\n",
       "         11254, 62072, 11259, 65514, 20412, 20411, 20409, 43278, 43276,\n",
       "         60038, 43273, 60031, 31243, 60028, 43333, 43364, 43362, 43360,\n",
       "         11211, 65520, 43357, 11214, 43355, 31289, 11217, 43353, 11219,\n",
       "         11220, 43351, 31291, 11223, 43345, 43344, 11226, 20430, 43341,\n",
       "         62075, 11230, 31293, 11233, 20426, 43481, 31242, 11119, 20518,\n",
       "         43634, 11010, 31161, 43632, 43631, 43630, 43629, 43627, 11018,\n",
       "         63918, 59992, 43623, 43621, 43617, 59993, 43611, 31172, 20508,\n",
       "         11036, 11037, 43601, 31177, 11042, 31178, 20519, 11044, 11006,\n",
       "         43644, 43688, 63916, 59984, 20533, 10978, 43682, 31148, 10982,\n",
       "         43678, 20530, 10986, 10987, 31151, 65554, 10991, 43672, 20525,\n",
       "         43669, 43668, 43666, 59986, 59987, 62101, 31157, 43647, 20520,\n",
       "         60039, 11045, 20501, 43522, 43521, 43515, 31224, 11094, 20482,\n",
       "         31228, 31229, 31230, 20478, 43499, 43498, 43497, 65533, 20475,\n",
       "         20474, 65530, 11110, 20472, 20471, 65529, 20469, 11116, 31240,\n",
       "         43486, 31217, 59995, 43531, 31211, 59996, 11052, 11053, 11055,\n",
       "         43578, 43576, 11059, 43575, 31194, 43569, 43567, 11065, 65540,\n",
       "         43566, 43561, 11069, 43560, 11071, 43556, 31201, 43551, 43542,\n",
       "         11080, 31210, 20488, 43533, 31312, 11274, 11276, 43012, 11482,\n",
       "         43009, 11484, 31435, 11486, 31438, 60083, 42991, 42990, 11493,\n",
       "         42987, 65488, 20321, 11498, 11501, 11502, 31445, 65487, 20317,\n",
       "         20316, 42973, 42972, 42971, 11513, 60082, 42968, 20327, 31429,\n",
       "         43061, 11447, 43055, 43053, 43051, 31414, 43048, 43047, 11455,\n",
       "         60073, 43044, 43041, 11459, 31416, 31417, 11462, 43036, 31418,\n",
       "         11465, 43034, 43029, 20331, 11471, 31426, 43024, 11476, 43066,\n",
       "         20315, 20313, 11557, 65482, 11559, 31469, 63948, 42911, 20294,\n",
       "         11565, 11567, 60100, 20290, 11573, 11575, 42897, 60104, 42891,\n",
       "         42890, 60107, 42888, 31477, 42885, 11584, 42883, 11586, 42881,\n",
       "         31467, 31453, 42919, 20299, 31455, 11520, 42960, 31456, 42958,\n",
       "         63944, 42953, 11530, 60093, 11534, 11535, 11538, 11539, 20302,\n",
       "         42933, 42932, 42931, 20301, 42928, 11546, 20300, 65483, 11549,\n",
       "         42925, 42924, 42920, 43691, 43069, 31399, 43203, 11321, 43201,\n",
       "         43198, 43197, 63931, 43192, 62056, 11331, 60053, 31355, 65505,\n",
       "         43177, 65504, 62055, 11340, 63933, 31360, 43164, 43161, 11350,\n",
       "         43159, 11352, 11353, 11354, 43204, 11355, 43205, 11314, 20403,\n",
       "         60041, 11281, 62068, 43248, 11285, 43244, 11287, 43243, 43241,\n",
       "         43239, 43237, 43235, 65508, 60047, 31328, 20396, 43226, 11303,\n",
       "         43222, 11306, 11307, 43220, 62058, 31346, 43206, 11437, 65503,\n",
       "         20374, 60065, 31386, 63937, 43097, 43095, 43094, 11409, 11410,\n",
       "         65495, 31389, 11417, 20352, 11419, 43081, 11422, 11423, 20350,\n",
       "         43076, 11427, 11428, 11429, 11430, 11432, 43073, 11434, 43103,\n",
       "         43157, 11400, 11397, 31367, 20372, 11361, 43149, 11363, 60056,\n",
       "         11366, 43144, 43143, 11371, 43139, 43138, 43133, 11378, 65500,\n",
       "         43132, 31379, 43118, 43117, 11390, 43116, 11392, 43115, 43114,\n",
       "         43112, 43107, 42880, 43692, 31146, 10575, 10576, 44132, 10578,\n",
       "         10579, 59899, 30941, 44127, 44125, 10584, 44124, 44133, 44123,\n",
       "         10589, 59901, 59903, 44112, 44111, 59904, 44108, 44105, 44100,\n",
       "         30949, 10602, 44119, 63891, 30939, 44143, 20701, 30898, 44189,\n",
       "         30901, 30907, 20694, 10540, 59892, 10544, 30917, 65622, 10547,\n",
       "         10549, 44171, 30926, 44160, 20685, 44158, 10558, 44156, 65618,\n",
       "         30930, 44151, 44148, 10565, 44097, 44095, 30953, 44091, 10645,\n",
       "         10646, 62131, 10649, 20650, 59917, 30976, 10654, 30979, 44047,\n",
       "         44042, 10658, 10659, 65609, 62129, 44038, 20646, 10665, 10666,\n",
       "         44035, 44031, 44030, 59920, 59921, 10673, 62132, 44193, 44058,\n",
       "         10641, 30955, 30957, 10611, 20664, 20663, 10618, 59909, 62133,\n",
       "         20659, 59911, 44069, 10626, 30966, 59914, 44065, 10630, 59915,\n",
       "         10632, 10633, 10634, 30967, 30968, 10638, 44059, 65612, 10642,\n",
       "         10527, 30889, 44198, 44340, 44339, 59870, 44337, 44335, 44333,\n",
       "         44331, 30823, 30826, 44320, 44317, 44313, 44312, 44311, 44305,\n",
       "         44303, 10441, 10442, 20746, 30834, 20744, 44295, 20743, 30837,\n",
       "         44285, 59868, 10451, 59866, 30816, 44380, 10376, 10377, 20773,\n",
       "         44376, 30804, 10383, 44372, 59864, 62170, 10388, 30810, 10390,\n",
       "         10391, 10392, 10394, 10395, 44363, 20768, 44361, 20767, 44353,\n",
       "         10402, 44350, 44347, 10408, 44026, 20739, 44279, 44230, 20720,\n",
       "         30872, 10496, 30874, 44222, 30875, 10502, 10503, 62154, 59885,\n",
       "         62153, 20712, 44214, 44212, 10511, 65626, 10514, 30881, 62152,\n",
       "         10518, 20707, 44204, 44203, 10522, 30871, 30840, 10490, 30865,\n",
       "         30843, 44277, 30844, 44272, 44267, 63884, 65635, 44262, 30849,\n",
       "         30851, 10468, 59877, 20731, 20729, 10474, 62158, 65631, 44250,\n",
       "         10478, 44248, 30861, 44242, 44241, 44239, 59883, 44236, 30983,\n",
       "         44023, 10677, 59960, 62111, 31092, 10874, 31101, 43803, 43798,\n",
       "         10879, 62108, 31103, 10882, 10883, 43794, 43791, 31106, 31109,\n",
       "         10889, 43784, 62107, 43780, 10893, 10894, 59963, 31112, 59964,\n",
       "         65579, 10900, 20575, 10866, 31069, 20584, 10836, 31076, 10838,\n",
       "         10839, 43839, 65583, 10843, 31078, 10846, 65582, 65581, 43833,\n",
       "         10850, 43831, 10852, 59956, 43828, 43827, 43825, 20577, 31090,\n",
       "         59958, 59959, 43816, 59953, 31117, 43767, 43732, 43728, 10938,\n",
       "         31134, 10943, 10947, 31140, 43715, 20540, 62102, 43711, 20538,\n",
       "         65559, 43707, 10958, 43706, 10960, 43705, 43703, 10963, 65558,\n",
       "         31145, 43701, 10967, 43700, 43733, 43768, 31129, 10931, 65572,\n",
       "         10905, 20559, 43762, 43761, 43759, 10910, 10911, 43758, 10913,\n",
       "         31120, 43751, 62104, 31127, 20552, 10921, 10922, 43742, 20551,\n",
       "         43740, 59971, 43738, 10928, 31128, 43735, 10932, 43694, 43852,\n",
       "         43860, 43986, 10716, 10717, 10720, 31007, 65597, 10723, 63898,\n",
       "         43970, 43966, 10730, 31013, 43962, 10734, 43961, 10736, 10737,\n",
       "         43956, 10740, 20622, 10742, 20620, 43951, 10746, 31020, 43987,\n",
       "         43947, 31005, 10711, 59922, 65604, 10680, 20641, 20639, 44014,\n",
       "         10686, 10687, 44012, 44009, 65602, 44007, 44006, 44002, 44001,\n",
       "         10697, 20635, 10699, 30997, 43996, 65598, 10706, 10708, 43993,\n",
       "         10710, 43992, 43856, 59930, 59934, 65589, 10790, 43898, 59944,\n",
       "         43895, 20601, 10799, 43888, 10801, 59945, 10803, 31051, 43882,\n",
       "         10806, 43879, 20599, 59950, 20597, 31055, 31059, 31060, 65586,\n",
       "         65585, 10821, 10822, 10787, 59933, 10785, 43904, 59935, 59936,\n",
       "         31021, 10758, 43933, 31028, 62121, 10763, 43928, 10765, 31034,\n",
       "         10767, 63903, 43921, 43918, 65591, 10773, 20608, 31039, 65590,\n",
       "         20606, 31040, 43908, 59942, 10782, 59943, 30803, 11589, 42877,\n",
       "         31904, 41856, 19972, 41853, 41851, 41850, 41848, 41847, 31905,\n",
       "         41844, 41843, 12374, 31907, 12391, 31910, 41832, 41828, 61957,\n",
       "         31918, 60287, 41818, 41817, 12404, 65326, 12390, 12372, 31902,\n",
       "         31898, 60275, 61963, 41899, 41898, 12344, 41897, 12346, 41896,\n",
       "         31882, 65335, 60280, 41887, 41884, 31886, 12356, 19983, 31888,\n",
       "         31889, 41867, 12362, 12363, 12365, 12367, 12368, 31897, 41807,\n",
       "         65324, 12411, 12412, 12454, 41744, 41742, 41741, 12459, 12460,\n",
       "         41738, 19933, 41731, 41729, 31973, 12468, 41722, 19930, 41719,\n",
       "         41718], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_accompanier': {'feature_present_idx': array([48840, 40407, 25521, 63754,  2544, 62778, 48572, 23131, 25243,\n",
       "          1586,  6768, 28633, 30987, 31771, 33192, 57868, 67295, 21997,\n",
       "         62683, 20523, 20009, 19634, 17498, 17099, 15935, 15229, 12977,\n",
       "         23966, 66921, 35941, 34751, 57026, 55358, 54726, 58587, 53270,\n",
       "         51588, 48059, 47488, 47014, 46051, 60560, 42923, 42278, 39536,\n",
       "         38920, 61828, 61855, 37272, 37019, 35989, 64359, 62309, 64680,\n",
       "         28123,  5769,  9138,  4377,  6001,  2688,  5110,  6851,  2368,\n",
       "          7372,  3934,  1001,  7831,  4054, 38164, 35174, 61929, 35671,\n",
       "         62017, 38102,  4457, 12067, 33148,  6551,  6727, 30578, 29704,\n",
       "         29688, 28433, 62735, 26650, 25465, 11835, 38553, 39745, 39278,\n",
       "           486, 55588, 55258,  1472, 58819, 53077, 52109, 59340, 51305,\n",
       "         60010, 60017, 49908, 38635, 49613,  2007, 48693, 60221, 48369,\n",
       "         48142,  2548,  3412, 45789, 45328, 43409, 43257, 24850, 49371,\n",
       "         24427, 65549, 17329, 21375, 21090, 20204,  9240, 19010, 18724,\n",
       "         18687, 17315, 17142, 64708, 15510, 10583, 15206, 11286, 64218,\n",
       "         11415, 11671, 12125, 12084, 21510, 21737, 58073,  8512, 23792,\n",
       "         44680, 58861, 43319, 17239, 52809,  3838, 12922, 28146, 41414,\n",
       "         53343, 53819, 39443, 63776, 39146, 38979, 15384, 18070, 40629,\n",
       "         26304, 26247,  3282, 23382, 15187, 14755, 16204, 64007, 13981,\n",
       "         50881, 59801, 47718, 47490, 64215, 16787, 46710, 60299, 46456,\n",
       "         63240, 46080, 66512, 54982, 63736, 20076, 56211, 56268, 34996,\n",
       "         31233, 65007, 56508, 27189, 18250, 62569, 31868, 33457,  5827,\n",
       "         31880, 56549, 34520, 27288, 27750, 35601, 18554, 37848, 12382,\n",
       "         55262, 29108, 55404, 30928, 29518,  7354,  5188, 35680, 21278,\n",
       "         18976, 32615, 57674, 57756, 54969, 58387,  8176, 52264, 59307,\n",
       "         58420, 56003, 53114,  1778, 23433, 24743, 24511, 54601, 12188,\n",
       "          1834, 54620, 45219, 10037, 18241, 38417, 23012,  4505,  4511,\n",
       "         26754, 18875, 35558, 19279, 62045, 22218,  5583, 33274, 64946,\n",
       "         32192,  8615, 29625, 18214, 65574, 39304, 61702, 48590, 48317,\n",
       "         16312,  2454, 16413, 46701, 46254, 46156, 26114, 63871, 63811,\n",
       "         43023, 62815,  8483, 61451,  9617,  4066, 43873, 63518, 60783,\n",
       "         34629, 27779, 34647, 25363,  8637, 40377,  9955, 20481,  8626,\n",
       "         17236, 18050, 51090, 51648, 52285, 16254, 52630, 54207, 50480,\n",
       "          5554, 12582, 63493, 13075, 63103, 26320, 27247, 35557, 35148,\n",
       "         12963, 37401, 38551, 39461, 42697, 65648, 46520, 48626, 59238,\n",
       "         54166, 34264, 12781,  4280,  1169, 56357, 21734, 56701, 50837,\n",
       "         24325, 36744, 45964, 16978, 33339,   106], dtype=int64),\n",
       "  'feature_absent_idx': array([50750, 48510, 17828, 44151, 10097, 59603, 10099, 44156, 10102,\n",
       "         44158, 30325, 10105, 48511, 24518, 10108, 24520, 59594, 44160,\n",
       "         59593, 59592, 59590, 53652, 59587, 48502, 10119, 10107, 48498,\n",
       "         59609, 48512, 10064, 30352, 59636, 59635, 17838, 10071, 53641,\n",
       "         10073, 53643, 30346, 30345, 30334, 30344, 48514, 10080, 44143,\n",
       "         53645, 10083, 59618, 10085, 48513, 10087, 59612, 44148, 30343,\n",
       "         24529, 30312, 10125, 59560, 53662, 53664, 59555, 24546, 17800,\n",
       "         44198, 17799, 44203, 59547, 59544, 44193, 30276, 24547, 30272,\n",
       "         59537, 10177, 24550, 30269, 59529, 24552, 17792, 44212, 44214,\n",
       "         44204, 53660, 10153, 59564, 30311, 10127, 44171, 24531, 10130,\n",
       "         10132, 24534, 30306, 24535, 24536, 10137, 59573, 10139, 30300,\n",
       "         48494, 59570, 30297, 24539, 53657, 24540, 59565, 30292, 44189,\n",
       "         10150, 24542, 53639, 59638, 59639, 53638,  9964, 53613, 30420,\n",
       "         53617, 53619,  9973, 59714,  9975, 30414, 59710,  9978,  9963,\n",
       "         24488, 17862,  9982, 44091, 24491, 44095,  9987,  9988, 44097,\n",
       "         30404, 30403,  9994,  9980, 24477, 30428, 30429, 44058, 59744,\n",
       "         44059, 24470, 24471, 30446, 53600, 53601, 53602, 59739, 59738,\n",
       "         59737,  9942, 30442, 59736, 24472, 59734, 44065, 30438, 44069,\n",
       "         30436, 48548,  9953, 53606, 59725, 59698, 24553, 44100, 17856,\n",
       "         44125, 10034, 30375, 30373, 10038, 44127, 10040, 10041, 10042,\n",
       "         10043, 30371, 44124, 24502, 30367, 30366, 44132, 53636, 24506,\n",
       "         44133, 10055, 48517, 30358, 59643, 59641, 10046, 59665, 44123,\n",
       "         44119, 30398, 10001, 44105, 10003, 10004, 24496, 44108, 53626,\n",
       "         44111, 44112, 30389, 59678, 53627, 30387, 10015, 59676, 10017,\n",
       "         24498, 10019, 59673, 30385, 59670, 10024, 59668, 30383, 59691,\n",
       "         24469, 10187, 10189, 10349, 44285, 59392, 59391, 30145, 59389,\n",
       "         10355, 30144, 10357, 30143, 59387, 59393, 24590, 59384, 10363,\n",
       "         30141, 59383, 10366, 17731, 48444, 10370, 53718, 53719, 30133,\n",
       "         59385, 24595, 59395, 30147, 30168, 53705, 44272, 10321, 17743,\n",
       "         17742, 53708, 59412, 10326, 59411, 44277, 10346, 17740, 30157,\n",
       "         59406, 44279, 10336, 17737, 10339, 17735, 53712, 10342, 10343,\n",
       "         24589, 10330, 59368, 10376, 10377, 48433, 44311, 59330, 48431,\n",
       "         59326, 30103, 44312, 59323, 53735, 44313, 59320, 53730, 17710,\n",
       "         17708, 44317, 24612, 30087, 30086, 44320, 48424, 53741, 53743,\n",
       "         10441, 10442, 30097, 59339, 10408, 44305, 48441, 30130, 59363,\n",
       "         44295, 10383, 59358, 24598, 59357, 30126, 10388, 10390, 10391,\n",
       "         10392, 17721, 10394, 10395, 59349, 59348], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 330\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 330\n",
       "  })},\n",
       " 'contains_age': {'feature_present_idx': array([27711, 60720, 23624, 44495, 62843, 12259,  6693, 62067, 58291,\n",
       "         11140,  2920, 15258, 34068, 33285, 39334, 25944, 13033, 42019,\n",
       "         59109, 42539, 55472, 39432,  9402, 55238, 11993, 57141, 50984,\n",
       "         60863,  5885, 67114,  5472, 65133,  3855, 36664, 29818, 64201,\n",
       "         49977,  2455, 21223, 22677, 23329, 43451, 23083, 42768, 44374,\n",
       "         39636, 41995, 25476, 40155, 40003, 45421, 39315, 28187, 38398,\n",
       "         36121, 29261, 30088, 35126, 23549, 45936, 67229, 19114,   186,\n",
       "         64532,  2555, 63230, 62772, 61736,  7970,  8528, 59380,  9441,\n",
       "          9480, 59203, 19312, 56033, 14217, 32285, 46244, 15714, 16047,\n",
       "         16409, 31879, 18720, 50155, 14345, 32947, 66287, 65616, 33626,\n",
       "         65175, 64706, 45019, 41734, 63783, 48279, 50511, 50780, 51390,\n",
       "         52745, 55546, 44631, 57862,     8, 31688,  5540, 20856, 20494,\n",
       "         20136, 19625, 26137, 26568,  7661, 10104,  7568, 11477, 17824,\n",
       "         29082,   131, 31500, 10393, 31033, 44491, 50937, 56627, 58761,\n",
       "         17206, 45670,  8938, 19325, 45206, 18189, 15736, 28820,   918,\n",
       "          1796, 13497,  2271, 34390, 27236,  2943, 41788,  4412, 23493,\n",
       "         62670, 26157,   128, 55784, 55785, 66752, 12621,  7456, 57506,\n",
       "          2737, 63989, 65956, 61630, 16772, 43764, 22787, 50346, 28145,\n",
       "         52419, 25473, 47047, 16890, 31873, 21993, 22011,  3978, 39177,\n",
       "         37407, 34684, 33573, 23150,  9586, 31504, 18043, 55868, 55347,\n",
       "         45759, 54489, 33776, 52715, 30595, 28837, 55440, 14186, 52787,\n",
       "          3536, 16541, 43065, 11134, 47660, 16421, 46506, 16502, 25048,\n",
       "          1533, 26565], dtype=int64),\n",
       "  'feature_absent_idx': array([19040, 30297, 17800, 10083, 59603, 10085, 17799, 10087, 24496,\n",
       "         30292, 53645, 44143, 10080, 24498, 10097, 59593, 10099, 59592,\n",
       "         59590, 10102, 44148, 10105, 59587, 10107, 10108, 59594, 17792,\n",
       "         59609, 53643, 30325, 24491, 59636, 44119, 10055, 59635, 53636,\n",
       "         53638, 44123, 44124, 44125, 30300, 53639, 10064, 30311, 44127,\n",
       "         53641, 59618, 30306, 10071, 44132, 10073, 59612, 44133, 30312,\n",
       "         44151, 17790, 44156, 48478, 30248, 30247, 10150, 30246, 59555,\n",
       "         10153, 17775, 44189, 17774, 30241, 17779, 48477, 59544, 17772,\n",
       "         44193, 30236, 53657, 17769, 59537, 48475, 30232, 59529, 48471,\n",
       "         59547, 59560, 30255, 30257, 30276, 44158, 24502, 44160, 30272,\n",
       "         10119, 17788, 30269, 17785, 10125, 59573, 10127, 17784, 17783,\n",
       "         10130, 44171, 10132, 59570, 17782, 53652, 24506, 10137, 59565,\n",
       "         10139, 59564, 59638, 59639, 10046, 24488,  9953, 30389, 48513,\n",
       "         30387, 53617, 30385, 53619, 59714, 30383, 59710,  9963, 44059,\n",
       "          9964, 44069, 17838, 48512, 30375, 30373,  9973, 30371,  9975,\n",
       "         59698,  9978,  9980, 44065, 48514, 44058, 53613, 59749,  9918,\n",
       "         44035, 53600, 44038, 30414, 53601, 59744, 17856, 44042, 53602,\n",
       "         59739, 44047, 59738, 59737, 59736, 30404, 59734, 30403, 53606,\n",
       "         24448,  9942, 30398, 48517, 59725, 30367, 53660,  9982, 30366,\n",
       "         10017, 30345, 10019, 30344, 30343, 44097, 24477, 10024, 44100,\n",
       "         48498, 44105, 59665, 30334, 10034, 44108, 44111, 44112, 10038,\n",
       "         59643, 10040, 10041, 10042, 10043, 59641, 48494, 10015, 30346,\n",
       "         44095, 24464], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 200\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 200\n",
       "  })},\n",
       " 'contains_beneficiary': {'feature_present_idx': array([   75, 41159, 22656,  2869, 32544, 23123, 52985, 30777, 52704,\n",
       "         42822, 38517, 41080,  4458, 50259, 50011, 49653, 12458, 28811,\n",
       "         47624, 26363, 47010, 46959, 27384, 50620, 56080,  2489, 20631,\n",
       "           135, 67113,  9555, 14355, 14351, 17261, 64303, 14303, 37229,\n",
       "         62882,  2077, 33635, 61356, 57700,  8962, 20062, 20034, 11002,\n",
       "         14070, 40396, 45428, 18071, 39908, 28894, 32769, 35712, 28756,\n",
       "         28356, 32128, 29732, 24990, 26904, 16611, 17385, 17460, 17482,\n",
       "         17687, 18827, 18896, 19542, 27479, 20554, 21676, 22968, 24008,\n",
       "         24172, 24787, 25025, 26184, 26278, 21174, 37607, 41651, 38533,\n",
       "         53864, 54765, 55906, 56133, 56164, 56680, 57030, 57181, 57941,\n",
       "         58226, 58399, 58510, 58623, 59107, 62677, 63406, 63859, 65009,\n",
       "         65981, 66725, 67105, 53766, 53062, 53046, 52934, 38683, 38740,\n",
       "         39946, 40831, 41570, 16253, 42383, 42860, 43541, 44126, 38138,\n",
       "         44225, 46561, 46726, 46974, 47496, 47679, 48246, 49840, 50684,\n",
       "         52359, 52683, 44787, 15122, 67346,  6478,  2967, 13640,  9888,\n",
       "          4030,  1322,  1109,  9257,  3830,  9195,  1461, 11268, 13341,\n",
       "         11479,  6399, 12392,   664,  1539, 11460, 29156, 35728, 35283,\n",
       "         57692, 54026, 33901, 33858, 54609, 33161, 10856, 32593, 55028,\n",
       "         12295, 27093, 32489, 11170, 27716, 28183, 46665, 11231, 30275,\n",
       "         28625, 56672, 32663, 31524,  3946, 37152,  5093, 41842, 42113,\n",
       "         42207, 49200, 42756, 14932, 42998, 44004, 44170, 44821, 44985,\n",
       "         45182, 45344, 43979, 53380,  4703, 40821,  3886, 37995, 25420,\n",
       "         51883, 51776,  9402,  4461, 38796, 51568, 39259, 39432, 50950,\n",
       "         39776,  4433, 38878,  1557, 41285, 65072, 58539, 21630, 66375,\n",
       "         23049, 62388, 22922, 66252, 12926, 58805, 21935, 65928, 14763,\n",
       "         13304, 22457,  1360, 22268, 21899, 62003, 17956, 21515, 60476,\n",
       "         12779, 60097, 15369, 18775, 16825, 18362, 66578,  9468, 61887,\n",
       "         50653, 39196,   756, 60684, 52808, 13542,  9399, 38777, 18466,\n",
       "         52221, 18433, 62183, 38639, 38205, 12589,   685, 45560, 67142,\n",
       "          6374,   225, 45035,  6201, 15649,   672, 47037, 47219,  5339,\n",
       "          5303, 15753, 41089, 66493, 43555, 47914, 43513, 43462, 43317,\n",
       "         42878, 48422, 42408, 48662,   675, 41672,  8696, 16482, 47910,\n",
       "         57958, 53183, 31450, 13027, 13123, 12788, 27112, 32099, 12034,\n",
       "         11936, 12844, 27899, 31972, 54990, 36364,  2445,  2232, 31191,\n",
       "         31018, 28403, 13104, 56644, 30350, 30227, 22929,  1680, 32763,\n",
       "         12098, 26631, 53686,  2825, 25727, 53932, 35480, 12518, 57451,\n",
       "         21098, 34951, 34909, 60007, 21099, 34832, 10691, 54854, 57190,\n",
       "         21382, 26358, 13007,  1555, 34777, 54167,  1554, 56999, 47457,\n",
       "          1627,  5701, 56861,  1619, 57166, 60162, 48607, 53226, 53114,\n",
       "         61155,  1324, 52051, 51828, 54320, 60061, 51635, 54965, 62601,\n",
       "         62652, 63239, 59359, 64386, 55215, 64581, 64701, 55729, 50037,\n",
       "         65021,  5142, 56287, 48068, 55840, 14924, 16157,  9430,  9578,\n",
       "         38506, 38481, 38216, 37945, 15965, 10178, 36388, 16063, 19838,\n",
       "         34544, 33262, 16334, 32097, 32059, 16591, 31506, 46398, 30134,\n",
       "         17210, 14341, 27727, 24961, 22727, 22680, 17507, 21546, 18314,\n",
       "         15841, 15725, 19151, 41573, 42291,  8452, 15561, 41201,  6573,\n",
       "         15145, 44963, 45538, 39655, 43917,  9263, 40804,   871, 47114,\n",
       "         64185, 44584, 56894, 11783,  7847, 26264,  5549, 64589, 16683,\n",
       "         57388, 15710, 25639, 13385, 13351, 17923, 45011, 14141, 24854,\n",
       "         26232, 58353, 58001, 14278, 57952, 25105, 44219, 25520,  6942,\n",
       "         14643,  8052, 31329, 66017, 15979, 49838,  3181,  8825, 37494,\n",
       "          3832, 10060, 52724, 66428, 52564,  8833,  8834, 38498,  4460,\n",
       "         53293, 56109, 36251,  8549, 51078, 42898, 11103, 66830, 36060,\n",
       "          2586, 33539, 33759, 34438, 65427, 10546, 54722, 32740, 14235,\n",
       "         64094, 16297, 62484, 64556, 15178, 17294, 45684, 20867,  8318,\n",
       "          5189,  8433, 50993, 38815,  3397, 36806, 36709, 53509, 35875,\n",
       "         54918, 67226, 31762, 30831, 30439,  1977, 24428, 22009,  1702,\n",
       "         25050, 57400,  1935, 57067, 28145, 26979, 34781,   969, 13416,\n",
       "         23425, 38046, 22169, 39230, 56198, 13713, 13642, 46878, 13268,\n",
       "         11896], dtype=int64),\n",
       "  'feature_absent_idx': array([59089, 12769, 12770, 12771, 28378, 12773, 45638, 45639, 12777,\n",
       "         57599, 28374, 12782, 57596, 57594, 12768, 57591, 28370, 45643,\n",
       "         28361, 57579, 12799, 57578, 12805, 12807, 45652, 28350, 12811,\n",
       "         12812, 12813, 28371, 57571, 45635, 12763, 12717, 57643, 57642,\n",
       "         45619, 12721, 28416, 12723, 57641, 28410, 28408, 28407, 57629,\n",
       "         57628, 57601, 45626, 45628, 12742, 28398, 57626, 28397, 57611,\n",
       "         57609, 28388, 45634, 57605, 28383, 28382, 12762, 12739, 57570,\n",
       "         57568, 57567, 12880, 57516, 28299, 57513, 45699, 57511, 45701,\n",
       "         45704, 12892, 45705, 12894, 12898, 45711, 57518, 12901, 57502,\n",
       "         57501, 57493, 45716, 45717, 28274, 12915, 45722, 45725, 28267,\n",
       "         45726, 28265, 28264, 45713, 12878, 12877, 45696, 57566, 45664,\n",
       "         12824, 28341, 12826, 12829, 28337, 45671, 12835, 28333, 45672,\n",
       "         28331, 45674, 57550, 45683, 57544, 12851, 12852, 12854, 28316,\n",
       "         12858, 28310, 12862, 12865, 28304, 45695, 57526, 57525, 57524,\n",
       "         45618, 45731, 12714, 28421, 57762, 12568, 28529, 28525, 12574,\n",
       "         45542, 45544, 57753, 57750, 28521, 28520, 12581, 28519, 28530,\n",
       "         12583, 57745, 45553, 12592, 45557, 12595, 12596, 12597, 12598,\n",
       "         57741, 45565, 57736, 57735, 28504, 12586, 45567, 57766, 12562,\n",
       "         57811, 12506, 12510, 57807, 12512, 57801, 57796, 57795, 45520,\n",
       "         28562, 12527, 28558, 12530, 57768, 12534, 28552, 28548, 12544,\n",
       "         28544, 12546, 12550, 57772, 28537, 57770, 28536, 12557, 45535,\n",
       "         28534, 57782, 57731, 57730, 28501, 57683, 28450, 28448, 28447,\n",
       "         12675, 12676, 28445, 45603, 28441, 28439, 57676, 57670, 57667,\n",
       "         28452, 57666, 28436, 12693, 45609, 12696, 57662, 28429, 45611,\n",
       "         57656, 57650, 12707, 45615, 12710, 12711, 57665, 12667, 45600,\n",
       "         45599, 28500, 28498, 57725, 28494, 28493, 57723, 45573, 28487,\n",
       "         57718, 45576, 28482, 12633, 12634, 28478, 57717, 57715, 28476,\n",
       "         28473, 12644, 45583, 57699, 12653, 45592, 45594, 45598, 12661,\n",
       "         57688, 12663, 12664, 45616, 57821, 57480, 45732, 45865, 13183,\n",
       "         57271, 45872, 28064, 28063, 57266, 13190, 57265, 13193, 45874,\n",
       "         28056, 45879, 45864, 13201, 28051, 57257, 57256, 13209, 28047,\n",
       "         57254, 28042, 13214, 57252, 57251, 13217, 13219, 13221, 57261,\n",
       "         45892, 45863, 28076, 57306, 28097, 57305, 57303, 57301, 13146,\n",
       "         45849, 13148, 13149, 57299, 13151, 28093, 57297, 13176, 13154,\n",
       "         28088, 13160, 13161, 45856, 28085, 28084, 28082, 13167, 57283,\n",
       "         28080, 28079, 28078, 13173, 28091, 57247, 28034, 45895, 13288,\n",
       "         13290, 13292, 13293, 45935, 13295, 45939, 13301, 45945, 45948,\n",
       "         13307, 45953, 13311, 27992, 27967, 13317, 13322, 27958, 27957,\n",
       "         27955, 13328, 13329, 57156, 45968, 45969, 13333, 13338, 27946,\n",
       "         27963, 57188, 27994, 13280, 13233, 57237, 45899, 28026, 45900,\n",
       "         45903, 57232, 57230, 13243, 45904, 57227, 13247, 57224, 13249,\n",
       "         57221, 28018, 57218, 13255, 13259, 28013, 57209, 57208, 45923,\n",
       "         13269, 13271, 13273, 13274, 45927, 45929, 45847, 12930, 45846,\n",
       "         28108, 57437, 57433, 28213, 12983, 28209, 28208, 12987, 57430,\n",
       "         12989, 28207, 57429, 28205, 45769, 28218, 57428, 57425, 13002,\n",
       "         13003, 57423, 57422, 57420, 57415, 57413, 13014, 13016, 28191,\n",
       "         57405, 13020, 57427, 28188, 45761, 12971, 45736, 45740, 28248,\n",
       "         28247, 45743, 57468, 12943, 28241, 28240, 28238, 12947, 12948,\n",
       "         12951, 12973, 12952, 28232, 45747, 57450, 12960, 57447, 28225,\n",
       "         28224, 12964, 45758, 57442, 57441, 12969, 12970, 28233, 45779,\n",
       "         57403, 13028, 28136, 57350, 28135, 45824, 45826, 57344, 13095,\n",
       "         13096, 13098, 28128, 13101, 28126, 13103, 57352, 57341, 13108,\n",
       "         57339, 28124, 13112, 45828, 57336, 57334, 28117, 28114, 57329,\n",
       "         28113, 57325, 28109, 13106, 45823, 13084, 13081, 13029, 57401,\n",
       "         28182, 57399, 45786, 57395, 13037, 13040, 57392, 57391, 57389,\n",
       "         28173, 57386, 28167, 13052, 57381, 45800, 45803, 45807, 45809,\n",
       "         13065, 57367, 28150, 57366, 57365, 57362, 57359, 13079, 28140,\n",
       "         45843, 57825, 28580, 12495, 28993, 58243, 11959, 58242, 28986,\n",
       "         28983, 28982, 58240, 11968, 58239, 58237, 28981, 58236, 28994,\n",
       "         45188], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 532\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 532\n",
       "  })},\n",
       " 'contains_concession': {'feature_present_idx': array([23226, 35633, 63486, 50914, 54074, 16851, 51364,  1370, 23819,\n",
       "          9326, 33632, 57148, 62215, 22099, 52389,  9604, 18117, 38465,\n",
       "         56194, 44767, 13082, 43776, 37332, 28618, 42918, 44919, 36048,\n",
       "         37513,  8464, 19774, 31463, 19786, 38762, 17575,  7268,  6244,\n",
       "          8406, 56827, 16777, 16765,  6070, 53233, 17839, 54524, 17879,\n",
       "           167, 52292, 14077, 12327, 12140, 43564, 45875, 45998, 43424,\n",
       "         11605, 11512, 14796, 42426, 39151, 15423, 48201, 42012, 41990,\n",
       "         48926, 50909, 41076, 40712, 39943,  9272, 51497, 51601, 47846,\n",
       "          5750, 13370, 33364, 34671,  3027, 31110, 31266,  2698, 33674,\n",
       "         31835,  2564, 23708, 63786,  2139, 57171,  2065, 63602, 32950,\n",
       "         24187, 63399, 28941, 35009, 21839, 60255, 66573, 19365,  4887,\n",
       "         57964, 59035, 28011, 20848,   341, 59708, 24302, 65537, 43212,\n",
       "         14454, 27842, 32446, 13629, 43502, 31965, 44115, 13891, 31917,\n",
       "         14018, 25332, 28045, 41800, 43167, 14413, 31614, 30974, 28037,\n",
       "         43422, 43982, 14872, 36894, 15578, 38797, 17043, 17573, 35106,\n",
       "         21001, 17646, 34860, 38234, 36599, 18811, 19450, 18871, 36817,\n",
       "         19112, 35690, 41563, 16891, 22182, 41413, 66977, 33021, 40565,\n",
       "         39872, 16205, 21709, 23212, 16306, 22956, 39761, 33950, 38822,\n",
       "         22269, 16276, 18594, 12119,  5211,  6108, 51331,  9614, 51502,\n",
       "         57710, 53184,  8612,  3293, 53778, 53917,  8174, 54360,  7596,\n",
       "         51097,  1738,  7303,  7263, 54850, 63322, 63287,  6875, 63049,\n",
       "         56134,  2173,  2283,  5100, 57471,  2668,  1805,  1013, 58877,\n",
       "         10335, 60266, 45262, 66124, 12757, 60087,   297, 45679, 65948,\n",
       "         12044,   516, 11990, 46432,  3092, 46936, 11401, 65359, 47248,\n",
       "           980, 50035,  4157, 64252,  3551, 64893, 44942,  3208, 47829,\n",
       "         59394, 47431, 48469, 61999, 33771, 61939, 34182, 34662, 33766,\n",
       "         33963, 63342, 62661, 26927, 27738, 28004, 65682, 65333, 29964,\n",
       "         30469, 62176, 64056, 31650, 63947, 63766, 63720, 63520, 62968,\n",
       "         62885, 31591, 61300, 45228, 60516, 39780, 40527, 50954, 40851,\n",
       "         41264, 49258, 48931, 48851, 48436, 51455, 42306, 46823, 46265,\n",
       "         45708, 26893, 45590, 45358, 45291, 44639, 44666, 47134, 51536,\n",
       "         52433, 53680, 35104, 35406, 59347, 35937, 58850, 57805, 36790,\n",
       "         57636, 57406, 56508, 37397, 56231, 56151, 56149, 37573, 37723,\n",
       "         38012, 55998, 55507, 54591, 54545, 61146, 26706, 32937, 17902,\n",
       "         12920,  1492,  4136,  8397, 13379, 16383, 16112,  3635, 16043,\n",
       "          3310, 24863, 12788,  9252, 14497, 22476, 14617, 15903, 22870,\n",
       "         18150, 23385, 24353,  8234, 15635, 15529, 24826, 21273, 21642,\n",
       "         25545, 11107,   402,   526,  6079,   813, 26068, 20473, 17704,\n",
       "         23902,  1244,  4257,  4515, 37611, 15542, 53699, 37675, 11054,\n",
       "         37808,  8216, 39552,  8130, 39329, 40932, 15725, 16531, 38249,\n",
       "         56399, 54175, 39587,  6839, 16013, 56347, 54317, 40338, 56287,\n",
       "          6361, 39741, 16188,  5951,  6530, 42993, 52952, 49496, 12303,\n",
       "         12018, 49438, 11776, 46062, 46188, 46194, 46218, 45453, 11652,\n",
       "         11406, 46993, 11356, 10810, 48853, 10895, 47955, 48816, 48237,\n",
       "         49283, 13048, 45163, 50037, 42423, 52278, 51970, 15140, 43078,\n",
       "         43096,  9118, 43236,  9238, 43447, 43524, 43636, 14399, 14324,\n",
       "         44066, 44120, 10037, 13726, 10176, 10415, 50449, 15435, 18403,\n",
       "         10908, 57270, 25284,  3230, 29458, 24124, 24104,  3235, 33042,\n",
       "         29164, 33262, 23889, 29148, 60823, 22717, 60663, 60604, 32449,\n",
       "         31268, 61491,  5365, 25035, 31451, 25001, 24843, 31620,  2626,\n",
       "         24768, 25191, 30745, 32028,  2138, 32038, 32089, 32097, 63210,\n",
       "         61644,  3260, 22374, 64645, 36094, 65406, 20334, 58802, 20991,\n",
       "         27797, 28918, 21022, 19493, 27724, 27983, 58336, 65986, 21196,\n",
       "         34838,  4108, 26048, 66147, 36915, 59658, 25905, 28142, 25609,\n",
       "         66607, 63594, 66768,   237,  4662,   537, 62873, 63582, 50382,\n",
       "         49073, 10513,  1583, 64100, 49359,  1190, 49623,  1453, 49476,\n",
       "         10546, 51229,  2881, 62464,  7149, 55999, 59512, 56109, 59373,\n",
       "         59019,  6755, 56153, 60229, 59011, 56691, 56698, 57000, 57115,\n",
       "          5063, 57527, 57476,  5146, 58756, 51335, 55046,  7358,  9354,\n",
       "         62370,  2644,  2661,  2845,  9144, 51651, 51797,  7150,  9035,\n",
       "         61221,  8626, 53605, 61093, 61077,  3309, 60259,  7497,  8700,\n",
       "         26582, 67046, 25915, 14654, 15009, 43006, 36638, 42517, 15162,\n",
       "         24559, 26229, 27747, 31754, 15419, 31329, 41786, 14400, 18840,\n",
       "         41504, 26107, 15603, 18818, 41226, 37822, 37888, 40263, 40094,\n",
       "         38436, 38511, 17504, 39734, 37340, 26264, 24435, 13762, 26550,\n",
       "         21983, 32224, 32972, 33379, 33433, 12407, 11682, 46829, 34480,\n",
       "         11149, 22007, 47916, 11084, 11558, 32550, 12291, 29934, 32273,\n",
       "         35208, 44446, 13639, 44691, 35152, 21583, 13215,  1924, 30183,\n",
       "         35466, 35557,  1977, 58624, 17040, 19768, 31836, 17889,  2389,\n",
       "         60161,  1719, 48579, 58299, 35061, 62736, 34759,  2104, 33853,\n",
       "          5200, 16486, 43077, 44050, 27223, 66347, 51129, 10035, 50993,\n",
       "         45025,   183, 49881, 49773, 49487, 26481, 26484, 49397, 10537,\n",
       "         49139, 11261, 11125, 65812,  8724, 27512, 64094, 34060,   936,\n",
       "           656, 41236,  1565,  1239, 39932, 27802,  6898,   746, 15431,\n",
       "         39721, 64271, 28190, 29786, 63424,   745, 66422, 25216, 28005,\n",
       "         32190, 27488, 63350, 28967, 33857, 48690, 40108, 15929, 34048,\n",
       "         40080, 53427, 53361, 52890, 52527, 52446,  6241, 42414, 17809,\n",
       "         52010, 37881, 40515, 37354, 45200,  3403, 59879, 34619, 49460,\n",
       "         14762, 21734,  7909, 13163,  9833, 44103, 19270,  5090,  4280,\n",
       "         53349,  9752, 53742, 11896, 42773, 34564,  1335, 35913, 19620,\n",
       "         57621, 19109, 38408, 59623, 39003, 56262,  6593, 39868, 22900,\n",
       "         28851, 28658, 39071, 32822,  8105, 30279,  8342, 25068,  4856,\n",
       "         15651, 27515, 55501, 45461], dtype=int64),\n",
       "  'feature_absent_idx': array([18529, 12763, 61709, 12768, 12769, 12770, 12771, 41762, 12773,\n",
       "         12777, 27776, 49503, 12782, 49500, 12762, 41772, 64797, 27763,\n",
       "         49493, 41775, 41776, 49490, 12799, 41777, 49489, 27758, 64792,\n",
       "         27757, 12805, 41773, 12807, 49507, 49509, 41747, 12710, 12711,\n",
       "         57329, 27820, 12714, 61700, 12717, 49532, 12721, 12723, 49529,\n",
       "         27811, 49508, 49526, 49523, 27805, 64806, 12739, 27801, 12742,\n",
       "         27799, 27796, 49516, 61704, 27792, 27791, 49511, 49524, 12707,\n",
       "         49486, 12811, 49450, 27712, 49446, 49445, 27710, 49444, 12877,\n",
       "         12878, 57339, 12880, 27708, 27707, 49439, 27713, 64779, 64778,\n",
       "         49437, 57341, 49434, 12892, 27703, 12894, 41802, 27701, 64776,\n",
       "         12898, 12901, 41807, 61724, 27754, 27715, 41798, 12812, 12813,\n",
       "         61717, 57334, 58897, 58894, 12824, 49474, 12826, 57336, 12829,\n",
       "         49471, 12835, 12865, 27735, 27731, 49468, 49466, 49463, 27726,\n",
       "         27725, 12851, 12852, 27723, 12854, 49456, 12858, 12862, 27733,\n",
       "         27693, 41744, 49546, 27946, 12544, 12546, 12550, 64851, 27937,\n",
       "         64850, 12557, 27931, 12562, 64849, 64847, 12568, 41671, 49610,\n",
       "         64845, 12574, 49606, 58915, 58914, 12581, 64840, 12583, 49605,\n",
       "         12586, 41694, 41695, 12592, 49609, 27910, 27955, 27957, 27992,\n",
       "         12490, 12491, 57303, 12494, 12495, 49654, 49649, 41649, 49648,\n",
       "         41650, 12506, 41653, 12534, 12510, 12512, 41655, 49639, 41658,\n",
       "         27967, 57305, 41664, 27963, 12527, 57306, 58919, 12530, 27958,\n",
       "         49642, 61698, 12595, 12597, 64820, 64819, 27861, 12661, 27860,\n",
       "         12663, 12664, 12667, 41729, 49560, 41731, 12675, 12676, 27863,\n",
       "         27845, 49558, 41738, 41741, 64814, 57325, 12693, 41742, 49549,\n",
       "         12696, 49548, 27831, 61695, 27828, 64816, 12596, 64821, 12653,\n",
       "         12598, 27908, 41697, 49594, 49590, 64833, 49588, 41703, 27891,\n",
       "         64831, 49586, 41706, 27883, 27864, 58912, 12634, 27877, 49579,\n",
       "         49578, 58907, 41718, 12644, 41719, 49574, 41722, 49572, 49570,\n",
       "         64822, 12633, 49431, 58885, 27688, 13173, 41913, 64725, 13176,\n",
       "         41914, 49271, 49269, 13183, 27486, 41916, 61765, 61766, 49263,\n",
       "         49272, 13190, 13193, 61767, 41922, 61771, 27471, 13201, 61772,\n",
       "         58865, 64721, 41929, 27464, 13209, 49255, 41919, 13214, 13167,\n",
       "         27500, 27531, 41896, 27527, 64730, 49309, 57362, 41897, 41898,\n",
       "         41899, 27516, 49294, 64728, 49291, 57367, 49290, 13146, 13148,\n",
       "         13149, 41908, 13151, 49284, 13154, 61762, 57365, 49281, 57366,\n",
       "         13160, 13161, 27506, 27535, 27459, 49254, 49215, 27409, 64699,\n",
       "         27408, 57381, 13288, 13290, 13292, 13293, 13295, 27402, 27401,\n",
       "         27399, 49216, 27398, 27395, 27394, 13307, 49202, 13311, 27389,\n",
       "         27388, 57386, 13317, 27386, 41970, 49196, 13322, 13301, 13217,\n",
       "         13280, 27413, 13219, 27458, 13221, 41932, 27451, 41935, 27449,\n",
       "         13233, 58859, 27439, 49241, 13243, 41949, 41962, 13247, 27431,\n",
       "         27430, 49235, 13255, 13259, 49226, 27417, 64704, 13269, 13271,\n",
       "         13273, 13274, 49219, 13249, 49315, 13112, 13108, 12960, 49400,\n",
       "         12964, 61737, 49398, 12969, 12970, 12971, 27641, 12973, 41843,\n",
       "         49391, 27638, 27650, 27637, 41844, 12983, 27631, 12987, 41847,\n",
       "         12989, 41848, 49383, 41850, 41851, 27625, 27624, 57350, 61739,\n",
       "         64756, 61735, 27653, 27686, 41817, 41818, 12915, 61727, 49425,\n",
       "         58884, 49424, 27676, 49421, 61729, 49418, 12930, 61734, 41828,\n",
       "         57344, 61730, 12943, 49411, 64766, 41832, 12947, 12948, 27658,\n",
       "         12951, 12952, 61733, 27656, 58882, 41853, 49378, 49377, 27586,\n",
       "         49345, 27582, 27581, 49340, 27576, 13065, 27573, 27571, 27568,\n",
       "         27567, 61751, 27561, 13052, 13079, 27557, 13084, 41884, 57359,\n",
       "         27548, 13095, 13096, 13098, 41887, 13101, 64737, 13103, 13106,\n",
       "         13081, 27590, 49350, 27591, 61742, 13002, 13003, 57352, 27621,\n",
       "         49374, 49373, 27620, 49369, 27616, 13014, 13016, 27612, 41856,\n",
       "         13020, 27607, 49362, 64749, 27606, 64748, 13028, 13029, 27605,\n",
       "         49360, 64747, 13037, 13040, 27593, 41867, 12484, 27994, 64866,\n",
       "         49661, 28448, 28447, 28445, 57237, 11902, 49978, 49976, 11906,\n",
       "         28441, 28439, 49973, 64988, 11914, 28450, 28436, 64984, 11922,\n",
       "         11923, 28429, 41416, 49960, 28421, 11931, 41419, 28416, 49954,\n",
       "         11939, 11940, 41406, 64981, 28452, 61565, 28494, 28493, 28487,\n",
       "         65004, 61557, 57232, 11848, 11850, 28482, 65001, 61559, 50000,\n",
       "         49999, 49985, 28478, 28476, 11861, 49994, 64997, 28473, 64996,\n",
       "         11874, 61563, 11876, 49988, 11882, 58966, 11885, 41389, 11834,\n",
       "         28410, 28408, 41444, 28361, 64964, 12013, 12014, 12015, 41448,\n",
       "         12017, 61582, 49901, 12022, 28350, 49898, 57247, 49897, 41455,\n",
       "         41457, 57251, 12033, 49891, 49890, 28341, 64956, 57252, 28337,\n",
       "         12045, 12046, 12047, 12029, 49948, 64967, 11994, 28407, 11952,\n",
       "         41429, 28398, 28397, 11959, 49941, 41432, 61578, 28388, 41436,\n",
       "         11968, 28383, 11995, 28382, 11976, 49931, 28378, 41440, 41441,\n",
       "         28374, 11984, 11985, 61579, 11987, 28371, 28370, 49923, 11975,\n",
       "         11832, 65005, 11830, 57221, 11679, 28592, 28589, 61537, 50084,\n",
       "         61538, 28583, 28580, 11695, 11696, 65025, 41346, 11676, 11699,\n",
       "         41347, 57224, 11704, 11706, 11707, 11708, 41349, 11711, 41351,\n",
       "         11722, 28562, 50074, 28558, 11700, 50070, 50087, 11673, 28621,\n",
       "         11636, 61527, 11638, 61528, 11641, 41331, 11644, 28612, 50104,\n",
       "         11647, 50103, 11649, 28595, 41333, 11653, 11656, 58974, 11659,\n",
       "         28605, 57218, 65036, 41337, 50092, 28602, 11668, 11669, 11672,\n",
       "         11651, 11731, 11733, 11734, 11785, 28525, 41369, 28521, 65012,\n",
       "         28520, 28519, 57230, 50024, 50021, 11802, 41375, 11804, 11784,\n",
       "         11805, 41376, 11809, 11811, 11817, 50016, 28504, 11821, 28501,\n",
       "         28500, 11826, 11827, 11828, 28498, 11806, 11781, 11779, 28529,\n",
       "         11736, 11737, 11738, 11739], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 742\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 742\n",
       "  })},\n",
       " 'contains_condition': {'feature_present_idx': array([47560, 38572, 51255, 41352, 52650, 34451, 31876, 15175, 49321,\n",
       "          5415, 18566, 58348, 20666, 66616, 40388, 27340,  1486, 28539,\n",
       "          1395,   140, 26971, 27307, 51818, 37270, 62692, 63105, 20791,\n",
       "          8976, 25337, 47426, 64082, 39102,  6776,  6512, 11759, 24303,\n",
       "         13356, 26188, 61261, 14279, 67003, 55725, 60945, 60352, 17868,\n",
       "         21425, 29671, 19129, 58934, 55122, 23336, 60830, 52402, 65063,\n",
       "         48970, 66545, 49470, 66591,  1136,  4025, 45234, 66332, 65131,\n",
       "         41037,  3278,  5621, 45712, 45999, 17610, 60046, 17376, 17331,\n",
       "         13934, 17273, 30654, 17133, 61173, 17128, 14321,  3159, 42265,\n",
       "         31083, 16869, 14629, 16025,  2585,  2827, 32720, 31673, 54067,\n",
       "         49210, 31315, 59616, 30055, 56136, 24158, 24005, 46412, 25282,\n",
       "         22881, 47593, 26762, 55478,   371, 27053, 22064, 21965, 59814,\n",
       "         57272, 27833, 44595,  1975, 44288, 54986, 19829, 59335, 29373,\n",
       "         18708, 18590, 54205, 13913, 29824, 44756, 53682, 24613,  6888,\n",
       "         51738,  8309, 10372, 62604,  4443, 64610, 37435,  9916, 39173,\n",
       "         49943,  9668, 51827,  9603,  9249, 39047, 40902, 64425, 37731,\n",
       "         38169,  7457, 64131,  8490,  8243, 38744,  9557, 40539, 39016,\n",
       "         52206, 49388, 39855, 11216, 13225, 39582, 65825, 35144, 41882,\n",
       "         12883, 64891, 41410, 35914, 36200,  5693, 35319, 28216, 49928,\n",
       "         44589, 25144, 40344, 27572, 55245, 39688, 39892, 26056, 39506,\n",
       "         55323, 45308, 39405, 26992, 26356, 26591, 50191, 40216, 53608,\n",
       "         29746, 40723, 33826, 53240, 32806, 42232, 53187, 32721, 53095,\n",
       "         34941, 34996, 53841, 31899, 31699, 36621, 36660, 31292, 30963,\n",
       "         37167, 28746, 50679, 42907, 54711, 54538, 49754, 28744, 42073,\n",
       "         30069, 51424, 37449, 30201, 41145, 30909, 42790, 32421, 67008,\n",
       "         62001, 10141, 10842, 10956, 62143, 11108, 11643, 61501, 61304,\n",
       "         63263, 13748, 14580, 14928, 15695, 15991, 16357, 17134, 17268,\n",
       "         60196, 13765, 59466,  8827, 63897,   150,  1547,  2177,  2826,\n",
       "         66046,  3460,  3465,  4283,  8586,  4473, 65519,  5328,  5632,\n",
       "         64754,  6232,  6359,  6439, 64512,  4518, 18637, 23935, 57327,\n",
       "         22665, 24063, 22527, 22508, 21814, 22800, 23477, 56816, 19351,\n",
       "         57319, 22192, 21838, 64946, 65175, 39550, 49979, 26225,  5824,\n",
       "         64615, 22989,  5914, 55497, 19096, 50380, 37762, 54926, 63346,\n",
       "         38246, 50811,  8615, 38382, 56779, 38821, 50568, 39017,  7389,\n",
       "         39111,  4794,  7113,  6926,  4754, 56111,  4343,   777, 47793,\n",
       "           389,   246, 47670, 66880,  1516, 24486,    68,    56, 46484,\n",
       "         46701, 46790, 47046, 45830, 24673, 56440, 48258, 65667, 41490,\n",
       "         41901,  3847, 42218, 25286, 23746,  2986, 42596, 49167,  2486,\n",
       "         66356, 66439, 48404, 48266, 25862, 22218, 22290, 24610, 34516,\n",
       "         18058, 27724, 27793, 58735, 34085, 33998, 37641, 57798, 53812,\n",
       "         55155, 13826, 61044, 20937, 61029, 32505, 28176, 60993, 32184,\n",
       "         53888, 32031, 31946, 15041, 15085, 30940, 54116, 15734, 17002,\n",
       "         28490, 20761, 34623, 30034, 34690, 10072, 37322, 19057, 18875,\n",
       "         27108, 57140, 62061, 36751, 11664, 36523, 36354, 52246, 59427,\n",
       "         36247, 12701, 29794, 24526, 12599, 18138, 34802, 34898, 52258,\n",
       "         12425, 61504, 12286, 12180, 61965, 12068, 52260, 11970, 19856,\n",
       "         60622, 47704, 59642, 47992, 62710, 48071, 62266, 50874, 50599,\n",
       "         63919, 56627, 52742, 48006, 55777, 53314, 55815, 61181, 65771,\n",
       "         48686, 60954, 55260, 65525,    21, 22403, 17585, 17923, 18003,\n",
       "         18158, 18189, 19334, 19668, 20373, 21849, 17076, 21926, 25412,\n",
       "         26843, 27245, 28149, 28551, 28667, 29340, 29795, 31824, 22596,\n",
       "         16916, 15831, 15019,  2972,  3216,  3835,  4155,  4830,  5501,\n",
       "          5622,  5703,  5799,  5878,  7693,  8040,  8905,  9764, 10318,\n",
       "         11322, 11900, 12470, 12980, 14346, 14739, 33013, 34388, 32728,\n",
       "         38870, 38371, 38042, 35864, 38903, 37788, 34713, 45112, 38324,\n",
       "         36797, 44109, 36836, 43092, 36928, 40263,  8318, 58314, 58874,\n",
       "          9732, 42812, 51573, 64271, 58626, 50537, 17410, 39205, 39461,\n",
       "         15767, 15178, 40681, 13750, 13699, 13487, 49881, 10213, 41933,\n",
       "         41236, 20913, 64285, 57066, 28736,  1987, 31742, 47978, 35345,\n",
       "         54812, 53828,  7432, 36211, 36341, 27673,  3997,  1924, 26385,\n",
       "         34192, 34331,  5193,  5200, 43255, 25106, 56572, 45684,   183,\n",
       "         62019, 34801,  2239, 42400, 64435,  2415, 45200,  3978, 62974,\n",
       "         44260, 65516, 42414,  6935, 62845, 10365, 34684, 49460, 53024,\n",
       "         32864, 53887, 32139, 55385, 51953, 26110, 55882, 55918, 10992,\n",
       "         21993, 58095, 24289, 40727, 20180, 19963, 37645, 57621, 62554,\n",
       "         14088, 52715, 29341, 40611, 44718, 42635, 18655, 43781,  8691,\n",
       "          8282, 51745, 36982,  7444, 21750, 25470, 45482, 26291, 12115,\n",
       "         29057, 35310,  2437, 32378, 43054], dtype=int64),\n",
       "  'feature_absent_idx': array([15619,  9161,  9162, 55939, 50943, 23501, 23502, 45282, 17928,\n",
       "          9169, 45281, 17932, 29532,  9173, 14365, 63820, 29529, 25921,\n",
       "          9178, 17924,  9180, 29526, 29525, 50688, 55938, 38072, 25919,\n",
       "         38066, 17940,  9135, 29558, 49771, 14369, 24760, 17936, 53418,\n",
       "         29552, 45292, 17934, 38068,  9147, 29549, 29548,  9150, 29547,\n",
       "         63833,  9153, 52562, 29544, 29543, 55943, 63840,  9184, 29522,\n",
       "         17911,  9215, 40167,  9217, 45266, 25924,  9220, 58283, 29495,\n",
       "         16067, 17912, 63804, 17905, 49796, 63800, 29490, 25927,  9231,\n",
       "         42883, 52080, 55960, 29483, 60421, 24758,  9211, 29504,  9187,\n",
       "         29521, 17921,  9190, 38075, 45275, 14363, 55948, 29516, 60420,\n",
       "         58286, 55950, 58285, 45271,  9201, 55951, 40169,  9204, 55954,\n",
       "         29508,  9207, 14362, 24759, 42194, 29482, 63841,  9129, 23470,\n",
       "         40184, 58301,  9056, 45317, 38044, 55911, 38045, 29608, 25906,\n",
       "         29615, 42184, 38049, 16057, 29602, 29601,  9069, 14380,  9071,\n",
       "         25908, 14378, 29597, 29605, 55908, 42182, 63884, 63891,  9027,\n",
       "         60401, 17978, 49760,  9031, 29628, 17977, 51747, 16056, 29624,\n",
       "         14384, 49761, 29622, 45323, 23467,  9042, 14383, 17971, 58305,\n",
       "         45321,  9047,  9048, 51753, 23495,  9076, 17958,  9106, 63850,\n",
       "         17948, 55926, 38059, 17947, 29574, 63849, 29572, 42885, 55925,\n",
       "         49767, 29569, 45299, 58292,  9122, 14371,  9124, 63843,  9126,\n",
       "         55933, 49768, 58294, 29580, 63852,  9102,  9079, 38054, 38055,\n",
       "          9082, 45310, 55916, 55917, 25909, 25910, 58297, 23484,  9090,\n",
       "         42187,  9092, 63860, 60410, 24763,  9096, 55922, 45305, 45304,\n",
       "         23486, 61115,  9077, 45331, 63795, 45258, 29393,  9375,  9376,\n",
       "         29392, 17856, 29389, 29388, 63738, 29387, 56004, 42223, 63737,\n",
       "         43456, 25946, 29383,  9389, 29382,  9391,  9393, 29380, 24756,\n",
       "         56006,  9385, 57365, 45212,  9370, 29413, 60438, 29410, 45223,\n",
       "         52547, 29408, 45220, 58267, 29406,  9356, 42881,  9358, 17862,\n",
       "          9360, 38113, 50930, 38114, 38115,  9365, 57366, 56001, 63742,\n",
       "         60440, 29377,  9346, 25949, 42880,  9428,  9429, 17838, 24755,\n",
       "         63717, 29353, 29352, 50923, 29350, 29349, 52543, 52085, 29345,\n",
       "         63715, 14319,  9443, 63713,  9445, 57359,  9447, 14317, 40146,\n",
       "         29346, 29357, 50462,  9424, 29372, 63728, 63727, 23557, 40151,\n",
       "         23559,  9407, 29368, 45199, 57362, 52544,  9412,  9413,  9414,\n",
       "         51770, 45197,  9417, 25952, 50465, 50463, 56013,  9422, 61808,\n",
       "         42226, 29481,  9345, 29414,  9268, 38094,  9270,  9271, 45247,\n",
       "         39327,  9274, 55976, 55977, 49800, 29461, 55978, 49803, 51767,\n",
       "         38095, 63772, 63771,  9285, 29453, 17888, 63768, 60430, 45243,\n",
       "         29462, 23528, 60428, 52081, 61801, 38085, 17899, 45255, 25931,\n",
       "          9246, 23523, 55970, 40162, 29470, 45253, 63784, 45252, 58277,\n",
       "         52556, 50689,  9258, 45250, 45249, 45248, 50938, 29465, 63767,\n",
       "          9344, 42204, 16070, 29432, 25940, 45233, 45232, 29430, 55989,\n",
       "         61804, 60435, 38105, 52548, 29433,  9331, 29423, 29422, 55993,\n",
       "         60436, 42215, 14340, 39322, 25942,  9341, 49809, 29424,  9319,\n",
       "         50934, 16072, 16071,  9295, 45239, 25937,  9298, 29444, 42206,\n",
       "         57367, 43454,  9303, 45237, 63761, 42210, 23536, 45236, 63759,\n",
       "          9310,  9311,  9312,  9313, 58274, 29436, 63758, 63765,  9450,\n",
       "         55904, 58310, 49725, 51731,  8730,  8731, 29857, 29856, 42891,\n",
       "         37963,  8736, 14427, 40218,  8738, 18090, 49729, 29849, 23388,\n",
       "         18088, 29845, 64009,  8747, 14426, 18086, 29851, 23383, 18096,\n",
       "         64017, 18105, 55820, 29883, 29882, 37956, 29880, 29879, 64022,\n",
       "         25874, 23376, 29876, 29875, 52604, 25875, 52603, 16042, 29870,\n",
       "         25877, 40219, 29867, 61765, 61766, 55824, 58340, 61762, 18084,\n",
       "         61767, 29817, 50953, 29815, 29814, 23401, 29811, 61123, 18067,\n",
       "         29808, 49739, 55834, 23403,  8793,  8794, 42890, 63982,  8797,\n",
       "         63981, 55837, 14417, 60367, 55839,  8792, 58333, 16044, 18073,\n",
       "         45415, 45414, 64001, 45413, 14424, 25879, 64000, 29834, 58337,\n",
       "         45411, 45410, 63994, 14422, 29831, 49732, 29830,  8770, 18077,\n",
       "         23397, 42153, 29825, 25880, 29822, 23391, 37975, 29887, 55817,\n",
       "         18137, 60340,  8622, 45457, 16040, 14443, 40226,  8627, 57392,\n",
       "         49707, 23358, 23363, 60342, 49708, 60344, 29929,  8636, 50962,\n",
       "         18127, 18126, 14441,  8641, 55790, 60338,  8617, 29943,  8591,\n",
       "         64070, 52619, 45467, 55779, 29957, 29956, 14448, 55781, 14447,\n",
       "         29950,  8602, 23355,  8604, 45462, 18143, 64062, 49703, 45460,\n",
       "         39711, 45458, 52616,  8614, 37939, 18107, 64045, 50961, 55805,\n",
       "          8675, 55806, 29903, 23371, 57391, 18112, 29899, 64037, 64036,\n",
       "         18115, 23373, 18110,  8687, 49712, 18109, 37951, 49713,  8693,\n",
       "          8694, 18108, 29891, 55813, 64040], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 608\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 608\n",
       "  })},\n",
       " 'contains_consist_of': {'feature_present_idx': array([56146,  3253, 65940, 65743, 38657,  4006,  4403, 51994, 51614,\n",
       "         27463, 50965,  5634, 16022, 27925, 60616, 28891, 11058, 29520,\n",
       "         61172, 34641, 34484, 56410, 30332, 61955, 33221,  5920, 44441,\n",
       "         32033,  1194,  1024, 18498, 41758, 21620, 20753, 55961,  1759,\n",
       "         19855, 17957,  1086,  2016, 42922, 29132, 50277, 11898, 21810,\n",
       "         50397,  8975, 28502, 28431, 50744, 27993, 31861, 31924, 11278,\n",
       "         49964, 31002, 60870,  9051, 20126, 49711, 27917, 61544, 19707,\n",
       "         20609, 30226, 61595, 61844, 20018,  9635,  9602, 31652, 21179,\n",
       "         54517, 17771, 59027, 54552, 57547, 24607, 58830, 58678, 22930,\n",
       "         25223, 24256, 16559, 16648, 24177, 16968, 24046, 23906, 17394,\n",
       "         54051, 42863, 53340, 15004, 13490, 21903, 27339, 59657, 13848,\n",
       "         52307, 27028, 26131, 26928, 26809, 52483, 21977, 67211, 26518,\n",
       "         52848, 26171, 18377, 14368, 61633,  6498,   661, 40134, 38184,\n",
       "         63109,  1442, 49050,  6678,  2618, 37835,  1566, 36021, 45692,\n",
       "         41341, 63487, 46352, 37247,  4747, 36257, 66173, 64753,  4989,\n",
       "         66326, 45884, 39691, 42034,  1002,  2863,  8502, 62225,   174,\n",
       "         62347, 43033, 33291,   267, 48061, 62505, 42185, 47666, 62619,\n",
       "          7780, 47625, 47041, 39573, 34653, 34321, 45384, 42055, 40483,\n",
       "         39731, 24728, 24525, 40069, 24377, 40106, 39336, 24574, 39844,\n",
       "         24806, 53714, 39750, 48675, 23793, 42466, 42146, 42120, 55609,\n",
       "         55220, 21328, 21541, 55218, 21805, 43195, 41800, 43318, 40350,\n",
       "         22141, 22432, 22470, 54597, 54590, 39185, 41456, 41096, 23094,\n",
       "         41041, 23213, 23284, 54416, 22202, 39027, 38048, 25757, 28603,\n",
       "         50383, 46514, 35659, 46652, 46654, 29399, 34749, 34743, 49882,\n",
       "         29702, 49774, 34742, 29989, 30032, 49735, 49543, 47537, 33767,\n",
       "         30472, 30696, 30946, 31299, 49099, 31795, 33124, 48473, 28561,\n",
       "         25384, 36028, 28334, 25765, 52867, 45192, 38404, 26306, 26386,\n",
       "         38185, 52509, 26715, 38129, 26796, 37958, 37716, 27078, 52276,\n",
       "         27309, 45870, 36894, 51393, 45914, 51051, 51034, 27876, 45974,\n",
       "         46039, 50809, 36218, 50735,    25, 54986, 20326, 10110, 10161,\n",
       "         61435, 10361, 10403, 10439, 61136, 10923, 11062, 60669, 11609,\n",
       "         11818, 11852, 12175, 60227, 12333, 12785, 15303, 14770, 14756,\n",
       "         14408, 14154, 14137, 20340, 14121, 13944, 59578, 59687, 13304,\n",
       "         59854, 59912, 14074,  9768,  9444,  8919, 66008,  2554,  2373,\n",
       "         66239, 66392,  1975, 64836,  1387, 66472, 66508,   532, 66611,\n",
       "           148,    60,  1385, 15391,  3880,  4686,  8605,  8436, 62599,\n",
       "         62920,  7294,  7208,  4328,  7140,  6525,  6426,  6310, 63608,\n",
       "          5557,  5313, 63322, 59223, 61660, 15967, 16175, 18754, 58275,\n",
       "         16743, 18503, 19091, 18685, 18905, 15836, 17189, 18449, 56570,\n",
       "         19698, 18170, 18483,  6645, 56829, 47162, 55115, 46109, 63522,\n",
       "         45983, 36749,  5485, 18604,  5046,  4987, 55216, 37275, 36156,\n",
       "         34662, 25186, 21931, 54799, 32994, 48610, 18250, 48394, 48341,\n",
       "         62360, 62503, 53353, 47865, 54826, 33585, 62852, 22015, 62921,\n",
       "         47490, 47448, 47225, 18357, 34376,  7245, 34557, 37533,  7154,\n",
       "         45710,  4185,  4515,  2481, 21223,  2285, 21217, 40658, 41322,\n",
       "          1799,  1744, 41531,  2483,  1458, 55949, 19359,   610,   553,\n",
       "         43147,   523, 42271, 43035, 42531, 21002, 40104, 44710,  2607,\n",
       "         64764, 45660, 56731, 62009,  3925,  3896, 45551, 38323, 21416,\n",
       "          3623, 38562, 38810,  3462,  3429, 39260, 65480, 39514, 39530,\n",
       "          2959,  2652, 39759, 64761, 49080,  8139,  8689, 51372, 53940,\n",
       "         27888, 60007, 12648, 12589, 12194, 28293, 32181, 51383, 17430,\n",
       "         12039, 57752, 11716, 28878, 11680, 28925, 57697, 28968, 23352,\n",
       "         12129, 13470, 13480, 13641, 59130, 15466, 25376, 53400, 25485,\n",
       "         15272, 15130, 15067, 14785, 24750, 59231, 52551, 14411, 26589,\n",
       "         59468, 14311, 53572, 27012, 58497, 27262, 59591, 60805, 23351,\n",
       "         28373, 42746,  9859, 31558, 31540, 49382, 49195, 18008, 22912,\n",
       "         17897, 61859, 18155, 57564, 30791,  9486, 60975, 18235,  8885,\n",
       "         17572, 31334, 57691, 31031, 43999, 48068, 47919, 43917, 44402,\n",
       "         56697, 43820, 59126, 59427, 48274, 54786, 43458, 42899, 48958,\n",
       "         56111, 55964, 48771, 53297, 62005, 53542, 53284, 43184, 62206,\n",
       "         61965, 55663, 43234, 49127, 43322, 53477, 58866, 60901, 49163,\n",
       "         63046, 63209, 60612, 54389, 46957, 63280, 63341, 46526, 49769,\n",
       "         63346, 55205, 49843, 64597, 46225, 55190, 57275, 57756, 45645,\n",
       "         57162, 59561, 52287, 66120, 51949, 61743, 49167, 58381, 52449,\n",
       "         47485, 65207, 51080, 44963, 61644, 64963, 49257, 45406, 47328,\n",
       "         53737, 32031, 42704, 27793, 27528, 27433, 27178, 27131, 27108,\n",
       "         27928, 26780, 26048, 24798, 24768, 24460, 42743, 24214, 26429,\n",
       "         28159, 28535, 28812, 33274, 33186, 33123, 33048, 32588, 32402,\n",
       "         31743, 31268, 30980, 30077, 30070, 29930, 29737, 29390, 28966,\n",
       "         23433, 22837, 22780, 22155,  9558,  9255,  9158,  9118,  8006,\n",
       "          7389,  6926,  6842,  6246,  3847,  3468,  2531,  2229,  2181,\n",
       "           237,  9827, 33277, 10629, 11054, 22102, 21836, 21758, 21326,\n",
       "         20944, 20387, 18146, 17937, 17833, 17578, 17456, 16971, 15760,\n",
       "         13786, 11970, 10648, 33335, 67348, 33443, 34745, 42404, 38557,\n",
       "         35710, 37900, 36116, 36310, 42161, 34690, 36489, 36793, 36800,\n",
       "         38376, 42069, 41643, 37137, 37599, 41796, 36658, 34667, 38246,\n",
       "         42596, 33459, 34172, 33938, 40578, 33957, 44653, 44345,  8549,\n",
       "         11322, 15447,  8457,  8407, 45267, 45324, 12181, 14654, 22282,\n",
       "         14325, 38332, 41717, 12800, 23673, 54267, 54162, 54117,  8335,\n",
       "         21582, 21563, 38436, 44706, 61387, 44605, 44219, 16053, 10640,\n",
       "         10318, 61535, 18541, 10147, 15992, 33376, 19154, 56647, 44273,\n",
       "          9807, 20342,  9442, 11046, 41320, 20677, 61870,  8924, 17455,\n",
       "         44185, 40107,  3377, 34110, 27618, 51335,  3317, 27870, 49112,\n",
       "         50920, 46414, 34079, 31070, 28526, 46467,  2852, 49963, 30681,\n",
       "         42330, 49607,  2182, 46459, 66497,  1155, 65478, 42004, 37651,\n",
       "         33182,  6404, 32622, 48509, 47696, 52789, 48604, 27004,  5651,\n",
       "         32978, 32924, 65293, 64149, 25150, 66560, 60167,   656, 12732,\n",
       "         63103,  9946,  2610, 13210,  7658,  7769,  6568, 63493,  6012,\n",
       "         64292,  4419, 42319,  8613, 41550, 41358, 65911,  7070,  3306,\n",
       "         42912,  6656, 56707, 20192, 19808, 56492, 24239, 27247, 20594,\n",
       "         55833, 26420, 21643, 26409, 54813, 25279, 22511, 24668, 13750,\n",
       "         38269, 27255, 18642, 24665, 17925, 47729, 13818, 33849, 30183,\n",
       "         30129, 15424, 27453, 29753, 15467, 34854, 29539, 15948, 35148,\n",
       "         27881, 63722, 52403, 36963, 25731,  3645, 30450, 24737,  6869,\n",
       "         46269,  5806, 59782, 23399, 53817, 13855, 14401, 12016, 16012,\n",
       "         16392, 44827,  7052, 40693, 20756, 55752, 10051, 21117, 62919,\n",
       "         21734, 45475,  8034, 52787, 14088, 49273, 11134, 25470, 53876,\n",
       "         45263, 36485, 27689, 39992,  8350, 44498,  7968, 44970,  4613,\n",
       "         45013, 15573, 51811, 34226, 59622, 35310], dtype=int64),\n",
       "  'feature_absent_idx': array([52990, 21019, 32276, 51721, 41932, 21016, 51718, 32278, 15365,\n",
       "          9407, 51712, 21020, 51709,  9412,  9413,  9414, 21011, 51705,\n",
       "          9417, 32284, 32286, 32287, 41935, 15364, 51727, 51731, 32270,\n",
       "         41916,  9370, 51767, 32251, 41919,  9375,  9376, 32254, 21030,\n",
       "         51753, 15372, 32262, 51747, 41922, 51743,  9385, 51742, 21026,\n",
       "         15370,  9389,  9391, 41929,  9393,  9422,  9424, 32293, 32297,\n",
       "          9458, 51660, 20988,  9461, 15353, 20985, 20984, 51646,  9467,\n",
       "         20983,  9469, 32338, 51638, 20981, 32340, 51632,  9475, 20979,\n",
       "         20977, 41962, 51620, 32348, 18283,  9457, 51770,  9456, 15354,\n",
       "         37057,  9428,  9429, 37054, 32306, 51685, 32309, 32311, 32312,\n",
       "         32316, 41949, 51675, 32328, 37051,  9443,  9445, 51671,  9447,\n",
       "         51669,  9450, 20990, 51665,  9453, 51661, 21036, 15376,  9365,\n",
       "         51922,  9285, 32186, 51915, 51914, 41884, 21071, 51909, 32194,\n",
       "          9295, 21068, 32195,  9298, 51900, 51895, 21066, 32199,  9303,\n",
       "         21064, 15392, 51886, 41887, 32203, 51924, 51878, 51928, 51935,\n",
       "         51977, 21083,  9258, 51972, 51968, 32167, 51958, 51957, 32169,\n",
       "         51954, 32170,  9268, 37083,  9270,  9271, 32177, 51945,  9274,\n",
       "         37081, 51943, 51941, 32179, 51937, 51933,  9483,  9310,  9312,\n",
       "          9341, 51810,  9344,  9345,  9346, 51809, 41908, 51807, 51806,\n",
       "         37069, 51799, 51793, 51791, 51788,  9356, 37067,  9358, 51785,\n",
       "          9360, 51784, 41913, 32245, 41914, 32235,  9311, 51819, 15383,\n",
       "          9313, 51877, 21060, 32209, 51868, 51867,  9319, 32215, 51859,\n",
       "         51856, 41896, 51853, 41897, 41898, 51848, 41899, 18267,  9331,\n",
       "         32226, 32227, 32228, 32230, 32232, 51820, 51978, 32351,  9487,\n",
       "         20909, 51358, 51356, 42009,  9634, 51352, 51351, 51348, 51344,\n",
       "          9640, 42008,  9641, 42011, 51337, 51333, 15320, 42014, 42015,\n",
       "         51317, 32459, 42016, 51303, 20907,  9628, 20911, 37024, 51415,\n",
       "         51411, 32435, 15326, 51403,  9608, 51402, 20916, 51392, 51391,\n",
       "         51389, 51384, 51382,  9616, 51377,  9618, 51376, 51375, 42006,\n",
       "         51370,  9623, 20914, 32440, 32464, 15316, 51300, 51299, 51248,\n",
       "         42031, 32506, 42037,  9689, 51234, 42039, 32509, 20879, 32511,\n",
       "         32514, 32515, 32518, 20874, 42050, 20871,  9702, 51199, 37012,\n",
       "         32524, 51195, 51190, 32525, 37014, 51419, 32495, 20888, 15315,\n",
       "         51295, 51286, 51280, 18294, 32472, 37022, 51275, 51274,  9666,\n",
       "          9667, 37017, 51269, 51268,  9672, 51267, 32483, 51264, 20891,\n",
       "         51262, 32486, 51260, 42024, 32493, 42005, 32431, 32430, 15337,\n",
       "         32388, 32392, 15336, 41989, 51540,  9525, 37031, 20948, 20947,\n",
       "         32399, 20945, 32400, 51526, 51523, 32401,  9535, 32404,  9537,\n",
       "          9538,  9539, 41992,  9541, 51552, 51513,  9515, 37036, 37040,\n",
       "         41970, 51593, 32362, 51585,  9494,  9495, 32364, 32365,  9498,\n",
       "         20965, 41971, 51578, 32371,  9503, 51572,  9505, 37039, 41973,\n",
       "         41976, 20959, 51558, 51557,  9514, 20972, 20939, 51506, 51453,\n",
       "         51452,  9576, 20929, 51446, 32423, 51440, 51439, 20927, 51436,\n",
       "         20926,  9585, 32424,  9587, 32427,  9589,  9591, 20922,  9593,\n",
       "         51428, 51427,  9596, 51425,  9573, 51508, 42001,  9570, 41994,\n",
       "         41996, 32411, 32412, 32415,  9551, 51489, 51485, 51484, 51482,\n",
       "         20933, 15330,  9559,  9560, 51474,  9562, 51473, 51469, 32417,\n",
       "          9566, 51463, 51459,  9569,  9571,  9709, 21084, 21086, 52503,\n",
       "         31918, 52501, 18223, 21228,  8947,  8948,  8949, 52493, 52492,\n",
       "         21231, 21227, 37126, 52481, 52480,  8958, 18226, 21221, 21220,\n",
       "         31934, 21218, 52468, 52486, 41747, 52508, 52518,  8913, 52544,\n",
       "         52543, 41741, 52541, 31904,  8920, 52539, 52537,  8923, 31905,\n",
       "         52535,  8927, 41742, 31907,  8930, 31910,  8932, 21235, 21234,\n",
       "          8935,  8936, 41744, 31935, 52465, 21215,  8969, 52406, 21200,\n",
       "         41762, 18232, 52396,  9006,  9007,  9008, 31973, 18236, 52385,\n",
       "         41772, 41773, 31982, 41775,  9018, 41776, 52376, 21188, 52369,\n",
       "         41777, 52364, 18237, 21202, 21242,  8998,  8996, 52462, 52461,\n",
       "         31937, 31938,  8974, 52452, 52450, 52445, 52444, 15462, 31943,\n",
       "         21209, 31944, 52429, 31948, 37122, 52418, 15459,  8990, 52414,\n",
       "         31954, 52409,  8995, 52408, 52547, 52548, 31902, 41703, 31837,\n",
       "         52695, 37135, 41706, 31845, 31846, 31848, 52680, 52679, 21275,\n",
       "         52676,  8842, 15485, 52671,  8845, 31854, 52669, 52664,  8849,\n",
       "         52662, 52661, 21271, 52698, 18218, 15490, 31828, 31803, 52740,\n",
       "         41695, 52738, 52734, 52733, 31806,  8807,  8808, 31807, 52728,\n",
       "         52725, 52721, 31811,  8815, 52718, 52714, 41697,  8819, 18213,\n",
       "         15493,  8822, 31826, 37139,  9027, 21269, 52640, 52596, 52595,\n",
       "          8888, 37128, 52591, 21251, 52585, 31888, 31889,  8895, 52581,\n",
       "         52580,  8898,  8899, 41738, 37127,  8902, 31897, 52562, 31898,\n",
       "         21244,  8907, 52556,  8884, 41718, 31886,  8881, 31859, 52637,\n",
       "         21266, 52635, 41719,  8862, 21264, 52627, 41722, 52623, 52620,\n",
       "         52619, 52616, 31866, 31870, 31872, 31874, 41729, 52604, 52603,\n",
       "         41731, 31882, 52599, 37129, 21085, 31994, 32000,  9173, 52119,\n",
       "         32098, 32105, 52115,  9178, 52114,  9180, 32106, 21116, 32096,\n",
       "         52108, 52103, 52102,  9187, 52096, 15417,  9190, 52094, 52090,\n",
       "         52085, 41844,  9184, 52121, 21122,  9169, 52160, 32093, 52153,\n",
       "          9147, 21129, 52149,  9150, 52148, 21128,  9153, 52143, 52140,\n",
       "         52136, 41843, 21125,  9161,  9162, 52131, 21124, 52129, 52127,\n",
       "         21123, 52124, 32113, 52081, 52080, 32115, 41853, 52037, 18255,\n",
       "         21100, 15406,  9231, 32141, 52023, 32142, 41856, 52016, 32146,\n",
       "         52011, 37088, 32154, 37086, 41867, 51998,  9246, 32158, 51992,\n",
       "         37085, 51987, 41851, 32091, 52043, 52046, 18253, 52074,  9201,\n",
       "         18254, 52072,  9204, 52071, 41847,  9207, 32126, 52063, 32130,\n",
       "          9211, 41848, 41850, 52057,  9215, 52055,  9217, 52050, 52048,\n",
       "          9220, 52047, 15410, 32086, 52170, 52172, 41807, 52312, 52310,\n",
       "         52305, 52303, 32024, 21165, 21164, 15433,  9069, 52296,  9071,\n",
       "         32030, 32032, 41817, 32040,  9076,  9077, 41818,  9079, 52279,\n",
       "         52277,  9082, 37107, 37104, 52318, 52323,  9031, 52349, 37110,\n",
       "         52346, 52345, 32005, 21178, 52342, 52341, 32008, 41798,  9042,\n",
       "         21175, 52335, 32010, 15440,  9047,  9048, 37109, 52331, 21171,\n",
       "         41802, 15437,  9056, 18239, 32047, 52270, 52210, 52208, 52207,\n",
       "         32077, 52202, 52201,  9122, 52194,  9124, 52192,  9126, 37098,\n",
       "         41832,  9129, 32082, 21137, 52181, 37097, 21135,  9135, 52176,\n",
       "         21134, 52173, 52212, 32050, 41828, 52219, 32051, 32057, 52265,\n",
       "          9090, 52263,  9092, 15429, 52254, 32061,  9096, 52249, 52248,\n",
       "         52243, 21149, 21148,  9102, 32063, 52237, 21146,  9106, 52225,\n",
       "         52224, 37099, 18247,  9710, 42053, 51183, 20597, 10308, 10309,\n",
       "         50273, 33014, 36905, 15166, 50262, 15165, 42274, 36906, 42276,\n",
       "         42280, 10321, 50249, 15161, 18361, 50245, 10326, 33035, 50241,\n",
       "         20584, 33025, 20599, 10304, 50279, 10280], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 888\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 888\n",
       "  })},\n",
       " 'contains_degree': {'feature_present_idx': array([35893, 58860, 52697,  9864,  9819, 58886, 42937,  9776,  9763,\n",
       "         52689, 22719, 42870,  9696, 47905,  9654, 58903, 58855, 22730,\n",
       "         52739,  9909, 16790, 10118, 28215, 10096, 58765, 16801, 42985,\n",
       "         22706, 58771, 28386, 52796,  9991, 42956, 16860, 58826, 22767,\n",
       "         28308, 42787, 58910, 28601, 59151, 42519, 59172,  9243, 47969,\n",
       "         28852, 22627, 28785, 28861, 52540, 48002, 17214, 28972,  9109,\n",
       "         28977, 28999, 42457, 58711,  9386, 28774, 47951, 28626, 58986,\n",
       "          9594, 22672, 28704, 42689, 59124, 59044, 28729, 17041, 42544,\n",
       "          9436,  9435, 28769, 42533, 42685, 43079, 28127, 43087, 10885,\n",
       "         10884, 10859, 58231, 27736, 27746, 10784, 43488, 22991, 22983,\n",
       "         16583, 10749, 58266, 16592, 10639, 27823, 58245, 58407, 58205,\n",
       "         43506, 11057, 57918, 27526, 47529, 23054, 57999, 58043, 58194,\n",
       "         58059, 27589, 47565, 27642, 10944, 43579, 53061, 58192, 43619,\n",
       "         22535, 10564, 47638, 28003, 28015, 28036, 43211, 52873, 10233,\n",
       "         16693, 10284, 47746, 10200, 52866, 43151, 58690, 10184, 43123,\n",
       "         22795, 22813, 16616, 58647, 10320, 10523, 22932, 43401, 58485,\n",
       "         52886, 58525, 43289, 43214, 43287, 10418, 10404, 27924, 10369,\n",
       "         43242, 47742, 43221, 10426, 43674, 59443, 59470, 60564, 41500,\n",
       "         30009,  7763, 41478, 17550, 48405, 22274, 22225, 60702, 30090,\n",
       "         41407, 52177, 52175,  7629, 41526, 29962,  7829, 60549,  8007,\n",
       "         60456, 29852,  7989, 60480, 48278, 22342, 60762, 41642,  7945,\n",
       "         41617,  7924, 60520,  7896, 60530,  7865, 29866,  7618, 60776,\n",
       "         30173, 52130,  7423, 30318, 41228,  7361,  7338, 17718, 48440,\n",
       "         60992, 41203,  7232, 48446, 22165, 61042,  7174, 48462, 22186,\n",
       "         60449, 52133, 17691, 24224, 41377, 60809,  7574, 41334, 41324,\n",
       "         60840,  7452,  7554,  7523, 35900,  7514, 41272, 17666, 17685,\n",
       "         60912, 30214, 29810, 60399,  8023, 17334,  8766, 29321, 59970,\n",
       "         60019, 42150, 29343, 59815, 42128, 60076,  8671, 60089, 29370,\n",
       "         29376, 17365,  8582, 42115,  8530, 42245,  8872, 48046, 42317,\n",
       "          8999, 42289, 48091,  8970, 29167, 59694, 42272, 29179, 42268,\n",
       "         42263, 29228, 29257, 29268, 29270, 59588, 17230, 17368, 29416,\n",
       "         60346, 29647, 29673,  8149,  8141, 41880, 29711, 29618, 29724,\n",
       "         60371, 48261, 60391, 29783,  8071, 41748,  8025, 41806, 29405,\n",
       "         41953, 60262, 42057, 52432, 42017, 29493, 22380, 29507,  8395,\n",
       "          8240,  8385, 41984, 29575, 29578,  8313, 52360, 60246, 52317,\n",
       "         29512, 43679, 11100, 27447, 25207, 13665, 45840, 25240, 13630,\n",
       "         25250, 25309, 47118, 25339, 54036, 13560, 25353, 23659, 55563,\n",
       "         55583, 13702, 13758, 25185, 45901, 23821, 55374, 45997, 13915,\n",
       "         25098, 47038, 13885, 55634, 13879, 55408, 13859, 13854, 15553,\n",
       "         13836, 55471, 45930, 55395, 23643, 55653, 55664, 53931, 13204,\n",
       "         13185, 47173, 13174, 45471, 45468, 55836, 55942, 15735, 13097,\n",
       "         25721, 45448, 13058, 13053, 13049, 23597, 25074, 13222, 53949,\n",
       "         15620, 25426, 45669, 13433, 25490, 25522, 45601, 15683, 53981,\n",
       "         45580, 55758, 25561, 13298, 25582, 45568, 55819, 55750, 54094,\n",
       "         46090, 23869, 54731, 46727, 54747, 46282, 54760, 54769, 14812,\n",
       "         54729, 54793, 46280, 24484, 54869, 54874, 14688, 54888, 24045,\n",
       "         24451, 14664, 15286, 24351, 24231, 24126, 15100, 46537, 15023,\n",
       "         46474, 24079, 15265, 24068, 46386, 14946, 54607, 46717, 14920,\n",
       "         54617, 24340, 15225, 15749, 14658, 46247, 15411, 23924, 55087,\n",
       "         24793, 24809, 15434, 46144, 46911, 24884, 24943, 23886, 55221,\n",
       "         54217, 14072, 55257, 46113, 46137, 24549, 24747, 24736, 14613,\n",
       "         46233, 46231, 14575, 14567, 54913, 54941, 24742, 24614, 46778,\n",
       "         14513, 15387, 24653, 24658, 24702, 14397, 46775, 53787, 56005,\n",
       "         47188, 26777, 26795, 23236, 26862, 11720, 47410, 26911, 23261,\n",
       "         11691, 53282, 11661, 16344, 26941, 57313, 26964, 44294, 23223,\n",
       "         53281, 57093, 11851, 12000, 44482, 26606, 26622, 53412, 11965,\n",
       "         11963, 47374, 23317, 44419, 56957, 44416, 11871, 26750, 23279,\n",
       "         57073, 53407, 44512, 44258, 16367, 23160, 43936, 23127, 11318,\n",
       "         11308, 11300, 11297, 57788, 27280, 27316, 11203, 16471, 53120,\n",
       "         43752, 57884, 53101, 11215, 44256, 27168, 44025, 57435, 57439,\n",
       "         44192, 53214, 57461, 44072, 11540, 27159, 11536, 57562, 11508,\n",
       "         11497, 11494, 44060, 53203, 57664, 57522, 61127, 12025, 16097,\n",
       "         56166, 12725, 47207, 26030, 56239, 45009, 56245, 56158, 12682,\n",
       "         12666, 23570, 23568, 47215, 15920, 12556, 15936, 26072, 53696,\n",
       "         53752, 25996, 12953, 56018, 53779, 56040, 25786, 53774, 25803,\n",
       "         12810, 25808, 25923, 56124, 15861, 25981, 25985, 12823, 25987,\n",
       "         12866, 44538, 23563, 23522, 56510, 56554, 56557, 44689, 44668,\n",
       "         56641, 12131, 44794, 12121, 44606, 44581, 53452, 56700, 26511,\n",
       "         56721, 12057, 56665, 15971, 16065, 12305, 12489, 26253, 56416,\n",
       "         12469, 15996, 12443, 44902, 12285, 23494, 56463, 56469, 26296,\n",
       "         26312, 44848, 47254, 53538, 56456, 17767,  7598, 41163,  2816,\n",
       "         65422,  2805, 50910, 19381,  2769, 34176, 19403,  2750, 37844,\n",
       "         34199, 20987, 65538, 65570, 65571,  2828,  2831, 65412, 37909,\n",
       "         65177, 19309,  2977, 34032, 49458, 34051, 65245, 49644, 65255,\n",
       "         65284, 65305, 21003, 65317, 65336, 19363, 34151,  2907,  2635,\n",
       "         49647, 50840, 34424, 37491, 19599, 19619, 37415,  2329, 65863,\n",
       "          2432, 49682, 37376, 34527,  2231, 65954, 50701, 37361, 65987,\n",
       "         20873,  2991, 65768, 50739, 65592, 50802,  2595, 49662, 34295,\n",
       "          2572, 19529, 65752, 20908,  2530, 34352, 34377, 65700, 50740,\n",
       "         37548, 37527, 19557, 33985, 65110,  3076, 49279,  3689, 18962,\n",
       "         33369, 18971,  3669, 33382,  3742, 38640,  3601, 48476, 64373,\n",
       "         51154, 64399, 64433, 64472,  3606,  3554, 33317, 38700, 51224,\n",
       "         33118, 38798,  3991,  3972, 64142, 38791, 18900, 64172,  3906,\n",
       "         51204,  3863, 64198, 18876, 33183, 49198, 49192, 20857, 19009,\n",
       "         19018, 19138,  3259, 64929,  3256, 19142, 38121, 50960, 19137,\n",
       "         19232, 64959, 21041, 19239, 38064, 38038, 19254, 65038, 33865,\n",
       "         64561,  3290, 33655, 64579,  3492, 51142, 38567, 33517, 33538,\n",
       "         33546, 64916, 51028, 33582, 21076, 64696, 33607, 33611, 38420,\n",
       "         49304, 49303,  4059,  2121, 20804,   719, 66846, 66851, 50344,\n",
       "         20100, 20447, 36177,   531,   481, 20156, 66910, 50152,   442,\n",
       "         49950,   421,   720,   732, 36261, 66797, 35301, 36334, 66690,\n",
       "           890, 66709,   874, 66712, 49962, 35307, 35337,   793, 36322,\n",
       "         50348,   758, 35401, 66778, 66731, 20408, 66920, 35541, 49990,\n",
       "         67195, 67202, 36012, 50006, 20332, 67216, 67179,    80, 35798,\n",
       "         20273, 35923, 67281, 35825, 35921, 35905, 67240, 49912, 36016,\n",
       "         49984, 35553,   318,   317,   306, 66948,   292, 20210, 36019,\n",
       "         35614, 35617,   217, 35625, 66973, 66991, 66996, 67015,   235,\n",
       "           924, 66646,   961, 36995, 20735,  1732, 66176,  1709, 20716,\n",
       "         50531, 19846, 20706, 66229, 34900, 36923, 36865, 19895,  1532,\n",
       "         50524, 66226,  1520, 34840, 34808,  1984, 20801,  1945, 34700,\n",
       "         19764, 49751, 37296,  1801, 37071, 37044, 34792, 37009,  1853,\n",
       "         49784,  1849,  1825,  1906, 19678, 34998, 66304, 66429, 36483,\n",
       "         36474, 66451, 66457, 35249, 66533,  1120, 66544, 36381,  1026,\n",
       "         50374, 36358, 49877,   976, 66620, 66577,  1490, 49841,  1139,\n",
       "          1440, 20638,  1396,  1388, 50455, 36687,  1337, 20625, 66373,\n",
       "         66379,  1248, 49820, 36622, 35114, 36608,  1161,  1314,  4062,\n",
       "         54532, 62980,  6578, 62734, 61640, 31842, 40922,  5539, 40012,\n",
       "          5552,  5568, 48700, 51720, 48689,  5595, 31809, 31006, 31804,\n",
       "          5640, 17891, 38831, 40919, 61697, 18198, 61719,  5660,  6518,\n",
       "          6511, 18187, 51729, 51748, 31062, 61677, 62555,  6629, 62760,\n",
       "         51975,  6716, 17864, 62992,  5202,  5205, 40944, 32109, 51599,\n",
       "         61546], dtype=int64),\n",
       "  'feature_absent_idx': array([39377, 46402, 46406, 13606, 57656, 13608, 29424, 29423, 29422,\n",
       "         57650, 13615, 29414, 29413, 13620, 57643, 57642, 57641, 13626,\n",
       "         29410, 29408, 13631, 29406, 13637, 13638, 46417, 57629, 57628,\n",
       "         57626, 29430, 57662, 29432, 29433, 29462, 57699, 13551, 29461,\n",
       "         13557, 29453, 13564, 13565, 13566, 46389, 13568, 57688, 13571,\n",
       "         13647, 46390, 13577, 29444, 13579, 13582, 46393, 57676, 29436,\n",
       "         57670, 57667, 57666, 13595, 57665, 46399, 57683, 29393, 29392,\n",
       "         29389, 29353, 13701, 29352, 13705, 29350, 29349, 46442, 57579,\n",
       "         57578, 29346, 29345, 46446, 57571, 13698, 13718, 46447, 57570,\n",
       "         29335, 57568, 13725, 57567, 29334, 57566, 13729, 13731, 46449,\n",
       "         29329, 29326, 13719, 46383, 29357, 46439, 29388, 13654, 29387,\n",
       "         57611, 13659, 57609, 29383, 29382, 29380, 57605, 13671, 13672,\n",
       "         29377, 13696, 13675, 57601, 46427, 57599, 29372, 57596, 46428,\n",
       "         57594, 29368, 13688, 13689, 57591, 13692, 46434, 46426, 29465,\n",
       "         46382, 13541, 57825, 57821, 29572, 29569, 13399, 57811, 13405,\n",
       "         57807, 57801, 13410, 29558, 57796, 13415, 29574, 57795, 13422,\n",
       "         13423, 13425, 13426, 29552, 13429, 29549, 29548, 57782, 13435,\n",
       "         29547, 29544, 29543, 46334, 46341, 57835, 57840, 13338, 29615,\n",
       "         57876, 46299, 13344, 13345, 13347, 29608, 29605, 46304, 29602,\n",
       "         57867, 57864, 46317, 29601, 46305, 29597, 13362, 13364, 13365,\n",
       "         57857, 57856, 57850, 46312, 57846, 46314, 46316, 29580, 57860,\n",
       "         46458, 46342, 46343, 13495, 57736, 13498, 29495, 57735, 29490,\n",
       "         13507, 13511, 57731, 13513, 57730, 29483, 29482, 13494, 13519,\n",
       "         57725, 29481, 13524, 46372, 57723, 46374, 46377, 13532, 57718,\n",
       "         57717, 13536, 57715, 29470, 13520, 13441, 46361, 13485, 46344,\n",
       "         13446, 57772, 13448, 57770, 29532, 13454, 57768, 57766, 29529,\n",
       "         57762, 46349, 29526, 57741, 29525, 46350, 29522, 13466, 13467,\n",
       "         29521, 46353, 57753, 57750, 29516, 13476, 29508, 29504, 57745,\n",
       "         13463, 46294, 29320, 57550, 46572, 14028, 57336, 57334, 14033,\n",
       "         14034, 14035, 29115, 29114, 57329, 46573, 29111, 57325, 29110,\n",
       "         29107, 29105, 46575, 29098, 14054, 14056, 29097, 14059, 29094,\n",
       "         14062, 46582, 57306, 57305, 14026, 29119, 29123, 14021, 13974,\n",
       "         13975, 13976, 29152, 46558, 57367, 13986, 29149, 13988, 57366,\n",
       "         57365, 57362, 29147, 29086, 57359, 57352, 57350, 29140, 29139,\n",
       "         29135, 29133, 46563, 57344, 29131, 46564, 29127, 57341, 57339,\n",
       "         29146, 57303, 14073, 57301, 14135, 29042, 57247, 29041, 29040,\n",
       "         29039, 14143, 46617, 14146, 29035, 29033, 57237, 29032, 14134,\n",
       "         57232, 14157, 14158, 29029, 57227, 29028, 14162, 14163, 14164,\n",
       "         57224, 46632, 14169, 57221, 29020, 57230, 13973, 46609, 57251,\n",
       "         57299, 14078, 14079, 57297, 46588, 14085, 46589, 46591, 29071,\n",
       "         14091, 57283, 14099, 14102, 14131, 46602, 14110, 14111, 29058,\n",
       "         14113, 57266, 57265, 46603, 57261, 57257, 57256, 57254, 14127,\n",
       "         57252, 57271, 29161, 57381, 13964, 13804, 13808, 57502, 46480,\n",
       "         57501, 13815, 46482, 57493, 46486, 13823, 13825, 46487, 46488,\n",
       "         13801, 13829, 46490, 29254, 46493, 29252, 46494, 13840, 29249,\n",
       "         57480, 46495, 57468, 29239, 46510, 46511, 46489, 46513, 13799,\n",
       "         13796, 46462, 57544, 29308, 29306, 29305, 29304, 29303, 13767,\n",
       "         13772, 13773, 13774, 13776, 13778, 57511, 57526, 57524, 29287,\n",
       "         46472, 57518, 57516, 13788, 46473, 29284, 13791, 57513, 46475,\n",
       "         13794, 13795, 57525, 29317, 13864, 13868, 46536, 29191, 46538,\n",
       "         57420, 46542, 13933, 57415, 57413, 13936, 13937, 29184, 13941,\n",
       "         57405, 57422, 57403, 29177, 57399, 13950, 46546, 57395, 29175,\n",
       "         57392, 57391, 57389, 13958, 29170, 13961, 57386, 57401, 13867,\n",
       "         13921, 57423, 13869, 29229, 13872, 29226, 46518, 57450, 57447,\n",
       "         29219, 57442, 57441, 29214, 29213, 57437, 13920, 46530, 29205,\n",
       "         57430, 13900, 13901, 57429, 57428, 29200, 13908, 57427, 29199,\n",
       "         57425, 29196, 29194, 57433, 46638, 13333, 13329, 30023, 30020,\n",
       "         46013, 46016, 58318, 58316, 12762, 12763, 58311, 46018, 12768,\n",
       "         12769, 12770, 12771, 12773, 30007, 12777, 58310, 30005, 30004,\n",
       "         12782, 58305, 46023, 58301, 46024, 58297, 29997, 30024, 46008,\n",
       "         46007, 46006, 12696, 58358, 30064, 58357, 58354, 45990, 12707,\n",
       "         58349, 12710, 12711, 30054, 12714, 30052, 46028, 45993, 45994,\n",
       "         12721, 12723, 30044, 30040, 58340, 58337, 30036, 58333, 30035,\n",
       "         30033, 12739, 12742, 12717, 58294, 58292, 12799, 58242, 12858,\n",
       "         29950, 58240, 12862, 58239, 12865, 58237, 58236, 29943, 12877,\n",
       "         12878, 12880, 58243, 46063, 46066, 58215, 12892, 46067, 12894,\n",
       "         29929, 12898, 46071, 12901, 46075, 29920, 29915, 58208, 58221,\n",
       "         58360, 58246, 12852, 58286, 58285, 29988, 12805, 29987, 12807,\n",
       "         29986, 58283, 12811, 12812, 12813, 58277, 58274, 12854, 46036,\n",
       "         12824, 58267, 12826, 12829, 29971, 12835, 29969, 46047, 46049,\n",
       "         29957, 29956, 58254, 12851, 29979, 12693, 58361, 58363, 58488,\n",
       "         12527, 12530, 30191, 12534, 30188, 30185, 30184, 45923, 30180,\n",
       "         12544, 58476, 12546, 58489, 30178, 12550, 45927, 58465, 30170,\n",
       "         12557, 45929, 30168, 12562, 58460, 45935, 12568, 30157, 58450,\n",
       "         30177, 12574, 30200, 30203, 30232, 58526, 58519, 45899, 45900,\n",
       "         45903, 12484, 30224, 45904, 30222, 12490, 12491, 30221, 58491,\n",
       "         12494, 58513, 30217, 30216, 30213, 30212, 58506, 12506, 58502,\n",
       "         30209, 12510, 12512, 58496, 30208, 12495, 58207, 45939, 58444,\n",
       "         12633, 12634, 30103, 45968, 45969, 12644, 30097, 58389, 58388,\n",
       "         58385, 12653, 58380, 30087, 30116, 30086, 12663, 12664, 12667,\n",
       "         45976, 58373, 12675, 12676, 30071, 45984, 45986, 58367, 30067,\n",
       "         58364, 12661, 12581, 58411, 58413, 12583, 58443, 58442, 12586,\n",
       "         58439, 58438, 30147, 45945, 12592, 30145, 30144, 12595, 12596,\n",
       "         30117, 12597, 58434, 30143, 30141, 58429, 58428, 45948, 30133,\n",
       "         30130, 30126, 45953, 58416, 30121, 58415, 12598, 29622, 46088,\n",
       "         12915, 29717, 46228, 46237, 46239, 13183, 29709, 57978, 57977,\n",
       "         13190, 29708, 13193, 57975, 57974, 57973, 29705, 46241, 13201,\n",
       "         57972, 29703, 57971, 29701, 29700, 13209, 57968, 13214, 29696,\n",
       "         13217, 13176, 57988, 13173, 57990, 58034, 58032, 29745, 58030,\n",
       "         58029, 46198, 46199, 58021, 58017, 29735, 46209, 13146, 29731,\n",
       "         13219, 13148, 13151, 58006, 13154, 58000, 57998, 13160, 13161,\n",
       "         29727, 29726, 13167, 46214, 29720, 57991, 13149, 13221, 29693,\n",
       "         29692, 13280, 57919, 57911, 57908, 57907, 13288, 13290, 13292,\n",
       "         13293, 13295, 13301, 57901, 57900, 57922, 57899, 29640, 13307,\n",
       "         46284, 13311, 29635, 46287, 13317, 57887, 13322, 29628, 29624,\n",
       "         57885, 13328, 57898, 58036, 57924, 13274, 57960, 13233, 46258,\n",
       "         29683, 57955, 29675, 57953, 13243, 46268, 46271, 13247, 13249,\n",
       "         29666, 29654, 29661, 57940, 46274, 13259, 57938, 57937, 57933,\n",
       "         29658, 29656, 13269, 57929, 13271, 57927, 13273, 13255, 58037,\n",
       "         29750, 29751, 46124, 29870, 12969, 12970, 12971, 12973, 58152,\n",
       "         58151, 29867, 12983, 46128, 29857, 12987, 12964, 29856, 46129,\n",
       "         29851, 29849, 46130, 58132, 58130, 29845, 13002, 13003, 46135,\n",
       "         58122, 58118, 58112, 12989, 46138, 29875, 12960, 58203, 29907,\n",
       "         58200, 58197, 29903, 58195, 58191, 29899, 46100, 12930, 46110,\n",
       "         29891, 29887, 58158, 46117, 12943, 58178, 29883, 12947, 12948,\n",
       "         29882, 46120, 12951, 12952, 29880, 29879, 58163, 29876, 58179,\n",
       "         46089, 13014, 13016, 58060, 13079, 13081, 29776, 46180, 13084,\n",
       "         58057, 46182, 29771, 46183, 46184, 29765, 13095, 46172, 13096,\n",
       "         58052, 46187, 13101, 13103, 58049, 13106, 58046, 13108, 29758,\n",
       "         29757, 13112, 29754, 58039, 13098, 58110, 29782, 46168, 29834,\n",
       "         13020, 29831, 29830, 58106, 46146, 29825, 13028, 13029, 29822,\n",
       "         13037], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_destination': {'feature_present_idx': array([ 1048, 66468, 62455, 58639, 48836, 43916, 39551, 30107, 24467,\n",
       "         17819, 14642, 12331, 38940,  8265, 57652, 36096,  4712, 57732,\n",
       "         57783, 39546, 63231, 45916, 57588, 10333,  7481, 32984, 38222,\n",
       "         38621,  1301, 39387, 26475, 24718, 65625,  7639, 57390, 24456,\n",
       "         53749, 51857, 65140, 62228, 43411, 43137, 12716, 18289, 55798,\n",
       "         54294, 46677, 40799, 50670, 40882, 56129, 53400, 46313, 36147,\n",
       "         47884, 51147, 55532, 55216, 50303, 33463, 65501, 12138, 15695,\n",
       "         63626, 63344,  6717, 21477, 33466, 22024, 58720, 22866,  5788,\n",
       "         25122, 10956, 58010, 57668,  2999, 57631,  9247, 31292, 31475,\n",
       "         14836, 13573, 61865, 58344, 57203, 65178, 41423, 66843, 46059,\n",
       "         10935, 13584, 14987, 17232, 17314, 18157, 21836, 27122, 47610,\n",
       "         29906, 27330, 42747, 45003,  3213, 45221, 37952, 35918, 53451,\n",
       "         15667, 30330, 39744,  1550, 21240, 62004,  1927, 22282, 66708,\n",
       "         63313,  3082, 29687, 51514, 59671, 26963, 17301, 61596, 34294,\n",
       "         57538, 52572, 45964, 27689, 52232,  9117], dtype=int64),\n",
       "  'feature_absent_idx': array([10511, 43828, 12490, 12491, 62479, 12494, 12495, 43827, 26983,\n",
       "         26982, 43825, 62475, 56734, 26974, 12506, 12510, 12512, 43816,\n",
       "         26965, 56742, 56746, 56747, 56748, 12527, 62461, 12530, 26948,\n",
       "         12534, 26987, 56726, 56725, 12484, 38616, 12431, 49994, 62497,\n",
       "         56706, 56710, 27022, 27018, 49999, 12446, 12447, 12448, 27013,\n",
       "         38647, 12452, 43839, 12459, 12460, 62490, 62489, 12468, 27000,\n",
       "         52037, 43833, 43831, 50000, 62483, 56724, 12454, 26940, 62456,\n",
       "         12544, 12598, 62427, 62426, 38654, 26906, 26905, 38655, 62423,\n",
       "         26899, 43784, 26897, 56765, 50016, 12597, 62418, 38664, 26878,\n",
       "         12633, 12634, 38666, 26870, 52016, 56775, 12644, 26865, 62410,\n",
       "         26863, 26860, 43780, 12428, 12596, 12592, 56750, 12546, 62454,\n",
       "         43803, 26936, 12550, 62452, 26932, 12557, 12562, 38651, 43798,\n",
       "         62443, 12595, 12568, 62442, 12574, 43794, 26918, 26915, 12581,\n",
       "         62435, 12583, 43791, 12586, 62431, 52023, 26910, 26920, 62500,\n",
       "         56704, 43852, 12267, 49973, 27144, 62551], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 132\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 132\n",
       "  })},\n",
       " 'contains_direction': {'feature_present_idx': array([   88, 43141, 42103, 41911, 40335, 39588, 37691, 37053, 36313,\n",
       "         35870,  9001, 35583,  9448, 34273, 33464, 32850, 30225, 29603,\n",
       "         14453, 15879, 15989, 16447, 16680, 17352, 50540, 17631, 21167,\n",
       "         21260, 22279, 22954, 26038, 10756, 20031, 52015, 15422,  2492,\n",
       "         61068, 59918,  1656, 58232,  1596, 61324,  1302, 62828, 61664,\n",
       "         60448, 63882, 65436, 64029,   658, 31002, 32049, 16060, 66529,\n",
       "         61279, 28375, 16101, 28214, 27817, 26783, 66414, 26534, 18639,\n",
       "         25667, 24813, 24548, 24012, 33147, 22408, 21997, 21989, 61684,\n",
       "         20544, 63413, 19642, 64665, 25688, 51861, 35260, 53674, 53054,\n",
       "         42481, 42772, 43136, 52897, 43552, 41562, 44542, 45963, 47643,\n",
       "         48039, 48151, 49602, 50367, 52768, 45352, 52655, 41029, 40561,\n",
       "         59937, 35616, 59281, 36055, 57875, 36964, 56948, 40915, 37247,\n",
       "         38470, 38929, 39366, 54942, 15669, 39683, 54549, 55616, 39594,\n",
       "         32698, 11899,  6015,  7664, 10712, 12881,  5888, 12856, 10994,\n",
       "          2862,  2773,  2776, 11162, 10448,  2950,   189,  5730, 25836,\n",
       "         29889, 10676, 28991, 45344, 54088, 24512, 24525, 11852, 43802,\n",
       "         24633, 28315, 54198, 27151, 45784, 55554, 26763, 55609, 41289,\n",
       "         41431, 46767, 25370, 25627, 26103, 11504, 25933, 57472, 11021,\n",
       "         54168, 30271, 48758, 35611, 35743, 35775, 35891, 36146, 36400,\n",
       "         35441, 46533,  8436, 39712, 47737,  7798,  8309, 47579, 39266,\n",
       "         46766, 49056, 49068,  4903,  7375, 10222, 31213, 31512,  3734,\n",
       "         40285, 52660, 32647, 52104, 32736, 32910, 33179,  5557, 33950,\n",
       "         34039, 50691,  4837, 53756, 53721, 26152, 43526, 44864, 65515,\n",
       "         43693,   352,  6503, 20243, 65409, 65238, 20007, 61692, 16795,\n",
       "         60302,   475, 19484, 13515, 17378, 19073, 18836,  5978, 18318,\n",
       "         64513, 18289, 63854, 64334, 19561,   205, 64008, 15087, 59692,\n",
       "         45048, 23442, 59902, 66957, 23290, 23043, 12128, 59693, 12126,\n",
       "         37275,  8219, 43737, 16909,  5308, 39166, 39219, 33255, 15318,\n",
       "         51418,  7861, 17487, 10007,  4031,  7821, 10048, 46779, 51030,\n",
       "         49228, 16631, 66568, 14627, 66279, 44253, 36749, 36424, 65746,\n",
       "         48251, 13798, 37652, 39903, 13742,  8349, 16106, 38339, 35668,\n",
       "         35629, 48406, 16362,  9170, 48653, 43779, 38623, 38099,  8785,\n",
       "         23997, 32648, 26800, 61032, 60826, 26688, 60377, 26503, 60144,\n",
       "         44915,  3184, 12480, 12433,  6953, 25896, 22076, 25741, 11253,\n",
       "         22483, 25613, 25454, 22538, 22566, 24719, 59436, 24594, 24557,\n",
       "          6865, 58977, 21237, 52228,  7074, 21217,  3807, 32236, 31763,\n",
       "          3585, 59002, 62921, 40801,  3490, 30523, 44263, 29961, 61090,\n",
       "         19614, 44352, 29721, 53770, 29386, 28543, 13073, 61366, 44708,\n",
       "         28100, 40828, 40903, 54799, 29836, 39592, 46202, 45771, 45911,\n",
       "         15233, 47735, 58595, 59272, 59967,  1833,  1630,  1315,  1240,\n",
       "         58384, 61838, 63013, 63108, 63801,   751, 64963, 65960, 66843,\n",
       "         62046, 58327, 58093, 56960, 47919,  5017, 48167, 48274,  4931,\n",
       "         51324, 52754, 52908, 52925, 53242, 53477, 54523,  3468, 55160,\n",
       "         55190,  3213, 56687, 46957, 43999, 67320, 43739, 28352, 38935,\n",
       "         38648, 25956, 21283, 10812, 37375, 18175, 16207, 26754, 28479,\n",
       "         26962,  9158, 26984, 35499, 27034,  9513, 34920, 21225, 17223,\n",
       "         34745,  9669, 12731, 21192, 15142, 29659, 12300, 21536,  6543,\n",
       "         31280, 21344, 23580, 19432, 42357, 21332, 42069, 23998, 13202,\n",
       "         15860, 41785,  7180, 30971, 30733, 39905, 13481, 67213, 39766,\n",
       "         29930, 13985, 20737, 10892, 30244, 56491, 43958, 21492, 23863,\n",
       "         24021,  2076, 58356, 11844, 60568, 60767,  3107, 57830, 21299,\n",
       "         57205, 26359, 19344, 61057, 27771, 31522, 52093, 19008, 47964,\n",
       "         37651, 38388, 15992, 47523,  7834, 39756, 13843,  5305, 46217,\n",
       "         40377, 42004, 66665, 66818, 15626, 44653, 15507,  6260, 66142,\n",
       "         62978, 65415,  9860,  1155, 32484, 52285, 32728, 21547, 32990,\n",
       "          4623, 48479, 33476, 18190, 21751, 18069, 64603, 49098, 35472,\n",
       "           746, 13780, 20780, 66219, 13487, 15767, 19603, 63755, 16432,\n",
       "         18799, 65938, 13744, 55073, 52236, 44695, 42433, 44851,  6656,\n",
       "         40114, 39520,  8470, 34801, 49896, 34329, 50893, 52658, 10213,\n",
       "         31836, 27169, 39426, 59353, 23970, 24239, 55038,  3306, 25682,\n",
       "         20718, 22703, 15741, 25216,  8547,  8686, 17106, 18043, 34294,\n",
       "         64690, 59879, 31504, 22011, 52446, 55135, 30640, 45759, 45964,\n",
       "         46506, 55440, 47660,  3536, 41819, 63180, 49880, 33776, 53840,\n",
       "         42793, 26143,  8474, 25048, 47561, 31613,  1158, 22503,  1533,\n",
       "         26565], dtype=int64),\n",
       "  'feature_absent_idx': array([27955, 49383, 27707, 27703, 49378, 64756, 49377, 12707, 27701,\n",
       "         12710, 12711, 12714, 49374, 49373, 27708, 12717, 27693, 12723,\n",
       "         49369, 41649, 41650, 27688, 41653, 27686, 41655, 49362, 41658,\n",
       "         12739, 27676, 12721, 12742, 12696, 12693, 49411, 12653, 41631,\n",
       "         61650, 64766, 58796, 27735, 12661, 27733, 12663, 12664, 41634,\n",
       "         27731, 27710, 12667, 27726, 27725, 12675, 12676, 27723, 49398,\n",
       "         41638, 27715, 57208, 49391, 27713, 27712, 57209, 49400, 41628,\n",
       "         49360, 27658, 12807, 12811, 12812, 12813, 27616, 41695, 64737,\n",
       "         27612, 57224, 49315, 12824, 12826, 41697, 27620, 27607, 27606,\n",
       "         27605, 49309, 12835, 41703, 27593, 27591, 27590, 12851, 12852,\n",
       "         49294, 12854, 27586, 12829, 41664, 12805, 41694, 49350, 57218,\n",
       "         27656, 49345, 41671, 12762, 12763, 27653, 27650, 12768, 12769,\n",
       "         12770, 12771, 27621, 12773, 64749, 49340, 27641, 64748, 12782,\n",
       "         64747, 27638, 27637, 27631, 27625, 12799, 57221, 27624, 12777,\n",
       "         41706, 41626, 12644, 12495, 27864, 49486, 27863, 57188, 27861,\n",
       "         27860, 64806, 12506, 58814, 49474, 12510, 41558, 12494, 12512,\n",
       "         49468, 41565, 41566, 27845, 49466, 12527, 49463, 12530, 12534,\n",
       "         41572, 27831, 27828, 61627, 49471, 12544, 12491, 49489, 61607,\n",
       "         49516, 41530, 58821, 49511, 49509, 12446, 12447, 12448, 61608,\n",
       "         12452, 49508, 12454, 12490, 49507, 12459, 12460, 58820, 27891,\n",
       "         49503, 61611, 12468, 27883, 49500, 27877, 49493, 12484, 49490,\n",
       "         41533, 61648, 49456, 41580, 12595, 12596, 12597, 12598, 49434,\n",
       "         61637, 49431, 58799, 64779, 27776, 49425, 41614, 64778, 12592,\n",
       "         58797, 49424, 49421, 61641, 27763, 27758, 27757, 12633, 12634,\n",
       "         41624, 27754, 61646, 49418, 61647, 64776, 12546, 27791, 49437,\n",
       "         64797, 12550, 27820, 61629, 41582, 12557, 58809, 41584, 27811,\n",
       "         12562, 49450, 64792, 61632, 27792, 12568, 49446, 49445, 12574,\n",
       "         49444, 27801, 27799, 12581, 41591, 12583, 27796, 49439, 12586,\n",
       "         41593, 27805, 12858, 49291, 49290, 27386, 57261, 61733, 27381,\n",
       "         49133, 49131, 49130, 27376, 27374, 13146, 57265, 13148, 13149,\n",
       "         49140, 49125, 49124, 64668, 13154, 57266, 27371, 13160, 13161,\n",
       "         41798, 61734, 27365, 13167, 27364, 27363, 13151, 61735, 27388,\n",
       "         27389, 13079, 13081, 13084, 27417, 49164, 27413, 13095, 13096,\n",
       "         27409, 13098, 57256, 27408, 13101, 49143, 13103, 13106, 61729,\n",
       "         13108, 27402, 13112, 27401, 57257, 49153, 27399, 27398, 61730,\n",
       "         27395, 27394, 49160, 41777, 27361, 13173, 13221, 49088, 49087,\n",
       "         61742, 49084, 27319, 13233, 49082, 27317, 41828, 27314, 64650,\n",
       "         49078, 49089, 13243, 13247, 13249, 27306, 27304, 49067, 13255,\n",
       "         13259, 49062, 64646, 27298, 49060, 49059, 27294, 41832, 49111,\n",
       "         13219, 64654, 27360, 27359, 13176, 27356, 41802, 49108, 13183,\n",
       "         64663, 58754, 64662, 41807, 49102, 13190, 13217, 27349, 57271,\n",
       "         61737, 41817, 13201, 27337, 61739, 49094, 13209, 41818, 49091,\n",
       "         27331, 27329, 13214, 13193, 41776, 49168, 41775, 41719, 27561,\n",
       "         27557, 41722, 49263, 27548, 12915, 64721, 41729, 27535, 49255,\n",
       "         49254, 12930, 12901, 41731, 57237, 61695, 27527, 12943, 61698,\n",
       "         27516, 12947, 12948, 41738, 12951, 12952, 61700, 49241, 27531,\n",
       "         12960, 41718, 12898, 12862, 64730, 12865, 27582, 27581, 64728,\n",
       "         49284, 57227, 58781, 58780, 49281, 27576, 12877, 58776, 12878,\n",
       "         58779, 57230, 27573, 64725, 27571, 57232, 49272, 49271, 12892,\n",
       "         27568, 12894, 27567, 49269, 12880, 27506, 12964, 41741, 13028,\n",
       "         13029, 27458, 41762, 49196, 57251, 13037, 13040, 27451, 27449,\n",
       "         57252, 49186, 58769, 27459, 49185, 13052, 49182, 27439, 49181,\n",
       "         41772, 41773, 27431, 13065, 27430, 61727, 49174, 49173, 57254,\n",
       "         61724, 57247, 49202, 13020, 41742, 49235, 12969, 12970, 12971,\n",
       "         41744, 12973, 27500, 61704, 41747, 49226, 12983, 64704, 12987,\n",
       "         12989, 27486, 61709, 58770, 49219, 13002, 13003, 49216, 64699,\n",
       "         49215, 27471, 13014, 13016, 61717, 27464, 64814, 27908, 64816,\n",
       "         12431, 58865, 11832, 49825, 11834, 41270, 28361, 28350, 64948,\n",
       "         11848, 11850, 41279, 41282, 28341, 11830, 28337, 49809, 11861,\n",
       "         64943, 64941, 28333, 57112, 28331, 49803, 11874, 41296, 11876,\n",
       "         49800, 11882, 41290, 28316, 11828, 11826, 11785, 49851, 61507,\n",
       "         49847, 64956, 61508, 41257, 28388, 11802, 28383, 11804, 11805,\n",
       "         11806, 11827, 28382, 11811, 28378, 49837, 41262, 28374, 61510,\n",
       "         11817, 57107, 28371, 28370, 11821, 49831, 41266, 11809, 11784,\n",
       "         11885], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 577\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 577\n",
       "  })},\n",
       " 'contains_domain': {'feature_present_idx': array([38730, 62404, 62375,  7285, 47765,  7343,  7346,  7355, 62314,\n",
       "         26540, 47896, 26439, 47977, 48017, 26303,  7578, 26885,  7169,\n",
       "         26887, 26938, 62824, 46988, 27596, 27551, 27525, 27514, 47060,\n",
       "          7588, 47090, 62718, 27219, 47375, 27019, 27011, 47536, 47581,\n",
       "         27392,  7617,  7692, 62141, 24954,  8466, 24890, 49159,  8546,\n",
       "         61502,  8603, 61591, 24635, 49386,  8744,  8897, 49547, 49565,\n",
       "         24123, 49641, 61412, 46945, 49018,  8218, 26047, 26032, 62125,\n",
       "         62092, 48352, 62051, 48412,  8228, 25883, 48425, 61982, 25758,\n",
       "          8038, 61857, 61848, 48747, 25882, 46929,  6513,  6435, 44929,\n",
       "          4922,  4937, 30235, 63826,  5030, 45211, 63862, 29985, 45313,\n",
       "         63743, 29748, 29695, 29663, 45452, 45524, 45217, 45541, 63873,\n",
       "         44785, 43822, 43984, 64085, 31122, 31066, 30996, 64024, 44912,\n",
       "         44147, 30811, 30669,  4645,  4658, 30554, 30531,  4698, 44249,\n",
       "         24061, 29536, 29503, 28531, 28467, 28412,  5986, 63132, 28249,\n",
       "         28220, 46288, 28132, 46765, 27853,  6365, 62874, 27800,  6415,\n",
       "          6428, 27995, 63668, 46195, 28916, 63648, 45698, 45781, 29420,\n",
       "         29342,  5420, 29294, 46125,  5481, 29185, 29181, 29137, 63494,\n",
       "         29084, 45996, 46068,  5491, 61111, 49860, 23964, 12602, 17686,\n",
       "         17665, 54687, 16672, 58563, 16589, 54494, 13091, 58401, 16449,\n",
       "         16410, 55273, 16298, 16280, 16120, 55162, 58313, 58871, 12463,\n",
       "         18797, 18677, 53968, 18674, 59227, 12136, 18641, 12535, 12170,\n",
       "         12245, 54182, 18413, 12299, 12340, 12397, 18276, 18481, 18934,\n",
       "         55673, 55707, 14145, 57454, 56715, 14173, 14898, 14878, 14230,\n",
       "         56705, 57380, 14290, 56834, 14370, 56977, 57029, 57064, 57094,\n",
       "         14810, 15990, 56666, 15269, 15916, 15811, 15794, 15492, 13627,\n",
       "         56370, 15401, 56531, 56429, 13811, 56468, 57754, 13850, 13861,\n",
       "         13888, 57619, 57820,  4286, 59267, 59277,  9995, 22494, 22448,\n",
       "         22197, 10053, 10111, 51430,  9938, 51565, 51592, 51686, 21558,\n",
       "         21397, 21386, 21212, 21166, 21955, 21115, 51035, 50939, 61100,\n",
       "         23926, 23757, 61079,  9265,  9273, 61053, 22751,  9378,  9411,\n",
       "         50436,  9642, 23034,  9685, 50720, 50823, 50207, 53738, 60282,\n",
       "         20954, 19986, 59785, 19927, 19887, 59745, 19623, 11606, 11386,\n",
       "         53292, 53350, 11721, 19305, 38689, 59310, 11907, 53678, 19548,\n",
       "         10774, 59848, 11311, 20901, 20850, 20837, 52583, 52601, 20675,\n",
       "         20626, 52972, 52648, 11081, 52687, 11111, 20347, 20275, 20262,\n",
       "         59988, 20493, 43777, 62315, 64178, 41169, 34844, 32624,  3257,\n",
       "         40432, 37597, 36072, 41258, 40017, 32645, 36229, 66307,  2261,\n",
       "         66535, 34807, 40406, 41793, 65721, 35058, 39532, 37732, 32386,\n",
       "         40871, 43074,   468, 43039, 32422, 33614,  2647, 34984, 65423,\n",
       "         32535, 40157, 36345, 64762, 66148, 36456, 41454, 34471, 42486,\n",
       "         41613, 42485, 33125, 42432, 41542,  2994, 32975, 40175, 66282,\n",
       "          2953, 42449, 32855, 64858, 34492, 41749, 66770, 34597,  3123,\n",
       "         37515, 42719, 32778, 42334, 40126, 36541, 41652, 41392, 37450,\n",
       "         37374, 32807, 42142, 39127, 35872,  3474, 64305,  3721, 35327,\n",
       "         33712,   888, 31830, 43613, 65802, 64287, 35211, 31601, 33640,\n",
       "         35231, 38808, 39624, 38963, 38930,   992, 38875,  3877,  2381,\n",
       "         40784, 39713, 67110, 38501, 41854, 35744,  3718,  2320, 43186,\n",
       "         66413,   370,   832, 31402, 35520, 33870, 31377,  3579, 35356,\n",
       "         35647,    67, 36725, 31423, 38626, 33799, 43421,  2532, 66511,\n",
       "         32068, 39036, 31490, 34015, 36730, 43509, 31519, 53089, 36724,\n",
       "         36535, 19906, 18959, 19907, 18994, 53697, 40038, 53164, 53558,\n",
       "         19236, 53530, 19213, 19281, 19178, 19170, 39806, 39929, 19331,\n",
       "         53575, 19158, 53473, 39946, 39971, 53340, 53667, 53322, 39804,\n",
       "         19604, 19050, 36719, 19608, 19624, 53232, 53133, 40140, 20393,\n",
       "         20051, 21390, 21360, 52039, 21279, 52060, 52122, 21216, 40732,\n",
       "         40712, 52189, 52220, 21118, 40586, 52292, 21092, 35725, 21050,\n",
       "         51950, 51926, 40832, 21902, 21839, 51603, 21810, 51606, 21763,\n",
       "         51650, 21685, 51800, 21657, 21644, 21615, 40774, 51872, 51938,\n",
       "         40584, 21033, 21008, 20363, 36372, 20335, 52702, 52736, 40343,\n",
       "         40294, 20254, 36452, 52793, 20237, 52800, 20172, 52956, 36479,\n",
       "         36747, 20459, 36281, 20502, 52447, 35926, 52515, 40485, 20889,\n",
       "         35979, 35982, 19958, 20809, 20730, 52602, 36098, 36215, 52652,\n",
       "         20516, 20503, 20782, 53751, 54268, 39779, 55979, 56088, 56123,\n",
       "         15729, 56159, 56233, 15579, 56263, 39159, 56295, 56336, 56362,\n",
       "         39144, 37760, 15397, 15390, 56460, 39172, 39054, 55802, 15934,\n",
       "         55463, 55555, 16206, 16198, 16197, 16160, 16133, 16131, 37555,\n",
       "         16069, 39227, 55590, 16018, 37613, 15975, 55679, 39178, 37670,\n",
       "         55442, 37917, 37983, 38403, 38405, 14873, 14828, 38548, 38799,\n",
       "         56837, 56860, 14759, 56922, 38745, 56938, 14601, 38733, 38669,\n",
       "         14557, 57097, 38345, 37934, 38253, 15025, 39045, 15351, 56480,\n",
       "         15312, 15304, 15301, 56523, 56527, 38071, 38123, 15200, 38132,\n",
       "         15180, 15102, 15039, 15030, 15027, 38230, 18839, 39234, 55290,\n",
       "         18333, 54220, 18207, 18200, 18193, 54278, 54279, 18165, 18135,\n",
       "         54344, 39440, 18075, 54393, 54432, 17967, 17935, 17895, 18345,\n",
       "         17867, 39547, 39548, 18764, 53869, 36781, 36826, 36852, 36860,\n",
       "         18667, 39656, 54012, 18601, 18576, 18491, 54149, 18473, 18439,\n",
       "         39573, 37007, 54196, 39275, 17813, 37209, 54994, 54995, 39419,\n",
       "         37346, 16641, 16637, 16635, 16600, 55064, 55070, 16521, 16500,\n",
       "         37484, 37502, 39310, 16430, 55271, 16710, 37177, 16764, 54834,\n",
       "         17765, 37238, 54504, 37259, 37280, 17652, 17630, 17529, 17474,\n",
       "         54680, 17393, 17361, 37318, 17026, 54825, 54830, 16941, 16821,\n",
       "         51460, 23021, 51323, 46686, 27906, 32779, 46777, 27884, 27869,\n",
       "         42713, 46672, 42633, 32918, 42546, 27795, 27773, 46898, 27761,\n",
       "         27744, 46840, 28168, 28175, 28204, 42796, 28641, 28533, 32658,\n",
       "         46364, 28514, 46419, 42780, 46440, 32742, 46534, 46592, 28362,\n",
       "         28339, 42721, 28262, 32765, 27687, 27671, 46944, 27623, 33351,\n",
       "         42195, 26970, 33385, 47667, 26907, 42180, 33430, 42152, 33508,\n",
       "         47753, 26852, 42145, 47769, 26712, 26711, 33622, 47517, 46136,\n",
       "         33329, 27031, 42482, 27570, 33005, 33038, 33106, 27482, 27437,\n",
       "         27273, 47230, 33202, 47234, 27233, 47319, 42310, 47401, 27074,\n",
       "         47477, 42307, 26687, 42835, 28787, 31667, 31695, 31720, 30496,\n",
       "         43686, 44888, 44904, 30629, 30339, 43651, 30328, 31885, 31896,\n",
       "         30258, 45068, 45109, 43677, 31663, 44515, 30690, 43837, 31275,\n",
       "         43876, 43920, 31206, 43938, 43949, 31124, 43755, 31542, 44140,\n",
       "         31552, 30942, 44271, 31619, 44368, 44460, 45121, 43559, 31951,\n",
       "         43507, 29275, 29236, 29215, 45867, 32467, 32491, 42997, 29151,\n",
       "         42983, 45912, 32568, 29118, 32580, 28951, 42855, 46044, 46104,\n",
       "         45844, 28757, 45829, 29403, 29839, 29832, 43331, 29716, 43298,\n",
       "         29611, 29604, 32128, 43279, 43209, 32300, 29460, 43093, 32381,\n",
       "         29438, 45748, 32383, 45821, 40841, 26648, 33672, 41286, 41283,\n",
       "         23903, 23712, 23691, 49967, 49991, 23953, 49998, 50032, 50101,\n",
       "         41139, 50211, 41119, 23263, 50224, 23496, 34735, 41341, 23969,\n",
       "         24385, 24359, 24336, 34591, 24256, 49589, 24197, 24138, 49637,\n",
       "         34609, 24095, 34660, 24059, 49812, 23995, 34677, 23984, 23240,\n",
       "         23206, 50339, 50362, 51019, 22678, 22646, 22633, 51036, 35266,\n",
       "         22583, 22524, 51106, 35273, 22449, 22400, 22283, 40905, 51291,\n",
       "         22167, 51310, 50971, 24416, 40924, 35201, 23153, 23072, 50529,\n",
       "         35087, 50538, 40993, 40949, 50598, 22996, 22959, 22957, 50690,\n",
       "         22933, 50712, 35179, 22898, 22889, 50827, 57106, 49441, 24510,\n",
       "         26111, 26108, 41930, 33879, 26019, 41926, 25993, 26112, 33952,\n",
       "         48391, 25928, 48396, 41904, 41868, 34076, 25835, 33965, 41987,\n",
       "         26168], dtype=int64),\n",
       "  'feature_absent_idx': array([39735, 13564, 13565, 13566, 13568, 57924, 13571, 57922, 57919,\n",
       "         13577, 29640, 13579, 13582, 29635, 57927, 57911, 57907, 46802,\n",
       "         57901, 57900, 57899, 13595, 57898, 29628, 46804, 29624, 29622,\n",
       "         13606, 13608, 57908, 57887, 46787, 57929, 46759, 29683, 13507,\n",
       "         46769, 13511, 57960, 13513, 29675, 13519, 13520, 57955, 13524,\n",
       "         57953, 13557, 29666, 29661, 46783, 13536, 46784, 29658, 29656,\n",
       "         13541, 57940, 57938, 57937, 57933, 29654, 13551, 13532, 13498,\n",
       "         46812, 13615, 57850, 13675, 57846, 29558, 57840, 46851, 29552,\n",
       "         13688, 13689, 57835, 46852, 13692, 57825, 13672, 29549, 13696,\n",
       "         29548, 13698, 29547, 13701, 29544, 29543, 13705, 46860, 46862,\n",
       "         57811, 46863, 57807, 57821, 29615, 13671, 29569, 57885, 46815,\n",
       "         46816, 13620, 29608, 29605, 13626, 29602, 29601, 13631, 57876,\n",
       "         46818, 29597, 46844, 13637, 57867, 57864, 57860, 13647, 46832,\n",
       "         29580, 13654, 57857, 57856, 13659, 29574, 29572, 46835, 13638,\n",
       "         29692, 29693, 13495, 13328, 13329, 13333, 13338, 46703, 29788,\n",
       "         13344, 13345, 13347, 29782, 46712, 58072, 29776, 29799, 13362,\n",
       "         13365, 29771, 58060, 29765, 58057, 58052, 29758, 58049, 58046,\n",
       "         29757, 29754, 58039, 29751, 13364, 58037, 58090, 13322, 29834,\n",
       "         29831, 29830, 13280, 58122, 46671, 58118, 58112, 13288, 13290,\n",
       "         29825, 13292, 13293, 58092, 13295, 58110, 13301, 29817, 58106,\n",
       "         13307, 29815, 29814, 46679, 13311, 29811, 13317, 29808, 46688,\n",
       "         29822, 58036, 58034, 29750, 46747, 13454, 57991, 57990, 57988,\n",
       "         29709, 13463, 29708, 13466, 13467, 29705, 46749, 57978, 13448,\n",
       "         57977, 13476, 29701, 57975, 57974, 29700, 57973, 13485, 46755,\n",
       "         57972, 57971, 29696, 57968, 13494, 29703, 29717, 13446, 57998,\n",
       "         58032, 13399, 29745, 58030, 58029, 46729, 13405, 46730, 58021,\n",
       "         13410, 46731, 58017, 13415, 29735, 46735, 29731, 13422, 13423,\n",
       "         13425, 13426, 13429, 29727, 29726, 58006, 46737, 13435, 58000,\n",
       "         13441, 29720, 57801, 46670, 29532, 13718, 57596, 57594, 57591,\n",
       "         13986, 46986, 13988, 29335, 29334, 29329, 57579, 47002, 29326,\n",
       "         57578, 29345, 47004, 29317, 57571, 57570, 57568, 57567, 14021,\n",
       "         57566, 29308, 29306, 14026, 29305, 14028, 29304, 29320, 29303,\n",
       "         57599, 13976, 29372, 13936, 13937, 29368, 13941, 46962, 57629,\n",
       "         57628, 57626, 13950, 46964, 57611, 57609, 29346, 13958, 46976,\n",
       "         13961, 57605, 13964, 29353, 29352, 29350, 29349, 57601, 46977,\n",
       "         13973, 13974, 13975, 29357, 13933, 14033, 14035, 47049, 57511,\n",
       "         14110, 14111, 29239, 14113, 57502, 57501, 47056, 57493, 29229,\n",
       "         14127, 29226, 57513, 47061, 47064, 14134, 14135, 29219, 47066,\n",
       "         14143, 29214, 14146, 29213, 47070, 57480, 47072, 47073, 14131,\n",
       "         14034, 14102, 47044, 47013, 47016, 57550, 29287, 29284, 14054,\n",
       "         14056, 57544, 14059, 47025, 14062, 47028, 47030, 14099, 14073,\n",
       "         14079, 47036, 29254, 57526, 14085, 57525, 57524, 29252, 14091,\n",
       "         47039, 57518, 29249, 57516, 14078, 46953, 57641, 57642, 13774,\n",
       "         57750, 13776, 13778, 29483, 29482, 29481, 46896, 57745, 13788,\n",
       "         46899, 57741, 13791, 13773, 13794, 13796, 57736, 13799, 13801,\n",
       "         57735, 13804, 46905, 57731, 29470, 13808, 57730, 46906, 46908,\n",
       "         13795, 13815, 13772, 29490, 13719, 29529, 57795, 13725, 29526,\n",
       "         29525, 46871, 13729, 29522, 13731, 29521, 46872, 29516, 57753,\n",
       "         57782, 46882, 29504, 57772, 46883, 57770, 57768, 46884, 46886,\n",
       "         57766, 29495, 46890, 57762, 13767, 29508, 46909, 29465, 57725,\n",
       "         29410, 57676, 29408, 29406, 57670, 57667, 57666, 57665, 46938,\n",
       "         57662, 13900, 13901, 29393, 29413, 29392, 57656, 13908, 29389,\n",
       "         29388, 29387, 57650, 29383, 29382, 13920, 13921, 29380, 29377,\n",
       "         57643, 46943, 29414, 46932, 13872, 57723, 29462, 29461, 13823,\n",
       "         13825, 57718, 13829, 57717, 57715, 29453, 29444, 13840, 46919,\n",
       "         57699, 29436, 29433, 29432, 29430, 57688, 46924, 29424, 29423,\n",
       "         57683, 13864, 29422, 13867, 13868, 13869, 46930, 57796, 29205,\n",
       "         13274, 58130, 46389, 46390, 12675, 12676, 30257, 46393, 30255,\n",
       "         58573, 58572, 58571, 46399, 30248, 12693, 30269, 30247, 12696,\n",
       "         58559, 46402, 46406, 30241, 58553, 30236, 12707, 12710, 12711,\n",
       "         58548, 12714, 30232, 30246, 12717, 12667, 12664, 58631, 30325,\n",
       "         46349, 58628, 46350, 46353, 30312, 58621, 30311, 30306, 46361,\n",
       "         30300, 12633, 46383, 12634, 58615, 30292, 12644, 46372, 46374,\n",
       "         58601, 12653, 46377, 30276, 46382, 12661, 30272, 12663, 30297,\n",
       "         58632, 12721, 12723, 12777, 58506, 30184, 58502, 12782, 46434,\n",
       "         58496, 30180, 30178, 30177, 46439, 58491, 58489, 30185, 58488,\n",
       "         46442, 12799, 30168, 12805, 12807, 46446, 12811, 12812, 12813,\n",
       "         46447, 30157, 58476, 46449, 30170, 46417, 30188, 46428, 30224,\n",
       "         30222, 30221, 58538, 58537, 58536, 30217, 30216, 58526, 12739,\n",
       "         30213, 30212, 12742, 12773, 30209, 58519, 30203, 30200, 58513,\n",
       "         12762, 12763, 46426, 30191, 46427, 12768, 12769, 12770, 12771,\n",
       "         30208, 46344, 58635, 46343, 58741, 58740, 58739, 46274, 12446,\n",
       "         12447, 12448, 30446, 12452, 12454, 30442, 12459, 12460, 12431,\n",
       "         30438, 46284, 12468, 30429, 30428, 58718, 58714, 58713, 46287,\n",
       "         12484, 58712, 30420, 12490, 12491, 30436, 12494, 12428, 58746,\n",
       "         12363, 30506, 12365, 58776, 12367, 12368, 46241, 12372, 12374,\n",
       "         30499, 58770, 58769, 30489, 58744, 30488, 12391, 30483, 46258,\n",
       "         12404, 58754, 12411, 12412, 46268, 12418, 46271, 30460, 30459,\n",
       "         58747, 12390, 12495, 46294, 58708, 30371, 12557, 30367, 12562,\n",
       "         58666, 30366, 12568, 30358, 58657, 12574, 30352, 46334, 12581,\n",
       "         30373, 12583, 30346, 58643, 30345, 30344, 30343, 12592, 46341,\n",
       "         12595, 12596, 12597, 12598, 46342, 30334, 12586, 30375, 12550,\n",
       "         58671, 30414, 46299, 12506, 30404, 12510, 58697, 12512, 30403,\n",
       "         46304, 58694, 46305, 30398, 58687, 58684, 12527, 58680, 12530,\n",
       "         46312, 30389, 46314, 12534, 30387, 30385, 30383, 46316, 46317,\n",
       "         12544, 12546, 58672, 58465, 13273, 12824, 12829, 13103, 46573,\n",
       "         13106, 29957, 13108, 29956, 58246, 13112, 58243, 58242, 46575,\n",
       "         29950, 58240, 13101, 58239, 58236, 29943, 46582, 46588, 46589,\n",
       "         29929, 46591, 58221, 13146, 13148, 13149, 13151, 58215, 58237,\n",
       "         13154, 46572, 13098, 58292, 46546, 30007, 30005, 58286, 30004,\n",
       "         13052, 58285, 29997, 58283, 58277, 58274, 13065, 58254, 46558,\n",
       "         29987, 58267, 29986, 13079, 29979, 13081, 46563, 13084, 46564,\n",
       "         29971, 29969, 13095, 13096, 29988, 13040, 13160, 46602, 13214,\n",
       "         29875, 58179, 13217, 58178, 13219, 13221, 29870, 29867, 46647,\n",
       "         13233, 58163, 29857, 29876, 29856, 13243, 29851, 13247, 58152,\n",
       "         13249, 58151, 29849, 13255, 29845, 13259, 13269, 58132, 13271,\n",
       "         58158, 13161, 29879, 29880, 29920, 46603, 58208, 13167, 58207,\n",
       "         29915, 13173, 13176, 46609, 58203, 29907, 13183, 58200, 13209,\n",
       "         29903, 58197, 13190, 58195, 13193, 29899, 29891, 46632, 13201,\n",
       "         58191, 29887, 29883, 29882, 46638, 46617, 13037, 58294, 46542,\n",
       "         46475, 12880, 58416, 58415, 30117, 58413, 30116, 58411, 12892,\n",
       "         12894, 46480, 12898, 12901, 12878, 30103, 30097, 46486, 46487,\n",
       "         46488, 12915, 58389, 58388, 46489, 58385, 46490, 58380, 30087,\n",
       "         30086, 46482, 58373, 12877, 58428, 46458, 30147, 58460, 12835,\n",
       "         30145, 30144, 30143, 30141, 46462, 58450, 30133, 58444, 12851,\n",
       "         30121, 12852, 12854, 58442, 58439, 12858, 58438, 12862, 30130,\n",
       "         12865, 30126, 46472, 58434, 46473, 58429, 58443, 46493, 12930,\n",
       "         46494, 12987, 12989, 30044, 46530, 58333, 30040, 30036, 13002,\n",
       "         13003, 30035, 30033, 46536, 58318, 58337, 58316, 58311, 13016,\n",
       "         46538, 58310, 13020, 30024, 30023, 30020, 58305, 13028, 13029,\n",
       "         58301, 58297, 13014, 30052, 12983, 30054, 46495, 30071, 58367,\n",
       "         12943], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_duration': {'feature_present_idx': array([    3, 43271, 41957, 40883,  3326,  3337, 36115, 35631, 33896,\n",
       "          3927, 32237, 32233, 47429, 28101, 26733, 24640, 23031, 22040,\n",
       "         20432, 18132, 17823, 17129, 13559, 12935, 11903, 27237, 47652,\n",
       "         39863, 59244, 60400, 47716, 60867, 58003, 63371, 53681, 52834,\n",
       "         64121, 65754, 60190, 50916, 66603, 49568, 14893, 10016, 11263,\n",
       "         22814, 61625, 62477, 19267, 13198, 65991, 13114, 63867, 25590,\n",
       "         15762, 12376, 17690, 49161, 27221, 46631, 45491, 49208, 43037,\n",
       "         42706, 49709, 51104, 40730,  7716, 39317, 38381, 37568, 37119,\n",
       "         55774, 57797, 58748, 31163, 29835, 59046, 26768,  7541, 32537,\n",
       "          4673,   137,  2981,  4913,  1820, 50052, 49892, 49817, 13821,\n",
       "         20306, 14129, 46601, 49106, 48141, 14808, 47585, 47213, 19826,\n",
       "         34531, 13539, 49449, 51680, 33145, 56664, 12507, 31516, 31643,\n",
       "         39483, 55375, 32528, 53957, 53915, 13275, 13281, 13353, 13367,\n",
       "         52550, 33133, 19724, 45757, 15381, 30228, 41678, 41422, 36740,\n",
       "         41078, 40850, 38467, 40739, 40542, 40230, 40191, 38584, 40071,\n",
       "         39839, 39767, 18385,  3135, 35084, 17071, 42874, 15604, 45537,\n",
       "         15739, 45047, 44728, 44520, 44327, 44195, 35854, 35949, 42995,\n",
       "         16503, 16780, 42941, 16969,  3031, 12073, 32327, 57331,   619,\n",
       "         26105, 26620,  8151, 26779, 26901,  8754, 62762, 62636, 23252,\n",
       "         23192, 61530,  9023, 56962, 61462, 61453,  9074, 64132, 26021,\n",
       "          7796,  7783, 24833, 66799, 24985, 25466,  6394, 65933,  6569,\n",
       "         23971, 27163, 25759,  7165,  7243,  7316, 65376, 65097, 64961,\n",
       "         23799,  5317,  7006, 61124, 18208, 29366, 58406, 22452, 11284,\n",
       "         59533, 29160,  1265, 27949, 22367, 58461, 60433, 29513, 11174,\n",
       "          9181,  9843, 60832,  9387,  1022, 29704, 60629,  4348, 30793,\n",
       "         32368, 24848, 29355, 31972, 39443, 31116, 25664, 31709, 38480,\n",
       "         31364, 37965, 34317, 28609, 28750, 33884, 27315, 34414, 33866,\n",
       "         27645, 35391, 33474, 33341, 33275, 32874, 35566, 26892, 26828,\n",
       "         27954, 26338, 28486, 36604, 34156, 28720, 33011, 35629, 34489,\n",
       "          5692, 39631, 61038, 60943, 60268, 60127, 59919, 59375,  1298,\n",
       "         61134, 58730, 58044, 57910,  1616, 57787, 57759, 57702, 56880,\n",
       "         58238, 56840, 61840, 62943, 67142, 66902, 66687, 66579, 66320,\n",
       "           330, 65694, 62474, 65389, 64189, 64104, 64003,   716, 63425,\n",
       "         63387, 62954, 64855, 56256, 56143,  1626, 24750, 46232, 45715,\n",
       "         45591, 45419, 45242, 44134, 46707, 43891, 42866, 41359, 41264,\n",
       "         40753,  3384, 40072,  3490, 43202, 46958, 47037, 48422, 55773,\n",
       "         55740, 55568, 55404, 54498, 54066, 53802, 53188, 52383, 52304,\n",
       "         51194,  2005, 50544, 49808, 49749,  2103, 48451, 39464, 24707,\n",
       "          3797, 67331, 17871,  4742, 17806, 17797, 19821,  8854, 22414,\n",
       "         13376, 22447, 13379, 13504, 22538, 22665, 17044,  8036, 16990,\n",
       "         16262,  8914,  9028, 18044,  4675, 20082, 20220, 19317, 20790,\n",
       "         20866, 20872, 10946, 12349,  7894, 21087, 12691, 12844, 21378,\n",
       "          5303, 12918,  5008,  9656, 21673, 10793,  7800, 15187, 24322,\n",
       "         13805, 23530, 15616, 24476, 24143, 13922, 14030, 23999,  6019,\n",
       "         16225,  7437, 23269, 16256,  6170, 24127, 15249, 24268, 12466,\n",
       "          2503,  3578, 56217, 43096, 19006, 12801, 55677, 55662, 55647,\n",
       "          2848, 18999, 55597, 37957, 37041, 36602, 36841, 34717, 11747,\n",
       "         34920, 35025, 47009, 57543, 57495, 15241, 11944, 56379, 19448,\n",
       "         57154, 46015,  3671, 57003, 56990, 36434, 45423, 45942, 56519,\n",
       "         57183, 12863, 55123, 55452, 52199, 52053, 16007, 17223, 17192,\n",
       "         51517, 51490, 41688, 41767, 13550, 13576, 42661, 13594, 16992,\n",
       "         42873, 16920, 13790, 43657, 50003, 49375, 44516, 44608, 44709,\n",
       "         55416, 39413,  4824, 18460, 14874, 54391, 45165, 18024, 45081,\n",
       "         38676, 14747, 48607, 54320, 54317, 48846, 53889, 49054,  4758,\n",
       "         53616, 53540, 14451, 17316, 11665,  2810, 62299, 62206,  6543,\n",
       "          6348, 29679, 62191, 25905, 29884, 61864, 30295, 30347,  9053,\n",
       "         23808,  9620, 64514, 31160,  4126, 23920, 21567, 29469,  9977,\n",
       "          6696, 29390, 27518,  5369, 27928, 65151,   867,  4244, 65374,\n",
       "         28185, 26740, 63234, 65424, 28647, 28670,  8542,  8767,  8773,\n",
       "         26542,  6839, 28961, 23580, 31472, 64102, 60527, 10812,  5299,\n",
       "         34201, 59263, 24917, 32951,  6255, 20877, 33012,  4464,  1330,\n",
       "          5874, 20806, 11033, 24896, 24895,  1470, 58710, 24976, 58541,\n",
       "         58131, 31549,  1174, 66718, 21361, 31999, 10434, 10572, 67205,\n",
       "         60059, 59967,  6161, 58081, 21142, 59947, 10754, 32279, 46820,\n",
       "         64691, 14896,  7490, 64868, 14359, 67092,  2289, 49464, 65643,\n",
       "         49112, 47040,  4830, 66830, 47456, 66393, 48326, 66492, 48008,\n",
       "          6964, 47776, 11480, 63919, 54948,  9764, 60719, 55505, 10044,\n",
       "         55945, 56260, 59503, 59373, 56627,  5180, 12332, 58841, 57138,\n",
       "         57249, 11198, 57527, 58353, 11328,  9157, 61590,  8905, 13208,\n",
       "         63671, 50480, 63408,  8457,  4832, 51223, 63172, 51395, 62712,\n",
       "         50212, 51781, 52214, 52234, 13385, 11348,  1669, 53342,  1640,\n",
       "         53844, 62095, 62614,   871, 24543, 15309, 21464, 17354, 21563,\n",
       "         31273, 40835, 17295, 30395, 30242, 41131, 21974, 36877, 17251,\n",
       "         41442, 41535, 17164,  4789, 42308, 29932, 42479, 31729, 21240,\n",
       "         32517, 32715, 36960,  3594, 19099, 37753, 38181, 46612, 19465,\n",
       "         38599, 35166, 42732, 34775, 18189, 34438, 19850, 34042, 33539,\n",
       "         33422, 21007, 32740, 17663,  3497, 29583, 41155, 15905, 26736,\n",
       "         29337, 27024, 15831, 26095,  4273, 45563, 15343, 25559, 44682,\n",
       "         15786, 45670, 22935, 27916,  4294,  2912, 44487, 22772, 22743,\n",
       "         46583,  4580, 24817, 36158, 20045, 58171, 26409, 23684, 56572,\n",
       "           183, 24420, 56663, 19269,  5275, 57654, 56890, 66953, 19611,\n",
       "         57473,  6252, 35875, 24969, 11951,  1590, 22312, 59353,  4629,\n",
       "          4201, 28825, 28799,  8672, 61798, 28793, 62972, 62979, 61781,\n",
       "         63835, 64005,  9540, 30956, 27513, 21653, 31397, 31502, 27443,\n",
       "          4491, 64263, 64271,  3997, 23075, 23450, 65332, 59132, 33446,\n",
       "          3824, 36806,  5417, 56277, 54876, 54813, 13067,  4973, 49414,\n",
       "         17807, 14289, 13210, 40114, 14174, 40210, 49793, 44291, 40225,\n",
       "         16049, 16297, 50373, 50981, 17294, 56445, 53015, 17311,  3240,\n",
       "         39289, 48710, 39585, 40785, 48582, 45647, 55807, 19003, 55639,\n",
       "         38577, 46429, 47267, 55477, 12679, 15011, 46842, 39164, 48183,\n",
       "         24200,   908, 51716, 43853, 42322, 30163, 25446, 30783, 28960,\n",
       "         61783,  4252,  2487, 64174, 45015, 15845, 64859, 31100,  7940,\n",
       "         49175,  8034, 27630,  7318, 14762, 65475, 23554, 15929, 45254,\n",
       "         25899, 65672, 30250, 15118, 19436, 57311, 13261, 53887, 33119,\n",
       "         57414, 53472, 58686, 38993, 39230, 34716, 39947, 52403, 34619,\n",
       "         19708, 38151,  3501, 19775, 60201, 59818,  4112, 13314, 40664,\n",
       "         53171, 37717, 38046, 56845, 36706, 36262, 32473, 32139, 46093,\n",
       "         37540, 36766, 23788, 48312, 18515, 57382, 35855, 34564, 57041,\n",
       "         45263, 26922,  4278,  2429, 28821, 40611, 32822, 62554, 13678,\n",
       "         22049, 49830,  8282, 42773,  2391, 20288, 52209, 52572, 52454,\n",
       "         32656, 25068,  4613, 26291, 25542, 44970, 47894,  7968, 39992,\n",
       "         44498, 58255, 27941, 52232, 11019, 22847, 23423, 59622, 32378,\n",
       "         51811, 44386,  9117, 45013,  2437, 45074], dtype=int64),\n",
       "  'feature_absent_idx': array([24363, 60209, 60210, 51180, 18678, 42109, 42110, 18670, 18668,\n",
       "         42112, 51177, 18665, 18661, 18660, 18656, 60228, 18691, 18650,\n",
       "         51183, 42102, 60180, 60183, 18733, 18732, 18727, 60188, 60189,\n",
       "         60191, 18718, 18715, 18714, 18712, 18707, 18700, 60206, 18694,\n",
       "         60178, 18648, 18640, 18592, 60256, 18589, 18584, 60258, 18578,\n",
       "         60260, 60270, 60274, 18551, 18550, 60275, 42153, 60280, 18542,\n",
       "         51167, 60235, 42137, 60253, 60238, 42121, 60243, 18630, 42123,\n",
       "         18624, 18623, 18622, 42126, 18619, 18617, 18616, 60248, 18610,\n",
       "         60249, 18596, 18536, 18750, 18761, 18898, 60113, 18894, 42031,\n",
       "         18889, 18887, 42037, 42039, 18880, 60124, 18867, 18864, 60128,\n",
       "         60129, 18860, 42024, 60130, 18911, 60107, 18953, 18952, 18951,\n",
       "         42011, 18948, 18947, 18946, 18942, 18938, 60100, 42014, 42015,\n",
       "         42016, 18919, 60104, 18912, 42091, 18856, 42050, 18808, 51195,\n",
       "         18796, 18794, 60160, 18791, 42078, 60164, 18783, 18778, 42081,\n",
       "         60168, 51190, 18773, 18765, 60154, 18855, 42070, 42067, 18850,\n",
       "         18847, 42053, 18841, 42054, 60138, 60139, 60140, 18832, 60143,\n",
       "         18830, 18826, 42062, 51199, 42066, 42068, 18535, 18531, 18529,\n",
       "         42276, 18223, 18218, 60401, 18213, 51112, 18204, 18202, 42280,\n",
       "         18195, 60410, 18185, 18180, 18176, 51108, 18226, 42293, 42274,\n",
       "         60394, 42256, 42257, 18267, 60382, 42269, 18255, 18254, 18253,\n",
       "         60386, 60387, 18247, 60390, 18239, 18237, 18236, 18232, 60374,\n",
       "         60420, 60421, 18119, 18115, 18112, 18110, 18109, 18108, 18107,\n",
       "         18105, 42318, 18096, 51091, 18090, 42326, 18088, 18086, 60440,\n",
       "         42295, 42313, 18127, 18160, 18156, 18152, 18151, 18149, 51101,\n",
       "         60428, 60430, 18143, 42304, 60435, 18137, 60436, 51098, 60438,\n",
       "         18126, 18283, 60373, 18294, 18469, 42182, 42184, 18451, 42187,\n",
       "         42194, 51151, 18426, 51148, 18423, 18422, 18420, 18412, 42204,\n",
       "         60329, 60305, 60332, 42177, 60300, 42160, 18521, 18520, 18518,\n",
       "         51159, 18516, 60287, 18511, 18501, 42168, 18494, 60292, 42171,\n",
       "         18487, 42174, 42176, 18402, 18400, 42206, 18343, 51136, 51135,\n",
       "         18337, 18336, 18334, 18332, 18330, 51127, 18324, 18315, 18304,\n",
       "         60367, 42249, 42252, 18344, 42226, 42223, 18355, 18392, 18391,\n",
       "         42210, 18389, 18383, 60338, 42215, 18954, 18376, 18370, 18369,\n",
       "         60340, 18361, 60342, 60344, 60345, 18371, 42009, 42008, 18960,\n",
       "         19502, 51300, 51299, 41832, 59899, 59901, 59903, 59904, 51295,\n",
       "         19479, 41843, 19477, 41844, 19475, 19466, 41828, 41847, 19505,\n",
       "         19507, 19552, 19550, 19549, 41818, 51303, 19541, 19540, 19539,\n",
       "         19538, 19537, 19523, 19521, 59892, 19512, 19511, 19506, 41817,\n",
       "         59909, 41848, 19419, 19410, 19405, 19402, 19400, 19396, 59930,\n",
       "         59933, 59934, 19386, 19385, 59935, 19379, 59936, 41867, 19420,\n",
       "         19459, 19422, 59922, 59911, 19454, 41850, 59914, 59915, 41851,\n",
       "         19445, 41853, 19439, 59917, 59920, 59921, 19431, 19430, 41856,\n",
       "         19423, 19555, 19560, 19562, 19696, 19695, 19691, 19687, 59837,\n",
       "         19677, 41772, 41773, 59840, 59843, 19663, 19661, 19660, 59845,\n",
       "         59846, 19697, 41775, 41762, 19706, 59817, 19745, 41747, 19739,\n",
       "         59820, 59821, 19726, 19725, 59825, 19719, 19717, 59827, 19714,\n",
       "         59828, 19709, 19701, 19654, 19651, 41776, 41802, 19590, 19584,\n",
       "         59877, 41807, 19581, 19578, 19577, 19576, 19570, 59883, 19566,\n",
       "         19565, 19564, 59885, 51317, 59870, 19602, 41798, 59852, 41777,\n",
       "         19646, 59853, 51337, 51333, 19640, 19369, 19639, 19630, 19621,\n",
       "         59864, 59866, 19615, 59868, 19606, 19636, 18084, 51286, 59942,\n",
       "         19119, 51248, 60038, 60039, 60041, 19103, 41962, 19088, 19087,\n",
       "         19086, 19085, 19084, 19083, 19080, 19079, 19123, 60047, 19124,\n",
       "         41949, 60015, 41929, 19173, 60018, 41932, 60020, 51260, 41935,\n",
       "         60024, 19159, 60028, 19149, 60031, 19135, 19132, 19127, 51262,\n",
       "         19074, 60053, 60083, 41992, 18993, 18992, 18989, 41994, 41996,\n",
       "         18980, 18979, 18977, 18973, 42001, 60093, 42005, 42006, 18998,\n",
       "         41970, 60082, 41989, 41971, 60056, 41973, 19052, 19051, 41976,\n",
       "         19045, 60065, 19040, 19038, 19036, 19031, 51234, 19021, 60073,\n",
       "         19001, 19181, 19184, 60013, 59971, 41887, 19310, 19297, 19294,\n",
       "         19293, 19290, 19288, 19287, 51275, 51274, 41896, 41897, 41898,\n",
       "         19273, 59964, 19271, 59963, 19319, 19355, 59943, 19350, 59944,\n",
       "         59945, 59950, 19339, 59953, 51280, 19335, 59956, 41884, 59958,\n",
       "         59959, 59960, 19318, 59984, 19266, 59986, 41916, 60006, 19211,\n",
       "         19209, 41919, 19207, 19201, 19199, 41922, 19197, 19194, 19192,\n",
       "         51264, 19189, 19187, 19216, 41914, 19221, 41913, 41899, 59987,\n",
       "         19257, 19256, 59992, 19251, 59993, 19362, 19248, 59996, 51269,\n",
       "         41908, 19234, 51268, 19228, 51267, 59995, 19748, 60453, 51086,\n",
       "         16981, 50949, 42707, 16973, 60837, 16970, 50943, 42715, 60842,\n",
       "         16955, 42717, 16943, 42723, 50938, 42726, 42699, 16937, 16986,\n",
       "         16989, 17037, 42682, 42684, 17027, 60820, 42686, 17019, 42687,\n",
       "         60822, 42690, 17006, 17001, 16996, 50953, 16991, 42696, 60817,\n",
       "         16935, 50934, 42758, 16874, 16873, 42759, 16871, 60881, 16867,\n",
       "         42760, 42761, 50923, 42764, 16856, 16855, 42765, 16849, 16876,\n",
       "         60852, 60880, 60877, 60856, 42735, 16919, 60859, 60864, 16905,\n",
       "         16901, 42745, 16898, 16897, 50930, 16893, 60871, 60872, 16889,\n",
       "         60878, 42766, 60816, 17050, 17179, 17177, 50972, 17173, 17169,\n",
       "         17165, 17163, 17162, 17161, 17159, 17156, 17154, 60772, 17152,\n",
       "         17148, 17184, 17146, 42632, 50976, 60754, 17228, 17227, 50980,\n",
       "         60756, 42618, 17216, 17215, 17209, 17208, 50978, 42624, 17204,\n",
       "         60764, 17201, 42631, 42679, 42644, 42646, 42666, 17090, 60803,\n",
       "         50961, 17080, 17077, 60806, 60807, 17072, 17070, 42674, 60812,\n",
       "         17056, 17055, 17053, 50962, 50966, 17105, 17111, 60777, 17139,\n",
       "         60781, 17132, 60786, 60788, 42652, 17125, 42653, 42654, 17118,\n",
       "         42656, 17116, 17113, 42658, 42659, 16847, 42767, 16844, 16626,\n",
       "         42847, 60965, 42850, 50896, 60968, 42853, 16607, 42857, 42859,\n",
       "         42861, 50892, 42867, 16588, 16586, 16627, 16585, 60961, 60953,\n",
       "         60937, 60939, 16668, 42824, 16661, 42827, 42828, 42829, 42831,\n",
       "         16654, 50900, 16644, 42840, 16640, 50898, 42843, 16675, 42869,\n",
       "         16578, 16543, 42890, 16539, 42891, 16537, 50883, 16534, 16533,\n",
       "         16532, 50882, 42897, 50877, 16522, 16517, 50872, 16544, 16579,\n",
       "         60991, 42888, 42871, 16575, 42875, 42877, 60982, 42880, 16566,\n",
       "         42881, 16564, 42883, 16560, 50887, 42885, 60986, 50885, 16551,\n",
       "         16681, 16685, 42821, 16797, 60899, 16794, 16792, 16788, 16786,\n",
       "         16785, 16782, 16778, 16776, 16775, 50911, 60906, 16771, 16770,\n",
       "         42782, 16766, 16802, 16808, 60888, 16835, 42769, 16830, 42770,\n",
       "         16827, 60891, 16824, 60892, 42776, 60894, 42778, 60895, 16813,\n",
       "         16812, 16807, 16760, 60913, 16755, 60924, 16715, 16712, 16711,\n",
       "         42815, 16709, 50904, 42817, 16702, 16699, 16698, 16697, 42820,\n",
       "         16694, 16692, 50905, 16719, 50906, 16721, 16752, 16750, 42798,\n",
       "         16748, 16747, 42799, 60920, 60753, 16736, 60921, 16732, 42807,\n",
       "         42808, 16725, 50907, 42810, 42804, 60752, 17235, 42612, 42430,\n",
       "         17775, 17774, 17772, 17769, 42437, 42439], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 924\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 924\n",
       "  })},\n",
       " 'contains_example': {'feature_present_idx': array([15765, 46813, 48197, 32016, 49024, 29112, 29038,  7689, 12461,\n",
       "         42515,  5522,  8840, 30309, 54409, 60976, 33752,   400, 24065,\n",
       "         31098,  2792, 64148, 38832, 17219, 15933, 35548, 35669, 29428,\n",
       "         45162, 22327, 38803, 35891, 44800, 42756, 41999, 14175, 41791,\n",
       "         29792, 16814, 45104, 29243, 12126,  8830,   352,   677, 63069,\n",
       "         21468, 61692, 24927, 20691, 58317,  9249, 48842,  8435, 53989,\n",
       "         50219,  6083, 52931,  6375, 54137, 50663,  6809, 26611, 31166,\n",
       "         28420, 24594, 26039, 29759, 24290, 26165,     6, 34778, 65312,\n",
       "         63539, 62349, 61656, 60286, 59614, 57816, 56728, 56112, 34267,\n",
       "         52606, 49531, 47884, 45967, 45917, 41615, 41506, 41269, 40060,\n",
       "         37742, 50132, 23026, 30580, 12793, 14903,  3590,  3553, 13918,\n",
       "         15287,  4784, 16385, 13503, 13389, 13153, 16922, 14314,  4927,\n",
       "         17582,  1493, 14226, 10819, 10662, 12523, 21930,  7946, 21357,\n",
       "         11666, 38755, 52442, 52415,  6405,  4116, 39237, 13621, 56960,\n",
       "         40138, 58327,  5395, 48661,  8078, 52801, 47228, 56685, 56490,\n",
       "         56352, 12873, 45919, 10869, 43320, 43905, 44090, 44113, 40477,\n",
       "         67247, 37461, 50349, 17023, 17351, 17886, 60060, 63193, 27405,\n",
       "         16884,   771, 20565, 25568, 64411, 25058, 20949, 23630, 20379,\n",
       "         29846, 28522, 16762, 14993, 60295, 34057, 33326, 32326, 61447,\n",
       "         32752,  7493, 16284, 30688, 61769,  3422, 52316, 66741,  3823,\n",
       "           528, 65116, 62329,  6318, 54754,  4155,  5970,  1545, 63832,\n",
       "          3133,  5533,  1155, 63526, 62831, 53762, 22628, 49888, 39207,\n",
       "         37765, 37593, 14969, 34320, 32198, 31342, 30818, 66878, 29992,\n",
       "         28400, 27636, 19563, 26583, 25305, 21895, 23863, 40221, 13094,\n",
       "         44178, 48999, 42000, 48390, 13006,  9908, 44712, 11900, 56485,\n",
       "         49442, 52347,  8495, 15527,  6471, 50651, 54792,  7823, 58782,\n",
       "         14044, 66564, 28144, 49401,  7909, 65516, 23519, 61852, 46266,\n",
       "         15127, 22703, 39190, 40131, 59381, 18928, 29057, 43054],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([55813, 37571, 37569, 37567, 37565, 37562, 37559, 13767, 37551,\n",
       "         13772, 13773, 13774, 59519, 13776, 13778, 37545, 64505, 37539,\n",
       "         13788, 13791, 37532, 13794, 13795, 13796, 13799, 37524, 13801,\n",
       "         37523, 37521, 13804, 59515, 37575, 37578, 37584, 37657, 13701,\n",
       "         59499, 59500, 13705, 37646, 64525, 37642, 37640, 37635, 13718,\n",
       "         13719, 37634, 37633, 13808, 37632, 13729, 13731, 37617, 37616,\n",
       "         64521, 59508, 59509, 37610, 37609, 37606, 64518, 64517, 37587,\n",
       "         37585, 13725, 13698, 64497, 13815, 37440, 13872, 37439, 37438,\n",
       "         37432, 37430, 64478, 37427, 64477, 37426, 37425, 37411, 37410,\n",
       "         37409, 37408, 37402, 37398, 59544, 37396, 13900, 13901, 37387,\n",
       "         37386, 13908, 59547, 37363, 13920, 13921, 37360, 37441, 13869,\n",
       "         13868, 13867, 37508, 37504, 64494, 37500, 37499, 13823, 37497,\n",
       "         13825, 59529, 37495, 13829, 37490, 37485, 37482, 37509, 37481,\n",
       "         13840, 64486, 37466, 37464, 37460, 37459, 64482, 59537, 37453,\n",
       "         37452, 64480, 13864, 37447, 37446, 37479, 13696, 37666, 13692,\n",
       "         64566, 37868, 37867, 13541, 37865, 37863, 64562, 37856, 64560,\n",
       "         13551, 37854, 37853, 37850, 59456, 64557, 13557, 37841, 13564,\n",
       "         13565, 13566, 13568, 37837, 13571, 37834, 37829, 37825, 13577,\n",
       "         13579, 37820, 13536, 59454, 13532, 59452, 59444, 13485, 37924,\n",
       "         37921, 37919, 37918, 13494, 13495, 37914, 64576, 13498, 37904,\n",
       "         37901, 59449, 13582, 13507, 13511, 37895, 13513, 37894, 37892,\n",
       "         64570, 37890, 13519, 13520, 37889, 37887, 13524, 37883, 37882,\n",
       "         64572, 59460, 37816, 37810, 59479, 64540, 37729, 64537, 13647,\n",
       "         37726, 37725, 59484, 13654, 37714, 13659, 37707, 37704, 37703,\n",
       "         37736, 37701, 59486, 37696, 13671, 13672, 13675, 64534, 64531,\n",
       "         37684, 64530, 64528, 37677, 37676, 13688, 13689, 37700, 37351,\n",
       "         13638, 37740, 37806, 37804, 37803, 64550, 13595, 64549, 37795,\n",
       "         37794, 64548, 59467, 37789, 13606, 37784, 13608, 13637],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 251\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 251\n",
       "  })},\n",
       " 'contains_extent': {'feature_present_idx': array([33795, 20468, 37855, 18795, 17495, 46942, 52705, 12904, 53903,\n",
       "         10148, 25577,  7207, 65881,  5923, 62788,  3696, 62787, 55134,\n",
       "         30599, 30984, 39234, 40492, 42172, 42458, 43245, 45646, 46828,\n",
       "         62477, 47343, 29330, 61509, 59200, 55822, 47611,   137, 16731,\n",
       "         14730, 19890, 16757, 12747, 16102, 18608, 22898,  2752,  1540,\n",
       "          7019, 48268, 46076, 48336, 14493, 42623, 14850, 42347, 19713,\n",
       "         47681, 36024,  7798, 33366, 20223, 61568, 28457, 19030, 53343,\n",
       "         55764,  7557, 56878, 26516, 15187, 45591, 27214, 27465, 30329,\n",
       "         32236, 21286, 16739, 43367, 34063,  4721, 35918, 49098,  5305,\n",
       "          6964, 24299, 66580, 66665, 59530, 61781, 61302, 57538, 52010,\n",
       "         65447, 41687], dtype=int64),\n",
       "  'feature_absent_idx': array([59444, 57938, 57937, 12212, 57933, 12215, 36093, 57929, 12218,\n",
       "         36092, 57927, 47630, 25508, 57924, 12224, 47634, 57922, 47635,\n",
       "         12230, 25503, 57919, 12234, 12236, 12239, 12240, 12243, 36088,\n",
       "         47641, 25511, 57940, 12207, 25512, 57971, 25543, 57968, 47613,\n",
       "         39515, 39516, 47618, 25536, 57960, 47620, 12178, 47623, 57955,\n",
       "         39528, 12184, 12186, 57953, 39521, 36097, 47626, 25519, 12198,\n",
       "         25517, 25516, 12202, 25514, 47627, 12205, 25526, 57972, 12247,\n",
       "         12251, 34005, 41164, 57876, 47669, 12308, 47671, 25457, 25456,\n",
       "         12313, 12315, 57867, 12318, 57864, 25452, 57860, 57857, 34009,\n",
       "         57856, 47680, 47682, 57850, 12338, 25438, 57846, 47684, 12344,\n",
       "         47687, 47664], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 92\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 92\n",
       "  })},\n",
       " 'contains_frequency': {'feature_present_idx': array([52941, 25425, 46547, 25002, 60926, 47031,  8165, 23959, 23529,\n",
       "          8422, 47476,  8599, 48024, 60664, 22415, 48777, 25534, 14656,\n",
       "          6969, 46192, 43807, 44016, 44107, 44401, 44403, 62187, 27064,\n",
       "         48821, 61889, 26683, 26621,  6228,  6295, 26321, 26191, 45808,\n",
       "         61763, 49944, 59897, 59889, 13060, 17541, 53287, 13178, 53372,\n",
       "         56823, 53374, 17812, 13294, 13505, 56565, 16148, 16094, 16028,\n",
       "         54899, 15531, 13350, 28849, 12791, 57869, 10350, 21280, 20966,\n",
       "         50423, 50705, 19926, 11473, 18477, 19736, 19704, 50903, 51047,\n",
       "         59039, 11884, 12226, 18686, 59162, 28944, 25699, 40092, 35213,\n",
       "         31260, 41447, 35086, 41229, 31782, 38644,  1406, 64739, 32529,\n",
       "          1564, 65008, 40604, 32901, 40405, 33930, 65384, 29021, 33462,\n",
       "         33370, 33166,  2422, 65839, 31133,   863,  2032, 66802, 67022,\n",
       "         38370, 42463, 35805, 43082, 42446, 62794, 30078,   158, 35811,\n",
       "         43166, 30727, 30384, 15461, 50624, 39031, 40065, 15956, 19129,\n",
       "         15017, 33923, 15242, 39102, 39407, 33576, 33571, 15792, 20083,\n",
       "         19922, 20054, 36194, 19985, 19830, 51602, 51192, 38474, 16865,\n",
       "         38359, 53491, 35072, 17272, 35014, 53558, 34901, 17575, 53276,\n",
       "         38263, 50468, 17969, 18123, 37292, 16209, 52367, 34358, 52030,\n",
       "         18491, 51990, 38908, 19015, 38737, 43272, 21029, 25382, 46445,\n",
       "         41217, 41305, 31382, 41356, 46058, 45806, 45767, 26257, 31015,\n",
       "         45523, 30864, 25338, 26764, 45092, 29937, 27087, 44972, 27728,\n",
       "         27777, 27848, 29435, 43990, 43814, 28631, 43736, 28743, 42388,\n",
       "         33253, 25323, 25154, 21053, 50314, 40087, 50295, 50114, 49981,\n",
       "         22029, 48972, 33141, 33105, 22678, 48302, 23019, 25296, 23259,\n",
       "         47484, 23354, 23429, 47426, 32619, 23854, 40694, 24137, 32366,\n",
       "         24625, 46917, 46794, 41125, 32977, 14498, 67221,  7307,  9561,\n",
       "          9718, 60050, 62759, 63137,  4179,  3667, 63872, 63965, 63991,\n",
       "          7335,  3342, 64274, 59098, 11774, 64750, 58352, 12271, 57946,\n",
       "         12423, 65091, 65321,  2589, 62726,  2476, 62637,  5127, 61260,\n",
       "         61445,  7107, 60919,  7972,  8185,  6691, 61623,  8472,  8539,\n",
       "         60799,  6205, 61713, 60688,  6096, 60548,  5877, 62289, 60279,\n",
       "          5635, 62473,  5322,  9277, 60158,  2440, 11334, 66056, 57139,\n",
       "         66298, 13182,  1414, 56817, 13570, 13622, 13129, 65551,  1232,\n",
       "         66394,  1127, 56335, 67040, 56214, 14334, 56558,  1753,  7424,\n",
       "         57394, 66139,  1883, 39467, 65037, 35711, 38217, 35533, 26782,\n",
       "         45245,  5998, 45055, 66776,  5785, 44900, 44781, 44633, 44497,\n",
       "         38524, 66536,  1118, 62380, 66836, 26618, 37978, 37858, 55793,\n",
       "         37321, 36617,  6838, 46145, 37365, 37470, 46133,  6798,  6743,\n",
       "         37531, 36157, 61689, 26442, 45678, 61693, 45455, 45416, 26601,\n",
       "         62416, 32268, 35017,  1814,  3050,  3913, 41587,  3698,  1553,\n",
       "          1595, 40684,  3110, 63996, 30382, 31411, 41312, 66192, 32374,\n",
       "         31648, 64703, 31799,  1756,  3208, 40973,  1730, 40437, 41820,\n",
       "          4482, 27971, 28050,  5217, 39912,  2865,  5126,  5031, 40506,\n",
       "         39710, 40641, 38671,  4828, 28946,  1284, 38739,  2982,  4701,\n",
       "          4644,  4614, 62765, 28856, 34548, 56017,  7446, 57455, 57572,\n",
       "         52936, 52862, 57810, 51664, 12204, 18743, 18792, 11713, 50864,\n",
       "         11663, 19762, 11474, 11443, 20012, 59420, 59644, 59769, 59798,\n",
       "         10829, 20602, 50383, 50360, 50353, 10601, 21001, 12687, 53104,\n",
       "         17887, 17791, 14354, 15044, 15090, 15398, 15399, 55021, 14027,\n",
       "         13970, 15878, 54359, 13797, 56505, 54323, 10582, 13679, 54059,\n",
       "         53870, 13289, 16655, 56859, 16887, 53296, 17282, 17357, 17450,\n",
       "         57225, 17597, 17613, 54150, 21061, 59222, 37000, 22348, 60893,\n",
       "         24149, 48577, 22475, 22573,  8163,  8261, 48430, 22664,  9050,\n",
       "         22863, 60599, 23767, 59882, 23237, 60647, 47309, 47587, 23333,\n",
       "         60889, 22297, 24178, 23538, 49631, 46923,  9403, 10197, 49777,\n",
       "         21570, 21462,  7473, 60103,  7798, 61120, 49072, 37480, 53755,\n",
       "         66942, 61381, 38786, 38893, 47417, 39028, 55543, 45693, 46223,\n",
       "         67112, 54294, 38321, 38212, 54854, 54815, 56498, 66719, 66958,\n",
       "         61459, 60960, 38031, 55139, 61541, 38539, 55419, 47127, 47242,\n",
       "         66674, 59849, 60805, 64409, 50760, 61292, 62594, 48998, 49035,\n",
       "         59624, 49070, 50563, 41495, 49531, 63344, 62706, 63240, 63198,\n",
       "         63162, 43689, 60216, 48654, 51076, 51121, 39482, 39522, 57143,\n",
       "         39693, 39980, 57369, 48259, 62064, 66321, 40329, 57764, 44755,\n",
       "         58091, 48527, 51313, 64957, 58124, 58523, 48323, 45402,    32,\n",
       "         33341,  9936, 21294, 10456, 11200, 11667, 27859,  9774, 11684,\n",
       "         27502, 27466, 27333, 12529, 12638, 26880, 11858, 26859, 29300,\n",
       "         29530, 31579,  7861, 31357, 31323, 31064,  7870, 29431,  7946,\n",
       "         30093, 29591,  8543,  8963,  9235,  9584, 30304,  7690, 12912,\n",
       "         26563, 23434, 16540, 23274, 16751, 16938, 18404, 16158, 22385,\n",
       "         22292, 22281, 18565, 19161, 19528, 20757, 36967, 26570, 23606,\n",
       "         23845, 12922, 13139, 26406, 26068, 26054, 25979, 23806, 25799,\n",
       "         25388, 14039, 24874, 15219, 24687, 24287, 13918,  7435, 29189,\n",
       "         21331, 33526,  4874, 33684,  4257,  1965,  4240,  3750,  3553,\n",
       "          3383,  2332,  2395,  1094, 34217, 35606, 34336,  3266, 31927,\n",
       "         34515, 35537, 34521,  3167, 35433,  3081,  3020, 34305,   770,\n",
       "          1682,  6662, 32973, 33522,  6079,  5985, 32882,  6362,  6145,\n",
       "         32589,   441,  6264, 36562, 32439,  5008, 33463, 20201,  2575,\n",
       "         16063, 20297, 54823, 54364, 65667, 50449, 54327, 20379, 54786,\n",
       "         20617, 20816, 18485, 53750, 20133,   912,  1078,   570, 51804,\n",
       "         52295, 18480, 52458, 15661, 17024,  1686, 66232, 19279, 16623,\n",
       "          1778, 16558, 67118, 19818, 16405, 15569,  7125, 65325,  4571,\n",
       "         11189, 59626, 11099, 11001, 10526, 10074,  5505,  5828,  4506,\n",
       "         62045, 61743,  8644,  8415,  8413, 60901,  6526, 60987,  6833,\n",
       "         61451, 61990, 15441, 11820,  4342, 65021, 14324, 64784, 13549,\n",
       "         56986,  3183, 56992, 57006, 13121, 58800, 13010,  3320,  3376,\n",
       "         12655, 57841, 58069, 12330, 11891, 58473, 58501, 64701, 57129,\n",
       "         36823, 50099, 31732, 31568, 41596, 42327, 42889, 43052, 43290,\n",
       "         43524, 28660, 43749, 41050, 28522, 21449, 44379, 27740, 27727,\n",
       "         27362, 45474, 26551, 45926, 25494, 46907, 43873, 46952, 32811,\n",
       "         32915, 36396, 37599, 37611, 37747, 36094, 37996, 35866, 38557,\n",
       "         34670, 38983, 40469, 34023, 39355, 33683, 33625, 39603, 39819,\n",
       "         67165, 33235, 33163, 33159, 40390, 39208, 23543, 52278, 22104,\n",
       "         21746, 47610, 48449, 49266, 22105, 22654, 48237, 21546, 23297,\n",
       "         18740, 40570, 61753, 32633, 51417, 32224, 30818, 22352, 18684,\n",
       "         53986, 18988, 41947, 29583, 60273, 22594, 43398, 18328, 43958,\n",
       "         11480, 22772, 44436, 60907, 41781, 62230, 44691,   160, 66869,\n",
       "         21583, 66654, 37952, 20309, 49561, 38332, 35176, 65118,  2748,\n",
       "         38511, 64971, 34485, 63829, 63582, 63526, 50850, 19657, 33775,\n",
       "         49098,  4704,  5305,  5501,  5575,  5928, 58217, 22588, 54456,\n",
       "         54674, 53451, 25821, 13601, 13676, 45103, 15693, 24631, 26912,\n",
       "         14421, 23454, 14436, 16095, 54104, 48113, 12415, 16230, 12440,\n",
       "         14554, 12467, 26197, 57767, 54460, 22277, 46842, 33853, 41142,\n",
       "          7200,  2771, 26106, 40920, 51875, 35148, 53631, 54792,  3397,\n",
       "         63755, 34908, 63103, 27429, 63609, 46623, 64414,  3308, 21802,\n",
       "         59530, 63493, 58171, 36158, 28223, 17741,   693, 59671, 53015,\n",
       "           746, 18252, 21670, 53794, 60068,  9481, 15368, 47267, 35232,\n",
       "         47146, 57349,  8690, 16277, 54444, 36114,  8613, 46857, 67044,\n",
       "         36262, 63650, 46878,   745, 35695, 34206, 35769, 23343,  2621,\n",
       "         15929, 50656, 38606, 21734,   702, 54843, 12016, 47703, 13248,\n",
       "         22169, 31504,  7935, 26458,  8839, 57503, 52890, 57622, 11157,\n",
       "         17898, 28030, 44886, 44501, 44573, 13261, 56624, 51103, 18961,\n",
       "         13736], dtype=int64),\n",
       "  'feature_absent_idx': array([63587, 49468, 49466, 64779, 64778, 64776, 49463, 27820, 41772,\n",
       "         12799, 41773, 41775, 27811, 12805, 12782, 41776, 41777, 27805,\n",
       "         12811, 12812, 12813, 49456, 58842, 27801, 27799, 49450, 12824,\n",
       "         27796, 12826, 12807, 49446, 27828, 12777, 12723, 41744, 41747,\n",
       "         49503, 49500, 27864, 27863, 27861, 27860, 49493, 12739, 12742,\n",
       "         57271, 49471, 49490, 49486, 27845, 12762, 12763, 49474, 41762,\n",
       "         12768, 12769, 12770, 12771, 12773, 27831, 58851, 49489, 41742,\n",
       "         49445, 49444, 27757, 41818, 27754, 61704, 49411, 12892, 12894,\n",
       "         12898, 12901, 64756, 27735, 27733, 41828, 12880, 27731, 12915,\n",
       "         27725, 49400, 61709, 49398, 27723, 49391, 12930, 27715, 27713,\n",
       "         27712, 27710, 64749, 27726, 12829, 49418, 12877, 27792, 27791,\n",
       "         12835, 61695, 41798, 57283, 49439, 49437, 41802, 64766, 49434,\n",
       "         12851, 12852, 12878, 12854, 49431, 12858, 61698, 12862, 41807,\n",
       "         12865, 61700, 27763, 49425, 49424, 41817, 49421, 27758, 27776,\n",
       "         27708, 12721, 12717, 27992, 12562, 49579, 49578, 12568, 41671,\n",
       "         49574, 12574, 64822, 64821, 64820, 57261, 61641, 12557, 12581,\n",
       "         12583, 49572, 49570, 12586, 64816, 12592, 27967, 12595, 12596,\n",
       "         12597, 12598, 64814, 27963, 64819, 61646, 27994, 49586, 61629,\n",
       "         12510, 57251, 12512, 49606, 41655, 49605, 41658, 28018, 57252,\n",
       "         57254, 12527, 57256, 61637, 12530, 28013, 12534, 55978, 64833,\n",
       "         57257, 61632, 49590, 12544, 12546, 49588, 41664, 64831, 12550,\n",
       "         49594, 41741, 27958, 61647, 57266, 27908, 49532, 12675, 12676,\n",
       "         49529, 41729, 64797, 49526, 49524, 49523, 41731, 27891, 12667,\n",
       "         12693, 27883, 49516, 41738, 64792, 12707, 49511, 12710, 12711,\n",
       "         49509, 27877, 12714, 49508, 49507, 12696, 27957, 57265, 12663,\n",
       "         27955, 61648, 49560, 41694, 41695, 49558, 41697, 61650, 27946,\n",
       "         27937, 41703, 12633, 12634, 12664, 27931, 64806, 49549, 49548,\n",
       "         12644, 58865, 49546, 12653, 58859, 41718, 41719, 41722, 12661,\n",
       "         27910, 41706, 27707, 64748, 41832, 41929, 41932, 13201, 27516,\n",
       "         64699, 61751, 13209, 13214, 49241, 13217, 27506, 13219, 41935,\n",
       "         13193, 13221, 49235, 58814, 57325, 13233, 49226, 27486, 13243,\n",
       "         57329, 13247, 13249, 41949, 49219, 49216, 27500, 49215, 27527,\n",
       "         41922, 58820, 27557, 49272, 49271, 13146, 49269, 13148, 13149,\n",
       "         13151, 13154, 41908, 49263, 13160, 13190, 13161, 13167, 41913,\n",
       "         41914, 41916, 49255, 13173, 13176, 49254, 41919, 13183, 64704,\n",
       "         27535, 27531, 27548, 27561, 13255, 61762, 13311, 49181, 41971,\n",
       "         13317, 27439, 41973, 13322, 41976, 49174, 27431, 49173, 13328,\n",
       "         13329, 41970, 57339, 13333, 49168, 58809, 13338, 49164, 57341,\n",
       "         13344, 13345, 13347, 64668, 49160, 27417, 27413, 27430, 13259,\n",
       "         49182, 27449, 27471, 61765, 41962, 13269, 13271, 49202, 13273,\n",
       "         13274, 61766, 27464, 57334, 13280, 49196, 13307, 61767, 27459,\n",
       "         27458, 13288, 13290, 13292, 13293, 13295, 61771, 27451, 61772,\n",
       "         13301, 49186, 49185, 57336, 61742, 58821, 49281, 61717, 12987,\n",
       "         64737, 12989, 41850, 41851, 41853, 27676, 41856, 57301, 13002,\n",
       "         13003, 49350, 41848, 57303, 13014, 49340, 13016, 27658, 61724,\n",
       "         13020, 27656, 27653, 64730, 13028, 13029, 27650, 41867, 49345,\n",
       "         61727, 12983, 27686, 12943, 49383, 64747, 12947, 12948, 49378,\n",
       "         12951, 12952, 27703, 49377, 57297, 27701, 49374, 41847, 49373,\n",
       "         49369, 12964, 57299, 12969, 12970, 12971, 27693, 12973, 41843,\n",
       "         41844, 27688, 49362, 49360, 12960, 57305, 13037, 64728, 13096,\n",
       "         27593, 13098, 27591, 27590, 13101, 13103, 13106, 27586, 13108,\n",
       "         41896, 61737, 13112, 13095, 27582, 27581, 49291, 49290, 61739,\n",
       "         41897, 27576, 41898, 27573, 41899, 27571, 49284, 27568, 27567,\n",
       "         49294, 61735, 41887, 27605, 13040, 27641, 27638, 27637, 61729,\n",
       "         57306, 58827, 27631, 13052, 61730, 64725, 27625, 27624, 27621,\n",
       "         27620, 13065, 49315, 61733, 27616, 27612, 64721, 49309, 61734,\n",
       "         13079, 41884, 13081, 27607, 27606, 13084, 49609, 12506, 49610,\n",
       "         28026, 64964, 28473, 49931, 11922, 11923, 61545, 41416, 41419,\n",
       "         49923, 11931, 28452, 11939, 11940, 11914, 28450, 28447, 64956,\n",
       "         28445, 41429, 28441, 28439, 11952, 28436, 41432, 11959, 49901,\n",
       "         28429, 41436, 28448, 41440, 28476, 64967, 49973, 28521, 28520,\n",
       "         28519, 11861, 41389, 49960, 11874, 28504, 11876, 28501, 28500,\n",
       "         28498, 28478, 11882, 11885, 28494, 28493, 58919, 49948, 28487,\n",
       "         61537, 41406, 11902, 28482, 49941, 11906, 61538, 49954, 61528,\n",
       "         11968, 49897, 49865, 28388, 12029, 28383, 28382, 12033, 28378,\n",
       "         41455, 28374, 41457, 28371, 49856, 49855, 12022, 12045, 12047,\n",
       "         64928, 49854, 28370, 49851, 12056, 12059, 41465, 12062, 49847,\n",
       "         12064, 28361, 64920, 12046, 49898, 61559, 12015, 28421, 11975,\n",
       "         11976, 64948, 41441, 57188, 49891, 49890, 58915, 28416, 11984,\n",
       "         11985, 11987, 12017, 49885, 11994, 11995, 41444, 64943, 64941,\n",
       "         28408, 28407, 41448, 28398, 28397, 61557, 12013, 12014, 28410,\n",
       "         28525, 61527, 11850, 41337, 11699, 11700, 65001, 28624, 11704,\n",
       "         11706, 11707, 11708, 28622, 28621, 11711, 61507, 11696, 61508,\n",
       "         11722, 61510, 28605, 41346, 28602, 11731, 11733, 11734, 41347,\n",
       "         11736, 11737, 11738, 11739, 28612, 41349, 11695, 28634, 58933,\n",
       "         11647, 11649, 41321, 11651, 11653, 11656, 28649, 50062, 11659,\n",
       "         50060, 50058, 65012, 28630, 50055, 11669, 11672, 11673, 11676,\n",
       "         50049, 28642, 11679, 41331, 41333, 50046, 65005, 58928, 65004,\n",
       "         11668, 41351, 28595, 50024, 28552, 11809, 41375, 11811, 28548,\n",
       "         41376, 61522, 11817, 28544, 11821, 49988, 11826, 11827, 64984,\n",
       "         11828, 11830, 64981, 11832, 11834, 28537, 28536, 61525, 28534,\n",
       "         28530, 28529, 49978, 49976, 11848, 49985, 11806, 11805, 11804,\n",
       "         64997, 50021, 11749, 64996, 28592, 28589, 58925, 50016, 11758,\n",
       "         41360, 28583, 11765, 11766, 28580, 41361, 11777, 11779, 11781,\n",
       "         41365, 11784, 11785, 41369, 64988, 28562, 50000, 49999, 28558,\n",
       "         49994, 11802, 49837, 27409, 12075, 61563, 12356, 49691, 28128,\n",
       "         12362, 12363, 12365, 28126, 12367, 12368, 28124, 12372, 57237,\n",
       "         12374, 41593, 49686, 64866, 28117, 49679, 58884, 28114, 28113,\n",
       "         58882, 12390, 12391, 49678, 49677, 28109, 28108, 58885, 41614,\n",
       "         49696, 28136, 41580, 12313, 12315, 49713, 49712, 12318, 64874,\n",
       "         61601, 61602, 41582, 49708, 49707, 61603, 28135, 28150, 64872,\n",
       "         64871, 49703, 12338, 41584, 61607, 57232, 61608, 12344, 12346,\n",
       "         28140, 61611, 41591, 61604, 12308, 12404, 28097, 64845, 41628,\n",
       "         12459, 12460, 41631, 49642, 28064, 28063, 41634, 12468, 49639,\n",
       "         28056, 41638, 12454, 28051, 64840, 12484, 28042, 61627, 41649,\n",
       "         12490, 12491, 41650, 12494, 12495, 57247, 28034, 41653, 28047,\n",
       "         49668, 12452, 12448, 49667, 12411, 12412, 28093, 49666, 28091,\n",
       "         12418, 28088, 49661, 28085, 28084, 49654, 12428, 41626, 28082,\n",
       "         12431, 64850, 64849, 64847, 28080, 28079, 28078, 28076, 49649,\n",
       "         49648, 41624, 12446, 12447, 64851, 28167, 28173, 12297, 64908,\n",
       "         49796, 28299, 12142, 12143, 58907, 41509, 41515, 41516, 12158,\n",
       "         41520, 28274, 61578, 41503, 41523, 28265, 28264, 57218, 12178,\n",
       "         64900, 41530, 49771, 12184, 12186, 49768, 49767, 61579, 41533,\n",
       "         28267, 28248, 12134, 12132, 12079, 28350, 61565, 58914, 57208,\n",
       "         49825, 12087, 41474, 28341, 28337, 28333, 28331, 58912, 28304,\n",
       "         41485, 41486, 12106, 12108, 12109, 41487, 64914, 28316, 49809,\n",
       "         57209, 41494, 28310, 49803, 49800, 12104, 28247, 61582, 12198,\n",
       "         28208, 12251, 12252, 12253, 12254, 64888, 49742, 28207, 12258,\n",
       "         64887, 28205, 49739, 12267, 28209, 49732, 49729, 12279, 28188,\n",
       "         12283, 41565, 41566, 28182, 41572, 12292, 12293, 12294, 49725,\n",
       "         57230, 28191, 12247, 41558, 28213, 28241, 12202, 28240, 12205,\n",
       "         28238], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_instrument': {'feature_present_idx': array([35051, 18652, 19522, 19931, 46980, 20687, 63220,  6736, 45621,\n",
       "          5010,  4875,  4543,  7061, 27580, 29117, 24288, 39531, 43640,\n",
       "         16189, 17544, 54047, 37510, 52271, 19243, 30685, 51711, 30572,\n",
       "         20771, 21247, 46687, 22411, 22630, 56577, 28237, 41732, 23551,\n",
       "         24931, 41669, 56940, 19042, 57185, 13218, 64033,  1997,  9868,\n",
       "         64553, 11398,   971, 58656, 64911, 63338,   249, 12876, 67070,\n",
       "         36200, 63510, 24389, 24390, 38357, 43464, 39728, 41332, 27050,\n",
       "         64278,  5871,   287, 29016, 66067, 43105, 42370, 44370,  7674,\n",
       "         57462, 56264,  9671,  9148,  8866, 35318, 62793,  7962, 46533,\n",
       "         33648,  8375, 42227, 35607, 36844, 62868, 37801, 56192, 38366,\n",
       "         39340, 55654, 47232, 57593, 46965, 53755, 65926, 53709, 45360,\n",
       "         41708, 59374, 51921, 61381, 55550, 58338,   142, 33754, 26214,\n",
       "         25314, 23960, 23654, 23222, 21930, 21619, 19766, 19315, 12263,\n",
       "         11643,  8398,  7964,  4617,  4395,  1922,   262, 26322, 28824,\n",
       "         18637, 67238, 29637, 29893, 31699, 14993, 55684, 14263, 56440,\n",
       "         29174, 13400, 56682, 13396, 13025, 32114, 58050, 11770, 37461,\n",
       "         18290, 11068, 60580, 32125, 63130,  7493, 33634, 36057, 67201,\n",
       "          1859,  1315, 58561, 54664, 27961, 30034, 45919, 38291, 27095,\n",
       "         20737, 20142, 43320, 19896, 31181, 47735, 48718, 38906, 37719,\n",
       "         19057, 53185, 33915, 47801, 54069, 64268, 64407, 44345,  9860,\n",
       "          6318, 61221, 56501, 58896, 30713, 13006, 57083, 14969, 35604,\n",
       "         43092,   931,   557, 66223, 18299, 37401, 31836, 22763, 60615,\n",
       "         59816, 46692, 46857, 56919, 67044, 18961, 62911], dtype=int64),\n",
       "  'feature_absent_idx': array([52664, 57571, 57570, 12721, 12723, 57568, 45583, 57567, 57566,\n",
       "         28274, 45592, 45594, 28267, 12739, 12717, 28265, 12742, 45598,\n",
       "         45599, 57550, 45600, 45603, 57544, 28248, 28247, 45609, 12762,\n",
       "         12763, 28241, 28264, 28240, 12714, 12710, 12661, 12663, 12664,\n",
       "         57611, 45557, 12667, 57609, 28316, 57605, 12675, 12676, 28310,\n",
       "         57601, 12711, 45565, 57596, 28304, 57594, 57591, 45567, 12693,\n",
       "         12696, 28299, 45573, 57579, 57578, 12707, 45576, 57599, 45611,\n",
       "         28238, 12768, 57502, 57501, 28207, 57493, 28205, 12824, 12826,\n",
       "         12829, 45634, 45635, 12835, 28191, 28188, 12813, 45638, 57480,\n",
       "         28182, 45643, 57468, 12851, 12852, 45652, 12854, 28173, 12858,\n",
       "         12862, 28167, 12865, 45639, 12812, 12811, 28208, 12769, 12770,\n",
       "         12771, 12773, 28233, 12777, 28232, 45615, 45616, 12782, 57526,\n",
       "         57525, 57524, 45618, 45619, 28225, 57518, 28224, 57516, 57513,\n",
       "         57511, 12799, 28218, 45626, 28213, 12805, 45628, 12807, 28209,\n",
       "         45553, 57450, 45544, 57626, 57745, 28447, 57741, 12506, 28445,\n",
       "         45458, 57736, 12510, 57735, 12512, 28441, 57731, 57730, 28448,\n",
       "         45460, 57725, 28436, 57723, 45462, 12527, 57718, 12530, 57717,\n",
       "         57715, 12534, 28429, 45467, 45469, 28439, 28421, 45457, 57750,\n",
       "         28487, 45411, 12452, 57782, 12454, 45413, 45414, 28482, 12459,\n",
       "         12460, 45415, 28478, 28476, 28450, 57772, 28473, 57770, 57768,\n",
       "         57766, 57762, 45446, 12484, 12490, 12491, 28452, 12494, 12495,\n",
       "         57753, 12468, 12544, 45473, 12546, 12598, 57666, 57665, 28374,\n",
       "         45509, 28371, 28370, 57662, 45511, 57656, 28361], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 205\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 205\n",
       "  })},\n",
       " 'contains_location': {'feature_present_idx': array([   12, 36023, 15909, 56154, 35763, 16170, 56386, 35378, 36377,\n",
       "         56573, 35250,  5053, 35068, 57507, 34538, 17092, 17107, 16418,\n",
       "         34236, 15625, 37050, 54862, 39479, 14791, 54923, 54972, 38487,\n",
       "         15050, 15611,  5901, 15108, 55319, 55363, 55513,  5818, 38039,\n",
       "         15445, 55230, 39769, 17158,  4535,  3517, 60194, 60404, 31387,\n",
       "          3369, 30648, 30432, 31448, 30431, 61063, 19298, 19348, 19607,\n",
       "         29655,  2860, 19785, 19125, 33990, 60095, 18302, 58675, 33769,\n",
       "         33395, 33389, 17657,  4113, 32443, 18446, 59061, 17973, 32264,\n",
       "         18015,  3923, 18047, 32201, 18212,  4022, 19794, 39933, 40152,\n",
       "         45822, 49230, 49389, 45673, 49582, 45405, 10995,  9315, 45150,\n",
       "         49818, 11061, 45101, 45094,  8892, 50156,  8801, 45131, 11292,\n",
       "         45876, 49152, 47885,  9901,  9889, 10063, 47281, 48542, 48565,\n",
       "          9425, 48709, 46286, 46279, 46206, 46152, 10480, 49092, 45977,\n",
       "         46394, 54390, 44673, 44237, 41522, 41374,  7333, 13707, 13708,\n",
       "         13732, 13740, 52720, 53201,  7084, 13875, 53366, 13999, 53710,\n",
       "          6906, 53944, 53255,  8752, 41668, 52567, 44233,  8680, 44062,\n",
       "         50838, 51339, 12206, 43343, 41761, 51503, 51719, 12673, 52075,\n",
       "         52118, 42092, 52470, 52536, 51616, 61708,  9945, 26700, 62967,\n",
       "         62941,  2286,   479, 64284, 28096, 62889, 21300, 27826, 26122,\n",
       "         62783,   387, 64479, 66705,  1106, 66849, 26333, 21346, 20274,\n",
       "         65785, 24164, 21258, 28089, 66207,  2001, 27674, 20917, 25641,\n",
       "          2067, 27517, 63441, 63407, 27903, 66322, 63950, 20652, 27989,\n",
       "           563, 24830,  1795, 27428, 63096, 27375, 62694, 62796, 62583,\n",
       "         28988, 21566, 21568, 28975, 62413,  2613, 62422,  1400, 26599,\n",
       "         67302, 26412,  2596, 24133, 23585,   233, 66949, 26373, 66884,\n",
       "         62444, 62130, 43331, 13955, 13953, 42680, 26678, 40789, 25771,\n",
       "         13894, 42562, 12827, 42480, 40513, 25676, 12750, 43171, 42688,\n",
       "         42737, 12698, 40413, 12422, 42979, 25655, 43042, 43146, 43268,\n",
       "         43223, 25455, 40415, 40485, 22140, 42143, 42292, 41287, 13287,\n",
       "         26452, 41883, 41302, 26189, 26523, 26392, 13484, 41670, 41561,\n",
       "         26289, 41532, 13670, 41700, 42399, 41207, 26548, 13890, 12996,\n",
       "         13616, 40816, 42097, 13061, 41139, 25845, 22054, 42061, 41092,\n",
       "         13242, 26585, 26574, 42075, 25448, 19811, 43412, 24033, 46272,\n",
       "         24049, 24148, 10536, 10559, 10570, 45954, 10603, 24334, 10636,\n",
       "         24402, 24447, 45793, 24455, 45742, 45625, 45476, 10877, 23774,\n",
       "         24504, 10325, 23709,  9960, 23225, 47699, 23217, 47614, 23499,\n",
       "         47575, 10090, 47373, 47365, 46708, 10230, 10232, 46616, 23602,\n",
       "         23662, 46545, 46529, 46470, 23720, 43348, 45384, 24558, 44136,\n",
       "         11616, 44130, 40410, 25180, 44005, 43858, 43771, 43750, 11941,\n",
       "         43467, 25304, 43457, 43439, 43415, 12165, 12169, 12189, 25381,\n",
       "         22333, 45315, 44155, 11564, 22666, 11026, 24698, 22609, 22589,\n",
       "         24734, 44890, 44744, 11239, 44683, 24815, 11283, 24823, 22450,\n",
       "         44582, 44450, 22397, 11481, 11490, 25109, 44073, 39814, 26714,\n",
       "         33616, 17454, 33236, 20610, 33233, 17850, 32749, 32599, 32337,\n",
       "         32280, 20583, 20576, 32255, 28194, 32164, 32054, 18118, 20509,\n",
       "         31998, 33623, 31988, 33669, 17404, 34582, 34559, 27868, 34523,\n",
       "         34517, 34466, 27944, 17187, 34130, 34104, 17274, 34025, 33994,\n",
       "         17313, 33935, 33854, 33838, 33824, 20623, 20616, 16931, 18270,\n",
       "         18293, 30370, 20178, 30322, 20017, 19300, 29963, 19500, 29763,\n",
       "         29665, 19974, 19951, 29396, 19655, 29087, 29278, 29207, 29089,\n",
       "         19859, 19827, 19027, 18273, 30379, 30657, 31812, 28653, 18311,\n",
       "         18395, 31787, 31727, 31478, 20212, 28801, 31443, 28848, 18742,\n",
       "         18772, 31115, 31093, 31050, 18815, 30990, 30984, 18927, 34660,\n",
       "         16735, 34678, 39658, 39570, 21383, 39305, 21354, 38907, 38881,\n",
       "         27015, 14858, 14879, 38811, 38788, 14894, 38694, 38610, 27047,\n",
       "         38421, 21325, 38282, 39661, 27341, 26855, 14462, 40333, 40259,\n",
       "         26768, 40123, 14197, 40111, 14239, 14240, 40074, 14265, 40067,\n",
       "         14288, 21499, 14330, 26807, 39927, 39922, 19815, 26840, 14478,\n",
       "         21105, 27407, 37967, 35700, 35595, 35536, 27734, 35295, 35291,\n",
       "         27835, 20808, 16454, 35189, 27843, 16521, 16536, 47928, 34906,\n",
       "         16576, 34868, 34776, 34706, 16077, 35741, 27660, 15969, 37682,\n",
       "         15405, 37133, 37113, 36991, 15480, 15484, 36975, 36705, 14083,\n",
       "         27480, 27501, 36327, 15864, 15871, 27614, 15934, 15947, 27633,\n",
       "         35888, 36450, 34922, 45179, 56994,  2526, 62728,  6280,  6301,\n",
       "         54879,  6367, 54834,  6408, 54647, 54589, 54507,  6588,  6600,\n",
       "          6605, 62763, 54287, 54229, 54916,  6231, 54970, 55003,  5606,\n",
       "         55690, 55570, 61777,  2691,  5695, 55539, 55531,  6712,  2659,\n",
       "         62290, 55224,  5962,  2645,  6041,  6052,  6056, 62469, 55286,\n",
       "          5591,  2377, 54046,  1902,  1896, 63827, 52924,  1885, 63911,\n",
       "         64081, 64098,  7368,  1758, 52659, 52578, 64105,  7532, 64124,\n",
       "          1691,  7566,  7204, 63640, 63578, 53131, 53878, 53765,  6910,\n",
       "          6913, 63002, 53691, 53683, 59610,  6830, 53589, 63164, 63330,\n",
       "          2134, 53347, 63536,  2026,  1982, 63571, 53522,  5524, 55959,\n",
       "          5493, 58873,  4268, 60665,  3321, 58830, 58823, 58773,  4391,\n",
       "         58695, 58600, 58515,  4559, 58370,  4572,  4578, 58210,  3313,\n",
       "         58942, 58947, 58973, 60548, 59577, 59701, 59471, 59824, 59258,\n",
       "         59254, 59874,  3764,  4631, 60102,  4000,  4013,  4043, 59047,\n",
       "          4114,  4154, 60488,  4182, 59105,  4666, 57925, 57902, 61073,\n",
       "         56529, 56442, 56426,  5204, 61189, 56377, 56349, 60983,  5235,\n",
       "          3041,  5330,  2952, 56055, 56025,  5464, 61250,  5492, 56318,\n",
       "          1654, 56732,  3163, 57714, 57657,  4711, 57590, 60709, 60711,\n",
       "          4766, 57298, 56744,  4845,  4944, 57056, 57053, 60836, 60869,\n",
       "         56936,  3191, 56843, 57149,  7575, 63051,  1636,   362, 49557,\n",
       "         49672, 66615,   488,   534, 66513, 49716,  9033,  8987,   554,\n",
       "         50127,  8855,  8787, 50158,  8757, 50258, 65848, 50789, 65939,\n",
       "          8584, 50662, 66059,  9195,  8594, 50624, 50489, 66151, 50398,\n",
       "           696, 50324,  8595,  8527, 49402, 49313,  9923, 48063,    22,\n",
       "          9905, 48111, 48154, 48264, 48281, 48316, 48445, 48458, 67137,\n",
       "         48484, 48496, 48516, 67130, 67045, 66847,  9409,  9446, 49187,\n",
       "          9491, 49145, 66758, 49051,   229,   224,   207, 48855,  9684,\n",
       "          9723, 48986, 50994, 59652,  1123, 51401, 52182, 65671,  1506,\n",
       "         52319, 51462,  8088, 65566, 52235,  7791, 51496, 64740,  1510,\n",
       "         51497, 51663, 65534, 64595,  8193, 52042, 65680, 51386, 65361,\n",
       "         51217, 65060, 65709, 52531, 30613, 30445, 63552, 24155, 30998,\n",
       "         65195, 64898, 64854, 64812, 31046, 30441, 31041, 66877, 60682,\n",
       "         66845, 24337, 27813, 27825, 24333, 60691, 24234, 24407, 24210,\n",
       "         65045, 31047, 26607, 64961, 30866, 30522, 30895, 30466, 65018,\n",
       "         28234, 64014, 67034, 27372, 31439, 27008, 60380, 60133, 27230,\n",
       "         31501, 27151, 31544, 67232, 67282, 67294, 64286, 31746, 59712,\n",
       "         23400, 64372, 31795, 59689, 31424, 60455, 67204, 31348, 27505,\n",
       "         23911, 23870, 26814, 24482, 23868, 60679, 60561, 64681, 63883,\n",
       "         31130, 27377, 23665, 31221, 67173, 31261, 23618, 26978, 31285,\n",
       "         26985, 64619, 24492, 27982, 66655, 62811, 28952, 25513, 62341,\n",
       "         66126, 66131, 25414, 62906, 66267, 62283, 29000, 25268, 29023,\n",
       "         29078, 62254, 62214, 61904, 65595, 66315, 62378, 61642, 26259,\n",
       "         66008, 28315, 28332, 28434, 26069, 26057, 28459, 28532, 25938,\n",
       "         25925, 28607, 62749, 65889, 65928, 28669, 26194, 25755, 62515,\n",
       "         62784, 65980, 28164, 61624, 66328, 25101, 66385, 29999, 66387,\n",
       "         24799, 26453, 61110, 63294, 66510, 30091, 30113, 63325, 30135,\n",
       "         30181, 65515, 24731, 66590, 30336, 65358, 63331, 66363, 29978,\n",
       "         61194, 24850, 61619, 61581, 61500, 29362, 29363, 61367, 64582,\n",
       "         26383], dtype=int64),\n",
       "  'feature_absent_idx': array([39346, 25433, 54098, 10626, 31389, 18630, 10630, 31386, 10632,\n",
       "         10633, 10634, 49284, 45152, 25438, 49281, 10641, 10642, 31379,\n",
       "         10645, 10646, 45157, 10649, 18624, 18623, 59853, 10638, 18622,\n",
       "         59864, 10618, 59885, 31417, 10589, 31416, 59883, 31414, 18650,\n",
       "         18648, 59877, 54085, 54086, 45151, 54087, 54090, 25427, 18640,\n",
       "         59870, 25429, 10611, 31399, 45148, 59868, 54096, 59866, 10602,\n",
       "         10654, 18619, 59852, 49271, 31346, 59828, 10697, 59827, 10699,\n",
       "         25456, 59825, 25457, 45178, 49269, 49272, 59821, 10708, 10710,\n",
       "         10711, 59820, 45188, 10716, 10717, 59817, 18596, 10720, 10723,\n",
       "         10706, 25452, 45172, 31355, 10658, 10659, 18617, 18616, 59846,\n",
       "         10665, 10666, 45159, 59845, 31367, 45160, 59843, 10673, 54109,\n",
       "         10677, 59840, 10680, 31360, 18610, 54111, 45168, 59837, 10686,\n",
       "         10687, 54113, 31418, 31328, 45135, 49290, 59944, 59943, 31489,\n",
       "         59942, 54049, 25396, 10490, 31485, 59936, 49309, 45096, 54048,\n",
       "         59935, 59934, 59933, 18678, 31477, 10502, 10503, 59930, 54057,\n",
       "         10511, 31469, 59922, 10496, 10514, 31491, 31492, 31515, 45070,\n",
       "         54041, 18694, 10451, 59964, 59963, 45073, 59960, 59959, 59958,\n",
       "         59945, 59956, 45078, 59953, 25391, 18691, 59950, 10468, 54043,\n",
       "         54045, 10474, 45089, 10478, 31507, 59921, 25408, 31467, 59901,\n",
       "         31445, 59899, 25413, 18661, 10558, 31438, 18660, 31435, 45122,\n",
       "         10565, 45117, 49294, 54077, 18656, 31429, 45128, 31426, 10575,\n",
       "         10576, 49291, 10578, 10579, 25421, 59892, 59903, 10549, 45113,\n",
       "         10518, 18670, 59920, 54068, 10522, 18668, 59917, 54072, 59915,\n",
       "         10527, 59914, 18665, 59911, 45106, 45107, 59909, 45108, 31456,\n",
       "         10540, 31455, 31453, 10544, 45111, 59904, 10547, 10584, 54037,\n",
       "         54125, 49263, 45275, 45281, 10905, 59725, 45282, 31201, 18536,\n",
       "         10910, 10911, 18535, 10913, 25508, 31194, 45292, 59714, 10921,\n",
       "         10922, 18531, 25512, 59710, 18529, 45299, 10928, 25514, 25511,\n",
       "         54179, 10900, 31211, 54164, 45250, 59734, 31230, 31229, 31228,\n",
       "         10874, 45252, 45253, 31224, 10879, 31210, 45255, 10883, 45258,\n",
       "         18542, 49235, 31217, 54171, 10889, 45266, 10893, 10894, 45271,\n",
       "         10882, 10931, 10932, 45304, 10967, 31151, 59673, 54188, 31148,\n",
       "         59670, 18511, 59668, 10978, 31146, 59665, 45323, 10982, 45331,\n",
       "         10986, 10987, 25526, 45333, 31140, 10991, 45338, 49219, 54191,\n",
       "         45339, 31145, 59676, 10963, 18516, 31178, 31177, 45305, 59698,\n",
       "         10938, 25516, 59691, 10943, 25517, 31172, 10947, 25519, 45310,\n",
       "         18521, 18520, 49226, 18518, 54184, 59678, 31161, 45317, 10958,\n",
       "         45321, 10960, 31157, 10866, 18592, 59736, 59737, 49255, 10763,\n",
       "         59793, 10765, 31302, 10767, 31301, 25477, 59786, 10773, 45212,\n",
       "         59795, 54144, 59783, 31293, 31291, 10782, 31289, 45220, 10785,\n",
       "         45223, 10787, 59780, 10790, 49254, 59779, 59796, 10758, 59810,\n",
       "         10730, 18589, 54128, 59809, 10734, 10736, 10737, 59808, 45197,\n",
       "         10740, 59797, 25469, 54131, 45199, 18584, 10746, 31312, 54133,\n",
       "         54138, 59803, 18578, 25474, 59799, 10742, 59774, 31282, 54152,\n",
       "         45236, 31251, 10836, 31250, 10838, 10839, 18550, 45237, 45239,\n",
       "         10843, 59744, 59749, 54159, 31243, 31242, 10850, 10852, 31240,\n",
       "         59739, 59738, 45243, 45247, 25503, 45248, 10846, 18551, 31254,\n",
       "         59754, 31279, 59771, 10799, 25488, 10801, 31277, 10803, 59767,\n",
       "         31276, 10806, 31274, 59764, 45232, 31272, 54156, 45233, 25492,\n",
       "         59756, 59755, 10821, 10822, 49241, 54158, 31258, 31257, 45249,\n",
       "         31134, 45064, 10441, 10046, 18855, 60256, 31803, 31802, 25272,\n",
       "         44850, 53950, 10055, 60253, 18850, 60258, 60249, 10064, 31792,\n",
       "         25274, 53952, 18847, 60243, 53953, 10071, 10073, 60238, 31784,\n",
       "         60248, 44858, 60260, 10042, 10017, 44825, 10019, 53945, 53946,\n",
       "         60280, 44829, 10024, 60275, 18860, 60274, 10043, 44830, 44834,\n",
       "         25269, 49411, 10034, 31811, 18856, 31807, 10038, 31806, 10040,\n",
       "         10041, 60270, 44859, 10080, 60235, 53967, 10119, 49398, 31752,\n",
       "         31749, 10125, 10127, 60191, 53969, 10130, 10132, 44878, 60189,\n",
       "         53970, 10137, 49391, 10139, 31737, 60183, 31735, 60180, 60178,\n",
       "         44893, 18808, 60188, 60206, 60209, 60210, 10083, 44860, 10085,\n",
       "         18841, 10087, 53956, 44867, 53959, 60228, 25283, 49400, 10097,\n",
       "         18832, 10099, 31765, 53962, 10102, 18830, 10105, 10107, 10108,\n",
       "         53964, 18826, 53966, 31756, 18864, 10150, 10015, 31826, 31907,\n",
       "         25236, 31905, 31904, 53910, 31902, 31898, 31897,  9915, 53913,\n",
       "         53916, 31910,  9918, 49425, 60345, 60344, 60342, 44777, 60340,\n",
       "         31889, 31888, 60338, 18898, 31886, 44775, 49424,  9897, 18911,\n",
       "         31938, 31937, 44737, 60390, 60387, 31935,  9870, 31934, 60386,\n",
       "         44739, 53902, 49431, 60382, 44749, 25227, 25228, 60374, 60373,\n",
       "         25231, 31918,  9891, 60367, 44764, 18912, 18919, 31882, 18894,\n",
       "         49421,  9982, 53933, 31848,  9987,  9988, 31846, 31845, 44811,\n",
       "          9994, 44812, 60305, 18880, 53939, 53941, 10001, 60300, 10003,\n",
       "         10004, 53942, 18867, 60292, 53943, 31828, 60287, 31837,  9980,\n",
       "         25255,  9978, 60332,  9942, 25249, 60329, 18889, 31874, 31872,\n",
       "         31870, 44793,  9953, 18887, 31866, 44795, 53927, 25252, 44797,\n",
       "          9963,  9964, 31859, 53929, 44801, 49418, 31854,  9973,  9975,\n",
       "         44822, 10442, 31726, 53975, 10339, 31589, 60041, 10342, 10343,\n",
       "         60039, 31588, 10346, 60038, 10349, 18733, 60047, 18732, 25357,\n",
       "         10355, 60031, 10357, 45008, 60028, 25358, 31578, 10363, 18727,\n",
       "         10366, 45007, 60024, 54016, 31592, 54009, 44980, 10304, 44982,\n",
       "         44983, 18750, 10308, 10309, 54010, 60065, 44987, 10336, 31604,\n",
       "         10321, 44995, 44996, 60056, 10326, 54013, 10330, 25354, 54015,\n",
       "         60053, 49340, 44993, 31575, 10370, 31574, 31548, 18714, 59996,\n",
       "         31545, 59995, 25374, 59993, 59992, 18712, 54031, 31535, 10408,\n",
       "         45058, 54032, 31532, 18707, 59986, 25378, 59984, 31528, 18700,\n",
       "         45062, 49315, 59971, 59987, 18715, 31551, 18718, 25366, 60020,\n",
       "         10376, 10377, 25367, 60018, 60015, 10383, 60013, 45022, 31565,\n",
       "         10388, 31563, 10390, 10391, 10392, 45026, 10394, 10395, 60006,\n",
       "         45028, 31559, 54024, 45036, 10402, 31616, 10153, 10300, 44976,\n",
       "         10190, 10191, 60139, 60138, 18791, 49374, 31696, 31694, 53987,\n",
       "         10203, 53988, 10189, 10205, 60130, 44920, 44921, 60129, 44922,\n",
       "         10212, 60128, 53990, 60124, 31686, 25313, 49373, 10218, 60140,\n",
       "         60143, 31724, 44901, 25300, 44903, 60168, 31719, 25301, 31716,\n",
       "         60164, 60160, 49383, 10187, 31712, 60154, 49378, 25306, 10177,\n",
       "         31708, 44913, 18796, 31704, 49377, 18794, 31701, 31711, 10220,\n",
       "         44927, 18783, 31646, 18765, 44958, 10268, 18761, 10271, 44959,\n",
       "         60093, 49350, 31634, 44966, 60100, 44968, 10281, 10282, 31630,\n",
       "         60083, 60082, 31629, 31628, 10289, 31626, 49345, 60073, 10280,\n",
       "         49360, 60104, 31653, 25315, 10224, 49369, 31677, 10228, 18778,\n",
       "         10231, 31675, 31674, 60113, 44934, 31671, 10239, 53993, 53994,\n",
       "         10242, 18773, 31660, 31658, 10249, 10250, 31656, 49362, 60107,\n",
       "         10257, 10299, 45340, 59643, 31129, 30612, 49053, 30608, 25729,\n",
       "         45683, 18247, 11722, 30601, 30600, 25730, 59139, 30614, 49045,\n",
       "         59134, 11731, 11733, 11734, 11736, 11737, 11738, 11739, 18239,\n",
       "         59128, 18237, 49042, 30589, 45674, 45672, 30637, 30636, 30635,\n",
       "         59158, 30633, 59154, 25723, 30627, 45664, 11695, 11696, 11711,\n",
       "         18255, 11699, 11700, 30622, 18253, 25724, 11704, 45671, 11706,\n",
       "         11707, 11708, 59147, 18254, 18236, 54396, 59123, 18226, 11781,\n",
       "         59089, 11784, 11785, 59088, 59087, 49038, 18223, 45711, 30559,\n",
       "         11779, 30558, 25744, 25745, 25746, 30552, 45716, 59073, 45717,\n",
       "         11802, 11804, 11805, 11806, 45713, 54406, 11777, 59092, 45695,\n",
       "         11749, 30585, 54399, 45696, 30582, 30581, 54400, 45699, 11758,\n",
       "         30577], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_manner': {'feature_present_idx': array([36878, 64216,  8712, 24347, 24338, 45561, 58080, 45554, 24294,\n",
       "         40805,  8820, 24221,  8838, 24116, 24365, 24090, 40874,  8896,\n",
       "         49819, 64111,  8956, 45464,  8973, 64096, 23938, 23925,  9044,\n",
       "         23898, 40962, 40862, 23853, 24415, 57992, 64473, 25585,  8073,\n",
       "         57761, 64426, 25529, 25524, 64393, 25424, 45839, 25291, 40582,\n",
       "          8328, 24501, 25149,  8405, 25029, 40619, 49721,  8498, 49726,\n",
       "          8508,  8516,  8519, 24882, 64306, 24822, 40677,  8359,  9108,\n",
       "         23787, 49870, 22896, 58486,  9824,  9828, 45132, 22764, 41364,\n",
       "         63729, 58590,  9979, 63688,  9990, 58604, 22904, 63666, 63566,\n",
       "         45059, 63538, 22399, 22394, 63530, 51757, 22304, 22219, 51725,\n",
       "         10311, 63455, 45017, 10057, 22961, 63750, 23063, 23780, 64026,\n",
       "         41011,  9198, 23716, 23700, 41098,  9297,  9327,  9329,  9347,\n",
       "         23476, 23448, 45356, 23394, 58328, 23357, 23348, 23321, 23202,\n",
       "         45259, 45241, 63864, 41256,  9646,  9664, 23112, 23066, 49924,\n",
       "         25719, 58825, 45941, 49657, 28221, 56661, 28195,  6251, 28121,\n",
       "          6261, 65168, 49354, 56718, 46605, 46595, 65130, 46567,  6196,\n",
       "         56778,  6403, 65068, 56844, 27858, 65057, 39990, 56873,  6507,\n",
       "          6517, 46507, 52272, 56879, 56941, 65095, 56952, 56649,  6142,\n",
       "         39507,  5633, 29083,  5671, 29079, 65313, 29069, 29022, 39578,\n",
       "         52352, 56427, 28937, 28843,  6153, 46763, 39657, 28671,  5933,\n",
       "          5943, 28639, 28581, 28495,  6037,  6065, 56634, 28340, 52315,\n",
       "          6115, 56481, 27619, 27575, 27560, 26512, 49616, 26489, 57443,\n",
       "          7400,  7440, 40282, 40290, 57492, 26244, 26234, 26190, 26182,\n",
       "         40201, 57515, 26161,  7613,  7731, 46060, 25932, 40398, 25864,\n",
       "          7787,  7808,  7852,  7859, 57681, 45957,  7567, 26603, 26818,\n",
       "         26868, 27522,  6715, 27503, 64935, 27478, 64926, 27427,  6789,\n",
       "         27415, 57048,  6852, 27370,  6859, 27358, 64846, 27261,  6899,\n",
       "          6909, 57089, 57109, 40117, 52185, 27140, 57144, 27070, 46309,\n",
       "         26913,  7163,  7168, 40468, 58837, 10422, 10454, 44078, 17602,\n",
       "         13650, 17527, 13661, 51000, 13666, 42986, 50991, 13686, 50969,\n",
       "         17432, 13727, 17632, 50921, 17242, 17233, 62264, 17066, 43975,\n",
       "         13948, 61207, 43955, 16903, 14005, 14009, 14015, 50560, 43080,\n",
       "         62182, 50520, 13514, 51075, 62625, 12992, 18780, 13026, 18746,\n",
       "         13059, 18675, 62564, 13119, 62540, 50375, 42720, 13533, 60605,\n",
       "         18352, 44306, 42779, 60733, 42834, 13375, 13395, 13398, 60759,\n",
       "         44215, 13477, 60810, 60862, 60614, 61224, 16841, 50572, 16017,\n",
       "         14772, 14802, 15981, 15959, 61561, 50648, 14869, 15820, 15795,\n",
       "         61968, 15697, 14989, 61452, 43495, 15508, 15028, 15043, 15081,\n",
       "         15093, 43548, 15454, 15128, 61898, 15207, 43558, 43599, 15234,\n",
       "         61931, 14712, 16115, 43387, 43899, 16753, 43165, 16708, 61263,\n",
       "         16671, 14219, 16638, 62137, 61269, 14336, 14348, 14360, 43815,\n",
       "         61353, 61360, 43783, 14496, 61400, 16352, 61418, 14583, 16327,\n",
       "         43336, 50613, 43748, 16267, 14691, 16186, 60442, 60396, 60381,\n",
       "         18990, 21291, 42020, 11192, 11204, 51405, 59433, 11310, 59447,\n",
       "         20887, 59494, 59504, 59511, 20738, 21341, 20705, 20703, 50148,\n",
       "         11521, 59629, 59649, 51363, 11580, 20451, 20450, 42254, 59713,\n",
       "         11640, 20293, 11456, 11147, 59208, 21377, 58839, 51673, 22026,\n",
       "         10500, 21909, 21857, 41739, 50077, 58922, 21768, 63359, 10644,\n",
       "         41752, 44933, 63332, 10695, 10753, 21682, 51555, 10841, 10858,\n",
       "         44896, 21649, 21635, 10996, 21608, 41837, 59164, 59197, 59720,\n",
       "         29197, 20260, 11743, 12449, 19390, 42591, 12543, 60135, 50270,\n",
       "         19272, 50274, 60224, 12601, 19245, 12608, 19237, 12437, 62808,\n",
       "         50276, 62781, 62780, 60311, 60314, 42610, 42615, 19100, 19044,\n",
       "         19043, 19026, 12798, 60366, 12630, 62923, 12403, 62939, 11755,\n",
       "         44696, 63074, 59832, 20146, 11875, 20145, 59861, 20125, 11938,\n",
       "         59916, 20033, 20014, 19970, 63028, 44662, 19801, 59976, 19740,\n",
       "         19684, 60000, 42425, 12199, 12228, 19554, 19551, 60099, 50233,\n",
       "         19404, 20232, 29322, 15302, 33069, 66824, 47296, 38802, 35278,\n",
       "         54029, 55561, 54092,   762, 55565, 32949, 34268,  1772,   741,\n",
       "         35465, 31010,  3002, 32866, 37474,  4020, 34346, 31253,  4103,\n",
       "         66217,  4117, 32780,   889, 65910,  4125, 37718,  1708, 38772,\n",
       "         32809,  1717,  4293, 30931,  1782, 65730,   649, 30658, 30625,\n",
       "         39000, 37285, 35748,  1884, 35820,   597,  1890, 66434, 35852,\n",
       "         35861,  4577, 34081, 37293,  4012, 48960,  2847, 38867, 48367,\n",
       "         38885, 34266, 67101, 33009, 54844,  1823, 54449, 30743, 66396,\n",
       "         53965,  2850, 52582, 30675, 53948, 31265, 55499, 65971,  1433,\n",
       "          3629, 47420, 47404,  1189, 47395, 38620,  1464, 54176, 31555,\n",
       "         55394, 66927, 48230, 53202, 54141,  3622,  3276, 31697, 31740,\n",
       "         47481, 55204, 66118, 31958,  3469, 54254, 34614, 37619,  1234,\n",
       "         54215, 55299, 32248,  3535,  3319,  3540, 55355,  4588, 31529,\n",
       "         34925, 67066, 34432, 48903, 37518, 37708, 47313, 35136, 48300,\n",
       "          3178,  3151, 48161, 67067, 31297,  3119, 34407, 55035,  1527,\n",
       "         37663, 66901, 38685, 38422, 32436, 31462, 34954, 67009, 66058,\n",
       "         34505, 54123, 55426, 31436, 66006,  3917, 67053,  3234,  3920,\n",
       "         30481, 34656,  4601, 33371, 48520, 55973,  2042,  2354,  2536,\n",
       "         36277, 33510,  4999, 38167, 33839, 33294, 65458, 30065, 39226,\n",
       "         33837, 52398, 38172, 33997, 39427,  5349, 37148,  5363, 65494,\n",
       "         55921, 47078, 67156, 36368,  5083, 36635,  2416,  5240, 56105,\n",
       "         33851, 29747, 66592,   138, 38152, 37879, 52473, 36537, 53722,\n",
       "         65396, 47012, 47975, 53395,  5285,  2078, 47045, 65428, 29645,\n",
       "         29634, 37873, 37123,   200, 36387, 47052, 30197, 67153, 33441,\n",
       "          2631, 33155, 34067, 39118,   457,  4826,  5429, 67151, 47088,\n",
       "          2004, 56195, 56220, 38186,  4798,  4796, 56243, 36058, 30331,\n",
       "         46921, 30369, 48638,  5490, 36918,  2265, 39459, 30458, 55832,\n",
       "         37151, 36113, 66489, 53006,  4872, 36822,  4849, 49165, 67274,\n",
       "         47079, 34003, 34002, 29538, 54615, 33551, 34652, 59551, 21088,\n",
       "         19308, 19200, 42045, 60242, 51138, 53172, 52998, 33757, 33721,\n",
       "         34645, 20799, 20669, 60234, 54285, 33816, 19331, 53004, 19231,\n",
       "         37897, 54277, 34585, 20898, 53177, 37644, 20964, 19252, 42064,\n",
       "         37650, 42605, 33847, 20684, 20632, 59517, 20395, 20572, 20216,\n",
       "         42335, 20017, 20016, 34142, 53072, 42331, 19953, 19922, 59781,\n",
       "         53123, 20270, 19853, 34001, 19942, 19788, 19111, 20214, 20182,\n",
       "         42328, 20147, 34098, 20187, 53051, 34016, 51292, 37815, 54472,\n",
       "         34124, 20099, 20205, 37828, 42314, 54588, 19759, 19716, 33953,\n",
       "         34365, 42220, 34367, 42558, 33952, 20175, 20492, 37680, 20548,\n",
       "         19367, 37669, 60120, 59640, 19398, 20305, 19476, 19509, 59979,\n",
       "         20310, 34278, 34296, 34310, 42429, 37712, 42467, 19579, 19575,\n",
       "         42480, 20361, 37866, 60092, 51304, 29323, 18174, 19064, 36037,\n",
       "         16529, 16511, 37155, 16506, 43227, 16476, 16473, 16466, 37199,\n",
       "         36078, 36086, 16389, 61365, 36155, 37141, 16336, 36198, 53746,\n",
       "         36222, 43240, 16272, 16645, 43190, 43142, 16946, 16923, 53899,\n",
       "         16902, 61219, 35756, 35766, 53818, 16647, 16826, 16774, 37255,\n",
       "         16744, 37236, 35908, 53805, 37216, 16666, 16656, 16820, 53739,\n",
       "         53305, 43378, 53654, 61749, 36746, 43508, 36750, 43520, 15477,\n",
       "         36753, 36764, 43504, 36964, 53534, 61818, 36957, 61836, 15408,\n",
       "         15360, 15347, 36804, 53475, 61817, 36614, 43485, 15610, 36328,\n",
       "         16101, 16027, 37102, 50745, 36440, 50736, 53376, 36567, 43478,\n",
       "         15850, 61597, 36571, 36574, 15796, 36578, 37033, 15761, 61612,\n",
       "         61633, 15647, 43140, 19098, 61164, 35542, 34928, 60560, 18627,\n",
       "         34969, 18611, 34989, 18543, 60610, 34992, 60496, 60628, 54099,\n",
       "         18331, 51046, 35107, 18227, 18200, 42830, 42835, 18124, 51052,\n",
       "         18113], dtype=int64),\n",
       "  'feature_absent_idx': array([20091, 20701, 53312, 53316, 53317, 20694, 53320, 53323, 20685,\n",
       "         53326, 53328, 53331, 20664, 20663, 20659, 53341, 53310, 20650,\n",
       "         53309, 20712, 20768, 20767, 53265, 53266, 53279, 20746, 20744,\n",
       "         20743, 20739, 53285, 20731, 53288, 20729, 53290, 20720, 20707,\n",
       "         53261, 20646, 20639, 53401, 20577, 20575, 20559, 53411, 20552,\n",
       "         20551, 53414, 53415, 20540, 20538, 53417, 53418, 20533, 20530,\n",
       "         20584, 20641, 53393, 20597, 53356, 20635, 53358, 53359, 53360,\n",
       "         53365, 20622, 20620, 20608, 20606, 53382, 53383, 20601, 20599,\n",
       "         53389, 53391, 53260, 20773, 20776, 20939, 53137, 20933, 53142,\n",
       "         53143, 20929, 20927, 20926, 53145, 20922, 53147, 53148, 53149,\n",
       "         20916, 20914, 20945, 20911, 20947, 53132, 20990, 20988, 20985,\n",
       "         20984, 20983, 20981, 20979, 20977, 20972, 20965, 53119, 53121,\n",
       "         20959, 53124, 53128, 20948, 20909, 20907, 20891, 53224, 53227,\n",
       "         53229, 20812, 53230, 53231, 20803, 53234, 20795, 53244, 20792,\n",
       "         20787, 20785, 53249, 53258, 20819, 53218, 20829, 20831, 20888,\n",
       "         53175, 20879, 53176, 53178, 20874, 53181, 20525, 20871, 53190,\n",
       "         53198, 20851, 20845, 20840, 20839, 53212, 53182, 53426, 53429,\n",
       "         20520, 53595, 20219, 53597, 53600, 53601, 53602, 53606, 53613,\n",
       "         20197, 20196, 53617, 20191, 53619, 20181, 20179, 20221, 20176,\n",
       "         20222, 53592, 53566, 53568, 20261, 53570, 53571, 20252, 20249,\n",
       "         20248, 20246, 20244, 20242, 53582, 53584, 53590, 53591, 20224,\n",
       "         53626, 53627, 20167, 20108, 53662, 20103, 53664, 20090, 20084,\n",
       "         53679, 20079, 20077, 53684, 53687, 53688, 20066, 53694, 53700,\n",
       "         20109, 53660, 53657, 20116, 53636, 53638, 53639, 20152, 20150,\n",
       "         20149, 53641, 20267, 53643, 20135, 20134, 53652, 20128, 20122,\n",
       "         20121, 20118, 53645, 53106, 20268, 53562, 53462, 53464, 20456,\n",
       "         20454, 20452, 53469, 53480, 20439, 20430, 53484, 20426, 53489,\n",
       "         20423, 20420, 20419, 20465, 20418, 20469, 20472, 20519, 20518,\n",
       "         53438, 20508, 53443, 20501, 20488, 53453, 53455, 20482, 53456,\n",
       "         20478, 53457, 20475, 20474, 20471, 53492, 20412, 20411, 20316,\n",
       "         20315, 20313, 53547, 20302, 20301, 20300, 20299, 53552, 20294,\n",
       "         20290, 53556, 53560, 20281, 53561, 20317, 20321, 20327, 20331,\n",
       "         20409, 20403, 20396, 53502, 53508, 20374, 53511, 53565, 20372,\n",
       "         53515, 53516, 20352, 20350, 53523, 53526, 53529, 53513, 53103,\n",
       "         53100, 21011, 21623, 21610, 21607, 21603, 52695, 52698, 21593,\n",
       "         21584, 21579, 21578, 52714, 52718, 21571, 21564, 52721, 21626,\n",
       "         52725, 52680, 21632, 52661, 52662, 21663, 21660, 52664, 21656,\n",
       "         21654, 52669, 21648, 52671, 21641, 21640, 52676, 21636, 52679,\n",
       "         21631, 21561, 52728, 52733, 21496, 21491, 21490, 52780, 52785,\n",
       "         21479, 21478, 52786, 52790, 52791, 21473, 52795, 52798, 52810,\n",
       "         21459, 52774, 52767, 21503, 52766, 52734, 21543, 52738, 52740,\n",
       "         21528, 21526, 52751, 21668, 21524, 21522, 21518, 21514, 52761,\n",
       "         52764, 21507, 21505, 52753, 21458, 21684, 21691, 52543, 52544,\n",
       "         21848, 21846, 52547, 52548, 52556, 21834, 21832, 21829, 21826,\n",
       "         52562, 21821, 21816, 52580, 52541, 52581, 52539, 21863, 21922,\n",
       "         52493, 52501, 21906, 52503, 52508, 52518, 21897, 21894, 21880,\n",
       "         21879, 21878, 21874, 21866, 52535, 52537, 52585, 21808, 21807,\n",
       "         21741, 52619, 52620, 52623, 21726, 21724, 52627, 21720, 21718,\n",
       "         21710, 52635, 21702, 21700, 21697, 52637, 52616, 21747, 21757,\n",
       "         52604, 21804, 21801, 21798, 52591, 21796, 52595, 52596, 52640,\n",
       "         21787, 21783, 52599, 21781, 21780, 21773, 52603, 21767, 21784,\n",
       "         53703, 52813, 21455, 21175, 21171, 52996, 21165, 21164, 52997,\n",
       "         53008, 53012, 21149, 21148, 53013, 21146, 53019, 21137, 21135,\n",
       "         21178, 21134, 52991, 21188, 52961, 21221, 21220, 52963, 21218,\n",
       "         52965, 21215, 52966, 21209, 52975, 21202, 21200, 52977, 52979,\n",
       "         52982, 52990, 53020, 21129, 21128, 21071, 53055, 21068, 21066,\n",
       "         21064, 21060, 53074, 21036, 21030, 53087, 21026, 21020, 21019,\n",
       "         21016, 53092, 53049, 53047, 21083, 21084, 21125, 21124, 21123,\n",
       "         21122, 53027, 53028, 21116, 21227, 53030, 53036, 53039, 21100,\n",
       "         53040, 53042, 21086, 21085, 53033, 21456, 21228, 21234, 21392,\n",
       "         21389, 52859, 21381, 52864, 21372, 21370, 52868, 21367, 21365,\n",
       "         52869, 52871, 21353, 21349, 52884, 52855, 52885, 21400, 21405,\n",
       "         52814, 21451, 21448, 52821, 21441, 52831, 21430, 21424, 21421,\n",
       "         52840, 21418, 21415, 52842, 21411, 21410, 21403, 21345, 21343,\n",
       "         21342, 21275, 21271, 21269, 21266, 21264, 52938, 52939, 21251,\n",
       "         52942, 52946, 21244, 52947, 21242, 52958, 21235, 52933, 52919,\n",
       "         52914, 21305, 21340, 52888, 52892, 52893, 21333, 52895, 21330,\n",
       "         21231, 52898, 21323, 21322, 21321, 21319, 52905, 52906, 52909,\n",
       "         21324, 52492, 53705, 53708, 54519, 54520, 54525, 18867, 18864,\n",
       "         18860, 18856, 18855, 18850, 18847, 18841, 54542, 54546, 54547,\n",
       "         18832, 54518, 18830, 18880, 18887, 54483, 18919, 54485, 18912,\n",
       "         18911, 54490, 54491, 54493, 54495, 18898, 54497, 18894, 54499,\n",
       "         54503, 18889, 54509, 54480, 54550, 54558, 54614, 54616, 18733,\n",
       "         18732, 18727, 54623, 54625, 18718, 54629, 18715, 18714, 18712,\n",
       "         54632, 18707, 18700, 18750, 18826, 18761, 18765, 54559, 54560,\n",
       "         54562, 18808, 54564, 54566, 18796, 18794, 54568, 18791, 54571,\n",
       "         54573, 18783, 18778, 18773, 54587, 54477, 18938, 54476, 19088,\n",
       "         19087, 19086, 19085, 19084, 19083, 19080, 19079, 54379, 19074,\n",
       "         19052, 19051, 54396, 54399, 19045, 54372, 54400, 54369, 19103,\n",
       "         54318, 54319, 19159, 54337, 19149, 19135, 19132, 19127, 19124,\n",
       "         19123, 54350, 19119, 54351, 54354, 54361, 54365, 19040, 54402,\n",
       "         19038, 54445, 18973, 54452, 54457, 54465, 18960, 54470, 18954,\n",
       "         18953, 18952, 18951, 18948, 18947, 18946, 18942, 18977, 18979,\n",
       "         18980, 54438, 54404, 19036, 19031, 54406, 19021, 54412, 54413,\n",
       "         54639, 54418, 54430, 19001, 18998, 54433, 18993, 18992, 18989,\n",
       "         54419, 54641, 18694, 54646, 18392, 18391, 18389, 54849, 18383,\n",
       "         18376, 18371, 18370, 18369, 18361, 54868, 18355, 54870, 54871,\n",
       "         18344, 54842, 18343, 54840, 18400, 18451, 54809, 54811, 54814,\n",
       "         54816, 54820, 54822, 18426, 18423, 18422, 18420, 18412, 54831,\n",
       "         54837, 18402, 54838, 54878, 18337, 18336, 54943, 18255, 18254,\n",
       "         18253, 54952, 18247, 54962, 18239, 18237, 18236, 54966, 18232,\n",
       "         18226, 18223, 54975, 18267, 54940, 54935, 18283, 18334, 54880,\n",
       "         18332, 18330, 54882, 18324, 54890, 18469, 18315, 18304, 54907,\n",
       "         54909, 54912, 18294, 54915, 54922, 54892, 19173, 54795, 54781,\n",
       "         18640, 54688, 54694, 18630, 18624, 18623, 18622, 18619, 18617,\n",
       "         18616, 54700, 18610, 54702, 54705, 54712, 54678, 18596, 54675,\n",
       "         18650, 18691, 54650, 54651, 54653, 54655, 18678, 18670, 18668,\n",
       "         54665, 18665, 54666, 18661, 18660, 18656, 54670, 18648, 54715,\n",
       "         18592, 54718, 18531, 54755, 18529, 18521, 18520, 18518, 18516,\n",
       "         18511, 54767, 18501, 18494, 54775, 54776, 18487, 54780, 18535,\n",
       "         18536, 54753, 54752, 18589, 54719, 54723, 18584, 18578, 54730,\n",
       "         54734, 54789, 54735, 54738, 54741, 18551, 18550, 54746, 54748,\n",
       "         18542, 54736, 54306, 19181, 19184, 53939, 53941, 53942, 19750,\n",
       "         19748, 19745, 53943, 53945, 53946, 19739, 53950, 53952, 53953,\n",
       "         19726, 19725, 19758, 53956, 19763, 53933, 19825, 53892, 53893,\n",
       "         53896, 53900, 53902, 53910, 19802, 53913, 53916, 19791, 53927,\n",
       "         19779, 53929, 19770, 19765, 53959, 19719, 19717, 53993, 53994,\n",
       "         19663, 19661, 19660, 19654, 19651, 19646, 54009, 54010, 19640,\n",
       "         19639, 54013, 19636, 54015, 53990, 53988, 53987, 19677, 19714,\n",
       "         53962, 53964, 19709, 53966, 53967, 19706, 53891, 19701, 53970,\n",
       "         19697, 19696, 19695, 19691, 53975, 19687, 53969, 54016, 53890,\n",
       "         53885], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_medium': {'feature_present_idx': array([50340, 65807, 66354, 21024, 16925, 36408, 23463, 18349, 34965,\n",
       "         23487, 28616, 12674, 27125, 40128, 27669, 48808, 18188, 45350,\n",
       "         50226, 17380, 12055, 36228, 46260, 46303, 12954, 62389, 17207,\n",
       "         18450, 33863, 19482, 27769, 39511, 26833, 26515, 37662, 41476,\n",
       "         25253, 45156, 22619, 42570, 42868, 44142, 44164, 11908, 44951,\n",
       "         19498, 22600, 20208, 15240,  6275,  8608,  8325,  8213,  8053,\n",
       "         53347, 53594, 53021, 54078,  6449, 50869, 66587,  6216, 56281,\n",
       "          5295,  3343, 57238, 56184,  1206, 10173, 52994, 32733, 10520,\n",
       "         65071, 58219, 57653, 57477,  4597, 23046,  3361, 39964,  1039,\n",
       "          1736, 42477, 40642,  1920, 27068, 25113, 56969,  2864, 41223,\n",
       "         63328, 61015, 26975, 60463, 57002, 33661, 42279, 26014, 11216,\n",
       "         46771, 35962, 52100, 12119, 12486, 49972, 59650, 49351, 52197,\n",
       "         13530, 14570, 49086, 14872, 66738, 31318, 37288, 62303, 16399,\n",
       "         66390, 35920,  5958, 19627, 54598, 16076, 18725, 33050, 17434,\n",
       "         17051, 59329, 37001, 45661, 18683, 38031, 37075, 28252, 38994,\n",
       "         57416, 56908, 55300, 58977, 52033, 51388, 49212, 38483, 47226,\n",
       "         59961, 34697, 44013, 43479, 42762, 40801, 39451, 47127, 45510,\n",
       "         58456, 33828, 25046, 23849, 21211, 19711, 17919, 34494, 16045,\n",
       "         15616, 15375, 15339, 12521, 64799, 10728,  8746,  8223,  7891,\n",
       "          6865, 66279,  5370,  2420,  2018, 25545, 62574, 16643, 28845,\n",
       "         30355, 29626, 29122, 30890, 31286, 13684, 47141, 14761, 27397,\n",
       "         12628, 12626, 49893, 61970, 10694, 10648, 52329, 29796, 31732,\n",
       "         31946, 35960, 54325, 33326, 35407, 55493, 56027,  2551, 57862,\n",
       "         64863, 63508, 31472, 29794, 40145, 40453, 40491, 26592, 26225,\n",
       "         25373, 41490, 38990, 38821, 37641, 21369, 60157, 22533, 16492,\n",
       "         38256, 45548, 11049,  1054,  1076, 35298, 26843,  2980,  2983,\n",
       "          4230,  5187, 47062, 55253, 60644, 43383, 14805, 19465, 10929,\n",
       "         36877, 43120, 29340,  6708, 21046, 21236,  8954, 21013, 21010,\n",
       "         59234, 65525, 52849, 62460, 61781, 64414, 66981, 54014,  3620,\n",
       "          5275,  6656,  7658,  9224, 15424, 25728, 58314, 27255, 29586,\n",
       "         27137, 37667, 30410, 46429, 49773, 53189, 28960, 53444, 15497,\n",
       "         12016,  6935,  5518, 40418, 37289, 10495, 43054, 33339,   106],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([20533, 17163, 17162, 59749, 39306, 17161, 54144, 36549, 26987,\n",
       "         17159, 59744, 46588, 59754, 46589, 26982, 49978, 59739,  9942,\n",
       "         46591, 59738, 17156, 59737, 59736, 59734, 36548, 26983, 49976,\n",
       "         59755, 59756, 27013, 59774, 22612, 17177,  9897, 59771, 54131,\n",
       "         46572, 59767, 46573, 17173, 46582, 46575, 54133, 22616, 27000,\n",
       "         17169, 54138, 22617,  9915, 33892, 34554,  9918, 17165, 59764,\n",
       "         17179, 17154,  9953, 54156, 46617,  9987,  9988, 54158, 17139,\n",
       "         54159, 26948,  9994, 33904, 34552, 33903, 59698, 10001, 46632,\n",
       "         10003, 10004, 35371, 36538, 54164, 26940, 17132, 22634, 40884,\n",
       "         59691, 26974, 35369, 59710, 39311, 22624, 17152, 34553, 59725,\n",
       "         46602, 46603,  9963,  9964, 41376, 26965,  9982, 17148, 41375,\n",
       "         17146, 54152, 46609,  9973, 36544,  9975, 59714,  9978, 33902,\n",
       "          9980, 49973, 26936,  9891, 54128,  9795, 59852, 49999, 22590,\n",
       "         27066, 33878, 22591, 46530, 17209,  9804, 59846, 59853, 27061,\n",
       "          9808, 17208,  9811,  9812, 59843, 54109, 33880,  9816, 17204,\n",
       "         46536,  9820, 59845, 46538, 50000, 22586,  9766, 54098, 46518,\n",
       "         59870,  9770,  9771, 59868, 35358, 27076, 59866, 27075,  9792,\n",
       "          9777, 59864,  9780, 39298,  9782,  9784, 17216,  9786,  9787,\n",
       "         17215, 39299, 36565,  9778, 36556, 59840, 54111, 59808, 49985,\n",
       "         46558, 54125, 17184, 59803, 33887, 46563,  9870, 46564, 59799,\n",
       "         59809, 59797, 59795, 27022, 59793, 33888, 33889, 59786, 27018,\n",
       "         59783, 39303, 59780, 59779, 59796,  9823, 59810, 22604, 17201,\n",
       "          9826, 46542, 49994, 34556, 59837, 27046, 46546, 54113,  9835,\n",
       "         33883,  9856, 59828, 36561, 59825,  9845,  9846, 27037,  9848,\n",
       "         59821, 59820, 59817, 33885, 49988, 59827, 27080, 59678, 49960,\n",
       "         49923, 22681, 59529, 36505, 46712, 22682, 22683, 10187, 22684,\n",
       "         10189, 10190, 10177, 10191, 26831, 26829, 59519, 36502, 26826,\n",
       "         26825, 26824, 10203, 17056, 10205, 59515, 54223, 26822, 59537,\n",
       "         17070, 26863, 17080, 59565, 22671, 26860, 10150, 59564, 10153,\n",
       "         26858, 36510, 17077, 46703, 22673, 54213, 26854, 35380, 59555,\n",
       "         49931, 17072, 26850, 26848, 59547, 59544, 26847, 59560, 54209,\n",
       "         17055, 17053, 22699, 10249, 10250, 46729, 46730, 26794, 59479],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 288\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 288\n",
       "  })},\n",
       " 'contains_mod': {'feature_present_idx': array([30320, 13969, 56810, 45496, 45495, 56812, 28545, 28549, 13954,\n",
       "         45490, 28553, 28556, 13946, 56821, 13942, 13940, 28560, 56826,\n",
       "         28585, 56839, 28582, 28574, 28573, 13911, 13971, 13917, 56832,\n",
       "         13925, 13926, 13927, 28564, 45466, 28572, 56807, 13977, 56806,\n",
       "         45525, 14032, 28499, 14045, 56763, 28497, 14025, 14049, 14052,\n",
       "         45528, 56756, 56755, 56754, 14065, 56758, 13903, 14023, 14019,\n",
       "         13984, 56804, 13987, 56800, 45508, 56793, 45518, 45513, 14004,\n",
       "         56785, 14008, 45516, 14011, 28510, 14001, 14066, 13899, 13889,\n",
       "         56920, 13784, 56926, 45368, 56946, 45365, 56949, 13757, 13752,\n",
       "         13751, 28691, 28693, 28695, 28696, 28709, 28710, 13739, 57013,\n",
       "         57010, 45326, 57009, 45332, 28722, 28665, 13723, 56995, 45345,\n",
       "         13734, 45346, 28711, 13738, 28721, 13803, 56916, 13807, 45389,\n",
       "         28636, 56871, 28629, 45395, 13860, 13846, 56864, 56858, 45404,\n",
       "         45417, 28610, 13886, 45436, 28620, 56849, 45385, 56883, 56910,\n",
       "         45372, 13817, 56904, 56903, 56902, 28646, 28659, 13824, 28656,\n",
       "         56892, 45377, 45378, 13839, 13822, 56751, 56749, 56740, 28314,\n",
       "         14373, 56543, 45688, 14358, 56546, 56547, 45686, 14347, 45681,\n",
       "         28335, 45677, 14337, 45676, 14329, 45663, 45657, 14281, 56582,\n",
       "         56581, 28367, 14298, 14301, 14379, 56578, 45649, 28359, 28358,\n",
       "         14316, 45651, 56568, 28364, 14381, 28311, 56541, 28268, 14442,\n",
       "         14446, 45734, 14452, 28255, 56500, 14465, 56449, 28243, 14479,\n",
       "         56444, 56433, 14489, 14468, 56583, 14432, 56504, 14392, 14394,\n",
       "         28309, 56538, 56536, 28305, 56503, 56532, 45709, 45714, 28289,\n",
       "         14416, 28283, 28281, 14405, 28379, 14271, 14270, 14107, 28442,\n",
       "         45579, 56690, 14123, 56689, 28455, 28438, 14138, 56684, 14144,\n",
       "         14148, 56683, 56677, 28437, 45586, 45572, 28458, 14075, 28481,\n",
       "         45536, 56739, 56738, 28474, 56716, 28470, 45564, 14095, 56729,\n",
       "         14097, 14100, 28460, 14090, 13697, 14161, 28430, 28396, 14236,\n",
       "         28394, 14238, 45636, 28392, 56611, 56597, 45641, 28385, 14258,\n",
       "         28384, 28380, 14269, 14252, 56669, 56625, 45632, 14180, 56655,\n",
       "         28424, 28422, 14194, 14198, 14228, 56646, 45604, 14211, 14212,\n",
       "         28414, 56629, 45610, 14203, 28733, 57023, 13687, 57529, 13170,\n",
       "         13165, 57531, 29099, 29106, 45012, 57540, 29116, 29120, 13141,\n",
       "         45010, 29124, 44998, 57560, 13130, 44986, 29168, 57583, 44960,\n",
       "         29162, 29159, 13110, 13180, 57577, 13118, 44965, 29155, 29143,\n",
       "         13127, 44975, 57576, 45042, 29080, 13186, 13238, 57452, 45079,\n",
       "         29049, 13250, 45090, 29052, 45098, 45102, 57424, 13266, 57419,\n",
       "         57418, 57410, 13258, 57585, 13236, 29056, 57509, 45052, 13195,\n",
       "         45053, 13199, 13206, 29055, 29066, 13213, 57481, 57465, 13223,\n",
       "         29063, 29059, 57482, 29173, 13089, 44956, 29274, 44894, 29272,\n",
       "         57721, 29263, 12965, 29276, 29260, 44905, 12990, 44907, 12994,\n",
       "         57703, 57698, 12972, 57696, 57738, 44887, 57763, 12899, 29301,\n",
       "         12903, 12906, 12911, 12940, 57760, 29293, 44881, 57748, 12924,\n",
       "         29288, 12931, 29295, 45105, 13001, 57687, 29202, 57630, 57627,\n",
       "         57620, 13068, 13069, 44943, 57612, 44947, 57603, 29180, 13083,\n",
       "         44953, 13087, 29190, 29238, 57644, 13043, 29233, 57678, 57677,\n",
       "         57660, 29232, 44910, 29209, 44911, 29225, 29220, 13032, 57649,\n",
       "         29217, 13039, 13022, 56431, 45115, 29014, 57147, 28828, 28829,\n",
       "         13563, 28832, 13553, 13552, 57159, 45235, 57161, 57164, 57165,\n",
       "         28842, 45231, 57172, 28854, 13525, 57202, 45195, 13482, 45198,\n",
       "         45205, 13499, 45256, 13501, 57182, 28866, 28857, 13518, 57174,\n",
       "         13523, 28871, 57136, 13586, 13588, 13644, 13649, 28764, 13660,\n",
       "         28753, 57049, 28780, 45293, 45295, 28745, 13677, 57036, 13682,\n",
       "         28737, 13668, 13475, 28782, 13635, 13592, 13598, 28809, 13600,\n",
       "         57119, 13605, 57087, 57110, 45272, 57105, 57102, 28796, 28794,\n",
       "         13633, 13609, 28885, 57207, 13465, 28985, 45137, 13340, 13342,\n",
       "         13348, 57342, 13332, 28978, 57335, 57333, 13361, 57330, 45141,\n",
       "         28970, 57337, 45145, 45134, 57347, 57398, 57393, 29010, 29009,\n",
       "         13291, 13296, 45133, 13300, 13309, 45126, 13319, 57357, 28995,\n",
       "         13324, 45125, 13279, 28963, 45153, 57250, 57248, 28911, 13438,\n",
       "         57244, 28908, 13430, 57240, 13453, 28904, 57229, 28889, 45189,\n",
       "         28886, 57235, 45149, 13428, 28921, 45158, 45166, 57312, 57304,\n",
       "         45169, 57294, 28912, 57288, 28945, 28943, 57278, 28938, 13409,\n",
       "         13412, 45174, 28236, 28235, 14507, 15650, 15648, 46337, 27496,\n",
       "         15644, 15643, 55541, 15639, 27497, 55544, 46330, 15627, 27507,\n",
       "         15622, 15618, 27509, 27510, 46308, 46311, 55566, 15589, 15591,\n",
       "         15593, 27492, 15595, 15599, 46321, 46323, 15609, 15612, 55559,\n",
       "         15597, 15653, 55535, 15655, 27446, 46401, 55458, 55456, 27438,\n",
       "         55446, 55469, 15740, 46409, 27425, 27422, 55418, 15757, 27419,\n",
       "         46408, 55574, 46388, 15707, 46338, 15665, 27490, 27487, 55516,\n",
       "         55509, 27461, 55504, 55492, 46358, 27472, 55485, 46380, 15702,\n",
       "         55502, 46301, 46298, 15555, 46251, 55683, 27617, 27610, 46253,\n",
       "         46255, 46249, 27603, 27600, 15464, 55671, 55668, 55665, 15475,\n",
       "         27601, 27587, 55688, 55691, 46211, 15396, 27661, 15400, 55716,\n",
       "         55710, 15438, 55703, 15418, 46245, 15421, 55700, 15425, 46248,\n",
       "         27646, 55410, 55661, 15482, 27553, 46285, 27550, 27547, 27545,\n",
       "         55614, 15525, 46293, 15545, 55598, 27542, 46297, 55584, 27539,\n",
       "         55602, 15481, 27554, 15518, 15487, 46273, 55658, 27569, 46276,\n",
       "         55637, 27556, 46278, 55633, 15505, 55632, 55631, 55626, 15513,\n",
       "         15501, 15393, 27418, 15764, 55187, 46569, 55207, 27222, 46560,\n",
       "         16020, 16019, 27224, 46556, 55210, 27226, 46555, 55217, 16006,\n",
       "         46540, 55226, 27243, 15941, 15944, 46521, 55265, 55259, 15962,\n",
       "         46574, 46522, 46531, 15980, 15983, 55242, 27246, 55231, 55254,\n",
       "         46576, 16039, 27207, 16085, 16086, 16087, 16090, 27175, 55137,\n",
       "         27179, 55133, 46608, 46610, 55127, 16116, 55126, 16121, 55131,\n",
       "         15940, 16080, 27182, 27206, 27205, 16048, 27195, 55161, 16058,\n",
       "         55141, 55157, 55152, 55149, 46593, 55145, 16074, 27184, 27192,\n",
       "         27278, 27282, 46516, 15814, 15817, 15819, 46422, 46424, 15828,\n",
       "         55388, 27369, 55359, 55357, 55356, 55352, 27354, 55346, 15832,\n",
       "         46448, 46415, 27390, 27412, 15769, 15771, 15772, 15778, 15781,\n",
       "         27387, 15782, 15785, 15788, 55402, 46411, 27404, 46413, 55406,\n",
       "         27416, 15856, 27336, 15900, 46478, 55302, 15910, 55298, 27300,\n",
       "         46476, 15915, 46498, 46501, 27292, 46508, 46515, 55281, 27297,\n",
       "         55339, 55314, 55316, 27335, 46451, 46452, 15869, 15870, 27328,\n",
       "         15895, 27326, 15877, 15883, 46455, 46460, 27320, 15892, 55320,\n",
       "         12896, 15386, 55727, 28019, 56180, 28021, 56193, 14823, 28033,\n",
       "         14821, 56200, 56201, 28035, 14809, 28040, 45873, 56223, 56226,\n",
       "         28055, 45857, 45834, 14745, 14746, 28107, 45841, 45842, 45882,\n",
       "         28075, 56259, 45855, 56254, 14773, 28062, 14778, 56265, 28014,\n",
       "         14849, 56171, 56094, 45970, 56077, 56075, 56073, 56071, 45965,\n",
       "         45987, 14944, 14948, 27943, 56057, 56056, 56052, 27948, 14737,\n",
       "         27960, 56100, 14856, 14870, 27991, 45918, 56139, 14882, 56097,\n",
       "         27986, 27978, 45956, 56110, 45962, 14907, 56104, 45949, 45833,\n",
       "         56282, 45832, 28192, 56363, 28189, 56359, 45776, 14592, 28197,\n",
       "         45777, 14604, 14609, 28169, 56342, 14622, 14623, 45780, 14624,\n",
       "         56375, 56382, 14508, 45749, 56421, 45760, 56417, 56414, 28200,\n",
       "         14537, 28203, 56390, 56384, 28201, 14558, 14559, 45766, 56050,\n",
       "         28165, 14630, 14696, 14697, 14701, 56311, 14703, 56310, 45816,\n",
       "         45827, 14721, 14722, 14726, 56284, 14729, 56283, 14714, 45791,\n",
       "         14687, 14680, 28160, 45795, 14647, 28156, 56325, 28152, 56314,\n",
       "         56319, 14663, 28147, 14670, 14673, 56317, 45814, 45805, 55726,\n",
       "         56047], dtype=int64),\n",
       "  'feature_absent_idx': array([35509, 50885, 30543, 50883, 18176, 50882, 50877, 18180, 50872,\n",
       "         18185, 30542, 50862, 50861, 18195, 39969, 50853, 39972, 39973,\n",
       "         50849, 18202, 18204, 50848, 30535, 30534, 50887, 18213, 50892,\n",
       "         18156, 18112, 39942, 18115, 39952, 18119, 30552, 18126, 18127,\n",
       "         50911, 39954, 50907, 50906, 50905, 18137, 50904, 18143, 50900,\n",
       "         50898, 30546, 18149, 18151, 18152, 50896, 18160, 18218, 50843,\n",
       "         39974, 50799, 50797, 50796, 18294, 50795, 18304, 50792, 50790,\n",
       "         50788, 18315, 39995, 50781, 18324, 18330, 50773, 18332, 18334,\n",
       "         50771, 18336, 18337, 50769, 18343, 18344, 39984, 18283, 50806,\n",
       "         50807, 18223, 18226, 39975, 18232, 50835, 18236, 18237, 39977,\n",
       "         18239, 50829, 50828, 50923, 50824, 18247, 18253, 18254, 18255,\n",
       "         50821, 50819, 50816, 50815, 18267, 30524, 39979, 30527, 50768,\n",
       "         18110, 18108, 51098, 17932, 51091, 17934, 39890, 17936, 17940,\n",
       "         51086, 17947, 17948, 51079, 51068, 17958, 51066, 30589, 17971,\n",
       "         51059, 51055, 17977, 17978, 17984, 39902, 30585, 51101, 39907,\n",
       "         30600, 17924, 30622, 39879, 51159, 30614, 51151, 51148, 30612,\n",
       "         39882, 17888, 30608, 51136, 51135, 17899, 17905, 51127, 39886,\n",
       "         17911, 17912, 39888, 30601, 51112, 17921, 51108, 17928, 30582,\n",
       "         17996, 30581, 50966, 18067, 18073, 50962, 18077, 50961, 39938,\n",
       "         50953, 18084, 50949, 18086, 18088, 30559, 18090, 50943, 30558,\n",
       "         18096, 39940, 50938, 50934, 50930, 18105, 18107, 18061, 50972,\n",
       "         18056, 18054, 51033, 30577, 51021, 18006, 51018, 18010, 18011,\n",
       "         18012, 18013, 51017, 51004, 18109, 30576, 18023, 50999, 18031,\n",
       "         39919, 50988, 18037, 50986, 18042, 50980, 50978, 50976, 51001,\n",
       "         51167, 30513, 30511, 18660, 18661, 18665, 18668, 18670, 50515,\n",
       "         50512, 18678, 50507, 50506, 50498, 50496, 18691, 18694, 30414,\n",
       "         18700, 50493, 40093, 40095, 30404, 18707, 30403, 50479, 40088,\n",
       "         40109, 50523, 18656, 50558, 50555, 18616, 18617, 50554, 18619,\n",
       "         18622, 18623, 18624, 50553, 50552, 18630, 40083, 50541, 30429,\n",
       "         50535, 18640, 30428, 40086, 18648, 18650, 50527, 50526, 30420,\n",
       "         18712, 50476, 18714, 50432, 50430, 18783, 30387, 50427, 18791,\n",
       "         50424, 30385, 18794, 50422, 18796, 40129, 30383, 50406, 50405,\n",
       "         50403, 18808, 50400, 40139, 50393, 18826, 50392, 18830, 18778,\n",
       "         50434, 30389, 18773, 18715, 18718, 50475, 18727, 30398, 18732,\n",
       "         18733, 40119, 50465, 50463, 50462, 18610, 50460, 50458, 50457,\n",
       "         18750, 40127, 50452, 50450, 18761, 50448, 18765, 50446, 50442,\n",
       "         50459, 50764, 50561, 50566, 50722, 50719, 30489, 18420, 50711,\n",
       "         18422, 18423, 18426, 50709, 50706, 30488, 50704, 40011, 30483,\n",
       "         18451, 50696, 50689, 50688, 50677, 40023, 50672, 18469, 40028,\n",
       "         50723, 40033, 18412, 18402, 30510, 39998, 30508, 30506, 18355,\n",
       "         50750, 18361, 18369, 18370, 18371, 40001, 18376, 50747, 40002,\n",
       "         50742, 18383, 30499, 50738, 18389, 18391, 18392, 50737, 18400,\n",
       "         50728, 50652, 50650, 50649, 18550, 18551, 30446, 50596, 50594,\n",
       "         50593, 50592, 50591, 50588, 50585, 50581, 18578, 30442, 50578,\n",
       "         18584, 40077, 50575, 18589, 18592, 30438, 50571, 18596, 30436,\n",
       "         50600, 50601, 50603, 18542, 18487, 40044, 40047, 18494, 50644,\n",
       "         50642, 50640, 18501, 50635, 50629, 18511, 50564, 30460, 18518,\n",
       "         18520, 18521, 30459, 50616, 40058, 18529, 18531, 18535, 18536,\n",
       "         50606, 18516, 18832, 51177, 51183, 51791, 17293, 51788, 17296,\n",
       "         51785, 51784, 30816, 39711, 51770, 30810, 17318, 17319, 51767,\n",
       "         17321, 17322, 30804, 17324, 30803, 17330, 30801, 51753, 30797,\n",
       "         17338, 51793, 30796, 17288, 17286, 17241, 30837, 17244, 17247,\n",
       "         17248, 30834, 30826, 17252, 39703, 17254, 51820, 51819, 30823,\n",
       "         51810, 51809, 17265, 17266, 39706, 17278, 51807, 51806, 39708,\n",
       "         51799, 17287, 17343, 17344, 51747, 17402, 30778, 51685, 17408,\n",
       "         39757, 30776, 17415, 17417, 17420, 17421, 17423, 17424, 51675,\n",
       "         39768, 17428, 17429, 51671, 51669, 17435, 51665, 17437, 17438,\n",
       "         17439, 17401, 17399, 30780, 17396, 51743, 51742, 30795, 17353,\n",
       "         17355, 51731, 39735, 51727, 30792, 51721, 39736, 17240, 17367,\n",
       "         17369, 51718, 51712, 51709, 39748, 51705, 30786, 17384, 17389,\n",
       "         30784, 17392, 39739, 51661, 17235, 51853, 39666, 17072, 51987,\n",
       "         17077, 51978, 17080, 51977, 30865, 51972, 51968, 17090, 30861,\n",
       "         51958, 51957, 39674, 51954, 39685, 51945, 17105, 39690, 51943,\n",
       "         51941, 17111, 17070, 51937, 51992, 30872, 52050, 17006, 52048,\n",
       "         52047, 52046, 17019, 52043, 17027, 52037, 30881, 17037, 52023,\n",
       "         52016, 39663, 30875, 17050, 52011, 30874, 17053, 39665, 17055,\n",
       "         17056, 51998, 30871, 17113, 51935, 17116, 17179, 51895, 17184,\n",
       "         51886, 30844, 30843, 51878, 51877, 39696, 51868, 17201, 17204,\n",
       "         17208, 17209, 51867, 39700, 17215, 17216, 51859, 51856, 17227,\n",
       "         17228, 30840, 17177, 17173, 17169, 51900, 17118, 51933, 51928,\n",
       "         51924, 51922, 17125, 39692, 17132, 17139, 30851, 17146, 51848,\n",
       "         17148, 51914, 17152, 17154, 30849, 17156, 51909, 17159, 17161,\n",
       "         17162, 17163, 17165, 51915, 51180, 51660, 30768, 30668, 17708,\n",
       "         17710, 51358, 51356, 30664, 51352, 17721, 51351, 51348, 51344,\n",
       "         30663, 17731, 30661, 17735, 17737, 51337, 17740, 17742, 17743,\n",
       "         51333, 30660, 39843, 35513, 51317, 51370, 17698, 51428, 51427,\n",
       "         17659, 51425, 39835, 51419, 51415, 17667, 51411, 17671, 30670,\n",
       "         17679, 17680, 51403, 17683, 51402, 51392, 51391, 51389, 51384,\n",
       "         51382, 51377, 51376, 51375, 17758, 17759, 51303, 39856, 51264,\n",
       "         51262, 51260, 30643, 30642, 51248, 17828, 39865, 30637, 51234,\n",
       "         17838, 30636, 30635, 30633, 51199, 39875, 51195, 17856, 51190,\n",
       "         30627, 39877, 17862, 51267, 51268, 51269, 17800, 39849, 51300,\n",
       "         17769, 17772, 51299, 17774, 17775, 51295, 17779, 51286, 51280,\n",
       "         30678, 17782, 17784, 17785, 39850, 17788, 17790, 17792, 30651,\n",
       "         51275, 51274, 39851, 17799, 17783, 39771, 30679, 17648, 39787,\n",
       "         51585, 17512, 17513, 30742, 30737, 51578, 51572, 17519, 30735,\n",
       "         17521, 17522, 17523, 30734, 17525, 17526, 30732, 51558, 17530,\n",
       "         17532, 17533, 51557, 17540, 51593, 39791, 17502, 39783, 17449,\n",
       "         51646, 51638, 39775, 30762, 17458, 17462, 51632, 30760, 17465,\n",
       "         17466, 30759, 17469, 51620, 17471, 17475, 30756, 17478, 30755,\n",
       "         17491, 17492, 39781, 39782, 17497, 39799, 17545, 51552, 17608,\n",
       "         51489, 17614, 17615, 17616, 51485, 51484, 51482, 39816, 51474,\n",
       "         51473, 17627, 51469, 39817, 51463, 51459, 39818, 51453, 51452,\n",
       "         39823, 51446, 51440, 51439, 17606, 39813, 17603, 30698, 17549,\n",
       "         30719, 51540, 30716, 17558, 30706, 17563, 17564, 51526, 17570,\n",
       "         51523, 51436, 30705, 51513, 17581, 17583, 17584, 17587, 51508,\n",
       "         51506, 17592, 30700, 17596, 17600, 30701, 17001, 50391, 50389,\n",
       "         49235, 40475, 20066, 30007, 20077, 20079, 20084, 30005, 30004,\n",
       "         49226, 40481, 20090, 20091, 49219, 49216, 49215, 20103, 40484,\n",
       "         29997, 20108, 20109, 49202, 49196, 49241, 20116, 20052, 20038,\n",
       "         19994, 19996, 19999, 49294, 49291, 49290, 49284, 20011, 49281,\n",
       "         30024, 49272, 49271, 20019, 49269, 20022, 30023, 20026, 49263,\n",
       "         20028, 20029, 30020, 49255, 49254, 40470, 20118, 29988, 20121,\n",
       "         49131, 49130, 49125, 20191, 49124, 29971, 20196, 20197, 49111,\n",
       "         40519, 49108, 29969, 49102, 49094, 49091, 49089, 49088, 49087,\n",
       "         20219, 49084, 20221, 20222, 49082, 49133, 20181, 20179, 49140,\n",
       "         20122, 49186, 49185, 20128, 20134, 20135, 49182, 49181, 29987,\n",
       "         29986, 49174, 19989, 49173, 20150, 20152, 49168, 40498, 49164,\n",
       "         49160, 20167, 49153, 29979, 49143, 20176, 20149, 20224, 40463,\n",
       "         19983, 49466, 49463, 40402, 19802, 40404, 49456, 30087, 49450,\n",
       "         49446, 19825, 49445, 49444, 49439, 19831, 19832, 19833, 49437,\n",
       "         30086], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_mode': {'feature_present_idx': array([    0, 16218, 46190, 46178, 46167, 45950, 16323, 16375, 45947,\n",
       "         16535, 45931, 16577, 45893, 16831, 45571, 45361, 45303, 45093,\n",
       "         45091, 17121, 45000, 44988, 16202, 44935, 16169, 46471, 47906,\n",
       "         47893, 47855, 47818, 47787, 47727, 47700, 47439, 15526, 47318,\n",
       "         47212, 15752, 47105, 15793, 47021, 15874, 46937, 15924, 15938,\n",
       "         46590, 16105, 46346, 47908, 44842, 44788, 43512, 18713, 43189,\n",
       "         18813, 18863, 18874, 43108, 18949, 18975, 42832, 42673, 19122,\n",
       "         42507, 42303, 19311, 42285, 42250, 42148, 19357, 42056, 19392,\n",
       "         43540, 44818, 18528, 43609, 17548, 17561, 44619, 44545, 44504,\n",
       "         44289, 44223, 17840, 17893, 44110, 44044, 43964, 18181, 43932,\n",
       "         18197, 43906, 43870, 43809, 43808, 18259, 43643, 18523, 41821,\n",
       "         48051, 48054, 12002, 51645, 12066, 51561, 12096, 12124, 51501,\n",
       "         12150, 12219, 12220, 51476, 12304, 12312, 12336, 51410, 51399,\n",
       "         51342, 12590, 51328, 51100, 51015, 11942, 13297, 11918, 51849,\n",
       "         52425, 10805, 10950, 11007, 11031, 11034, 11060, 52196, 11090,\n",
       "         52179, 11316, 11345, 52135, 11552, 11577, 11604, 11631, 52061,\n",
       "         11690, 51892, 11728, 11859, 15208, 13303, 50868, 49788, 49763,\n",
       "         49697, 49612, 49599, 14460, 14538, 14595, 14639, 14725, 49285,\n",
       "         49064, 14758, 48941, 48827, 48773, 48724, 48593, 48209, 48107,\n",
       "         15169, 14196, 50870, 14155, 49914, 50772, 50697, 50549, 13439,\n",
       "         13447, 50510, 50472, 13528, 50332, 50321, 13691, 13700, 50272,\n",
       "         13714, 13733, 50063, 13847, 13928, 49945, 13979, 13994, 14153,\n",
       "         10794, 19471, 19605, 33213, 33210, 33113, 33033, 25911, 33008,\n",
       "         25926, 32873, 26012, 32837, 26055, 32646, 32441, 32418, 26196,\n",
       "         26255, 32207, 32155, 26336, 32102, 32073, 33245, 31769, 33272,\n",
       "         33319, 24606, 24706, 34961, 34934, 34876, 24958, 25077, 34419,\n",
       "         34257, 34211, 34167, 34010, 25278, 33719, 25365, 33651, 33477,\n",
       "         33410, 25505, 33357, 25594, 25661, 34993, 31717, 26587, 29812,\n",
       "         27964, 27976, 28001, 29714, 28028, 28130, 28143, 28186, 29546,\n",
       "         29415, 29409, 29267, 28511, 29172, 28611, 28662, 29081, 29070,\n",
       "         28755, 28802, 29973, 31625, 30056, 30260, 31600, 26834, 26944,\n",
       "         31154, 31080, 30970, 30933, 27139, 30587, 27193, 30548, 30422,\n",
       "         30351, 30310, 30302, 27302, 30301, 30294, 27481, 30261, 27485,\n",
       "         27566, 41579, 24493, 24296, 38974, 38894, 21162, 38545, 38430,\n",
       "         21318, 21336, 38416, 21555, 38179, 38109, 38007, 21799, 21822,\n",
       "         37737, 21856, 37688, 37658, 37589, 37564, 37512, 20956, 22063,\n",
       "         20955, 20868, 19703, 19718, 19772, 41316, 41152, 40927, 40880,\n",
       "         20137, 40668, 20235, 20241, 40555, 20329, 40412, 40234, 20511,\n",
       "         40037, 39812, 20678, 39468, 39316, 20892, 24396, 22086, 37205,\n",
       "         23180, 35907, 35890, 35823, 23435, 35761, 35721, 23682, 35621,\n",
       "         23739, 35609, 35570, 23844, 23947, 35516, 23987, 35389, 24182,\n",
       "         24240, 24269, 35287, 36036, 37250, 23059, 36246, 22220, 37169,\n",
       "         37166, 37052, 22276, 22332, 36969, 36871, 36776, 36727, 22575,\n",
       "         22613, 22618, 22659, 36514, 36480, 36426, 22770, 22911, 36271,\n",
       "         22978, 23017, 10741, 28958, 59983, 58326,  6544,  6561, 64563,\n",
       "          2200, 58077, 58025, 57987, 64685,  2062, 57886,  6725,  6748,\n",
       "         64876, 57877, 58362,  6780, 58368, 58453, 59136,  2669, 64067,\n",
       "         59049, 64190, 58927,  5867,  5869, 64234, 58732,  5982, 58640,\n",
       "          6095,  6248, 64424,  6475,  5619, 57608,  6970,  1374,  7686,\n",
       "         56730,  7724, 56662, 56642, 56609, 56475, 56412, 65417,  1286,\n",
       "         65442,  8024, 56389, 56339,  1380, 65006, 65259, 57104,  6977,\n",
       "         65010, 65080,  7124, 57372, 57326, 57324, 57307, 57273,  1605,\n",
       "          7363,  1579,  7387,  1507,  1482, 57033,  1235, 59148,  5479,\n",
       "          3732,  4374,  3644,  3605, 62157,  3584, 60620, 60593, 62324,\n",
       "         62340, 60583,  3521, 60519, 60483,  3479, 61951, 60471,  3760,\n",
       "          4357,  4092, 61148,  4007,  3959,  4163,  3957,  4189,  3930,\n",
       "          4214,  4228, 60948, 61383,  4285, 60925,  3794, 61831,  2709,\n",
       "         60416, 62573, 59461, 59438,  5055,  2841,  2840,  5121, 63623,\n",
       "         63680,  5255,  5286,  2803, 59341,  2754, 63725, 63782,  4968,\n",
       "          3437, 63440,  4941, 62688,  3248, 62785, 62887, 63050, 59905,\n",
       "          3140, 59835, 63196,  4860, 59715, 63208, 59653,  4938, 63428,\n",
       "          4947,  8061, 65135, 56330, 54407, 54534, 55361, 53505, 53467,\n",
       "         66260,  9644,  9643,  8971, 66275,  8538,   856,  8492,  8489,\n",
       "           865, 66051,   124, 66039, 53416,   520, 54103,  8655, 10175,\n",
       "          8676, 66939, 54979, 55045,  9748, 66838, 66842, 53789, 66181,\n",
       "         53546,   767, 53976, 54662, 66775, 53533,  8719, 66105, 66923,\n",
       "          9708, 55173,   801, 55285, 66094,  9933, 54110,  8456, 54328,\n",
       "         52865, 56031, 54142,  8222, 65764, 66433, 56161, 52737,    34,\n",
       "         56175, 52719,  9196, 65523, 67243,  1083,  8119,   396, 52555,\n",
       "         65449, 65925, 53043,  1020,   727, 67102, 55863, 55525,   925,\n",
       "         55875,   345, 53052, 54411, 53327,  9279, 55494, 10324,  9167,\n",
       "         10356, 55902, 67038, 36007, 63483, 36087, 62872, 36008, 66760,\n",
       "         35746, 66652, 35661, 35709, 29768, 35665, 29684, 35696, 35767,\n",
       "         29685, 29374, 36104, 29259, 67072, 29156, 37203, 61778, 61685,\n",
       "         61605, 37373, 36972, 29125, 67220, 29030, 37558, 61380, 37627,\n",
       "         29003, 37722, 61273, 67161, 62863, 61988, 36907, 62827, 66834,\n",
       "         29631, 29579, 29537, 36289, 36419, 36425, 36944, 29468, 62563,\n",
       "         36531, 62163, 36576, 29283, 66986, 36633, 62144, 36460, 35632,\n",
       "         35091, 66437, 65140, 65962, 31437, 31378, 33220, 66038, 37741,\n",
       "         65125, 65098, 31315, 31216, 31179, 67249, 64972, 33452, 64689,\n",
       "         66079, 33534, 33588, 33610, 30927, 33115, 64587, 65201, 31505,\n",
       "         32119, 65446, 32107, 32103, 65760, 32461, 32489, 32591, 65409,\n",
       "         31939, 31779, 32659, 65272, 32736, 65900, 32906, 32940, 65241,\n",
       "         31560, 31514, 33027, 31464, 30603, 33929, 33940, 35045, 35054,\n",
       "         64038, 35069, 32160, 63870, 30253, 63834, 30128, 30102, 30058,\n",
       "         35343, 66395, 30008, 30006, 66432, 29960, 35522, 35551, 63620,\n",
       "         35586, 66258, 66239, 64201, 34971, 66087, 64544, 34203, 30388,\n",
       "         64533, 64516, 34277, 34361, 64471, 30321, 63589, 66122, 64398,\n",
       "         66126, 34469, 34698, 34767, 64286, 34932, 64255, 64245, 66133,\n",
       "         34458, 37830, 52554, 37874, 48337, 48505, 48570, 48598, 48631,\n",
       "         48671, 56285, 48913, 56074, 56034, 49119, 56011, 55927, 48196,\n",
       "         29002, 49300, 49514, 49556, 55579, 55560, 55554, 55486, 49811,\n",
       "         49861, 49894, 49900, 49913, 55417, 55894, 48069, 56367, 48042,\n",
       "         45981, 46017, 46085, 57458, 57390, 46300, 57258, 46539, 46596,\n",
       "         46837, 57246, 57215, 57211, 46948, 46989, 56838, 47119, 56780,\n",
       "         56772, 47237, 47383, 47399, 47412, 56551, 56539, 47900, 56424,\n",
       "         47942, 48014, 55411, 57462, 50034, 50111, 51465, 54091, 51525,\n",
       "         53734, 51596, 53727, 53693, 51682, 51728, 51764, 51780, 53525,\n",
       "         51884, 51444, 53450, 53449, 52067, 53315, 52083, 53298, 52156,\n",
       "         52988, 52812, 52758, 52204, 52293, 52326, 52656, 51967, 54333,\n",
       "         51347, 54362, 50172, 50240, 55279, 50317, 55132, 50440, 55120,\n",
       "         50444, 55076, 55041, 54919, 50551, 54798, 50782, 54531, 54516,\n",
       "         50876, 50891, 50913, 50932, 50948, 51054, 51063, 51116, 51172,\n",
       "         51196, 51203, 51251, 51281, 55365, 57497, 57555, 45624, 39993,\n",
       "         60592, 40172, 40207, 60570, 40313, 40434, 40503, 40542, 60437,\n",
       "         40632, 40652, 60310, 39686, 40821, 60175, 60052, 40912, 40916,\n",
       "         52504, 40930, 40941, 59940, 41273, 41393, 41396, 41439, 41459,\n",
       "         40873, 39653, 39647, 39616, 37908, 61152, 37988, 38098, 61002,\n",
       "         60952, 38281, 38319, 38340, 38425, 38452, 38622, 38744, 38874,\n",
       "         38884, 60782, 38961, 39011, 39089, 39119, 39266, 60779, 39272,\n",
       "         60775, 39283, 60669, 60656, 39364, 60630, 41792, 41810, 41881,\n",
       "         41885], dtype=int64),\n",
       "  'feature_absent_idx': array([49087, 39601, 62592, 27845, 12892, 12894, 62589, 12898, 57015,\n",
       "         12901, 57017, 62588, 57019, 52599, 27831, 57020, 27828, 12915,\n",
       "         27820, 39611, 50696, 57027, 62582, 44687, 44686, 12930, 52596,\n",
       "         27811, 62593, 12880, 44705, 12878, 12835, 27883, 52603, 27877,\n",
       "         57004, 62612, 62611, 57005, 44725, 44724, 12851, 12852, 39597,\n",
       "         62579, 12854, 44719, 27864, 27863, 12862, 27861, 12865, 27860,\n",
       "         57008, 44714, 50688, 62600, 50689, 12877, 12858, 62578, 52595,\n",
       "         57031, 50706, 12983, 27776, 57043, 12987, 62551, 12989, 50709,\n",
       "         39628, 57044, 57046, 44663, 52591, 57042, 13002, 27763, 62544,\n",
       "         27758, 44659, 27757, 57052, 62539, 13014, 27754, 13016, 50711,\n",
       "         13020, 57054, 13003, 50677, 39625, 44671, 27805, 62576, 12943,\n",
       "         27801, 27799, 12947, 12948, 62568, 12951, 12952, 27796, 44679,\n",
       "         39620, 62560, 62566, 27791, 12960, 50704, 62562, 12964, 39621,\n",
       "         57038, 62561, 12969, 12970, 12971, 12973, 57040, 27792, 44730,\n",
       "         62615, 56991, 62671, 52619, 12667, 44793, 62669, 50644, 56942,\n",
       "         12675, 12676, 56943, 62668, 56944, 56945, 12664, 27994, 62664,\n",
       "         56947, 12693, 12696, 56951, 62662, 50649, 62657, 62656, 12707,\n",
       "         44777, 56953, 12710, 27992, 12711, 12663, 39543, 39528, 39529,\n",
       "         44812, 56931, 28042, 44811, 56934, 62693, 28034, 50640, 12633,\n",
       "         12634, 28026, 12661, 56937, 62684, 44801, 50642, 12644, 28018,\n",
       "         62680, 56939, 62678, 12653, 44797, 28013, 52620, 44795, 39538,\n",
       "         62536, 62655, 56955, 12773, 56971, 12777, 56972, 12782, 44749,\n",
       "         62629, 27910, 27908, 12799, 62624, 12805, 12807, 12771, 50672,\n",
       "         12812, 12813, 44739, 62621, 44737, 39586, 27891, 52604, 12824,\n",
       "         44734, 12826, 56989, 12829, 12811, 12714, 12770, 12768, 62654,\n",
       "         12717, 44775, 27967, 12721, 12723, 27963, 56956, 50650, 27958,\n",
       "         62650, 62649, 27957, 12769, 50652, 27955, 12739, 52616, 12742,\n",
       "         39564, 44764, 27946, 56968, 27937, 12762, 12763, 27931, 56970,\n",
       "         56958, 13028, 13029, 62535, 27567, 57107, 13280, 44565, 27561,\n",
       "         62435, 27557, 13288, 62431, 13290, 13292, 13293, 13295, 44567,\n",
       "         13301, 62427, 27548, 13307, 62426, 13311, 50737, 62423, 57112,\n",
       "         13317, 39703, 13322, 57117, 62418, 39700, 13328, 27568, 13274,\n",
       "         44587, 13233, 44586, 44585, 44583, 27586, 13243, 44580, 57101,\n",
       "         27582, 13247, 62456, 13249, 62442, 27581, 44577, 13255, 13259,\n",
       "         27576, 62452, 27573, 44571, 27571, 39696, 13269, 13271, 62443,\n",
       "         13273, 62454, 44588, 13329, 44553, 62395, 50747, 44531, 27500,\n",
       "         62393, 52562, 44525, 13399, 50750, 44521, 13405, 62387, 13410,\n",
       "         57133, 27486, 44514, 52556, 13422, 13423, 13425, 13426, 27471,\n",
       "         13429, 57156, 44510, 13435, 52548, 27464, 13415, 50738, 62398,\n",
       "         44537, 27535, 13333, 39706, 39708, 27531, 13338, 57120, 27527,\n",
       "         13344, 13345, 13347, 57121, 39711, 62399, 57124, 50742, 44543,\n",
       "         62410, 27516, 57126, 13362, 13364, 13365, 62406, 57130, 27506,\n",
       "         62400, 57131, 57125, 62696, 62461, 27591, 13084, 57071, 27693,\n",
       "         57072, 13095, 13096, 27688, 13098, 44635, 52581, 13101, 27686,\n",
       "         13103, 27701, 62510, 13108, 44634, 57076, 13112, 44632, 44630,\n",
       "         39663, 52580, 39665, 27676, 44628, 39666, 50719, 13106, 62500,\n",
       "         13081, 27703, 39638, 62534, 62532, 13037, 13040, 62530, 27735,\n",
       "         27733, 52585, 27731, 39646, 27726, 27725, 13079, 13052, 57062,\n",
       "         39651, 27715, 44645, 27713, 27712, 13065, 44642, 27710, 27708,\n",
       "         27707, 62517, 39652, 27723, 27590, 44621, 44616, 13183, 27624,\n",
       "         39685, 62479, 27621, 27620, 13190, 44600, 13193, 27616, 27612,\n",
       "         13201, 62475, 27625, 39690, 27607, 27606, 13209, 27605, 13214,\n",
       "         13217, 57095, 13219, 39692, 13221, 27593, 50728, 57098, 44597,\n",
       "         57080, 57091, 27631, 62497, 27658, 27656, 39674, 57082, 27653,\n",
       "         13146, 57084, 13148, 13149, 27650, 13151, 13154, 57090, 62490,\n",
       "         44610, 13160, 13161, 27641, 50722, 13167, 44607, 27638, 27637,\n",
       "         50723, 13173, 62483, 13176, 62489, 13441, 28047, 28056, 28452,\n",
       "         62903, 28450, 62902, 62901, 45008, 45007, 12045, 12046, 12047,\n",
       "         39382, 28448, 28447, 50571, 28445, 12056, 62896, 12059, 28441,\n",
       "         12062, 12064, 28439, 62894, 28436, 56801, 12075, 62888, 56797,\n",
       "         12033, 56795, 12029, 11987, 56786, 28478, 45026, 39375, 28476,\n",
       "         11994, 11995, 45022, 28473, 39377, 62917, 56790, 44996, 62916,\n",
       "         50561, 12013, 12014, 12015, 62914, 12017, 52680, 52679, 50564,\n",
       "         12022, 50566, 62909, 62908, 62915, 12079, 44995, 28429, 62865,\n",
       "         44976, 56813, 12142, 12143, 28388, 39399, 28383, 28382, 62859,\n",
       "         12158, 28378, 39401, 12134, 50585, 44968, 44966, 28374, 28371,\n",
       "         28370, 62856, 52669, 62855, 62854, 12178, 28361, 50588, 62848,\n",
       "         52671, 11985, 12132, 62866, 52676, 50575, 12087, 44993, 28421,\n",
       "         28416, 39394, 50578, 44987, 12104, 12106, 28410, 12108, 28397,\n",
       "         12109, 62879, 28408, 62878, 62877, 28407, 62875, 56808, 56811,\n",
       "         44983, 44982, 44980, 28398, 50581, 56805, 11984, 62927, 28482,\n",
       "         28595, 11830, 62994, 11832, 45073, 11834, 39346, 56746, 28592,\n",
       "         28589, 56747, 56748, 28583, 11828, 45070, 11850, 28580, 62988,\n",
       "         62986, 62985, 62984, 56750, 11861, 50535, 45064, 62976, 39351,\n",
       "         45062, 11848, 11874, 11827, 56742, 11779, 11781, 52695, 28624,\n",
       "         11784, 11785, 50526, 28622, 28621, 63008, 50527, 63005, 28612,\n",
       "         11826, 11802, 11805, 11806, 56734, 11809, 28605, 11811, 28602,\n",
       "         45078, 11817, 62999, 62998, 11821, 39344, 11804, 12184, 11876,\n",
       "         11882, 11940, 45036, 50553, 39367, 62944, 50554, 39368, 50555,\n",
       "         11952, 28504, 39370, 28501, 28500, 11939, 28498, 28494, 28493,\n",
       "         56775, 11968, 62937, 56782, 45028, 62934, 28487, 11975, 11976,\n",
       "         50558, 39374, 11959, 28562, 39363, 28519, 28558, 11885, 45058,\n",
       "         28552, 62965, 28548, 28544, 62961, 11902, 11906, 50541, 28537,\n",
       "         28536, 39362, 56765, 28534, 11914, 39358, 28530, 28529, 11922,\n",
       "         11923, 28525, 39360, 28521, 11931, 50552, 28520, 62957, 12186,\n",
       "         50591, 44959, 44867, 56895, 12468, 56897, 62754, 52637, 62752,\n",
       "         39497, 52635, 28140, 62750, 39499, 28136, 28150, 28135, 12490,\n",
       "         12491, 28128, 62747, 12494, 12495, 62745, 44860, 44859, 44858,\n",
       "         28126, 28124, 50616, 12484, 12506, 56893, 12459, 39478, 12411,\n",
       "         12412, 28191, 28188, 12418, 56877, 62768, 28182, 39481, 52640,\n",
       "         12428, 12431, 12460, 28173, 44878, 62761, 28167, 62758, 56884,\n",
       "         39489, 12446, 12447, 12448, 39493, 12452, 56891, 12454, 39485,\n",
       "         62776, 56905, 28117, 44834, 50629, 12568, 44830, 39516, 44829,\n",
       "         56917, 12574, 56918, 62709, 44825, 56921, 12581, 28076, 12583,\n",
       "         12586, 44822, 50635, 28063, 12592, 52627, 12595, 12596, 12597,\n",
       "         12598, 39521, 62699, 52623, 28064, 12510, 12562, 28078, 12512,\n",
       "         39504, 28114, 44850, 28113, 28109, 28108, 62730, 12527, 12530,\n",
       "         56912, 12534, 28097, 39515, 56913, 28091, 28088, 12544, 12546,\n",
       "         62723, 62722, 12550, 28085, 28084, 28082, 12557, 28080, 28079,\n",
       "         28093, 28051, 56872, 44893, 52661, 12247, 28316, 12251, 12252,\n",
       "         12253, 12254, 28310, 12258, 39429, 28304, 50596, 12267, 12243,\n",
       "         28299, 39431, 56847, 62810, 62809, 39433, 12279, 12283, 39437,\n",
       "         56851, 50600, 39439, 12292, 12293, 44934, 12294, 52662, 12239,\n",
       "         56822, 44958, 12198, 28350, 52664, 12202, 39411, 62840, 12205,\n",
       "         12207, 50592, 12212, 50593, 12240, 62837, 28341, 12218, 39416,\n",
       "         28337, 12224, 50594, 39417, 28333, 12230, 56833, 28331, 12234,\n",
       "         12236, 12215, 12404, 12297, 39442, 28238, 39460, 50606, 12362,\n",
       "         12363, 12365, 28233, 12367, 12368, 28232, 62790, 12372, 12374,\n",
       "         12356, 28225, 28224, 39470, 44901, 28218, 39474, 28213, 56870,\n",
       "         12390, 12391, 28209, 28208, 28207, 28205, 44903, 44927, 28240,\n",
       "         39458, 50601, 62805, 62804, 28274, 12308, 12313, 12315, 44922,\n",
       "         44921], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_name': {'feature_present_idx': array([35751, 40989, 31088, 17483, 17470, 17448,  6750, 64489, 17427,\n",
       "         31150,  6766, 17397,  6790, 64448,  6804, 64444, 31173, 50160,\n",
       "          6981, 31483, 54153, 50189, 31474, 31442, 40995, 40720, 31376,\n",
       "         31361, 40751, 54210, 54226, 17335,  6924, 17509, 17518, 41025,\n",
       "         64620, 17752, 41307,  6272, 17814, 17821,  6340, 17832, 30789,\n",
       "         30787,  6178, 30721, 59741,  6076, 30790, 31487,  6345, 17701,\n",
       "         17520, 50045, 54291, 64526, 17547, 41087, 30857,  6465, 50038,\n",
       "         41126, 17617, 64604,  6384, 17668, 50043, 31527,  7055, 60132,\n",
       "         32267, 60468, 16325, 60466, 63993, 60459, 40009, 53767,  7904,\n",
       "         16387, 16402,  7877, 64025, 60425, 64010,  7838, 32275,  8009,\n",
       "         39811, 60588, 15970, 53512, 60575,  8145, 16292, 39848, 16139,\n",
       "         39915, 63951, 39957, 50466,  8014, 16023, 17933, 32187, 60351,\n",
       "          7281, 60174, 50252, 31623, 31596,  7244, 40452, 60156,  7221,\n",
       "         17029, 64324, 64332,  7145, 40533,  7228, 16463, 60187, 60213,\n",
       "         60327, 16555, 16590, 40241, 53919, 40256, 60204,  7555,  7471,\n",
       "         60254, 16783, 31797, 40366, 60230, 16734, 30674, 17974, 41548,\n",
       "         19421, 29163, 65248, 19517, 29077, 29068, 42879, 58997, 58970,\n",
       "         43063, 29037, 19644, 49071, 49065, 54971,  4397, 42841, 49176,\n",
       "         54928, 29280, 19295,  4778,  4765,  4759, 65225, 59062, 19366,\n",
       "         59057, 42801,  4649, 54947, 42813, 42757, 29351, 19702, 65323,\n",
       "         28748, 20042, 58715, 58701, 58700, 48991,  4121, 65453, 20120,\n",
       "         20141, 48925, 58679, 20198, 20231, 43384, 54991,  4132, 43264,\n",
       "          4334, 19753, 28930, 43156,  4274, 43163, 43266, 58844,  4245,\n",
       "         58832, 43224, 58808, 43231,  4170, 49049, 39805,  4869,  4897,\n",
       "          5719, 30407,  5702, 18266, 41764, 30289, 41692, 18374, 30252,\n",
       "          5535,  5527, 18435, 41890, 30234, 18394, 41906, 54535, 59599,\n",
       "         41606,  5950, 30573, 18095,  5895, 30536, 30430, 30521, 41646,\n",
       "          5845,  5819, 54496, 18178, 49889,  5875, 19053, 30215, 41937,\n",
       "         29734, 49518, 18853, 54796, 18923, 29562, 18809, 49410, 49379,\n",
       "         49366, 65067, 29510, 29488,  4921, 49390, 30156, 18807, 29816,\n",
       "         18548, 41950, 41963, 59459, 18612, 64951, 54764, 42086, 29911,\n",
       "          5236, 49566, 29850, 49541, 29820, 29970, 28590,  8266, 32623,\n",
       "         34818, 10689, 10692, 34851, 52502, 61678, 13263, 13228, 61706,\n",
       "         10768, 13164, 10780, 36992, 34936, 52488, 36956, 13135, 62549,\n",
       "         62550, 12966, 11023, 35118, 51539, 34798, 13046, 13051, 13093,\n",
       "         36920, 10863, 52455, 13125, 35050, 51368, 34769, 52520, 13703,\n",
       "         10237, 34404, 61471, 37546, 37581, 10298, 61465, 34344, 62918,\n",
       "         34300, 51273, 34256, 13916, 13816, 12913, 10316, 61533, 13421,\n",
       "         10508, 13492, 10494, 13529, 10473, 62832, 34622, 34511, 61567,\n",
       "         13614, 10381, 34487, 13657, 34532, 35254, 62542, 12902, 62280,\n",
       "         12262, 11712, 12284, 52186, 12307, 35832, 12309, 36392, 24679,\n",
       "         11635, 51880, 36404, 35701, 36367, 11595, 62262, 36202, 52069,\n",
       "         36081, 62192, 12040, 35976, 62209, 36227, 52120, 11887, 62114,\n",
       "         11843, 11841, 11839, 11814, 11893, 51244, 11590, 36417, 51654,\n",
       "         62450, 11269, 35346, 11241, 12720, 51655, 11221, 61860, 35312,\n",
       "         52372, 36742, 52382, 12867, 36673, 11566, 35412, 35449, 36453,\n",
       "         61966, 35628, 12419, 61948, 61937, 52301, 36501, 36555, 11468,\n",
       "         11457, 11451, 12594, 11441, 12540, 37778, 61370, 62982, 50785,\n",
       "          8874, 50776, 39131, 60798, 33062, 39084,  8799, 39199, 39203,\n",
       "         39229, 53344, 15537, 33003, 60705, 63672, 53243, 60827, 15211,\n",
       "          9043, 15213, 60843, 39021,  9015, 63533, 63463,  9004, 50851,\n",
       "         39055, 39067, 39075, 53238, 39024, 63433, 32988, 63703, 32813,\n",
       "         39577,  8458, 15763, 15779, 39607, 32827, 50580, 50577, 15888,\n",
       "          8336, 50550, 15906, 53476, 32741, 63683, 50632, 50647, 60680,\n",
       "          8677, 63716, 63724, 53379,  8606, 39517, 32917,  8573, 39383,\n",
       "         32869, 53399,  8545, 39400, 15658, 63905, 63426, 53192, 14283,\n",
       "         14294,  9750,  9742,  9738, 33956, 14241, 33921,  9697,  9692,\n",
       "         38197, 14395, 61182, 61166, 33881, 38389, 38050, 14191, 62990,\n",
       "         52744, 51211,  9943, 37859, 14041, 61256, 52748, 51187, 51185,\n",
       "          9906, 52778, 38014, 38017, 37898, 63419, 38390, 38400, 38809,\n",
       "         15059,  9208, 53159, 15133,  9165, 15020, 38910,  9155, 33368,\n",
       "          9146, 63357, 38934,  9111, 53165, 38395, 50884, 53118, 61108,\n",
       "          9509, 38466, 33764, 14667, 33711, 33482, 50983, 14803, 53045,\n",
       "         53069, 33602, 33561,  9281, 38609,  3804, 41625, 52084,  2614,\n",
       "         25691, 66934, 48420, 23428, 21552, 25689, 27393, 27400, 27406,\n",
       "         25651, 66971, 55733,   942,  2673, 56470, 21391,   915, 55638,\n",
       "         21560,  2584, 66907, 55768,  2398, 21824, 25797, 27134,  2442,\n",
       "         66168, 23377,  1046, 27177, 25602, 46332, 27198, 44722, 21652,\n",
       "         44704, 55803, 21634, 55783, 66129, 46368, 66154, 23521,   886,\n",
       "         46551, 48551, 27798,  3015, 23737,   690, 44165, 55500,  3057,\n",
       "         67076,   730,   662, 44141, 46853,   637, 20998, 46892, 27898,\n",
       "         27909, 46895, 20975, 23835, 27109,  2988, 44188, 21263, 67007,\n",
       "          2788, 21253,  2799,  2802, 21222, 48532,  2838, 65842, 58235,\n",
       "         44287, 46680, 44274, 57169, 25478, 58281, 25462, 44228, 21121,\n",
       "         57177, 44099, 23303, 25868, 22563, 26538, 57704, 45442, 57724,\n",
       "         56048, 48075, 22873, 45752, 22874, 48164, 26136, 66479,  1956,\n",
       "         45820, 22381, 22360, 22349, 57826, 22857,  1847, 48082, 22825,\n",
       "         66562,  1699, 45602, 22709, 45640,  1725,  1750, 22644, 45577,\n",
       "         56016, 22760, 66575, 56117, 22599,  1791, 26506,  1603,  1601,\n",
       "         57701, 45667, 22777, 26731, 57554, 57843, 26972,  1178, 23155,\n",
       "         46056,  2245, 66334, 66890,  2258,  2260, 46038,  1156, 23185,\n",
       "          1151,  2291, 46086, 48297, 44879, 23244, 46099, 57431, 46065,\n",
       "         66269, 25995, 26930, 45207, 45921, 45940, 57863,  1363, 45966,\n",
       "         66740, 45971, 23048, 46031, 26916, 26923, 26924,  1261, 46004,\n",
       "         45067, 46005,  2161, 26005, 45039,  1276, 27927, 45613, 55415,\n",
       "         47323, 47094, 24139, 25062, 24066, 43877, 67254,  3287, 47239,\n",
       "           503, 28031,   508, 47336,  3690,   177, 43710, 47515, 24790,\n",
       "         24216, 48688, 43857, 24870, 28515, 28360, 58339, 47086,   478,\n",
       "         20453, 47272,  3312, 44015, 25111, 20479, 20766, 24111,  3633,\n",
       "         43995, 24112, 24825, 28125, 43649, 24801, 28355, 25176, 56929,\n",
       "         20696, 20807,  3660,  3402, 43620,  3407, 20353, 24805, 55447,\n",
       "         46935, 43796, 55434, 24297,   309, 25256, 58642, 28571, 20320,\n",
       "         28542, 44080, 67162, 47547, 58613, 43823, 28287, 24254, 55312,\n",
       "         28527, 20546, 24648, 57039, 25320, 65774, 28263, 53122, 60994,\n",
       "         15031, 33440, 56273, 33698, 52959, 33386, 57519, 26059, 15124,\n",
       "         15107, 60976, 14495, 60983, 53144, 14523, 15069, 56315, 33811,\n",
       "         56255, 24398, 52948, 15038, 35679, 33793, 56267, 33475, 33784,\n",
       "         12402, 14904, 56965, 14875, 61089, 61071, 61069, 33604, 33565,\n",
       "         14730, 14822, 56964, 25984, 57491, 33650, 61062, 14748, 12396,\n",
       "         61112, 23130, 14940, 24855, 56950, 12314, 24404, 60999, 12341,\n",
       "         52983, 25974, 24860, 33542, 14943, 56288, 14637, 56769, 33721,\n",
       "         52223, 61098, 61020, 23880, 35803, 57600, 60699, 26227, 24773,\n",
       "         35933, 15515, 26211, 15502, 35929, 15484, 26240, 24575, 15473,\n",
       "         52142, 60707, 26150, 15432, 24573, 60760, 60766, 15405, 33147,\n",
       "         15483, 24586, 33002, 56900, 24697, 36044, 32872, 26396, 62146,\n",
       "         36009, 32923, 15617, 56107, 12023, 22755, 15600, 24637, 32957,\n",
       "         53345, 12037, 56837, 24603, 62138, 32979, 56119, 15558, 56835,\n",
       "         52158, 23068, 12166, 60811, 15248, 22996, 24541, 56205, 26096,\n",
       "         23009, 60861, 24391, 15192, 57535, 62043, 23021, 26085, 60876,\n",
       "         33348, 35824, 53172, 15156, 26084, 57528, 12265, 53166, 35829,\n",
       "         57558, 56187, 33242, 35898, 33167, 33184, 33185, 22883, 22885,\n",
       "         22910], dtype=int64),\n",
       "  'feature_absent_idx': array([20922, 31355, 48180, 14511, 31346, 48191, 48195, 48200, 14530,\n",
       "         14531, 14533, 14534, 14535, 58389, 58388, 14541, 14542, 58385,\n",
       "         31328, 14545, 58380, 14549, 14550, 48208, 14552, 14553, 58373,\n",
       "         14561, 58411, 14504, 14503, 14501, 14449, 58443, 14457, 14458,\n",
       "         58442, 58439, 58438, 14463, 31379, 58434, 14474, 14477, 58429,\n",
       "         14562, 58428, 14484, 48174, 31367, 14488, 14490, 48175, 48176,\n",
       "         58416, 31360, 58415, 58413, 14499, 14500, 14482, 48213, 31312,\n",
       "         14573, 14626, 31274, 58340, 31272, 58337, 14634, 14635, 14636,\n",
       "         58333, 14645, 31258, 14651, 31257, 48240, 48247, 31251, 31250,\n",
       "         14659, 48249, 31243, 31242, 31240, 48253, 14675, 14677, 58318,\n",
       "         31230, 14681, 31254, 14448, 31276, 31279, 58367, 48220, 14577,\n",
       "         31302, 31301, 58364, 58363, 14584, 58361, 31293, 14593, 58360,\n",
       "         58358, 31277, 58357, 31291, 14600, 58354, 48229, 14603, 31289,\n",
       "         14605, 14610, 58349, 14615, 31282, 48236, 14619, 14598, 14447,\n",
       "         58444, 48165, 48096, 58553, 31515, 58548, 31507, 14285, 14286,\n",
       "         14287, 48103, 14291, 48106, 14293, 14295, 14268, 14296, 31492,\n",
       "         14304, 14305, 31491, 31489, 14310, 58538, 14312, 58537, 58536,\n",
       "         14317, 31485, 14319, 48109, 48115, 58559, 14262, 31574, 48055,\n",
       "         14215, 14216, 31565, 31563, 14220, 31559, 14225, 48065, 31551,\n",
       "         14232, 48070, 31528, 31548, 48079, 48080, 58573, 58572, 14249,\n",
       "         14251, 48083, 58571, 31535, 31532, 48087, 14260, 14261, 31545,\n",
       "         31229, 58526, 48117, 14387, 14388, 14390, 14393, 48150, 31418,\n",
       "         31417, 31416, 31414, 14402, 48157, 58476, 14414, 58488, 14417,\n",
       "         58465, 14422, 14424, 58460, 14426, 14427, 48162, 58450, 31389,\n",
       "         14439, 14441, 31386, 14443, 31399, 31477, 58489, 14383, 48118,\n",
       "         58519, 31469, 31467, 14340, 58513, 31456, 31455, 48123, 31453,\n",
       "         31445, 58506, 14362, 14384, 14363, 58502, 31438, 14369, 14371,\n",
       "         58496, 31435, 48143, 31429, 14378, 31426, 14380, 48146, 58491,\n",
       "         14365, 31228, 14684, 58316, 31039, 14953, 48401, 58132, 14958,\n",
       "         58130, 14960, 48403, 31034, 58122, 58118, 14966, 14967, 31040,\n",
       "         31028, 14973, 58112, 31021, 31020, 14983, 58110, 14986, 48413,\n",
       "         31013, 48415, 58106, 31007, 14999, 14971, 31005, 14947, 48388,\n",
       "         14888, 14889, 14890, 31078, 14892, 31076, 14897, 48370, 31069,\n",
       "         48374, 58163, 48375, 58158, 48400, 14914, 31060, 31059, 14921,\n",
       "         14922, 14925, 58152, 14927, 58151, 14929, 14930, 31055, 31051,\n",
       "         14937, 14917, 58178, 58092, 15008, 48461, 58060, 30949, 15066,\n",
       "         58057, 15071, 15075, 58052, 48471, 30941, 30939, 58049, 58046,\n",
       "         48459, 48475, 48477, 30930, 48478, 30926, 58039, 58037, 15106,\n",
       "         15109, 30917, 15112, 48494, 58036, 30907, 15092, 58090, 30953,\n",
       "         15057, 48424, 15010, 15013, 30997, 15015, 48431, 15018, 48433,\n",
       "         48438, 15026, 48441, 15029, 30983, 30955, 30979, 48444, 30976,\n",
       "         58072, 15040, 15042, 15046, 30968, 30967, 30966, 48455, 48456,\n",
       "         48457, 30957, 15034, 14207, 58179, 48364, 48295, 14740, 58286,\n",
       "         14744, 48299, 58285, 58283, 58277, 14753, 58274, 31178, 31177,\n",
       "         14760, 48292, 58267, 31172, 48303, 48304, 48310, 48315, 58254,\n",
       "         31161, 48319, 48320, 31157, 14780, 48321, 58246, 14764, 58243,\n",
       "         48291, 14733, 48262, 31224, 48265, 58311, 14694, 14695, 58310,\n",
       "         31217, 48271, 31211, 58305, 31210, 58301, 58292, 14707, 14710,\n",
       "         14711, 48280, 14716, 14717, 14718, 31201, 48282, 14723, 48286,\n",
       "         58294, 14727, 31194, 58297, 14883, 31151, 58242, 58207, 31117,\n",
       "         48340, 14842, 48342, 31112, 14845, 58203, 14847, 14848, 48345,\n",
       "         31109, 58200, 58208, 48346, 31106, 14857, 58195, 14859, 31103,\n",
       "         31101, 31092, 14871, 58191, 31090, 48359, 14877, 48361, 58197,\n",
       "         14788, 31120, 48339, 31148, 31146, 58240, 14794, 31145, 58239,\n",
       "         14797, 58237, 14799, 14800, 58236, 31140, 48329, 14833, 14811,\n",
       "         31134, 48333, 31129, 58221, 14820, 31128, 31127, 14824, 14825,\n",
       "         14826, 48338, 14829, 58215, 48332, 14206, 31575, 14204, 59037,\n",
       "         13541, 32077, 59032, 47748, 13551, 13557, 32063, 32061, 13564,\n",
       "         13565, 13566, 32057, 59038, 13568, 13571, 47759, 32051, 32050,\n",
       "         47760, 59006, 13577, 32047, 13579, 59003, 13582, 47762, 32040,\n",
       "         59016, 47767, 47744, 59040, 47721, 13494, 13495, 13498, 32106,\n",
       "         32105, 47728, 59058, 47730, 47732, 47733, 13507, 32098, 13536,\n",
       "         32096, 13513, 32093, 32091, 13519, 13520, 47738, 47740, 32086,\n",
       "         13524, 59045, 32082, 59043, 13532, 13511, 32113, 58992, 32032,\n",
       "         58951, 31973, 58950, 13671, 13672, 13675, 47810, 58941, 13688,\n",
       "         13689, 58937, 13692, 58935, 47797, 31954, 47814, 13698, 58933,\n",
       "         13701, 47816, 13705, 31948, 31944, 31943, 58928, 31938, 58925,\n",
       "         13718, 13696, 13595, 13659, 13654, 32030, 58987, 47770, 32024,\n",
       "         13606, 13608, 58982, 58981, 47772, 13615, 47773, 13620, 47774,\n",
       "         31982, 58974, 32010, 32008, 13631, 32005, 47785, 13637, 13638,\n",
       "         58966, 32000, 47786, 31994, 13647, 47794, 13626, 13719, 47719,\n",
       "         13485, 32232, 13317, 47645, 32230, 59179, 59178, 13322, 32228,\n",
       "         32227, 32226, 13328, 13329, 13333, 59183, 47646, 13338, 59168,\n",
       "         32215, 13344, 13345, 13347, 32209, 47659, 59163, 47664, 59158,\n",
       "         32203, 13362, 59170, 13364, 32235, 13307, 32270, 13259, 47634,\n",
       "         47635, 59212, 59211, 13269, 13271, 59210, 13273, 13274, 32262,\n",
       "         13280, 13311, 59206, 59199, 13288, 59198, 13290, 13292, 13293,\n",
       "         13295, 32251, 32245, 13301, 59195, 47641, 59191, 32254, 32115,\n",
       "         13365, 59154, 13429, 59106, 47694, 13435, 59104, 32146, 13441,\n",
       "         47695, 32142, 13446, 59093, 13448, 59092, 32154, 32141, 13454,\n",
       "         59088, 59087, 13463, 13466, 13467, 32130, 32126, 47710, 13476,\n",
       "         47715, 59073, 47717, 59089, 32199, 13426, 13423, 32195, 32194,\n",
       "         47669, 32186, 47671, 59147, 59139, 32179, 32177, 59134, 59128,\n",
       "         47680, 32170, 13425, 32169, 13399, 59123, 47682, 13405, 47684,\n",
       "         47687, 13410, 32158, 13415, 59112, 59110, 47691, 13422, 32167,\n",
       "         58034, 31937, 31934, 14028, 58708, 31694, 14033, 14034, 14035,\n",
       "         31686, 47988, 58697, 31677, 31675, 14054, 14056, 31696, 31674,\n",
       "         14059, 47993, 14062, 31671, 47995, 47996, 48000, 14073, 31660,\n",
       "         58687, 58684, 14078, 14079, 58694, 58680, 14026, 58712, 13974,\n",
       "         13975, 13976, 58747, 58746, 58744, 31737, 58741, 58740, 13986,\n",
       "         31735, 13988, 58739, 47976, 31726, 47965, 31719, 31716, 31712,\n",
       "         31711, 47970, 31708, 31704, 58718, 31701, 58714, 58713, 14021,\n",
       "         31724, 13973, 31658, 31656, 58635, 58632, 58631, 14157, 14158,\n",
       "         58628, 48037, 14162, 14163, 14164, 31604, 14169, 58621, 48034,\n",
       "         14176, 58615, 14181, 31589, 31588, 14187, 14189, 14190, 48049,\n",
       "         58601, 31578, 48053, 14200, 14201, 31592, 14085, 31616, 48030,\n",
       "         14091, 31653, 58672, 48009, 58671, 48011, 14099, 14102, 31646,\n",
       "         58666, 14110, 14111, 14113, 14146, 58657, 31634, 31630, 14127,\n",
       "         31629, 31628, 14131, 31626, 14134, 14135, 48027, 58643, 48029,\n",
       "         14143, 48022, 31935, 47956, 13964, 13788, 13791, 13794, 13795,\n",
       "         13796, 58885, 58884, 13799, 31889, 13801, 58882, 31888, 13804,\n",
       "         47852, 31886, 31882, 47860, 13815, 31874, 58865, 31872, 31870,\n",
       "         13823, 31866, 13825, 13829, 58859, 47870, 13808, 58851, 47850,\n",
       "         31898, 47823, 13725, 58919, 13729, 13731, 58915, 47830, 58914,\n",
       "         58912, 47831, 58907, 31918, 47841, 31897, 31910, 31907, 31905,\n",
       "         58897, 31904, 13767, 58894, 31902, 13772, 13773, 13774, 13776,\n",
       "         13778, 47848, 47845, 31749, 31859, 13840, 47918, 47922, 31792,\n",
       "         13920, 13921, 31784, 58781, 58780, 58779, 58776, 47931, 13933,\n",
       "         47933, 13908, 13936, 47937, 13941, 47939, 58770, 58769, 31765,\n",
       "         13950, 47947, 31756, 13958, 31752, 13961, 58754, 13937, 58842,\n",
       "         58796, 58797, 31854, 47876, 31848, 31846, 31845, 31837, 13864,\n",
       "         47883], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_ord': {'feature_present_idx': array([20211, 40808, 59138, 43308, 66276, 16247, 55605, 16870, 38847,\n",
       "         66969, 10466, 61050, 14115, 43976, 14313, 13938, 44063, 45155,\n",
       "         46587, 47725, 14551, 48815, 49447, 49873,  9299, 55063, 55188,\n",
       "          6922, 57198, 57340, 45729, 15002, 40660, 41091, 25277, 27420,\n",
       "         30607, 23414, 30902, 31004, 31431, 21606, 21457, 21243, 15274,\n",
       "         34537, 36940, 19642, 37702, 38478, 39252, 17989, 39312, 39548,\n",
       "         40115, 57747, 35491, 58087, 25403,  5054, 60717,  5748,  2691,\n",
       "         63014, 63199, 63303, 63358, 64591, 64829,  1528,   754, 66132,\n",
       "          5441, 60728,   250, 66966,  1785, 27844,  2148, 40097, 40099,\n",
       "          2185, 16906, 24900, 40174, 16684, 16630, 40322, 16307, 16276,\n",
       "         27493, 15974, 66335, 41348, 27150, 41473, 41713, 42862, 43083,\n",
       "         61474, 61427, 61295, 61237,  1738, 24791, 18443, 38785, 23156,\n",
       "         30522,   926, 66128, 31659, 31776, 22685, 21924, 65985, 21677,\n",
       "         65948, 34171,  1154, 34360,  1210, 65596, 65096, 23857, 36429,\n",
       "         29418, 19686, 64694, 37404, 14177, 27900, 38460, 64044, 18859,\n",
       "         18753, 30611,  5776, 15196,  9251, 10786, 59630, 10195, 59469,\n",
       "          5038, 50059,  9794, 50732, 50935, 51155, 52368, 53213,  8540,\n",
       "         53273, 10853, 53275, 54425, 54964, 59431,  7375,  5222, 55409,\n",
       "         55849,  6613,  6609, 56203, 56240, 58359, 57373,  5580, 53999,\n",
       "         11032, 67166, 11346, 48254, 46084, 45754, 60638, 60667, 46724,\n",
       "         12473, 47076, 13759, 60554, 14018, 47808, 47925, 44721, 55196,\n",
       "         61811, 42243, 42163, 58303, 42811, 32654, 32657, 58189, 32718,\n",
       "         32058, 30829, 55764, 27836, 30799, 30723, 45433, 33316, 30424,\n",
       "         55966, 44393, 43907, 56525, 27572, 59142, 59328, 54691, 54185,\n",
       "         45946, 48354, 60223, 39356, 48506, 39255, 48916, 40500, 47276,\n",
       "         62849, 38476, 62184, 37549, 51249, 37202, 44081, 51605, 40959,\n",
       "         54405, 54130, 34332, 53637, 62032, 46107, 33660, 35021, 41318,\n",
       "         35597, 35867, 36423, 26803, 52854, 35328, 61165, 33842, 15712,\n",
       "          9284, 15675,  2925,  3094, 23550, 23498,  9062, 23047,  3818,\n",
       "         13352,  3979, 15717,  4185, 22811, 15179, 16236,  8257, 22629,\n",
       "         22625,  4705,  5214, 21792,  7557, 18405, 21489, 21099,  5974,\n",
       "         19134,  7003, 20202,  8683,  9328,  6430,  1107, 11256, 11998,\n",
       "         24947, 13072,  1664, 25222, 25510, 10160, 39019,  7458, 39235,\n",
       "         13845,  7406,  7253, 44292, 18017,  7681, 17720, 44523, 15155,\n",
       "         13786, 38187, 55322, 37875, 19427, 37414, 55692, 13612, 56020,\n",
       "         19840, 36884, 36841,  6440, 13202,  7171, 55272, 39472, 12986,\n",
       "         41597, 41571, 41942, 50658, 15085, 10117, 42553, 49871, 42734,\n",
       "         41249, 51971, 48867, 51985, 48377, 14899, 11407, 15822, 47485,\n",
       "         12335, 53548, 40186, 12778, 16947, 16971, 17079,  7711, 14159,\n",
       "         14037, 41785, 39462, 25589, 36523, 20529, 28730, 28961, 62120,\n",
       "          2808, 24610, 29480, 29509, 61959, 30449, 36602, 22964,  4090,\n",
       "          4116, 60343, 31990, 28678, 28608, 28594, 28352, 66908, 66822,\n",
       "         26101, 66365, 26117, 26661, 25001, 32059,  1413, 27518,  1554,\n",
       "         24929, 24889, 27873,  1627, 63844, 24961, 32184, 23134, 32295,\n",
       "         56378, 36053, 20986, 21056, 60078, 58183, 58187,  5739, 34265,\n",
       "          5497, 58704, 34031, 45942, 22635, 59831, 59334, 59386, 55572,\n",
       "         64953, 12415, 46877,  6260, 46618,  7131,  1282,  6263,  5375,\n",
       "         57364, 46483, 60084,   617,  6591, 57115, 56911, 46074,  6387,\n",
       "          1066,  7160, 48007,  3181, 61106, 61973,  5469, 61077, 55057,\n",
       "          9364,  9374, 58322,  4623, 52093, 55269,  1898,  8040, 49573,\n",
       "          8170, 64402, 10318, 53162, 57396, 57388, 57589, 45056, 36077,\n",
       "         41740, 41267, 41155, 16318, 17556, 39149, 18657, 38704, 18922,\n",
       "         38069, 19344, 37494, 37082, 36173, 35749, 34704, 21782, 25639,\n",
       "         27170, 27747, 28115, 23673, 23562, 42000, 31226, 31434, 31536,\n",
       "         31919, 32261, 32622, 33032, 31329, 42630,    43, 43256, 14445,\n",
       "         14963, 43958, 14437, 13878, 43173, 43900, 43006,  4201, 59703,\n",
       "         59671, 33533, 34060, 21590,  4181, 49619, 34329, 21358, 34386,\n",
       "         57613, 35361, 20895, 20754, 57284,  5482, 46623, 49793, 60829,\n",
       "         45431,   936, 65920, 65812, 64777, 24639, 64329,  1663, 28162,\n",
       "         63755, 28318, 63339, 28523, 62484,  2654, 30129, 23784, 61592,\n",
       "         23483,  3565,  3711, 61140, 44166, 20547, 14423, 58624, 16733,\n",
       "         40188,  7820, 17725, 54812, 39164, 52944, 10379,  8699, 41097,\n",
       "         38551, 36403, 43077, 19592, 51129, 10192, 50762, 49592, 49487,\n",
       "         15084, 50530, 39618, 19598, 27488,    85, 46614, 41559,  8469,\n",
       "         25731, 23150, 16392, 26102,  3519,   136, 42452, 52527,  1622,\n",
       "         13163, 28967, 40664, 63722, 15497,  2415,  2371, 46457, 25351,\n",
       "         36195, 60603,  5806, 60615, 56919, 34189, 19000, 10811, 14935,\n",
       "         33949, 43658, 34781, 33573, 36625,  5983, 56701, 13248, 48690,\n",
       "         59695, 59816,  6869,  6241, 36942, 46692, 60358, 56090, 56618,\n",
       "         34716, 27483, 41819, 36744, 46093,  2391,   748, 29050, 52835,\n",
       "         18217, 22790, 22900, 39868, 47288, 37289, 10185, 42649, 42793,\n",
       "          8682,  8474, 11500, 26143, 55501, 45013, 59622, 31613, 27515,\n",
       "         45461, 22503], dtype=int64),\n",
       "  'feature_absent_idx': array([38261, 28450, 12807, 45711, 28448, 28447, 12811, 12812, 12813,\n",
       "         28445, 45713, 28441, 57611, 57609, 12805, 28439, 57605, 12826,\n",
       "         28436, 12829, 45716, 45717, 57601, 12835, 57599, 45722, 28429,\n",
       "         45725, 45726, 12824, 57596, 57626, 57628, 45683, 57662, 28482,\n",
       "         28478, 12762, 12763, 57656, 28476, 12768, 12769, 12770, 12771,\n",
       "         28473, 28452, 12773, 12777, 45696, 57650, 12782, 45699, 45701,\n",
       "         57643, 57642, 57641, 45704, 45705, 12799, 57629, 45695, 57594,\n",
       "         57591, 28421, 57550, 12898, 12901, 28378, 45758, 45761, 28374,\n",
       "         28371, 57544, 28370, 12915, 45769, 28361, 28382, 28350, 57525,\n",
       "         12930, 45779, 57524, 45786, 28341, 57518, 57516, 28337, 12943,\n",
       "         57513, 57511, 12947, 57526, 28383, 12894, 12892, 45731, 45732,\n",
       "         12851, 12852, 12854, 28416, 12858, 57579, 57578, 12862, 28410,\n",
       "         12865, 45736, 28408, 28407, 45740, 57571, 57570, 57568, 45743,\n",
       "         57567, 57566, 12877, 12878, 12880, 28398, 28397, 45747, 28388,\n",
       "         28487, 12948, 57665, 57667, 45611, 12595, 12596, 12597, 12598,\n",
       "         28605, 45615, 28602, 45616, 45618, 57782, 45619, 28595, 12592,\n",
       "         28592, 45626, 28583, 57772, 57770, 28580, 57768, 45628, 12633,\n",
       "         12634, 57766, 57762, 12644, 45634, 28589, 28562, 28612, 57795,\n",
       "         45594, 12546, 57840, 28642, 12550, 45598, 57835, 45599, 12557,\n",
       "         28634, 45600, 12562, 57825, 45609, 57821, 12568, 45603, 28624,\n",
       "         57811, 12574, 28622, 28621, 57807, 57801, 12581, 12583, 57796,\n",
       "         12586, 28630, 45635, 57753, 57750, 28525, 28521, 12707, 28520,\n",
       "         28519, 12710, 12711, 57699, 12714, 12717, 45664, 12721, 12723,\n",
       "         28529, 57688, 28504, 57683, 45672, 28501, 28500, 28498, 12739,\n",
       "         12742, 28494, 28493, 57676, 45674, 57670, 45671, 28530, 45652,\n",
       "         12696, 12653, 28558, 45638, 57745, 45639, 12661, 57741, 12663,\n",
       "         12664, 28552, 12667, 57736, 57735, 28548, 12675, 12676, 57731,\n",
       "         57730, 28544, 45643, 57725, 57723, 28537, 28536, 57718, 57717,\n",
       "         12693, 28534, 57715, 57666, 12544, 28333, 12952, 13217, 28136,\n",
       "         13219, 28135, 13221, 45953, 28128, 28126, 28124, 57283, 13233,\n",
       "         28117, 28114, 57297, 28113, 57271, 28109, 28108, 13247, 13249,\n",
       "         57266, 57265, 45968, 13255, 57261, 13259, 45969, 57257, 13243,\n",
       "         57256, 13214, 57299, 13160, 13161, 28182, 45904, 13167, 57329,\n",
       "         28173, 57325, 13173, 13176, 28167, 45923, 13183, 45948, 45927,\n",
       "         13190, 13193, 28150, 45935, 57306, 57305, 45939, 13201, 45945,\n",
       "         57303, 57301, 13209, 28140, 45929, 57254, 57252, 57251, 57218,\n",
       "         45986, 45990, 13317, 57209, 13322, 57208, 45993, 28064, 28063,\n",
       "         13328, 13329, 45994, 13311, 13333, 28051, 13338, 57188, 28047,\n",
       "         13344, 13345, 46006, 13347, 46007, 46008, 28042, 46013, 28034,\n",
       "         28056, 45984, 28076, 13307, 13269, 13271, 28097, 13273, 13274,\n",
       "         57247, 45976, 28093, 13280, 28091, 57237, 28088, 57232, 13288,\n",
       "         57230, 13290, 13292, 13293, 28085, 13295, 28084, 28082, 57227,\n",
       "         13301, 28080, 57224, 28079, 57221, 28078, 57334, 12951, 45903,\n",
       "         45900, 57447, 13020, 28274, 57442, 13028, 13029, 57441, 28267,\n",
       "         28265, 57437, 13037, 28264, 13040, 13016, 45843, 45846, 45847,\n",
       "         45849, 57430, 57429, 57428, 13052, 45856, 57427, 57425, 28248,\n",
       "         28247, 45863, 57433, 57423, 57450, 45828, 28331, 57502, 57501,\n",
       "         12960, 57493, 45800, 12964, 45803, 45807, 12969, 12970, 12971,\n",
       "         12973, 13014, 28316, 28310, 12983, 28304, 12987, 57480, 12989,\n",
       "         28299, 45823, 57468, 13002, 13003, 45824, 45826, 45809, 57422,\n",
       "         13065, 57420, 13112, 57386, 28213, 28209, 57381, 28208, 28207,\n",
       "         28205, 57367, 57366, 57365, 57362, 45892, 57389, 57359, 57352,\n",
       "         45895, 57350, 57344, 28188, 13146, 13148, 13149, 57341, 13151,\n",
       "         57339, 45899, 13154, 28191, 13108, 57391, 13106, 45864, 28241,\n",
       "         28240, 57415, 57413, 45865, 28238, 57405, 57403, 13079, 13081,\n",
       "         28233, 28232, 13084, 45872, 45874, 57401, 57399, 28225, 28224,\n",
       "         45879, 13095, 13096, 13098, 57395, 13101, 28218, 13103, 57392,\n",
       "         57336, 45592, 28649, 45583, 11984, 11985, 58274, 11987, 45255,\n",
       "         45258, 11994, 11995, 58267, 29071, 45266, 45271, 29058, 58277,\n",
       "         45275, 12014, 12015, 58254, 12017, 45281, 12022, 58246, 45282,\n",
       "         58243, 58242, 12029, 29042, 58240, 12013, 58239, 45253, 58285,\n",
       "         29107, 58311, 58310, 29105, 58305, 45236, 45237, 58301, 11952,\n",
       "         29098, 29097, 45239, 58297, 58283, 29094, 58294, 45243, 45247,\n",
       "         45248, 58292, 11968, 29086, 45249, 45250, 45252, 11975, 11976,\n",
       "         58286, 11959, 12033, 58237, 29041, 29004, 58195, 45317, 45321,\n",
       "         12087, 45323, 58191, 28994, 28993, 45331, 45333, 58179, 28986,\n",
       "         58197, 12104, 28983, 12108, 12109, 28982, 58178, 28981, 45338,\n",
       "         28976, 45339, 58163, 45340, 45342, 45343, 12106, 29007, 12079,\n",
       "         29008, 58236, 29040, 29039, 45292, 29035, 29033, 12045, 12046,\n",
       "         12047, 29032, 29029, 29028, 45299, 58221, 45304, 12056, 29020,\n",
       "         58215, 12059, 45305, 12062, 12064, 45310, 58208, 58207, 29012,\n",
       "         58203, 12075, 58200, 11940, 58158, 11939, 58316, 58439, 58438,\n",
       "         58434, 29214], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 650\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 650\n",
       "  })},\n",
       " 'contains_part': {'feature_present_idx': array([22578, 24581, 37486,  8252, 48880, 63551, 63386, 24632, 37048,\n",
       "         24664, 49234, 36568, 37590, 49317, 56494,  9451,  9472,  9479,\n",
       "          9536,  9582, 20123,  9783, 24953, 35699, 19982, 62491, 63607,\n",
       "         63634, 63661, 40649,  5711, 40567, 47878, 23374, 39961, 55699,\n",
       "         48004, 39842,  6133,  6207, 39702,  6535,  6550, 38882,  6892,\n",
       "          7040,  7212, 38361, 55995,  7499, 37911, 48719,  7837,  7885,\n",
       "         49794, 10479, 10613, 10643, 14640, 14860, 30205, 15214, 29514,\n",
       "         52636, 29006, 15821, 58677, 16054, 18238, 16232, 53992, 57561,\n",
       "         16377, 18161, 28166, 53056, 57614, 53897, 17326, 58258, 58213,\n",
       "         17524, 53849, 14620, 47689, 30418, 59540, 10745, 35228, 10974,\n",
       "         34919, 34853, 19457, 61307, 11185, 11243, 11301, 50153, 61229,\n",
       "         61006, 50396, 19453, 25356, 12080, 50702, 25392, 33095, 33024,\n",
       "         31767, 18970, 31235, 51521, 30729, 41255, 20227,  4746,  1585,\n",
       "         44559, 45595, 22880,  1535, 41902, 44637, 66551, 41991, 65919,\n",
       "         46746, 67223, 42119, 67109,   669,  3202, 42129, 55083, 45691,\n",
       "         44997,  3630, 66224, 22357, 46961, 55414,  4264, 42852,  4426,\n",
       "         43954,  4353,  1912, 45562, 45512, 66683, 45522, 54828, 21596,\n",
       "         51500, 51468, 11180,  2319, 22846, 13018, 51462, 31980, 57114,\n",
       "         51379, 32122, 19147, 51270, 34652, 61035, 11144, 14239, 14213,\n",
       "         14210, 52089, 46022, 18802, 51711,  2349, 34847, 22691, 51607,\n",
       "         13866, 51577,  1319, 32218, 59931, 30887, 25445, 12856, 22486,\n",
       "         56846, 50162, 11384, 34301, 66898, 25298, 34234, 60974, 11991,\n",
       "         56760, 66815, 61001, 50288, 44542, 34130, 33131, 34604, 12565,\n",
       "         44647, 60488, 34213, 51188, 50120, 32492, 56854, 12727, 32779,\n",
       "         32856, 12689, 12683, 11325, 32872, 14338, 22842, 60828, 12651,\n",
       "         41555, 14404, 27854, 53217, 27915,   273, 53034, 16888, 53011,\n",
       "         45397, 27850, 28194, 16403, 67176, 45234, 16238,   455, 45606,\n",
       "         45114, 22688, 16476, 28418, 53329, 27456,    22, 27006, 27021,\n",
       "         17611, 58038, 53824, 67265, 53818, 17075, 17881, 57873, 22450,\n",
       "           110, 67264, 26707, 17231, 26670, 17141, 53634, 28570, 28789,\n",
       "         58703, 26309, 52443, 52400, 57281, 30238, 54146, 14807, 30409,\n",
       "         29790, 18742, 46111, 45975, 52128, 52098, 59322, 18760, 30607,\n",
       "         25887, 59281, 52487, 15086, 15089, 52815,   554, 28884, 28919,\n",
       "           578, 58719, 26411, 52688, 22387, 52618, 15486, 52559, 57464,\n",
       "         18331, 26353, 29563, 54083, 29619, 52531, 30659,   753, 50029,\n",
       "         43968, 48722, 55450, 47069,  7678, 42156, 56007, 37964, 55495,\n",
       "         47067, 24292, 24217,  7308, 63809, 63853, 38368, 48504, 23832,\n",
       "         38600, 38128, 37787, 48864,  7977, 56292,  8504, 63347, 48945,\n",
       "         20708, 10975, 20713, 37320, 48885, 37338, 42800, 37369, 37391,\n",
       "         37419, 42663, 21772, 24392, 37653, 66221, 23709, 63298, 23499,\n",
       "         21306,  5825, 40355, 65331, 47301, 23305, 47872,  5486, 64973,\n",
       "         47989, 21474, 21485, 41202, 23344,  5080,  5007, 47355, 47577,\n",
       "         41544, 65070, 64524, 65370,  5896, 39128, 39195, 41944, 21339,\n",
       "         39547, 39553, 39643, 39670, 64133, 39682, 41811, 39802, 55604,\n",
       "         64204, 64261, 39814, 39923, 21667,  5909, 48217,  8583, 42814,\n",
       "         43181, 61974,  2777, 10030,  2782, 49603, 43359, 49602, 24931,\n",
       "         62287, 62386, 54395, 22069, 49395, 23071,  2939,  8650, 21941,\n",
       "         56577, 36226, 10124, 10133, 54387, 61878, 61550, 49844, 19647,\n",
       "          2549, 19788, 10727, 10701, 22193, 43598, 62429, 10557, 22137,\n",
       "         61649, 35394, 61807, 25052, 43467, 35511, 10180, 25019, 35366,\n",
       "          9352, 17853, 49246, 24698, 62864, 24796, 23158, 62825,  3219,\n",
       "         23141, 46736, 20324, 24663,  9033,  8912, 62763, 49313, 63275,\n",
       "          8660, 20322, 24682, 57995, 37034, 36281,  8768, 36530, 63224,\n",
       "         25072, 24627, 25753, 26691, 24025, 54208, 25812, 54585, 54371,\n",
       "         26784, 25080, 26814, 22863, 25759, 54198, 54168, 25736, 55011,\n",
       "         23974, 23290, 54533, 54644, 54686, 23525, 54284, 23491, 25496,\n",
       "         25550, 54263, 23296, 55029, 23237, 25694, 55114, 22692, 23212,\n",
       "         54819, 25840, 67325, 27020, 47631, 40770, 40684, 47882, 40252,\n",
       "         39949, 39220, 48211, 39109, 48328, 39048, 38883, 48473, 38556,\n",
       "         48505, 38217, 38135, 37025, 37056, 37070, 37073, 37180, 37276,\n",
       "         41678, 37281, 37572, 48871, 37916, 38005, 48717, 38048, 37309,\n",
       "         36973, 41693, 41794, 45435, 45658, 45048, 44967, 44762, 44742,\n",
       "         46055, 44655, 44551, 46095, 46096, 44084, 44076, 43865, 46630,\n",
       "         43329, 43307, 47119, 41892, 42019, 47115, 42120, 42346, 47124,\n",
       "         47005, 42693, 46931, 42949, 46838, 43137, 46660, 46985, 53825,\n",
       "         49210, 49287, 31216, 31089, 31041, 30951, 30895, 30866, 51855,\n",
       "         30628, 30569, 52104, 30417, 30271, 52211, 30122, 52460, 29595,\n",
       "         29559, 53761, 53603, 53525, 27249, 27327, 53425, 51519, 27440,\n",
       "         28234, 28332, 52875, 29023, 29491, 29545, 52981, 49224, 31330,\n",
       "         31816, 49381, 36337, 36309, 49393, 36224, 36213, 49461, 49498,\n",
       "         35732, 49613, 35608, 49646, 49801, 49805, 49811, 35313, 34997,\n",
       "         32001, 51308, 32210, 32260, 51107, 50834, 31501, 33165, 33761,\n",
       "         33872, 33912, 50410, 34674, 34733, 33366, 50056, 22209, 64577,\n",
       "         15443, 58836,  6525,  6615, 15160,  6633,  6673,  6695,  6743,\n",
       "         14942,  6835, 14819, 59204, 63922,  7030,  7048,  7271,  7345,\n",
       "         14607, 14514, 59332, 59351, 59437, 59451, 59476,  6454, 64076,\n",
       "         15444, 15556, 58008, 17697, 17649, 58101, 65733, 58276, 17310,\n",
       "         58398, 17145, 17091,  4504,  4771, 14122,  5143, 16489, 16330,\n",
       "         65003, 16005,  5833, 64513,  5885, 15747, 64496, 64452,  6011,\n",
       "          6173, 58531, 17746, 59485, 13968, 60879,  9091,  9098,  9166,\n",
       "         12384,  9244, 62388,  9595,  9603,  9614,  9843, 11504, 10169,\n",
       "         61210, 11349, 61275, 11284, 11172, 10306, 11074, 61310, 61320,\n",
       "         10972, 61761, 61613, 62640, 62695, 60755,  9002,  7520, 59692,\n",
       "          7551,  7736,  7887, 59912, 13724,  8016, 63576, 60133,  8174,\n",
       "         13320, 59531,  8187,  8199,  8303, 13225, 13063, 12976, 63363,\n",
       "          8473, 63294,  8708,  8732, 12786, 12665, 13302,  4086, 61562,\n",
       "         20455, 21287, 56792,   979, 19198,   899,  2872,  2884, 57037,\n",
       "          2832,  2962, 18902, 18871, 66474, 21525, 21534,   700, 66397,\n",
       "         66328, 56035, 21744,  2827, 19561, 55986, 20755, 55965,  2327,\n",
       "         57926, 66655, 21067, 20406,  2636, 20226, 66957, 20107,  1405,\n",
       "         21069, 19807, 21101, 19638,  1355,  2439, 18769,  2964, 67135,\n",
       "         22027, 21875,  3510,   103, 57332, 22194, 66004, 57331, 67166,\n",
       "         55178, 18706,  3627, 55212, 21835, 57320, 22346, 44688,   697,\n",
       "          1369, 35478, 49783, 63491, 63481,  8390,  8419, 37366,  8274,\n",
       "           173, 35406, 37721, 10744,  7964,    94, 10499, 37673, 35436,\n",
       "         44480,  8136,  8159, 37566, 37533, 66804,  1555, 63626, 37252,\n",
       "         44710, 48933, 49228,  8977, 44843, 62199, 35843, 44898, 44940,\n",
       "         62673,  9068, 49472, 45075,   735, 45778, 45043, 45703, 62088,\n",
       "         67128,  9974,  8963,  9322, 44713, 67008,  8529, 10275, 44757,\n",
       "         45637,   476,   518, 10141, 35668,  8802, 35678, 49126, 62849,\n",
       "         44831, 46078,  4010, 37864, 47628,  4980,  5122,  5123, 41110,\n",
       "         41108,  3460, 65088, 40754, 40726, 66313, 47859,  5618, 40658,\n",
       "         40628, 64731,  5788, 10820,  3266, 47582, 65094, 41469, 47432,\n",
       "         42028, 65926, 42036,  3925,  3896, 42192, 47117,  4098, 66178,\n",
       "         40180, 65840,  3652, 65501,  4292,  4325, 47257,  3589, 65278,\n",
       "          4735, 47361,  3670, 47930,  5848, 66493, 46313, 43863, 66568,\n",
       "          2462, 46236,  7360, 48555, 66677, 38053, 43797, 48569,  7425,\n",
       "          7435, 44134, 63723, 44145, 37968,  2158,  2127, 63708, 44118,\n",
       "          7864, 63947, 38668,  3037,  2999, 39759, 64184, 43188, 64182,\n",
       "         48139, 39482, 48171,  6844, 39219, 66554,  6667, 46391, 39079,\n",
       "         46360, 63958,  6843, 48363, 48436, 39215, 22579, 11716, 28731,\n",
       "         15810], dtype=int64),\n",
       "  'feature_absent_idx': array([59198, 57715, 45968, 28775, 45969, 28772, 13014, 28768, 13016,\n",
       "         28767, 13020, 28765, 45976, 57699, 13003, 13028, 28759, 45984,\n",
       "         45986, 28754, 57688, 13037, 45990, 13040, 57683, 45993, 45994,\n",
       "         28738, 13052, 13029, 57676, 13002, 57717, 45953, 28805, 28803,\n",
       "         12960, 57745, 57741, 12964, 12969, 12970, 12971, 12973, 57736,\n",
       "         57735, 28777, 57731, 28792, 28791, 12983, 28788, 57725, 12987,\n",
       "         12989, 57723, 28784, 28783, 28779, 28778, 57718, 57730, 28727,\n",
       "         57670, 57667, 28697, 13112, 46023, 57629, 46024, 57628, 28688,\n",
       "         57626, 46028, 28684, 46036, 57611, 57609, 28699, 28677, 28676,\n",
       "         57601, 57599, 57596, 13146, 46047, 13148, 13149, 57594, 13151,\n",
       "         57591, 13154, 28664, 57605, 13108, 57641, 13106, 57666, 13065,\n",
       "         57665, 46006, 28724, 46007, 57662, 46008, 57656, 46013, 13079,\n",
       "         28715, 13081, 28714, 28713, 13084, 57650, 46016, 46018, 13095,\n",
       "         13096, 28703, 13098, 28702, 13101, 28700, 13103, 57643, 57642,\n",
       "         57750, 46049, 12952, 57753, 28924, 45872, 12805, 12807, 57876,\n",
       "         45874, 12811, 12812, 12813, 45879, 57867, 57864, 12824, 28927,\n",
       "         57860, 28909, 12829, 28907, 57857, 57856, 28905, 12835, 28902,\n",
       "         28901, 28900, 28897, 28896, 28895, 12826, 28893, 28928, 28929,\n",
       "         45846, 28957, 45847, 57901, 12762, 12763, 57900, 57899, 45849,\n",
       "         28954, 12768, 12769, 12770, 12799, 12771, 45856, 12777, 57898,\n",
       "         12782, 28942, 28940, 45863, 57887, 45864, 57885, 45865, 28933,\n",
       "         28932, 12773, 57850, 57846, 28890, 12901, 28853, 28850, 45923,\n",
       "         45927, 28840, 12915, 57782, 28839, 45929, 45935, 57772, 57770,\n",
       "         12898, 28827, 45939, 28823, 57768, 57766, 45945, 28818, 28817,\n",
       "         57762, 45948, 12943, 28815, 12947, 12948, 12930, 28860, 12894,\n",
       "         12892, 12851, 12852, 12854, 28887, 57840, 12858, 45892, 12862,\n",
       "         57835, 12865, 28881, 28880, 57825, 57821, 45895, 45899, 45900,\n",
       "         45903, 12877, 12878, 57811, 12880, 45904, 57807, 57801, 28868,\n",
       "         28865, 57796, 57795, 12951, 57907, 13160, 57579, 13422, 13423,\n",
       "         13425, 13426, 28473, 46187, 13429, 57367, 13435, 57366, 57365,\n",
       "         57362, 13441, 28476, 57359, 13446, 13448, 46199, 57352, 13454,\n",
       "         57350, 28452, 57344, 28450, 57341, 28448, 28447, 13463, 46198,\n",
       "         57339, 46184, 46183, 57422, 28501, 57420, 28500, 57415, 57413,\n",
       "         28498, 57405, 57403, 57401, 57399, 28494, 57395, 28478, 28493,\n",
       "         46172, 57392, 13405, 57391, 57389, 28487, 46180, 13410, 57386,\n",
       "         28482, 13415, 46182, 57381, 13399, 13466, 13467, 28445, 57299,\n",
       "         13524, 57297, 13532, 28398, 28397, 13536, 57283, 46258, 13541,\n",
       "         28388, 57271, 28383, 13520, 28382, 57265, 13551, 28378, 13557,\n",
       "         46268, 28374, 46271, 57261, 28371, 28370, 13564, 13565, 13566,\n",
       "         57266, 13519, 28407, 57301, 46209, 57336, 57334, 28441, 13476,\n",
       "         28439, 57329, 28436, 46214, 13485, 57325, 28429, 46228, 13494,\n",
       "         13495, 46237, 13498, 28421, 46239, 28416, 46241, 13507, 57306,\n",
       "         13511, 57305, 13513, 28410, 28408, 57303, 57423, 13161, 46168,\n",
       "         28504, 13221, 28612, 46100, 57544, 28605, 13233, 28602, 46110,\n",
       "         28595, 46117, 28592, 13243, 28589, 13219, 13247, 46120, 57526,\n",
       "         57525, 57524, 13255, 28583, 13259, 57518, 57516, 57513, 28580,\n",
       "         46124, 57511, 13249, 13269, 57550, 13214, 13167, 57578, 46063,\n",
       "         13173, 28649, 46066, 13176, 46067, 28642, 46071, 57571, 13183,\n",
       "         57570, 13217, 46075, 57567, 57566, 13190, 13193, 28634, 28630,\n",
       "         46088, 13201, 46089, 28624, 28622, 28621, 13209, 57568, 13271,\n",
       "         13273, 13274, 13338, 28530, 28529, 57450, 13344, 13345, 13347,\n",
       "         28525, 57447, 28521, 28520, 57442, 28519, 28534, 57441, 46158,\n",
       "         46159, 13362, 13364, 13365, 46162, 57433, 46163, 57430, 57429,\n",
       "         46164, 57428, 57427, 57437, 13333, 46146, 28536, 57502, 13280,\n",
       "         57501, 57493, 46128, 46129, 13288, 46130, 13290, 13292, 13293,\n",
       "         13295, 28562, 28558, 46135, 13301, 28552, 13307, 13311, 57480,\n",
       "         28548, 46138, 13317, 28544, 13322, 57468, 13328, 13329, 28537,\n",
       "         57425, 57257, 57908, 57911, 29389, 12178, 58340, 29388, 58337,\n",
       "         29387, 12184, 12186, 58333, 29383, 29382, 29380, 29377, 45583,\n",
       "         45592, 29372, 12202, 45594, 29368, 12205, 12207, 45598, 45599,\n",
       "         58318, 12212, 58316, 45600, 12215, 12198, 58311, 29392, 45576,\n",
       "         29432, 29430, 58373, 45565, 12132, 45567, 12134, 29424, 29423,\n",
       "         29422, 58367, 12142, 12143, 29393, 29414, 29413, 58363, 58361,\n",
       "         45573, 29410, 58360, 58358, 29408, 12158, 58357, 29406, 58354,\n",
       "         58349, 58364, 58310, 12218, 58305, 58283, 12267, 45618, 58277,\n",
       "         58274, 45619, 29329, 29326, 58267, 12279, 12283, 29320, 29317,\n",
       "         45616, 45626, 12293, 12294, 12297, 45628, 29308, 58254, 29306,\n",
       "         29305, 29304, 29303, 58246, 12308, 12313, 12292, 29334, 58285,\n",
       "         29335, 29357, 12224, 58301, 45603, 29353, 12230, 29352, 58297,\n",
       "         12234, 58294, 12236, 29350, 29349, 12239, 12240, 29346, 29345,\n",
       "         12243, 45609, 58292, 12247, 12251, 12252, 12253, 12254, 45611,\n",
       "         12258, 45615, 58286, 58380, 58243, 29433, 29436, 29552, 11968,\n",
       "         45477, 58513, 29549, 29548, 29547, 29544, 11975, 11976, 29543,\n",
       "         58506, 45488, 45473, 11984, 58502, 11987, 45489, 58496, 29532,\n",
       "         11994, 11995, 29529, 58491, 29526, 58489, 58488, 29525, 11985,\n",
       "         29522, 29558, 58519, 29602, 29601, 29597, 11914, 45446, 58559,\n",
       "         58553, 11922, 11923, 58548, 45457, 45458, 11931, 11959, 29580,\n",
       "         45462, 58538, 11939, 11940, 58537, 58536, 29574, 29572, 58526,\n",
       "         29569, 45467, 11952, 45469, 45460, 29521, 45500, 29516, 45520,\n",
       "         58434, 58429, 58428, 12075, 29470, 12079, 29465, 58416, 58415,\n",
       "         12087, 58413, 58411, 58438, 29462, 45535, 29453, 45542, 12104,\n",
       "         45544, 12106, 29444, 12108, 12109, 58389, 58388, 45553, 58385,\n",
       "         29461, 12064, 58439, 12062, 12013, 12014, 12015, 12017, 29508,\n",
       "         58476, 12022, 29504, 12029, 45504, 58465, 12033, 29495, 45509,\n",
       "         58460, 29490, 45511, 12045, 12046, 12047, 58450, 29483, 58444,\n",
       "         12056, 29482, 58443, 12059, 29481, 58442, 45557, 45843, 12315,\n",
       "         12318, 12586, 58030, 58029, 29086, 12592, 12595, 12596, 12597,\n",
       "         12598, 58021, 45769, 29071, 58017, 58032, 45779, 58006, 58000,\n",
       "         57998, 45786, 12633, 12634, 29042, 29041, 29040, 29039, 57991,\n",
       "         57990, 57988, 29058, 12644, 12583, 45761, 58060, 29119, 29115,\n",
       "         29114, 12544, 58057, 12546, 29111, 12550, 58052, 29110, 29107,\n",
       "         58049, 12581, 12557, 45747, 12562, 58046, 29098, 29097, 12568,\n",
       "         45758, 29094, 12574, 58039, 58037, 58036, 58034, 29105, 29035,\n",
       "         29033, 29032, 45823, 12707, 45824, 45826, 12710, 12711, 12714,\n",
       "         28986, 57940, 12717, 57938, 12721, 28983, 28993, 12723, 28982,\n",
       "         28981, 45828, 57933, 57929, 28976, 57927, 57924, 12739, 12742,\n",
       "         57922, 57919, 28964, 57937, 28994, 57953, 12696, 57978, 12653,\n",
       "         29029, 57977, 57975, 57974, 57973, 57972, 29028, 12661, 57971,\n",
       "         12663, 12664, 45800, 12667, 45803, 57968, 29020, 45807, 12675,\n",
       "         12676, 45809, 29012, 29008, 29007, 57960, 29004, 12693, 57955,\n",
       "         45743, 58242, 12534, 45740, 58197, 58195, 45664, 45671, 12390,\n",
       "         12391, 29239, 58191, 45672, 45674, 29229, 12404, 58179, 29249,\n",
       "         58178, 12411, 12412, 45683, 29219, 12418, 58163, 29214, 29213,\n",
       "         58158, 12428, 45695, 58152, 12431, 29226, 58151, 29252, 58200,\n",
       "         58240, 58239, 58237, 58236, 45634, 45635, 29287, 45638, 29284,\n",
       "         45639, 12338, 58221, 12344, 12374, 45643, 58215, 58208, 12356,\n",
       "         58207, 45652, 12362, 12363, 12365, 58203, 12367, 12368, 29254,\n",
       "         12372, 12346, 45696, 29205, 29200, 12491, 45717, 12494, 12495,\n",
       "         45722, 58092, 58090, 45725, 29152, 45726, 12506, 29149, 29147,\n",
       "         12490, 29146, 12512, 45731, 29140, 29139, 45732, 58072, 29135,\n",
       "         29133, 29131, 45736, 12527, 29127, 12530, 12510, 29161, 45716,\n",
       "         12484], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_path': {'feature_present_idx': array([37800, 50562, 33176,  3269, 29994, 56376, 17503, 19240, 28068,\n",
       "         42607, 42185, 21975, 40725, 11169, 11937, 66963, 36941, 13099,\n",
       "         13188, 43003, 23334, 31413, 30238, 27380, 15244, 46565, 21542,\n",
       "         58943, 59772, 54230,  2868, 50196, 53141,  7152,  7559,  7729,\n",
       "           499, 59251, 66508, 23419, 24677, 22738, 25507, 64684, 26083,\n",
       "         26762, 64425, 60046, 29928, 47192, 47057, 57175, 53706, 34464,\n",
       "         36739, 53682, 37059, 52891, 40191, 49777, 41021, 47534, 31215,\n",
       "         41585, 67146,  4379, 10461, 10172,  4774,  8742, 13913, 17851,\n",
       "         21442, 53905, 53608, 49382, 48646, 47252, 53926, 45792, 43188,\n",
       "          9546, 12041, 36312, 48245,  4617, 54381, 56148, 66935, 66348,\n",
       "         65606, 65599, 63895, 63205, 61501, 36171, 61103,  1439, 59513,\n",
       "          2021, 58913, 57888, 57636, 56192, 60426, 13042, 47235,   330,\n",
       "         32171, 14836, 27785, 19141, 19568, 33089, 22192, 17382, 21551,\n",
       "         20381, 21432, 31099,  7420, 14170,  6754, 49995,  6303, 52246,\n",
       "         52491, 66558,  5060,  1082,  4681, 62501, 54325, 54649,  4511,\n",
       "         26284,  7752, 58602, 58710, 59631, 60123, 66232, 23012, 65717,\n",
       "         61526,  1198,  8620, 34499, 52295, 42379, 10094, 43070, 43078,\n",
       "         41310, 32748, 32836, 40489, 43131, 13960, 12794, 35561, 38723,\n",
       "         39498, 66891, 54055, 42040, 27004, 54450, 66850, 41557, 56647,\n",
       "         21926, 57847, 57982, 53954, 22393, 37637,  3377, 59361, 24329,\n",
       "         40221, 57834, 15447, 16497, 48611,  6666, 49915, 44150, 50770,\n",
       "         51219, 51230, 14297,  9955, 31773,  5863, 46219, 15009, 52566,\n",
       "         17889, 59775, 11413, 12732, 49225,  1288, 12679,  1393, 46893,\n",
       "         58392, 26484, 45439, 21177, 32494, 27063, 25572, 50373, 36963,\n",
       "         44827, 65944, 33119, 13314, 30250, 18171, 62919, 39937, 51932,\n",
       "         34049, 53472, 62974, 44718, 49273, 51745, 36485, 26922, 46506,\n",
       "         53876,  8682, 42649, 35310], dtype=int64),\n",
       "  'feature_absent_idx': array([61527, 18850, 46016, 18847, 46018, 18841, 63427, 46023, 46024,\n",
       "         46028, 18832, 18830, 18826, 63432, 46036, 18808, 46013, 63436,\n",
       "         18855, 18860, 45986, 18898, 45990, 18894, 45993, 45994, 18889,\n",
       "         18887, 57762, 18880, 46006, 46007, 46008, 18867, 18864, 18856,\n",
       "         18796, 18794, 18791, 18727, 63450, 63452, 18718, 18715, 18714,\n",
       "         18712, 18707, 46088, 46089, 18700, 57745, 18694, 18691, 46100,\n",
       "         63449, 46075, 18732, 18733, 46047, 46049, 63438, 18783, 18778,\n",
       "         18773, 18765, 45984, 57753, 46063, 46066, 46067, 18750, 63445,\n",
       "         46071, 57750, 18761, 63460, 18911, 18919, 19074, 45903, 45904,\n",
       "         63383, 57782, 63385, 19052, 19051, 19045, 19040, 19038, 19036,\n",
       "         19031, 45923, 19021, 45900, 45927, 63381, 19079, 19124, 19123,\n",
       "         19119, 63375, 45892, 19103, 63378, 45895, 19088, 19087, 19086,\n",
       "         19085, 19084, 19083, 19080, 45899, 45929, 45935, 63393, 18954,\n",
       "         18953, 18952, 18951, 18948, 18947, 18946, 63405, 18942, 45968,\n",
       "         18938, 45969, 63409, 63410, 45976, 57766, 18960, 57768, 45953,\n",
       "         57772, 19001, 45939, 63397, 18998, 63398, 18993, 18912, 18992,\n",
       "         45945, 57770, 45948, 18980, 18979, 18977, 18973, 18989, 19127,\n",
       "         18678, 46110, 18392, 18391, 18389, 46268, 18383, 46271, 63523,\n",
       "         18376, 46274, 18371, 18370, 18369, 18361, 46284, 18355, 46258,\n",
       "         63528, 18400, 18412, 18469, 57718, 57717, 46228, 57715, 18451,\n",
       "         46237, 46239, 63513, 63514, 46241, 18426, 18423, 18422, 18420,\n",
       "         18402, 46287, 18344, 18343, 46334, 18267, 46341, 46342, 46343,\n",
       "         46344, 63545, 18255, 18254, 18253, 18247, 46349, 18239, 18237,\n",
       "         18236, 18283, 63540, 18294, 46317, 18337, 18336, 18334, 46294,\n",
       "         18332, 18330, 46299, 46214, 18324, 46304, 46305, 18304, 46312,\n",
       "         57699, 46314, 46316, 18315, 57741, 63506, 46209, 46135, 18624,\n",
       "         18623, 18622, 46138, 18619], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 238\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 238\n",
       "  })},\n",
       " 'contains_polarity': {'feature_present_idx': array([46026, 38879, 36414, 17654, 23330, 37429, 57545, 48121, 19694,\n",
       "         57541,  2293, 14632, 66406, 36679, 35610, 53580, 24654,  2459,\n",
       "         48275, 46626, 19377, 34987, 49591, 51795, 53289, 53470, 54056,\n",
       "         16513, 49328, 17555, 25197, 45456, 36655, 36161, 35649, 34937,\n",
       "         34514, 33619, 36970, 37552, 23278, 31827, 38631, 39392, 39630,\n",
       "         39955, 40116, 40179, 26559, 54417, 38459, 16437, 36648, 64338,\n",
       "          8428,  2933,  7380,  2600,  6069,  2685,  1004, 10297, 60865,\n",
       "          8777,   922, 11872, 58691, 55445,  3360, 13634, 56069, 57672,\n",
       "         64994, 66745, 14544, 30186, 43941, 32231,  1979, 41783, 37699,\n",
       "          3165,  5555,  2855, 66371, 31518, 38023, 33442, 36929,  3791,\n",
       "         24869, 44326, 16314, 15689, 17281,   916, 17844, 52727, 57823,\n",
       "         18819, 12393, 48783, 24694, 61041, 20980,  1027, 22008, 22089,\n",
       "         22388, 23081, 36890, 45848,  9037, 45297, 61174, 32881, 55988,\n",
       "         64386, 39724, 40075, 64345, 40898, 41905, 64058, 45905, 62732,\n",
       "         60061, 57729, 56378, 65652, 52049,   157, 27244, 29154, 16326,\n",
       "         28490, 19411,  6030, 17773, 18476, 29187, 24666, 23474, 36508,\n",
       "         21348, 20969, 19328, 20515, 20039, 24382, 29772,  9262,  9426,\n",
       "         10918, 33603, 33481, 32055, 11246, 57155, 49394, 62689, 61786,\n",
       "          9368, 50080,  3788, 51864, 60783, 18657, 52459, 59549, 64589,\n",
       "         16972, 53844,  5554, 59404, 16348, 12352, 13094, 13905, 57456,\n",
       "         57364, 15696, 19152,  9175, 32788, 65185, 39446, 28734, 38371,\n",
       "         37986, 42101, 43557, 43652, 43824, 30237, 37028, 44824, 34073,\n",
       "         45723, 66863, 35521, 36296, 36459,  3657, 14631, 61085, 58402,\n",
       "         57872, 57720, 66564, 48561, 29990, 17110, 47421, 49850, 46668,\n",
       "         20779, 44779, 30146, 25473, 49298, 64358, 26320,  2917, 56445,\n",
       "          9141, 52031, 23425, 12864,   169, 15448, 31245, 14222, 36644,\n",
       "         54238, 16541, 53349, 51146, 19330, 38408, 60695, 30862, 67055,\n",
       "         16502, 25048, 26565,  1533], dtype=int64),\n",
       "  'feature_absent_idx': array([29788, 12717, 12721, 28310, 12723, 28304, 45609, 57579, 57578,\n",
       "         28299, 45611, 12739, 45615, 45616, 57591, 12742, 57570, 57568,\n",
       "         57567, 57566, 45618, 45619, 45626, 12762, 12763, 45628, 28274,\n",
       "         12768, 12769, 57571, 12770, 57594, 45603, 45576, 12675, 12676,\n",
       "         57629, 57628, 28341, 45583, 57626, 28337, 28333, 28331, 57611,\n",
       "         57609, 12714, 45592, 45594, 12696, 57605, 45598, 45599, 45600,\n",
       "         57601, 57599, 12707, 57596, 12710, 12711, 28316, 12693, 12771,\n",
       "         12773, 28267, 12826, 12829, 45664, 57502, 57501, 12835, 28225,\n",
       "         28224, 57493, 28218, 45671, 45672, 28213, 28232, 12851, 45674,\n",
       "         12854, 28209, 28208, 28207, 12858, 57480, 28205, 12862, 12865,\n",
       "         57468, 45683, 12877, 12852, 12824, 28233, 57511, 12777, 57550,\n",
       "         28265, 28264, 12782, 57544, 45634, 45635, 45638, 45639, 45643,\n",
       "         28248, 12799, 57526, 57525, 57524, 28247, 12805, 12807, 28241,\n",
       "         12811, 12812, 12813, 57518, 57516, 28240, 45652, 57513, 28238,\n",
       "         45573, 12878, 28350, 12664, 12506, 28473, 45488, 45489, 12510,\n",
       "         12512, 57753, 57750, 57745, 45500, 57741, 12527, 28452, 57762,\n",
       "         12530, 57735, 12534, 28450, 45504, 57731, 28448, 28447, 28445,\n",
       "         57730, 12544, 12546, 28441, 57725, 57736, 45509, 28476, 57768,\n",
       "         12460, 45458, 57796, 57795, 45460, 45462, 12468, 28504, 45467,\n",
       "         28501, 28500, 28498, 57782, 57766, 28494, 12484, 45469, 28487,\n",
       "         45473, 12490, 12491, 45477, 28482, 12494, 12495, 57772, 57770,\n",
       "         28478, 28493, 12550, 57723, 28439, 57676, 28383, 28382, 57670,\n",
       "         57667, 57666, 57665, 28378, 45553, 45557, 12633, 12634, 28374,\n",
       "         28388, 28371, 28370, 57656, 12644, 45565, 57650, 45567, 28361,\n",
       "         12653, 57643, 57642, 57641, 12661, 12663, 57662, 45544, 45542,\n",
       "         28397, 28436, 45511, 12557, 12562, 57718, 57717, 57715, 28429,\n",
       "         12568, 12574, 45520, 28421, 28416, 12581, 57699, 12583, 12586,\n",
       "         57688, 28410, 12592, 28408], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 247\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 247\n",
       "  })},\n",
       " 'contains_polite': {'feature_present_idx': array([62414,  2806, 44269, 59069, 35535, 49762, 52887, 57711, 66405,\n",
       "         66599], dtype=int64),\n",
       "  'feature_absent_idx': array([18992, 57567, 57566, 28225, 28224, 45542, 28218, 12693, 45544,\n",
       "         12696], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 10\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 10\n",
       "  })},\n",
       " 'contains_poss': {'feature_present_idx': array([67343, 10631, 10675, 10714, 10840, 10888, 49179, 49144, 49109,\n",
       "         10961, 48988, 50102, 11091, 48805, 11280, 48670, 11449, 48556,\n",
       "         48553, 48409, 48347, 11654, 48228, 48839, 11692, 50210, 50305,\n",
       "          9134, 52112, 52045,  9269,  9334,  9373,  9477, 51825, 51699,\n",
       "          9581, 50302,  9645, 51105, 51037,  9871, 50945, 50886, 10013,\n",
       "         50716, 10066, 50569, 10186, 51309,  9130, 48149, 11878, 13354,\n",
       "         45630, 45550, 45208, 45087, 45066, 13667, 45034, 13746, 13766,\n",
       "         13343, 44783, 13895, 44638, 13980, 44555, 13998, 14003, 44444,\n",
       "         44190, 14119, 14184, 44776, 48101, 45773, 45898, 11880, 11890,\n",
       "         47946, 12012, 47822, 47722, 12177, 47591, 12231, 47379, 45878,\n",
       "         47339, 12514, 12613, 46719, 46579, 46543, 46491, 46479, 13005,\n",
       "         13030, 46010, 47280, 44089,  9060, 52286, 58493, 58218,  5234,\n",
       "          5259, 58128,  5333,  5394,  5454, 57993, 57894, 58574, 57879,\n",
       "         57616, 57582, 57470,  5723, 57075, 56818, 56796, 56794,  6212,\n",
       "         56638, 57695,  6315, 58591, 58879, 60938, 60757,  3905, 60609,\n",
       "         60467, 60406, 60375, 60233, 60193, 60114,  4900, 59886, 59758,\n",
       "         59740,  4536, 59445, 59252, 59166,  4702,  4725,  4762, 59076,\n",
       "         59765, 52217,  6352,  6406,  7971,  8065, 53531,  8153,  8179,\n",
       "         53521, 53259, 53222, 53191, 53107, 53906, 53075,  8548,  8618,\n",
       "          8657, 52828, 52706, 52642,  8805, 52397, 52393, 52379, 53010,\n",
       "         56303, 53909, 53971, 56209, 56116, 56051, 55791,  6862, 55558,\n",
       "         55515, 55246, 55048, 54949,  7882, 54917, 54872,  7313,  7614,\n",
       "          7671, 54300,  7727,  7734, 54040,  7830,  7869, 54904, 44087,\n",
       "         14309, 43642, 32258, 32246, 32157, 32147, 32085, 21313, 32045,\n",
       "         31953, 31850, 21444, 32289, 31818, 21494, 31597, 21612, 31249,\n",
       "         21888, 31196, 21999, 30911, 30882, 30854, 31791, 30638, 20992,\n",
       "         32595, 19858, 34017, 19971, 33992, 33894, 33812, 33750, 20230,\n",
       "         20238, 20289, 32479, 33586, 33406, 20398, 33349, 33175, 20648,\n",
       "         20697, 33110, 20769, 33015, 32817, 33564, 19828, 30631, 22280,\n",
       "         27760, 24242, 24276, 27378, 27338, 27267, 27167, 24629, 27003,\n",
       "         26921, 27874, 24732, 24819, 24999, 26352, 25198, 25211, 26071,\n",
       "         25266, 25999, 25878, 25844, 26866, 30588, 23846, 23531, 30544,\n",
       "         30476, 30357, 22498, 22581, 30198, 30150, 22762, 29819, 22891,\n",
       "         28211, 22915, 22944, 29623, 23055, 29292, 29271, 29201, 23375,\n",
       "         29144, 29088, 28882, 29718, 34351, 34403, 19712, 15607, 41539,\n",
       "         41502, 15855, 41470, 41404, 41386, 15961, 41280, 16150, 41863,\n",
       "         16171, 16235, 40901, 40625, 16491, 40479, 40243, 40010, 39989,\n",
       "         39867, 39784, 41103, 39751, 42266, 15388, 14471, 43553, 43490,\n",
       "         14576, 14641, 14671, 14840, 43091, 14886, 42981, 15394, 14976,\n",
       "         15111, 42648, 42589, 15199, 42436, 15317, 15319, 15321, 15322,\n",
       "         42402, 15033, 16980, 39561, 39404, 18421, 18659, 18702, 36378,\n",
       "         36375, 18722, 36203, 18907, 18924, 18925, 36869, 35707, 35554,\n",
       "         35410, 35397, 35360, 35270, 19360, 34814, 34787, 34736, 34734,\n",
       "         35578, 18316, 37032, 37037, 39386, 39314, 39217, 39165, 38950,\n",
       "         38909, 17366, 17398, 38328, 38313, 38200, 17660, 37966, 17744,\n",
       "         17761, 37876, 17878, 37623, 37594, 37492, 18057, 18205, 37094,\n",
       "          3727,  3726, 25484, 65822,  2543, 64627, 61845, 65092, 63283,\n",
       "          2087,  2684, 62203, 66349, 63938, 64987, 64413,  3274,   434,\n",
       "         62374, 65627, 66345,  2330,  1798, 66482,  3126, 66657, 64109,\n",
       "          2513, 67267, 62724,  2250,   315, 61186, 65688, 62210,  3428,\n",
       "          3549, 62956, 65347, 62207, 63308, 64875, 62741, 67051, 67219,\n",
       "         66189, 64873,  2110,  3572, 66794, 66872, 66470, 63966, 62060,\n",
       "           567,  1740, 63847,   261, 65573,  1608, 64817, 63229, 63910,\n",
       "         62635,  2921, 65642,  3251, 66643,  2815, 65435,  1091,  1983,\n",
       "         66713,  2914, 64273, 61589, 63925, 13632,  1948, 13669,  1940,\n",
       "         32044, 44944, 45057, 45040, 13706, 45038, 13715, 44979, 45029,\n",
       "         63942, 13764, 44873,  1929, 66567, 45119, 31813, 45728, 45742,\n",
       "         45746, 13356, 45753, 63893, 21488, 45724, 13299, 45813, 45854,\n",
       "         13276, 63855, 21504, 13218, 31715, 45920, 31781, 13624, 31814,\n",
       "         45574, 31924, 13590, 31900, 13567, 31871, 45284, 31861, 66550,\n",
       "         45622, 13534,   609, 45441, 45447, 45491, 21454, 45543,  1963,\n",
       "         45570, 31833, 44862, 46407, 32122, 43480, 64257, 14568, 20921,\n",
       "         32651, 14526, 32625, 32605, 43460, 66215, 43637, 64222, 43680,\n",
       "         43717, 43760, 32414, 43817, 43832, 32488, 43943, 43403, 32678,\n",
       "         14867, 64312, 33055,  1770, 43178, 32999, 43199, 43209, 14594,\n",
       "         43219, 43250, 32948, 32897, 43303, 32858, 32828,  3663, 43346,\n",
       "         14749, 32064, 43969, 14328,  1873, 66416, 64103, 64047, 44592,\n",
       "         13967, 21169, 13197, 44522, 13935, 21176, 44678, 32191, 44738,\n",
       "         13866, 32159, 64011, 13834, 21170, 14332, 44506, 44471, 21038,\n",
       "         32298, 44019, 14213, 14195, 32272, 32266, 44121, 44485, 44126,\n",
       "         21118,  1863, 21119, 44218, 44264, 44265, 44413, 44423, 44146,\n",
       "          1905, 12958, 13166, 63349, 30773, 30741, 48250, 48272, 11622,\n",
       "         22241, 48335, 48343, 48355, 30610, 30605, 11528, 11527, 11516,\n",
       "         30568, 35941, 11490, 63276, 22122, 63275, 48122, 48089, 12049,\n",
       "         21975, 63456,   544, 47837, 47838, 47853, 47857, 47877, 47880,\n",
       "         11935, 22001, 30950,   538,  2190, 63376, 30848, 30842, 48088,\n",
       "         63353, 47779, 48568, 48571, 48889, 11097,  2339, 48902, 48909,\n",
       "         30433, 48993, 11056, 22405, 30393, 30374, 63248, 49101,  2367,\n",
       "         10920, 22478, 49155, 30333,  2375, 22389, 11389, 22387,  2338,\n",
       "         30555,  2313, 48683, 48705, 30530, 30529, 48721, 48742, 30507,\n",
       "         11278, 30500, 30495, 48791,  2337, 11238, 11187, 30468, 22366,\n",
       "         22370, 30448, 45928, 47747, 31014, 63744, 12847, 46519, 12820,\n",
       "         21664, 46570, 46690, 31508, 46736, 46782, 12760, 12753, 12733,\n",
       "         46836, 46845, 46847, 12678, 31482, 21701,  2071, 46870, 46444,\n",
       "         31543, 45995, 63805, 31666, 31633, 46116, 46121, 46169, 46193,\n",
       "           577, 63791, 46261, 46289, 46320, 43075, 46348, 46351, 31570,\n",
       "         46385, 12909, 21628, 21963, 46880, 21723, 63640, 47301, 63578,\n",
       "         47365, 47371, 47382, 12278, 47478, 31193, 31171, 47588,  2137,\n",
       "         12191, 47601, 12164, 12151, 47647, 47668, 47713, 47270, 46914,\n",
       "         31231,   568, 46933, 31457, 31440, 21772, 47003, 47022, 47041,\n",
       "         63645, 21813, 31420, 31368, 47123, 12464, 12444, 31256, 47224,\n",
       "         12424, 47236, 12399, 47247,  1753, 14994, 43003, 17612, 38062,\n",
       "         38087, 38128, 19409, 38143, 34944, 65009, 38262, 38276, 17553,\n",
       "         38299, 19444, 64998, 38320, 17517, 38360, 38387, 17480, 35007,\n",
       "         17630, 35012, 38009, 35134, 37733, 19323, 35089, 37771, 35037,\n",
       "         17845, 35035, 37852, 38407, 37872, 17755, 19365, 65033, 17713,\n",
       "         19373, 17687, 65027, 65020, 37985, 35030, 37605, 38426, 38477,\n",
       "         17135, 39214, 64945, 39279, 17096, 39357, 34676,  1367, 34616,\n",
       "         39558, 17009, 16988,  1386, 19673, 16968, 34615, 39610, 39617,\n",
       "         39643, 19643, 39210, 34708,  1344, 34910, 34897,  1326, 19542,\n",
       "         17359, 38778,   946, 19594, 38907, 38461, 34771, 38941, 17259,\n",
       "          1342, 38970, 38971, 65680, 17205, 39045, 17170, 17283, 34559,\n",
       "         37603, 18001, 35760, 65479, 35736, 65620, 18968, 18996, 18663,\n",
       "         18997, 36519, 35652, 36530, 35596,   988, 18595, 36577, 36578,\n",
       "         18562, 35543, 35529, 35764, 18748, 36329, 36323, 18908, 65537,\n",
       "         36009, 18901, 36015, 18873, 35857, 36045, 36106, 19022, 36117,\n",
       "         36194, 35834, 36207, 18828, 36226, 35780, 36264, 36300, 36320,\n",
       "         65577, 37595, 36646, 36700, 35323, 18221, 37219, 37233, 37277,\n",
       "         37300, 19191, 35248, 37412, 37419, 18100, 18097, 18089, 35194,\n",
       "         65154, 18052, 65152, 37519, 65120, 19148, 35332, 35334, 18234,\n",
       "         36719, 19042, 36786, 36831, 65363, 18414, 18387, 36897, 36908,\n",
       "         65628], dtype=int64),\n",
       "  'feature_absent_idx': array([33693, 53657, 53660, 21100, 53662, 53664, 21086, 21085, 21084,\n",
       "         21083, 21071, 53679, 21068, 53684, 21066, 21064, 53652, 53687,\n",
       "         21116, 21123, 21149, 21148, 53638, 21146, 53639, 53641, 21137,\n",
       "         21135, 21134, 53643, 53645, 21129, 21128, 21125, 21124, 21122,\n",
       "         21060, 53688, 53694, 20985, 20984, 20983, 20981, 53743, 20979,\n",
       "         20977, 20972, 53754, 20965, 20959, 53771, 53772, 20948, 20947,\n",
       "         53741, 20988, 20990, 53735, 53700, 53703, 53705, 21036, 53708,\n",
       "         21030, 53712, 53636, 21026, 21019, 21016, 53718, 53719, 21011,\n",
       "         53726, 53730, 21020, 20945, 53627, 21164, 21322, 21321, 21319,\n",
       "         21305, 53547, 53552, 53556, 53560, 53561, 21275, 53562, 21271,\n",
       "         53565, 21269, 53566, 21323, 21266, 21324, 21330, 53502, 53508,\n",
       "         53511, 21353, 21349, 53513, 53515, 21345, 53516, 21343, 21342,\n",
       "         21340, 53523, 53526, 21333, 53529, 21264, 53568, 53570, 53600,\n",
       "         53601, 21209, 53602, 53606, 21202, 21200, 53613, 21188, 53617,\n",
       "         53619, 21178, 21175, 21171, 21165, 21215, 53597, 53595, 21218,\n",
       "         53571, 21251, 21244, 53582, 21242, 53584, 21235, 53626, 21234,\n",
       "         21231, 21228, 21227, 53591, 53592, 21221, 21220, 53590, 21365,\n",
       "         20939, 53780, 53956, 20650, 53959, 20646, 53962, 20641, 20639,\n",
       "         53964, 20635, 53966, 53967, 53969, 53970, 20622, 20620, 53953,\n",
       "         53975, 53952, 20663, 53927, 20707, 53929, 20701, 53933, 20694,\n",
       "         20685, 53939, 53941, 53942, 53943, 53945, 53946, 53950, 20664,\n",
       "         20659, 53987, 53988, 53990, 54024, 20533, 20530, 20525, 54031,\n",
       "         54032, 20520, 20519, 20518, 54037, 54041, 20508, 54043, 54045,\n",
       "         20501, 20538, 20540, 20551, 20552, 20608, 20606, 53993, 20601,\n",
       "         53994, 20599, 20597, 20712, 20584, 20577, 54010, 20575, 54013,\n",
       "         54015, 20559, 54016, 54009, 53777, 20720, 20729, 53811, 20891,\n",
       "         20888, 53814, 53816, 20879, 53820, 20874, 20871, 53829, 53831,\n",
       "         53832, 53837, 53839, 20851, 53810, 20845, 53809, 53800, 20933,\n",
       "         53783, 53786, 20929, 20927, 20926, 20922, 53788, 53792, 20916,\n",
       "         20914, 53795, 20911, 20909, 20907, 53808, 20840, 20839, 53850,\n",
       "         53893, 20776, 53896, 20773, 20768, 20767, 53900, 53902, 53910,\n",
       "         20746, 20744, 20743, 20739, 20731, 53913, 53892, 53891, 53890,\n",
       "         53886, 53851, 53853, 53854, 20831, 20829, 53857, 20819, 53916,\n",
       "         53868, 20803, 20795, 20792, 53880, 20787, 20785, 53885, 20812,\n",
       "         54048, 21367, 21372, 22031, 22025, 53055, 22022, 22018, 22006,\n",
       "         21998, 53074, 21992, 53087, 21988, 21987, 21976, 53092, 21967,\n",
       "         22035, 21964, 53049, 53047, 53019, 53020, 22074, 53027, 53028,\n",
       "         53030, 53033, 22061, 22060, 53036, 53039, 53040, 22051, 53042,\n",
       "         22043, 22037, 21960, 21959, 53100, 53148, 21880, 21879, 21878,\n",
       "         53149, 21874, 21866, 21863, 53175, 21848, 53176, 21846, 53178,\n",
       "         53181, 53182, 53147, 53145, 53143, 21894, 21954, 53103, 53106,\n",
       "         21944, 53119, 21929, 21928, 22082, 53121, 53124, 53128, 53132,\n",
       "         21906, 53137, 53142, 21897, 21922, 53190, 22084, 22088, 22228,\n",
       "         52933, 22217, 22215, 52938, 52939, 22210, 22207, 52942, 52946,\n",
       "         52947, 22201, 22195, 52958, 52961, 22231, 22188, 22232, 22234,\n",
       "         22289, 52898, 52905, 22272, 52906, 52909, 22264, 22259, 52914,\n",
       "         22255, 22250, 52919, 22245, 22243, 22237, 22233, 52963, 22184,\n",
       "         52965, 22132, 52997, 22125, 22124, 22123, 22121, 22118, 22117,\n",
       "         22116, 22113, 53008, 22101, 53012, 22097, 53013, 52996, 22139,\n",
       "         52991, 22143, 22178, 52966, 22174, 22171, 22168, 52975, 52977,\n",
       "         22087, 22160, 22156, 52979, 52982, 22153, 22150, 52990, 22145,\n",
       "         22158, 21370, 21834, 21829, 21526, 53411, 21524, 21522, 21518,\n",
       "         53414, 53415, 21514, 53417, 53418, 21507, 21505, 21503, 21496,\n",
       "         21491, 21528, 21490, 53401, 53393, 53356, 53358, 53359, 53360,\n",
       "         21584, 53365, 21579, 21578, 21571, 21564, 21561, 53382, 53383,\n",
       "         53389, 53391, 21543, 53426, 21479, 21478, 21418, 21415, 53469,\n",
       "         21411, 21410, 21405, 21403, 53480, 21400, 53484, 21392, 21389,\n",
       "         53489, 21381, 53492, 21421, 21424, 53464, 53462, 53429, 21473,\n",
       "         53438, 53443, 21459, 21458, 21456, 21593, 21455, 53453, 21448,\n",
       "         21441, 53455, 53456, 53457, 21430, 21451, 21832, 21603, 21610,\n",
       "         53229, 53230, 53231, 21773, 21767, 53234, 21757, 53244, 53249,\n",
       "         21747, 21741, 53258, 53260, 53261, 21726, 21780, 21724, 21781,\n",
       "         21784, 53198, 21826, 21821, 21816, 21808, 21807, 53212, 21804,\n",
       "         21801, 21798, 53218, 21796, 53224, 21787, 53227, 21783, 53265,\n",
       "         53266, 21720, 53320, 21654, 53323, 21648, 53326, 53328, 21641,\n",
       "         21640, 53331, 21636, 21632, 21631, 21626, 21623, 53341, 21656,\n",
       "         53317, 53316, 53312, 21718, 21710, 53279, 21702, 21700, 21697,\n",
       "         53285, 21607, 21691, 53290, 21684, 21668, 53309, 53310, 21663,\n",
       "         21660, 53288, 52895, 54049, 54057, 19234, 19228, 54890, 54892,\n",
       "         19221, 19216, 19211, 54907, 19209, 19207, 54909, 19201, 54912,\n",
       "         19199, 19197, 54882, 54915, 54880, 54878, 19294, 19293, 19290,\n",
       "         54849, 19288, 19287, 19273, 19271, 19266, 54868, 54870, 19257,\n",
       "         19256, 54871, 19251, 19248, 19194, 19192, 54922, 54975, 54988,\n",
       "         19088, 19087, 19086, 19085, 19084, 19083, 19080, 19079, 19074,\n",
       "         54999, 19052, 19051, 19045, 19103, 54966, 54962, 19119, 19189,\n",
       "         19187, 19184, 19181, 19173, 54935, 54940, 19297, 19159, 19149,\n",
       "         54952, 19135, 19132, 19127, 19124, 19123, 54943, 19040, 54842,\n",
       "         54840, 54734, 19475, 54735, 54736, 19466, 54738, 54741, 19459,\n",
       "         54746, 19454, 54748, 54752, 54753, 54755, 19445, 19477, 19439,\n",
       "         19479, 54723, 54700, 19523, 19521, 54702, 54705, 19512, 19511,\n",
       "         19507, 19506, 19505, 19502, 54712, 54715, 54718, 54719, 54730,\n",
       "         19431, 19430, 54767, 19355, 19350, 54809, 54811, 54814, 19339,\n",
       "         54816, 19335, 54820, 54822, 54831, 19319, 19318, 54837, 54838,\n",
       "         54795, 19362, 19369, 19379, 19423, 19422, 19420, 19419, 54775,\n",
       "         54776, 19410, 19310, 54780, 19402, 54781, 19400, 19396, 19386,\n",
       "         19385, 54789, 19405, 19537, 19038, 19031, 18712, 18707, 18700,\n",
       "         55214, 18694, 55222, 18691, 55235, 18678, 55237, 55239, 55241,\n",
       "         18670, 18668, 18665, 18714, 18661, 18715, 18718, 55180, 18761,\n",
       "         55185, 18750, 55192, 55194, 55195, 18733, 18732, 55197, 55199,\n",
       "         18727, 55200, 55201, 55202, 55206, 18660, 55249, 18656, 55305,\n",
       "         55306, 18592, 18589, 55311, 18584, 18578, 55317, 55324, 55326,\n",
       "         55332, 55333, 18551, 18550, 55334, 18596, 55295, 55294, 18610,\n",
       "         55250, 55251, 18650, 18648, 55261, 18640, 55266, 18765, 55268,\n",
       "         18630, 18624, 18623, 18622, 18619, 18617, 18616, 55278, 19036,\n",
       "         55179, 18773, 18973, 55060, 18960, 18954, 18953, 18952, 18951,\n",
       "         55066, 55068, 18948, 18947, 18946, 18942, 18938, 55075, 55054,\n",
       "         55077, 55052, 18977, 55016, 19021, 55020, 55032, 55033, 19001,\n",
       "         18998, 55036, 55037, 18993, 18992, 18989, 55043, 18980, 18979,\n",
       "         55050, 55078, 55079, 55081, 18832, 18830, 18826, 55148, 55154,\n",
       "         18808, 18796, 18794, 18791, 55167, 55168, 55169, 18783, 18778,\n",
       "         55175, 55138, 18841, 18847, 18850, 18919, 55082, 18912, 18911,\n",
       "         55091, 18898, 18894, 55176, 18889, 18880, 55124, 18867, 18864,\n",
       "         18860, 18856, 18855, 18887, 20488, 19538, 19540, 54260, 20179,\n",
       "         54261, 20176, 54266, 20167, 54270, 54273, 54276, 20152, 20150,\n",
       "         20149, 54280, 54282, 20135, 20181, 20134, 54256, 54251, 20244,\n",
       "         20242, 54213, 20224, 20222, 20221, 54223, 20219, 54235, 54239,\n",
       "         54241, 54244, 54245, 20197, 20196, 20191, 20128, 54290, 20122,\n",
       "         54350, 54351, 54354, 20038, 20029, 20028, 20026, 54361, 20022,\n",
       "         20019, 54365, 54369, 54372, 20011, 54379, 20052, 54337, 20066,\n",
       "         54319, 20121, 20118, 20116, 54297, 20109, 20108, 54299, 54209,\n",
       "         20103, 20091, 20090, 54306, 20084, 20079, 54318, 20077, 54302,\n",
       "         19999], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_purpose': {'feature_present_idx': array([20875, 28735, 62518, 28635, 28554, 47214, 53656, 62590,  5432,\n",
       "          5949,  5997,  6137, 48060,  6520,  6539,  6548, 26040, 27936,\n",
       "         25038,  5418, 56270, 33977,  4450, 61884, 32468, 32193, 45934,\n",
       "         32023, 29183, 31654, 45988,  4924, 31184, 59292,  4952, 46585,\n",
       "         46973, 31647, 48962, 24207,  7117, 15682, 15430, 15194, 14586,\n",
       "         54237, 14502, 13403, 54645, 10713, 13191, 10808, 11137, 12524,\n",
       "         53544, 53659, 58269, 10769, 51134, 18417, 18734, 24171, 49162,\n",
       "          7349, 22510,  7597, 58068,  7726, 58676, 21698, 20828, 20727,\n",
       "         66040,  8316, 64727, 50231, 50323, 19113, 56717, 34058, 53653,\n",
       "         57277,   778,   349, 43605, 40587, 34765, 41787,   482,  2945,\n",
       "         40511, 61022, 41769, 36014, 42051, 35653, 36123,  3695, 66695,\n",
       "         42512,  1465, 44205,  2558,  2115, 39622, 60250, 34222, 17642,\n",
       "         51160, 18089, 41224, 51472, 41060, 18601, 17845, 58557, 19742,\n",
       "         40796, 64202, 22176, 21918, 50110, 42667, 64501, 39840, 58655,\n",
       "         40056, 19848, 19824, 19760, 51475, 40774, 50543, 18789, 16574,\n",
       "         45374, 58509, 52489, 13277, 41836, 52494, 41893, 42098, 13189,\n",
       "         13041, 12975, 42786, 12802, 12729, 42447, 42504, 42728, 13502,\n",
       "         58284, 13722, 13802, 16246, 16110, 51946, 15701, 43249, 38769,\n",
       "         52032, 51500, 14891, 58404, 41510, 14512, 14244, 65211, 14080,\n",
       "         13983, 14732, 41434, 23109, 22411, 46173, 46552, 35072, 59127,\n",
       "         30377, 30249, 57693, 31071, 45177, 35304, 28931, 35452, 35540,\n",
       "         35641, 28347, 36488, 35289, 34885, 34865, 34756, 61503, 61512,\n",
       "         33415, 33087, 61614, 32945, 32703, 61219, 45366, 45884, 61150,\n",
       "         32143, 45296, 45273, 34686, 31610, 59318, 36631, 47604, 60834,\n",
       "         44746, 37815, 44506, 24504, 24362, 37960, 37964, 24175, 24046,\n",
       "         59620, 24003, 38247, 49286, 34090, 49651, 49765, 44308, 38442,\n",
       "         48540, 59707, 25435, 63439, 36939, 47799, 27534, 63067, 27265,\n",
       "         47927, 26951, 37066, 44617, 37553, 26695, 37577, 48241, 26249,\n",
       "         26144, 37697, 25957, 25603, 28266,    28,  5045,  1982, 53912,\n",
       "         65861, 67122, 56225, 10593,  5608,  2080, 10561,  9017,  6724,\n",
       "          6709, 57536,  4507,   995,  2315, 57961, 55343,  8381, 10155,\n",
       "         56940,  2911, 56881,  3103,   791, 56719,  3241, 56856, 54149,\n",
       "          4524, 56820,  7062,  4829, 57281,  9398,  7979,  7195,  4915,\n",
       "         58064,   354,  1469, 58143,  6911,  7631,  7482,  9277,  9485,\n",
       "         56552,  1435,  7958, 55399, 10835,  4775,  1976,  5310, 66988,\n",
       "         60278, 40724, 40956, 27770, 46403,  5288, 40684,  5762,  5945,\n",
       "         28229, 30206, 43656, 47176, 28513, 46718,  5661, 46791,   990,\n",
       "         29011, 29251, 29328, 62480, 62640, 28858, 11483, 27695, 58868,\n",
       "         55854, 58766, 63625, 55801, 48666, 48769, 48869,  7249, 41421,\n",
       "         55625,  7299, 23855, 23545, 49233, 23453, 23296, 23186, 60221,\n",
       "         63515, 43525,  6798, 25687,  6336, 58998, 47907, 58020, 55967,\n",
       "         27092, 46290, 48032, 55965, 26903, 48064,  6540, 48072, 26530,\n",
       "          1033, 48243, 25840, 66184, 25734, 25645, 27053, 60414, 31000,\n",
       "         37257, 37096, 60692, 44649,  2020, 44974,  2060, 36681, 44999,\n",
       "         36664, 36634, 36528, 60586, 59496, 36025,  2172, 35994, 35977,\n",
       "         59489,  1831, 37324, 37529, 57370,  1058, 39512, 59948, 39225,\n",
       "         59888, 38580, 57231, 59692,  1278, 35854, 38107, 37922,  1634,\n",
       "         37870, 57175, 60607, 44527,  1650, 44551, 37602, 38024, 35686,\n",
       "         66977, 35507, 40147,  4295, 32989, 59382, 32913, 44034, 45790,\n",
       "         32849, 32616, 33179, 57814,  4590, 32103, 31983,  4814, 31611,\n",
       "         40408, 31188, 56344, 31058, 45883, 30994, 59465, 33409, 60932,\n",
       "         57068, 35272,  2668,  2753,  2883, 59477, 34374, 34373, 45443,\n",
       "         66832,  3508, 34180,  3776, 34038,  3961,  4186, 33872, 33627,\n",
       "          4279, 34290, 49718, 25933,   266, 65056, 54315, 14572, 55090,\n",
       "         64907, 10314, 58288,  8860, 52244,  8858, 41975, 19160, 50293,\n",
       "         64795, 65193, 19455, 19501, 14137, 19561, 14000, 65541,  8511,\n",
       "         64622, 65889,  8414, 19776, 10515, 20218, 57740, 14813, 51024,\n",
       "         18307, 18297, 16275,  9508, 42320, 51869, 58499, 15945, 57659,\n",
       "         16951, 15824, 17043, 17086, 17202, 58470, 17450, 13457, 51242,\n",
       "         15549, 17629, 17633, 65716, 17714,  9992, 17803, 17887, 52132,\n",
       "         18026,  9131, 51093, 18211, 54397, 51996, 65472, 54554, 53078,\n",
       "         12328, 12567, 12493, 12887,  7733, 12882, 52953, 50096, 53729,\n",
       "         49965, 53723, 52980, 11262, 41691, 58275,  8012, 64377, 21756,\n",
       "         21830, 50025, 53135, 11115, 22395,    79, 11271,  8118, 49817,\n",
       "         11920,  8188, 20904, 64496, 52804, 42557, 12221,   165, 34251,\n",
       "          4292, 33084,  1452, 38828, 60590, 45337, 10068, 16225, 15072,\n",
       "         38119, 15067,  9610, 51756,  4312, 15414, 52052, 52020, 33122,\n",
       "         12276, 15805, 61541, 38649, 39196,  4249, 45409, 45400, 54521,\n",
       "         54405, 33361, 61575, 12433,  1368, 15499, 34146, 39482, 44338,\n",
       "          9934, 45269, 13389,  3046, 35786, 37496, 13035, 10919, 65310,\n",
       "         52832, 10467, 10793, 13216, 39917, 52383, 37045, 45045, 36206,\n",
       "         36357, 42545, 13690, 13683, 45035, 53852,  2072, 57669, 13535,\n",
       "         13349, 52476, 42836, 34489, 35759, 35719, 53095, 66987, 34657,\n",
       "         36827, 52203, 37912, 34835, 54252, 45201, 12703, 37812,  2556,\n",
       "         35238, 10397,  2410,  2395, 35485, 60657, 35510, 42487,  1698,\n",
       "         14327, 57145, 54206, 12934, 35740, 22674, 51372, 61714, 63367,\n",
       "          6679,  8245,  6717,  8159, 20971, 26358, 50119, 48251, 21199,\n",
       "         25437,  6877, 21292, 63541, 21127, 48421,  6624, 57532, 62943,\n",
       "         11807, 64788, 27484, 27477, 66321,   338, 27385, 20021,   681,\n",
       "         20081, 43147, 26724, 20264, 50216,   536, 21416, 25059,  7392,\n",
       "         22383, 23385, 23313, 43200, 23277, 49274, 49791,  7398,  7510,\n",
       "          7502, 49749, 22779, 22766, 49502, 58126, 49209, 57559, 21445,\n",
       "         21453, 50061, 63694, 21580, 24683, 63865, 21616, 64456, 48977,\n",
       "          7003, 64412, 24146, 49070, 49993, 16435, 19383, 62884, 57404,\n",
       "         30693, 30775, 30788, 17797, 30863, 54619, 40486,  4961, 17485,\n",
       "         56525, 46080, 51249, 17257, 22598,  4779, 45946, 56644, 64957,\n",
       "         45848, 43941, 32665, 43914,  9507, 50242, 16639, 32243, 51487,\n",
       "         16713, 59343, 16910, 61939, 32450, 66532,  5046, 46615, 18582,\n",
       "         66459, 67099, 40605, 18688, 55101,  5733, 64902, 19105, 47315,\n",
       "         28138, 28007, 47522, 57996,  5985,  5174, 28878, 47143,   209,\n",
       "         30340, 30264, 30151, 46677, 42192,  5319, 56261, 39639,   981,\n",
       "          5338,  5399, 29031, 18415, 44186, 43025, 57615, 43854, 42712,\n",
       "         42964, 59015, 45037, 49440, 49483, 49979, 50129, 50138, 50171,\n",
       "         55398, 50285, 55160, 55104, 58650, 51082, 55042, 54605, 51490,\n",
       "         51624, 54442, 58448, 52258, 52404, 58214, 53845, 53153, 53278,\n",
       "         53446, 58735, 55596, 49043, 58789, 57160, 56774, 45527, 45645,\n",
       "         45771, 56695, 59359, 56657, 46042, 46082, 46114, 46805, 57162,\n",
       "         46993, 47170, 47246, 47436, 47506, 47556, 59017, 47720, 47743,\n",
       "         56070, 55877, 58954, 48194, 47046, 42639, 29187, 21536, 64581,\n",
       "         19432, 19343, 19328, 64823, 18314, 17456, 17130, 16603, 16571,\n",
       "         21449, 16334, 65000, 15564, 15468, 15280, 15003, 14817, 14481,\n",
       "         14425, 13593, 65408, 16032, 13267, 60059, 22532, 27764, 27528,\n",
       "         63022, 63134, 26917, 26637, 26519, 26483, 25850, 25286, 64199,\n",
       "         63605, 24798, 24486, 24154, 24004, 23791, 63995, 23179, 23110,\n",
       "         22925, 64114, 63653, 27918, 13140, 12792,  7334,  6926,  6443,\n",
       "          6423, 66418, 66439,  5889,  5494,  5425,  4934,  7652,  4931,\n",
       "          4693,  4464,  4418, 66737,  2179,  1713,   996,   611,   348,\n",
       "         67118,  4723, 12873,  7836,  8701, 12701, 12652, 12585, 12564,\n",
       "         12320, 12094, 12068, 11853, 11376, 10760,  8277, 10685, 10433,\n",
       "         10259, 65623, 10094, 10072, 65717, 65747,  9263,  9237,  9171,\n",
       "         10629, 28176, 57694, 60700, 33806, 36150, 41969, 33225, 41877,\n",
       "         31539], dtype=int64),\n",
       "  'feature_absent_idx': array([19257, 12930, 28642, 45879, 28634, 28630, 12943, 57676, 12947,\n",
       "         12948, 57670, 57667, 12951, 12952, 57683, 57666, 28624, 57662,\n",
       "         28622, 12960, 28621, 57656, 12964, 45892, 12969, 12970, 12971,\n",
       "         12973, 57650, 57665, 28612, 45874, 28649, 28688, 57725, 12877,\n",
       "         12878, 12880, 57723, 28684, 57718, 57717, 57715, 12892, 12894,\n",
       "         28677, 45872, 12898, 45843, 12901, 45846, 45847, 45849, 28664,\n",
       "         45856, 12915, 57699, 45863, 45864, 45865, 57688, 28676, 45895,\n",
       "         57643, 57642, 13037, 45935, 13040, 57596, 57594, 28562, 57591,\n",
       "         45939, 28558, 13052, 28552, 28548, 45945, 57599, 57579, 13065,\n",
       "         28544, 45948, 57571, 57570, 57568, 57567, 28537, 57566, 13079,\n",
       "         28536, 13081, 28534, 57578, 57601, 45929, 13029, 12983, 45899,\n",
       "         45900, 57641, 12987, 12989, 28605, 45903, 28602, 45904, 28595,\n",
       "         28592, 57629, 13002, 13003, 57628, 28589, 57626, 45923, 28583,\n",
       "         57611, 13014, 57609, 13016, 28580, 13020, 45927, 57605, 13028,\n",
       "         57730, 45953, 57731, 45828, 57857, 57856, 12721, 28805, 12723,\n",
       "         28803, 45758, 45761, 57850, 57846, 28792, 28791, 28788, 12717,\n",
       "         12739, 12742, 28784, 28783, 57840, 28779, 28778, 57835, 28777,\n",
       "         28775, 57825, 57821, 28772, 12762, 45769, 12763, 12714, 12711,\n",
       "         45722, 28850, 45725, 45726, 12675, 12676, 57887, 28840, 57885,\n",
       "         28839, 45731, 45732, 45736, 57860, 28827, 12693, 45740, 28823,\n",
       "         12696, 45743, 28818, 28817, 28815, 57867, 45747, 57864, 12707,\n",
       "         12710, 57876, 28768, 28767, 45779, 12826, 57768, 57766, 12829,\n",
       "         28715, 57762, 12835, 28714, 28713, 45823, 45824, 28703, 57753,\n",
       "         12824, 57750, 45826, 12851, 12852, 28700, 12854, 28699, 57745,\n",
       "         12858, 57741, 28697, 12862, 57736, 12865, 28702, 57770, 57772,\n",
       "         28724, 28765, 12768, 12769, 12770, 12771, 12773, 12777, 57811,\n",
       "         28759, 45786, 12782, 57807, 57801, 28754, 57796, 57795, 45800,\n",
       "         45803, 12799, 45807, 57782, 28738, 12805, 12807, 45809, 12811,\n",
       "         12812, 12813, 28727, 57735, 12667, 13084, 28529, 13345, 57362,\n",
       "         13347, 28341, 57359, 46088, 28337, 46089, 57352, 57350, 13362,\n",
       "         28333, 13364, 13344, 13365, 57344, 57341, 57339, 46100, 57336,\n",
       "         46110, 57334, 28316, 57329, 57325, 28310, 46117, 28304, 28331,\n",
       "         57306, 46075, 57365, 28378, 57401, 13301, 57399, 28374, 57395,\n",
       "         28371, 13307, 28370, 13311, 57392, 57391, 57389, 46071, 57386,\n",
       "         46063, 13322, 46066, 28361, 57381, 13328, 13329, 46067, 13333,\n",
       "         57367, 13338, 57366, 28350, 13317, 13399, 57305, 57303, 57257,\n",
       "         57256, 46146, 13463, 57254, 13466, 13467, 57252, 57251, 57247,\n",
       "         13476, 46158, 46159, 28264, 28248, 46162, 13485, 57237, 46163,\n",
       "         28241, 57232, 28240, 57230, 13494, 13495, 46164, 28238, 13498,\n",
       "         28247, 57261, 28265, 13454, 57301, 13405, 57299, 28299, 46120,\n",
       "         13410, 57297, 46124, 13415, 13422, 13423, 46128, 13425, 13426,\n",
       "         46129, 13429, 46130, 57283, 13435, 46135, 46138, 57271, 13441,\n",
       "         28274, 13446, 57266, 13448, 57265, 28267, 13295, 28530, 13293,\n",
       "         46049, 57513, 13146, 13148, 13149, 57511, 13151, 28478, 45990,\n",
       "         13154, 28476, 28473, 13160, 13161, 57516, 57502, 45993, 45994,\n",
       "         13167, 57493, 13173, 13176, 46006, 28452, 13183, 28450, 46007,\n",
       "         28448, 28447, 57501, 13190, 57518, 45986, 28525, 28521, 28520,\n",
       "         13095, 13096, 28519, 13098, 13101, 13103, 13106, 13108, 57550,\n",
       "         13112, 28482, 45968, 57544, 28504, 28501, 28500, 28498, 28494,\n",
       "         28493, 45976, 57526, 28487, 57525, 57524, 45984, 45969, 13193,\n",
       "         28445, 46008, 28398, 57433, 28397, 13255, 57430, 13259, 57429,\n",
       "         57428, 57427, 57425, 46047, 28388, 13269, 13249, 13271, 13273,\n",
       "         13274, 57422, 57420, 13280, 57415, 57413, 28383, 28382, 57405,\n",
       "         13288, 57403, 13290, 57423, 57437, 13247, 46036, 57480, 28441,\n",
       "         28439, 13201, 28436, 46013, 46016, 13209, 57468, 28429, 46018,\n",
       "         13214, 13217, 13219, 13221, 46023, 28421, 46024, 46028, 28416,\n",
       "         57450, 13233, 57447, 28410, 28408, 28407, 57442, 57441, 13243,\n",
       "         13292, 57227, 28853, 12663, 58333, 45446, 45457, 12104, 45458,\n",
       "         12106, 12108, 12109, 45460, 45462, 58318, 58316, 29254, 12087,\n",
       "         58311, 58310, 29249, 45467, 58305, 58301, 45469, 12132, 58297,\n",
       "         12134, 45473, 45477, 58294, 58292, 29252, 29239, 58337, 29287,\n",
       "         45411, 45413, 45414, 58367, 29308, 12045, 12046, 12047, 58364,\n",
       "         58363, 29306, 58361, 29305, 29284, 58360, 12056, 29304, 58357,\n",
       "         12059, 29303, 45415, 12062, 58354, 12064, 58349, 12075, 58340,\n",
       "         12079, 58358, 12142, 12143, 29229, 12202, 58239, 12205, 12207,\n",
       "         58237, 58236, 12212, 29177, 12215, 29175, 12218, 12224, 29170,\n",
       "         29184, 45520, 12230, 12234, 58215, 12236, 29161, 12239, 12240,\n",
       "         12243, 12247, 58208, 29152, 12251, 12252, 58221, 12198, 45511,\n",
       "         58240, 58286, 58285, 29226, 58283, 45488, 45489, 12158, 58277,\n",
       "         58274, 29219, 58267, 29214, 29213, 45500, 29205, 12178, 29200,\n",
       "         29199, 58254, 12184, 29196, 12186, 45504, 29194, 58246, 58243,\n",
       "         29191, 58242, 45509, 58373, 12253, 12033, 12029, 45348, 45349,\n",
       "         29424, 29423, 29422, 58506, 45351, 58502, 58496, 45354, 11902,\n",
       "         29414, 29413, 29430, 11906, 58491, 58489, 29408, 58488, 11914,\n",
       "         29406, 45357, 11922, 11923, 45364, 58476, 29393, 11931, 29410,\n",
       "         29392, 11885, 58513, 45317, 29465, 29462, 29461, 45321, 45323,\n",
       "         11848, 11850, 29453, 58538, 58537, 58536, 45331, 29432, 11861,\n",
       "         45333, 45338, 29444, 58519, 45339, 11874, 45340, 11876, 29436,\n",
       "         45342, 45343, 29433, 11882, 58526, 29389, 58465, 29388, 29350,\n",
       "         29349, 45390, 45391, 58416, 58415, 11994, 11995, 58413, 58411,\n",
       "         29346, 29345, 45393, 11987, 29335, 29329, 12013, 12014, 12015,\n",
       "         29326, 12017, 58389, 58388, 12022, 58385, 45410, 58380, 29320,\n",
       "         29334, 11985, 11984, 29352, 29387, 11939, 11940, 29383, 58460,\n",
       "         29382, 29380, 58450, 29377, 11952, 29372, 29368, 11959, 58444,\n",
       "         45382, 45383, 58443, 58442, 11968, 58439, 58438, 29357, 45388,\n",
       "         11975, 11976, 58434, 58429, 58428, 29353, 29317, 12664, 12254,\n",
       "         29149, 57991, 57990, 57988, 12527, 45664, 12530, 12534, 28942,\n",
       "         57978, 57977, 28940, 57975, 12544, 28954, 57974, 57973, 57972,\n",
       "         57971, 12550, 45671, 28933, 57968, 28932, 12557, 28929, 28928,\n",
       "         28927, 12562, 12546, 45672, 28957, 45652, 58039, 28982, 28981,\n",
       "         58037, 58036, 58034, 45634, 58032, 45635, 12484, 28976, 58030,\n",
       "         58029, 57998, 12490, 45638, 12494, 12495, 45639, 58021, 58017,\n",
       "         45643, 12506, 28964, 58006, 12510, 12512, 58000, 12491, 28924,\n",
       "         12568, 45674, 57927, 28881, 57924, 28880, 45701, 57922, 45704,\n",
       "         45705, 12633, 12634, 45711, 28868, 57919, 45699, 45713, 12644,\n",
       "         57911, 57908, 57907, 28860, 45716, 12653, 45717, 57901, 57900,\n",
       "         57899, 57898, 12661, 28865, 57929, 28887, 28890, 57960, 12574,\n",
       "         57955, 45683, 12581, 57953, 12583, 12586, 28909, 28907, 28905,\n",
       "         12592, 12595, 12596, 12597, 12598, 28902, 28901, 28900, 28897,\n",
       "         28896, 28895, 57940, 45695, 28893, 57938, 45696, 57937, 57933,\n",
       "         28983, 58207, 28986, 28993, 12308, 29111, 29110, 12313, 29107,\n",
       "         12315, 58163, 12318, 29105, 45565, 45567, 58158, 29098, 29114,\n",
       "         29097, 58151, 29094, 12338, 45573, 29086, 12344, 45576, 12346,\n",
       "         58132, 58130, 12356, 45583, 29071, 58152, 12362, 29115, 58178,\n",
       "         12258, 29147, 29146, 58203, 45535, 58200, 12267, 29140, 29139,\n",
       "         58197, 58195, 29135, 12279, 45557, 29133, 45542, 12283, 29131,\n",
       "         45544, 29127, 29123, 45553, 12292, 12293, 12294, 12297, 58179,\n",
       "         29119, 58191, 12363, 58122, 12365, 12418, 29020, 45615, 45616,\n",
       "         58072, 12428, 45618, 45619, 12431, 29012, 29008, 58060, 29007,\n",
       "         45611, 58057, 12446, 12447, 12448, 45626, 12452, 58052, 12454,\n",
       "         58049, 45628, 12459, 12460, 28994, 58046, 29004, 45609, 29028,\n",
       "         29029], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_quant': {'feature_present_idx': array([25404, 59847, 23689,  8991, 23860, 23876, 60012, 46762,  8911,\n",
       "         60284, 60285, 24086,  8850, 60458,  8706, 46559, 24249, 46387,\n",
       "         24393, 46318, 24495, 46291, 60825, 24585, 60839,  8338, 46165,\n",
       "         24692, 59706, 59581, 23478, 23475, 22196, 10164, 22244, 10123,\n",
       "         47686, 58706, 47673, 58785, 22560, 47663, 47619, 22601, 22650,\n",
       "          8235, 58876, 47444, 23024, 59129, 59133, 59186,  9765, 23171,\n",
       "         23281,  9462, 23285,  9400, 59522, 47194, 22794, 22149, 24852,\n",
       "          8005, 26669, 44636, 44613, 61531, 44575, 61615, 61667, 26931,\n",
       "         26945, 27048, 27149, 61787,  6596,  6541, 27209, 44149, 27357,\n",
       "         27467, 27555, 27635, 43756, 27666, 27768, 43653, 28540, 28661,\n",
       "          5566,  6937, 26638,  6992, 26424, 45811, 25348, 25395, 14792,\n",
       "         25411,  7816, 25443,  7757, 61074, 45532,  7738, 61169, 45486,\n",
       "         60929, 61177,  7589, 45449,  7508, 45309, 45285, 26193, 45193,\n",
       "         61316,  7287, 26324, 26345, 61426,  7069,  7623, 62639, 10209,\n",
       "         10240, 16011, 53221, 53210, 16119, 55384, 53111, 53090, 55585,\n",
       "         52935, 52686, 16557, 52421, 13452, 16842, 51637, 56054, 56142,\n",
       "         12910, 51422, 17411, 17447, 17842, 17965, 18022, 51125, 18262,\n",
       "         56632, 55331, 13768, 53304, 13841, 14742, 54434, 14692, 54334,\n",
       "         54473, 54331, 14515, 54189, 15032, 54631, 54115, 53907, 14418,\n",
       "         51083, 54807, 14320, 14231, 55000, 15588, 55096, 15596, 14136,\n",
       "         53672, 15681, 14024, 15713, 53578, 15744, 14343, 22021, 51053,\n",
       "         18464, 11435, 11395, 11197, 48982, 21079, 21107, 48828, 11109,\n",
       "         11047, 57845, 57966, 58109, 10926, 21371, 48591, 21521, 58271,\n",
       "         48358, 21790, 48205, 48202, 58400, 21883, 21912, 58427, 58505,\n",
       "         10243, 49357, 57633, 49430, 49436, 50894, 18587, 18597, 50831,\n",
       "         18849, 50628, 12167, 57099, 12102, 19029, 19046, 12083, 19060,\n",
       "         18459, 19062, 50416, 19264, 19463, 50033, 49930, 49867, 19777,\n",
       "         49689, 57478, 49635, 11678, 57510, 49454, 50433, 42614, 54382,\n",
       "          2996,  1570,  3904, 31930, 41134,  1602, 40938, 34880, 38638,\n",
       "         64155, 40891, 32247,  1746, 38674,  1846,  3591, 34723,  3561,\n",
       "         38497, 40700, 41292,  1437, 35577, 41750, 63420,  4531, 35395,\n",
       "         63482, 38110,  4481,  4382, 66140, 38286, 31400,  4199, 63851,\n",
       "         31554, 63869, 31571,  4124, 66380, 40670, 40595,  2918,  2888,\n",
       "          2882, 34088, 39801, 39764,  2360, 65169, 33758,  2376,  2774,\n",
       "         33768, 65161, 39445, 65155, 65102,  2640, 33461,  1899, 40063,\n",
       "         40220,  3459, 34578, 65673, 32684, 64522,  2135, 34447, 40473,\n",
       "         40467, 32908,  3294, 40465,  3272, 39222, 40314, 33094,  3158,\n",
       "         33342, 63131, 65111,   415, 66702,  5052, 66717, 36085, 42084,\n",
       "           654, 36462, 29977, 35961, 35915, 36240, 42270, 62841, 30047,\n",
       "          5138, 30254, 67048, 35782, 29648,   547, 29858,  5264, 36189,\n",
       "         42501, 42018, 37325, 37514, 36091, 29528, 36761,   783, 36798,\n",
       "         30592, 20093, 39187, 20209, 39060, 19374, 50149, 50258, 15533,\n",
       "         36191, 37119, 53835, 39183, 37220, 15465, 20008, 15442, 15456,\n",
       "         49651, 39145, 15521, 19862, 20212, 19848, 15472, 19780, 39087,\n",
       "         34506, 15483, 19440, 53044, 20405, 53898, 20973, 36911, 14998,\n",
       "         54264, 36902, 36818, 14905, 36557, 36587, 48868, 21239, 14862,\n",
       "         54380, 21265, 34068, 48714, 34061, 34052, 48707, 15006, 36466,\n",
       "         49048, 36464, 34242, 39282, 36998, 15200, 20417, 34202, 54046,\n",
       "         49363, 34175, 20234, 36913, 34142, 39347, 20628, 20656, 49256,\n",
       "         20865, 49057, 20961, 49051, 20615, 34580, 15645, 19236, 35367,\n",
       "         51589, 17168, 17213, 35275, 51451, 38282, 51243, 35768, 17590,\n",
       "         35806, 17770, 51236, 38287, 15946, 17869, 51217, 35179, 53299,\n",
       "         17999, 17112, 17060, 53022, 16351, 35662, 37962, 16431, 35641,\n",
       "         35582, 16272, 37849, 16612, 52322, 38087, 16885, 52028, 52013,\n",
       "         51768, 35682, 16994, 37953, 50388, 15880, 35056, 50786, 50661,\n",
       "         50657, 15666, 18956, 34868, 18958, 18964, 15698, 50604, 38719,\n",
       "         34708, 38960, 34586, 37381, 19183, 19215, 37335, 38662, 51184,\n",
       "         53594, 34906, 15871, 51123, 15864, 48683, 51119, 53481, 18292,\n",
       "         51094, 38581, 37802, 18350, 51058, 34991, 34916, 18484, 34914,\n",
       "         18493, 18505, 38522, 18128, 42581, 39396, 41900, 30708, 30655,\n",
       "         45177, 41997, 45171, 26380, 45072, 26560, 30579, 41893, 30574,\n",
       "         30551, 42029, 30493, 42061, 26729, 26767, 30379, 30333, 26939,\n",
       "         42211, 44754, 30813, 41804, 30867, 41537, 45788, 25221, 45654,\n",
       "         41621, 25415, 45644, 31256, 25540, 31126, 31110, 31087, 31032,\n",
       "         45530, 30991, 25701, 25704, 41728, 25710, 25973, 45440, 26049,\n",
       "         41774, 44452, 42225, 27098, 44314, 28116, 43385, 43348, 28172,\n",
       "         43324, 28231, 28245, 28251, 28324, 28391, 43250, 43178, 43101,\n",
       "         29636, 43026, 28771, 42837, 42358, 42825, 42754, 42706, 29186,\n",
       "         29356, 43412, 45853, 43429, 28065, 27186, 30112, 44175, 30041,\n",
       "         44130, 27342, 43923, 29963, 27475, 43778, 27501, 43775, 29779,\n",
       "         27639, 42333, 27672, 27737, 27803, 27894, 29715, 27970, 43637,\n",
       "         43585, 28072, 24948, 24945, 45868, 22428, 33211, 33185, 40262,\n",
       "         22639, 47575, 40387, 47519, 22791, 22817, 22867, 22869, 47311,\n",
       "         32852, 23057, 47263, 47260, 32795, 23190, 23225, 23255, 40508,\n",
       "         40518, 33338, 32704, 22365, 22301, 33980, 33948, 21499, 48516,\n",
       "         48507, 21513, 21533, 21621, 48324, 39589, 21828, 48145, 21868,\n",
       "         39828, 48125, 22020, 33448, 48086, 40089, 42563, 33377, 33346,\n",
       "         22246, 22308, 21337, 40520, 47106, 46651, 46642, 32043, 46625,\n",
       "         24202, 46604, 32041, 41117, 24283, 46431, 46355, 41209, 31893,\n",
       "         24541, 41277, 46259, 31819, 31768, 46243, 41302, 31714, 45955,\n",
       "         24815, 24144, 47164, 24110, 32205, 23380, 23402, 47053, 46926,\n",
       "         40637, 46864, 23567, 23608, 23655, 23713, 23781, 23834, 40769,\n",
       "         32420, 32337, 46821, 40823, 23896, 23917, 23951, 46706, 24043,\n",
       "         40890, 24099,    14, 50973, 14828, 11452, 62987, 62993, 57580,\n",
       "         11562,  4910, 11585, 63078, 63235,  4775, 63330, 11655, 63415,\n",
       "          4523,  7949, 63598, 11857, 11339, 62975, 57746,  5099, 62648,\n",
       "          5437,  5378, 10937, 62770,  5208, 57818, 57800, 57387, 62867,\n",
       "         11173,  5161, 57775, 11298, 11323, 57758, 62899,  5113, 57783,\n",
       "         63890,  4099, 11960, 64509, 56987, 56979, 12316,  3456,  3427,\n",
       "         12327,  3401, 12211, 12373, 56760,  3313, 64625, 12456, 64656,\n",
       "         56626, 56533, 64714, 56798, 58287, 12185, 57079,  3878,  3857,\n",
       "          3849, 64152,  3809, 12050,  3808, 57267, 57056, 64183, 64228,\n",
       "         64301,  3599, 57168, 64462,  3557,  3506, 12127, 64195, 64738,\n",
       "         62627, 10570, 60171, 60121,  6967, 61503,  6936,  8987, 59989,\n",
       "         61505,  9038,  6895, 59931, 59867, 59776,  9151, 59562, 61688,\n",
       "          6644,  8922,  7041,  7082, 61482, 60957, 60904,  7817,  8160,\n",
       "         60868, 60845,  8301,  7662,  6600, 60831, 60818,  7648,  7642,\n",
       "         60706,  8648,  7181, 61438, 60439,  7655, 59478, 59396,  6515,\n",
       "          6092, 62211, 58725,  5984, 58692, 62330,  5924,  5904,  9950,\n",
       "         58630, 62356, 10183,  5683, 10235, 62469, 58404, 62523, 10525,\n",
       "         10136, 62577,  6156,  6198,  6495, 59251,  9613,  6451,  9704,\n",
       "         61894, 61961,  9810, 58870, 59072,  9840,  6383,  9851, 59047,\n",
       "         58946,  6276, 62030,  6239,  9836, 12605, 11833, 13377,  2547,\n",
       "           167, 65121,  1700,  1197,  1695, 67073, 65744,  2630, 65951,\n",
       "         65732, 55955, 54977, 65974, 55209, 65134, 55929, 12876,   175,\n",
       "         14315, 66856, 66893, 56185,   930, 66921, 12939, 55771, 66469,\n",
       "         55182,  1827, 54742, 65845, 66819, 66384, 55816, 66174, 55368,\n",
       "         65624,  1900, 14223,  2128, 13623, 66582, 13996, 54437, 56388,\n",
       "          3039, 13312, 54422,  2252,   598, 65547, 14076, 55147, 65593,\n",
       "         54484,   332, 12606,  2920, 13761,    52, 55382, 56337, 54565,\n",
       "            59, 55397,  1974, 67106, 65629,  2830, 61981,  6400, 66610,\n",
       "         37941], dtype=int64),\n",
       "  'feature_absent_idx': array([49500, 19288, 19287, 42831, 60410, 19273, 19271, 19266, 42840,\n",
       "         19257, 19256, 42843, 19251, 19248, 42847, 19234, 19290, 60420,\n",
       "         19293, 19297, 42821, 60386, 19339, 60387, 60390, 19335, 42824,\n",
       "         60394, 19319, 19318, 42827, 60401, 42828, 19310, 42829, 19294,\n",
       "         42820, 42850, 19228, 19184, 19181, 51819, 42867, 42869, 42871,\n",
       "         19173, 60435, 60436, 42875, 60438, 19159, 42877, 60440, 19149,\n",
       "         19187, 60421, 19189, 19192, 19221, 42853, 19216, 19211, 19209,\n",
       "         42857, 19207, 60428, 19201, 42859, 19199, 19197, 42861, 19194,\n",
       "         60430, 51820, 42880, 60382, 19350, 19502, 60329, 51848, 42764,\n",
       "         60332, 42765, 42766, 42767, 42769, 42770, 19479, 19477, 19475,\n",
       "         42776, 60338, 19505, 42778, 19506, 42761, 19552, 19550, 19549,\n",
       "         19541, 19540, 19539, 19538, 19537, 19523, 19521, 42758, 42759,\n",
       "         42760, 19512, 19511, 19507, 42817, 19466, 60342, 42804, 19396,\n",
       "         60367, 42807, 42808, 19386, 19385, 19379, 60373, 19369, 42810,\n",
       "         60374, 19362, 19355, 42815, 19400, 60340, 19402, 19410, 19459,\n",
       "         60344, 60345, 19454, 42782, 19445, 19439, 19431, 19430, 19423,\n",
       "         19422, 19420, 19419, 42798, 42799, 19405, 51853, 42881, 19135,\n",
       "         18867, 60523, 18864, 60524, 60526, 18860, 60529, 18856, 18855,\n",
       "         18850, 18847, 60531, 60533, 18841, 60535, 42973, 18832, 42972,\n",
       "         18880, 51785, 42953, 18919, 18912, 18911, 51784, 42958, 42960,\n",
       "         18898, 60515, 18894, 18889, 18887, 60517, 42968, 42971, 18938,\n",
       "         18830, 60547, 18761, 60571, 18750, 60572, 60574, 60577, 18733,\n",
       "         18732, 60579, 18727, 43024, 60587, 18718, 18715, 18714, 18765,\n",
       "         18826, 43012, 18773, 42987, 42990, 42991, 60551, 60552, 18808,\n",
       "         18796, 18794, 60558, 18791, 60559, 51770, 18783, 18778, 43009,\n",
       "         51767, 42883, 18942, 18947, 19085, 19084, 19083, 19080, 19079,\n",
       "         19074, 60464, 60469, 19052, 19051, 42911, 60472, 19045, 51799,\n",
       "         19040, 19086, 60475, 19087, 51806, 19132, 42885, 19127, 19124,\n",
       "         19123, 51810, 19119, 42888, 51809, 42890, 42891, 60453, 19103,\n",
       "         51807, 42897, 19088, 18946, 19038, 19036, 18980, 18979, 60495,\n",
       "         18977, 42933, 18973, 51791, 60498, 18960, 51788, 18954, 18953,\n",
       "         18952, 18951, 18948, 42932, 51793, 42931, 18989, 19031, 42919,\n",
       "         60477, 60478, 42920, 19021, 42924, 42925, 60489, 19001, 18998,\n",
       "         42928, 60492, 18993, 18992, 60494, 19555, 19560, 42745, 42536,\n",
       "         20135, 20134, 42537, 60104, 20128, 42541, 20122, 20121, 20118,\n",
       "         20116, 51924, 20109, 20108, 60107, 60100, 20103, 20149, 20152,\n",
       "         20197, 20196, 42511, 20191, 51933, 20181, 20179, 42521, 60093,\n",
       "         20176, 42522, 42524, 42525, 20167, 51928, 20150, 60083, 51922,\n",
       "         20090, 60139, 60140, 20038, 20029, 20028, 20026, 42576, 60143,\n",
       "         20022, 20019, 51909, 42582, 42584, 42585, 20011, 60138, 20091,\n",
       "         42573, 20052, 42554, 20084, 60113, 20079, 20077, 42559, 42560,\n",
       "         60124, 20066, 60128, 60129, 42564, 42565, 60130, 51915, 51914,\n",
       "         42586, 60082, 51935, 60031, 42459, 42460, 42462, 20331, 20327,\n",
       "         60038, 51941, 60039, 20321, 60041, 20317, 20316, 20315, 20313,\n",
       "         20350, 42470, 20352, 42454, 20409, 42439, 20403, 60013, 20396,\n",
       "         42440, 60015, 51945, 60018, 60020, 20374, 20372, 42450, 60024,\n",
       "         51943, 60028, 42509, 42472, 20302, 20246, 42492, 20244, 20242,\n",
       "         42493, 42495, 42496, 42497, 60073, 20224, 20222, 20221, 20219,\n",
       "         42500, 51937, 20248, 60047, 20249, 42490, 20301, 20300, 20299,\n",
       "         42475, 20294, 20290, 60053, 20281, 60056, 42483, 20268, 20267,\n",
       "         20261, 60065, 42489, 20252, 60154, 19999, 19996, 60258, 19697,\n",
       "         19696, 19695, 19691, 42696, 60260, 19687, 42699, 19677, 60270,\n",
       "         19663, 19661, 19660, 60274, 19701, 60275, 51877, 60256, 19739,\n",
       "         42682, 42684, 60248, 60249, 19726, 19725, 42686, 60253, 19719,\n",
       "         42687, 19717, 19714, 42690, 19709, 19706, 51878, 42707, 51868,\n",
       "         51859, 60305, 42735, 19590, 19584, 19581, 19578, 19577, 19576,\n",
       "         19570, 51856, 19566, 19565, 19564, 19562, 19602, 19654, 19606,\n",
       "         42726, 19651, 60280, 51867, 19646, 42715, 19640, 19639, 42717,\n",
       "         60287, 19636, 19630, 60292, 19621, 42723, 19615, 60300, 42679,\n",
       "         19745, 60243, 42618, 60180, 60183, 19915, 51895, 42624, 19902,\n",
       "         19899, 60188, 19893, 60189, 42631, 42632, 19889, 19886, 19928,\n",
       "         19885, 19930, 42612, 19994, 19989, 60160, 42592, 19983, 60164,\n",
       "         42597, 19972, 42600, 19956, 51900, 60168, 42604, 19943, 60178,\n",
       "         19933, 19882, 19880, 60191, 42659, 19802, 42666, 19791, 60228,\n",
       "         19779, 42674, 19770, 60235, 19765, 19763, 19758, 60238, 19750,\n",
       "         19748, 42658, 42656, 42654, 42653, 19875, 19868, 19866, 60206,\n",
       "         42644, 51886, 19841, 43029, 60209, 60210, 42646, 19833, 19832,\n",
       "         19831, 19825, 42652, 19839, 20411, 18712, 43034, 17533, 17532,\n",
       "         43475, 17530, 43476, 17526, 17525, 17523, 17522, 17521, 17519,\n",
       "         17513, 17512, 61026, 61027, 17540, 61028, 43472, 43470, 43454,\n",
       "         17592, 17587, 43456, 17584, 17583, 17581, 17570, 61011, 17564,\n",
       "         17563, 51620, 17558, 61016, 17549, 17545, 17596, 43481, 17497,\n",
       "         17438, 17437, 17435, 17429, 17428, 61060, 17424, 17423, 61061,\n",
       "         17421, 17420, 17417, 17415, 17408, 61064, 17439, 17502, 61056,\n",
       "         17449, 17492, 17491, 43486, 17478, 17475, 17471, 17469, 17466,\n",
       "         17465, 61046, 17462, 17458, 43497, 43498, 43499, 61055, 17402,\n",
       "         17600, 17606, 17783, 17782, 17779, 17775, 17774, 17772, 17769,\n",
       "         43380, 17759, 17758, 43386, 60937, 60939, 17743, 17742, 17784,\n",
       "         17740, 17785, 17790, 43360, 43362, 17828, 43364, 51661, 60920,\n",
       "         60921, 43368, 60924, 43370, 17800, 17799, 51660, 43372, 17792,\n",
       "         17788, 17603, 17737, 17731, 17659, 51638, 17648, 51632, 43433,\n",
       "         43435, 43437, 17627, 60982, 17616, 17615, 17614, 60986, 60991,\n",
       "         17608, 60968, 17735, 43418, 17671, 43393, 43395, 43397, 17721,\n",
       "         51646, 60953, 17710, 17708, 17698, 60961, 17683, 17680, 17679,\n",
       "         60965, 43416, 17667, 17838, 17401, 17396, 17118, 17116, 17113,\n",
       "         17111, 17105, 43611, 61171, 17090, 61176, 61178, 43617, 17080,\n",
       "         17077, 17072, 61180, 61161, 17070, 17125, 17132, 17165, 17163,\n",
       "         17162, 17161, 17159, 17156, 51572, 17154, 61151, 17152, 17148,\n",
       "         17146, 61154, 17139, 61157, 43601, 17169, 43621, 17056, 61200,\n",
       "         16996, 16991, 16989, 16986, 43647, 16981, 61208, 16973, 61211,\n",
       "         61213, 16970, 61215, 61216, 51558, 43644, 43623, 17001, 17019,\n",
       "         17055, 17053, 17050, 43627, 61190, 61191, 61192, 43629, 17037,\n",
       "         43630, 43631, 43632, 17027, 43634, 61195, 17006, 17399, 17173,\n",
       "         17179, 17324, 17322, 17321, 17319, 17318, 43542, 61101, 17296,\n",
       "         51593, 17293, 43551, 17288, 17287, 17286, 17278, 17330, 61115,\n",
       "         61087, 17338, 43515, 17392, 17389, 17384, 43521, 43522, 17369,\n",
       "         17367, 61078, 17355, 17353, 17344, 17343, 43531, 43533, 61084,\n",
       "         17177, 43556, 17266, 43569, 61138, 61139, 17216, 17215, 17209,\n",
       "         17208, 17204, 43575, 61144, 17201, 43576, 43578, 51578, 17184,\n",
       "         43567, 61116, 17227, 43566, 17265, 43560, 43561, 61123, 17254,\n",
       "         51585, 17252, 17248, 17247, 17244, 17241, 17240, 61128, 17235,\n",
       "         61129, 17228, 43357, 43355, 60913, 60697, 43139, 60698, 18426,\n",
       "         18423, 18422, 18420, 18412, 43144, 51727, 18402, 18400, 43149,\n",
       "         18392, 18391, 43138, 18389, 60694, 18451, 18511, 43112, 43114,\n",
       "         18501, 43115, 18494, 60672, 43116, 60673, 43117, 18487, 43118,\n",
       "         18469, 51731, 43132, 43133, 18516, 43157, 51721, 18332, 51712,\n",
       "         18330, 43177, 18324, 60731, 18315, 18304, 51709, 60739, 43192,\n",
       "         18294, 60743, 18283, 60747, 18334, 18383, 18336, 18343, 43159,\n",
       "         43161, 18376, 18371, 18370, 18369, 60716, 43164, 18361, 51718,\n",
       "         60718, 18355, 60723, 60725, 18344, 18337, 43197, 43107, 18520,\n",
       "         60613, 18656, 18650, 60619, 18648, 43051, 43053, 60625, 43055,\n",
       "         18640], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_range': {'feature_present_idx': array([ 1413, 15155,  9374, 43256, 20547, 50530,  8469], dtype=int64),\n",
       "  'feature_absent_idx': array([37992, 53975, 17252, 17248, 17247, 35242, 17244], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 7\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 7\n",
       "  })},\n",
       " 'contains_scale': {'feature_present_idx': array([41196], dtype=int64),\n",
       "  'feature_absent_idx': array([18993], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1\n",
       "  })},\n",
       " 'contains_source': {'feature_present_idx': array([56465, 57962, 50414, 60713, 20941, 33645, 63027, 43335, 33509,\n",
       "         47475, 22270, 64558, 50239, 10399, 17768, 51109, 51318, 33205,\n",
       "         52262,  9361, 52708, 32921, 18166, 53661, 32384, 55511, 51589,\n",
       "         50095, 19180, 31430, 14616, 36529, 14505, 14466, 38443, 38552,\n",
       "         39290, 13685, 13674, 47552, 36332, 41727, 12795, 12520, 34988,\n",
       "         12355, 11883, 34626, 34533, 46553, 35612, 34293, 37065, 19525,\n",
       "          2550, 26510,  2479, 21854, 62617, 25888,  1835, 25280, 64241,\n",
       "         27985, 65328, 65965, 24278, 66481, 23962, 66541, 66854, 66989,\n",
       "           419,   206, 65511, 28763, 26609, 58863, 58667,  5981,  3682,\n",
       "          5779, 30617,  5389,  6912,  6300, 28969, 59664, 20509, 20605,\n",
       "         20946, 29027, 32849, 31261, 23807, 31341, 32370, 34275, 30946,\n",
       "         35507, 29725, 29429, 34911, 36739, 24210,   103, 48468, 38303,\n",
       "         59018, 59101, 59169, 59410, 59607, 59819, 59926, 60637, 61500,\n",
       "         61513, 61562, 61785, 62586, 62613, 63287, 64214, 64893, 66085,\n",
       "         66462, 66510, 66829, 58801, 37431, 57055, 56590, 38386, 39824,\n",
       "         41112, 41372, 43013, 45454, 46053, 46175, 46654, 23706, 50431,\n",
       "         50439, 51855, 52245, 52717, 53071, 53972, 54310, 55859, 56035,\n",
       "         56329, 56671, 23186, 32291, 16184,  4668,  9885, 11856, 18246,\n",
       "          7136,  7238, 11393, 21394, 11349, 11087, 21288, 20132,  8856,\n",
       "          9649, 19681, 21544, 11983, 10455, 22835,  3180, 22664, 17327,\n",
       "          2548, 22531, 13472, 15409,  2936, 16465, 49201, 15884, 49745,\n",
       "         48613, 50303, 35910, 48541, 48124, 50309, 36444, 41493, 38526,\n",
       "         14017, 46223, 11612, 22912, 45116, 44941, 40978, 43366, 41196,\n",
       "         43176, 42917, 41583, 14774, 44421, 23098, 51478,  4193, 60882,\n",
       "         61137,  3638, 61877, 62520, 62552, 60597,  2217,  1452, 65611,\n",
       "         65691,   873,   809,   779,   564, 63152,  4604,  4961, 59468,\n",
       "         51600, 51688,  9772, 51974, 35859, 54007,  8349, 55620,  8117,\n",
       "          8090, 56401, 57564, 57752,  6333,  5887, 59201,  5068, 10291,\n",
       "          9260, 45932, 27345, 25820, 22052, 26476, 32470, 21470, 26681,\n",
       "         26800, 33435, 33869, 19731, 17711, 28157, 28110, 33526, 17897,\n",
       "         27786, 28363, 18379, 22254, 29360, 16237, 22866, 34986, 23239,\n",
       "         30904, 31844, 35104, 22567, 34318, 30894, 20277, 55644, 10196,\n",
       "         19932, 20087,  9064, 53431, 53798, 54924,  8748, 54129, 50865,\n",
       "          7836, 52512, 57624, 23471,   815,  1220, 66060,  1279, 65834,\n",
       "          1317,  1859, 63264, 24666, 27753,  1897,  2364, 24765, 61865,\n",
       "         25401, 25615,  4251,  5134, 58344, 57979, 27474, 62743, 10813,\n",
       "         67306, 32288, 45003, 10935, 12405, 42551, 13000, 34150, 17386,\n",
       "         45756, 17314, 16962, 46059, 48816, 14817, 48194, 31651, 14900,\n",
       "         27779, 45221, 34629, 44116,  6404, 58075, 33557,  5594,  1243,\n",
       "         27245, 64163, 60202, 60451, 65859, 34188, 24128, 22421, 62239,\n",
       "         25151, 14346, 14464,  1351, 19014, 33775, 35139,  9228, 52405,\n",
       "         30330, 30615, 51334, 10147, 32438, 51335, 10970, 51041, 52426,\n",
       "         10488, 24428, 26320, 34019, 28762, 34801,  3738, 13357, 34746,\n",
       "         29753, 19162, 24994, 24668, 50378, 19808, 14563, 33983,  1719,\n",
       "          1707,  1565, 32153, 39426, 61302, 47729, 17994, 17925, 46179,\n",
       "         45584, 54487, 18844, 26481, 27247,  5244, 43381, 41589, 47705,\n",
       "         26988,  4419, 55135, 14935,  8034, 37407, 11973, 55752, 13642,\n",
       "         46457, 57661, 27116, 36427, 41559, 34982, 30640, 16012,  9014,\n",
       "          6219, 38653, 52403, 67044,  9586, 46857,   969, 27689, 52787,\n",
       "         53840, 11134, 30862,  6608, 47561], dtype=int64),\n",
       "  'feature_absent_idx': array([19083, 52503, 52508, 19369, 52518, 19362, 19355, 19350, 52535,\n",
       "         52537, 52539, 19339, 52541, 19335, 52543, 52544, 19379, 52547,\n",
       "         19385, 52501, 19430, 19423, 19422, 19420, 19419, 52480, 52481,\n",
       "         19410, 52486, 19405, 19402, 19400, 52492, 19396, 52493, 19386,\n",
       "         52548, 52556, 19319, 52604, 19257, 19256, 19251, 19248, 52616,\n",
       "         52619, 52620, 19234, 52623, 52627, 19228, 52635, 52637, 19221,\n",
       "         52603, 19266, 52599, 52596, 19318, 52562, 19310, 52580, 52581,\n",
       "         19297, 19294, 19431, 19293, 52585, 19288, 19287, 52591, 52595,\n",
       "         19273, 19271, 19290, 19439, 52468, 52465, 52349, 19590, 19584,\n",
       "         19581, 52364, 19578, 19577, 19576, 52369, 19570, 52376, 19566,\n",
       "         19565, 19564, 19562, 52346, 52345, 19602, 52342, 52305, 19646,\n",
       "         52310, 52312, 19640, 19639, 52318, 19560, 19636, 19630, 52331,\n",
       "         19621, 19615, 52335, 52341, 19606, 52323, 52640, 19555, 19550,\n",
       "         52418, 52429, 19479, 19477, 19475, 19466, 52444, 52445, 52450,\n",
       "         19459, 52452, 19454, 52461, 52462, 19445, 52414, 52409, 52408,\n",
       "         19502, 19549, 52385, 19541, 19540, 19539, 19538, 19537, 19552,\n",
       "         52396, 19521, 19512, 19511, 19507, 19506, 19505, 52406, 19523,\n",
       "         19651, 19216, 19209, 18919, 52864, 18912, 18911, 52868, 52869,\n",
       "         52871, 18898, 18894, 18889, 52884, 18887, 52885, 52888, 52892,\n",
       "         52859, 52893, 52855, 18942, 18979, 18977, 18973, 52821, 52831,\n",
       "         18960, 18954, 18953, 18952, 18951, 52840, 52842, 18948, 18947,\n",
       "         18946, 18938, 18880, 52895, 52898, 52946, 52947, 18808, 52958,\n",
       "         18796, 18794, 52961, 18791, 52963, 52965, 52966, 18783, 18778,\n",
       "         52975, 18773, 52942, 52939, 52938, 18826, 18867, 52905, 18864,\n",
       "         52906, 52909, 18860, 18856, 18980, 18855, 18850, 18847, 52919,\n",
       "         18841, 18832, 18830, 52933, 52914, 52814, 52813, 52810, 19149,\n",
       "         52695, 52698, 19135, 19132, 19127, 19124, 19123, 19119, 52714,\n",
       "         52718, 52721, 19103, 52725, 52728, 19159, 52680, 52679, 52676,\n",
       "         19207, 19201, 19199, 19197, 19194, 19192, 19189, 52733, 19187,\n",
       "         52661, 52662, 19181, 52664, 52669, 19173, 52671, 19184, 19211,\n",
       "         52734, 19087, 52767, 52774, 19021, 52780, 52785, 52786, 52790,\n",
       "         52791, 19001, 52795, 18998, 52798, 18993, 18992, 18989, 52766,\n",
       "         19031, 19036, 19038, 19086, 19085, 19084, 19080, 19079, 52738,\n",
       "         19074, 19088, 52740, 52753, 19052, 19051, 52761, 19045, 19040,\n",
       "         52764, 52751, 52303, 19654, 19660, 51807, 20294, 20290, 51809,\n",
       "         51810, 20281, 51819, 51820, 20268, 20267, 20261, 20252, 20249,\n",
       "         20248, 20246, 51806, 20244, 20299, 20301, 51770, 20331, 20327,\n",
       "         51784, 51785, 20321, 51788, 20317, 20316, 20315, 20313, 51791,\n",
       "         51793, 51799, 20302, 20300, 20242, 51848, 51853, 51909, 51914,\n",
       "         51915, 20152, 51922, 20150, 20149, 51924, 51928, 51933, 20135,\n",
       "         20134, 51935, 51937, 20128, 20167, 51900, 20176, 20179, 51856,\n",
       "         20224, 51859, 20222, 20221, 20219, 51867, 51767, 51868, 51878,\n",
       "         51886, 20197, 20196, 20191, 20181, 51895, 51877, 20350, 20352,\n",
       "         51753, 20538, 51638, 20533, 20530, 51646, 20525, 20520, 20519,\n",
       "         20518, 51660, 51661, 20508, 51665, 20501, 51669, 20540, 51632,\n",
       "         20551, 20552, 20622, 51572, 20620, 51578, 51585, 20608, 20606,\n",
       "         51671, 20601, 20599, 20597, 20584, 20577, 20575, 51620, 20559,\n",
       "         51593, 20122, 20488, 20482, 20418, 51718, 20412, 20411, 20409,\n",
       "         51721, 20403, 20396, 51727, 51731, 51742, 20374, 51743, 20372,\n",
       "         51747, 20419, 20420, 20423, 51712], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 446\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 446\n",
       "  })},\n",
       " 'contains_subevent': {'feature_present_idx': array([ 2363, 61201, 38576, 17453, 14264, 34681, 60247, 57530, 19481,\n",
       "         60711, 62337, 14125, 33171, 33343, 34148, 11888, 19981,  1165,\n",
       "         50354, 47224,  7121,  6701, 65479,  5775, 47189, 57472, 41022,\n",
       "         59422, 31035, 53436, 50199, 66462, 40173, 29909, 33566, 19681,\n",
       "          3217,  4562, 16479, 62341, 12567, 12497, 12233, 65791,  7767,\n",
       "         65054,  7777,  4019, 47914, 33869, 19937, 11933, 56291, 29487,\n",
       "         42464, 34882,  2316, 62397, 44152,   580,  2537, 42336, 42324,\n",
       "          9862, 11120, 35023, 17461, 19301, 19442, 29674, 44255, 14086,\n",
       "         43383, 66648, 55072, 53954, 51533, 26547, 17741, 37388, 66456,\n",
       "         20878, 20101, 32497, 51380, 35769, 46663, 57503, 11500],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([50294, 22562, 59734, 39218, 26920, 26918, 54111, 26915, 54113,\n",
       "          9915, 49931, 59725, 59736,  9918, 41321, 22570, 22571, 26906,\n",
       "         39223, 59714, 26905, 59710, 34468, 17090, 36473, 26910, 26899,\n",
       "         59737, 54109, 26940, 36484, 46538, 22555, 49941, 59756, 59755,\n",
       "         26936, 59754, 17113, 17111, 17105, 59749, 36482, 36481, 22559,\n",
       "         59744,  9891, 46542, 33808, 46546,  9897, 59739, 59738, 26932,\n",
       "         17116, 26897, 46558, 59668,  9975, 54133, 59665,  9978, 17072,\n",
       "          9980, 26870,  9982, 46575, 22586,  9973, 17070,  9987,  9988,\n",
       "         26865, 26863, 39232,  9994, 41309, 26860, 22590, 26858, 22591,\n",
       "         54138, 59698, 40829, 54131,  9942, 59691, 41315, 46563],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 89\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 89\n",
       "  })},\n",
       " 'contains_time': {'feature_present_idx': array([43315, 61010, 61017, 19816, 34444, 11881,  8279, 61118,  4009,\n",
       "         32360,  3976, 29833, 61305, 54561, 54537, 22377, 61327, 41644,\n",
       "         15139, 29848, 61384, 27344, 41600,  3822, 23990,  3782,  3743,\n",
       "         61484, 23916, 48181, 27396,  4236, 42530,  4560, 60315,  4512,\n",
       "         29588, 42361, 27751, 47442,  8035, 21103, 42201, 42131,  4387,\n",
       "         47572, 23804, 60508,  4324, 60581, 60606, 14855, 23809, 47683,\n",
       "         14909,  4265, 47749,  8196, 34401,  4197, 42556, 41480, 61588,\n",
       "          3104,  3096, 62439,  3087, 11289, 62482, 62512, 32035,  2966,\n",
       "         15950, 27032, 19559, 26902, 48639, 19547, 32011, 53555, 53483,\n",
       "         16109, 62813, 30240,  2694, 40090, 40062, 48824, 21295,  2625,\n",
       "         40710, 41477,  3114, 40781, 15382, 41362, 22343, 61683, 48223,\n",
       "         48252,  3575, 34558,  3522, 11620, 48270, 61903, 22315, 15575,\n",
       "         61935, 61947, 15636,  3365, 48416, 27097, 24113, 62083, 40870,\n",
       "          3268, 62127, 62279, 48515, 19667, 60211, 60205, 42634, 56098,\n",
       "         20634, 58058, 44928,  6033, 23182,  6025, 44872,  6004, 20859,\n",
       "         58295, 44806, 22753, 58320, 46425,  5820, 28508, 46441, 33423,\n",
       "         44579,  5734, 12560, 58544, 12541,  5687, 44430, 55708, 12748,\n",
       "         33490, 45147,  7147, 12985,  6758, 45642, 45620, 56594,  6900,\n",
       "         45515,  6971, 45381, 57222, 12840, 23029,  7007, 29090, 56466,\n",
       "         12839, 20786, 28728, 12806, 57466, 57475, 57489, 45229, 57539,\n",
       "         46029, 45190, 45184, 29141, 32772, 55676, 58788, 12171, 21733,\n",
       "         14218, 47104, 23605, 32612, 59576, 14335, 43258, 55158, 27919,\n",
       "         43229, 55112, 55110, 33725, 55103,  4793, 59887, 23657, 23676,\n",
       "         59913, 42938, 14467, 54987, 54974, 33843, 14510, 55318, 20970,\n",
       "         32634, 12183, 58795, 46689, 44128, 58815, 22700, 33496, 28300,\n",
       "         58833, 46702, 13856, 46711, 43965, 29443, 39996, 55611, 43655,\n",
       "          5350, 28206, 28174, 28154,  5256, 28133, 28092, 28066, 33597,\n",
       "         33657, 59300, 47065, 12354, 21320, 53881, 31941, 30746, 17413,\n",
       "         37869, 35305, 37840, 18965, 65584,  9637, 51622, 49781, 25785,\n",
       "         25747, 65653, 17379,   941, 65674, 37743,   902, 49799, 49857,\n",
       "         51466, 37622, 65786, 31526, 65793, 17656, 37542, 37516, 65663,\n",
       "         51450, 37937,  1146,  1501, 52166, 64889, 19145, 10709, 52058,\n",
       "         49530, 52009, 26073, 35255, 17087, 51993,  1312, 51774,  1283,\n",
       "         22005, 38325, 10681, 51964, 30652, 49643,  9471, 49665, 51841,\n",
       "         38074, 37987, 25860, 53096, 19121, 35230,   733, 35837, 36752,\n",
       "         36275, 51085, 50248, 36715, 50267, 66816, 36290, 31317, 25389,\n",
       "         31137, 50940, 18448, 25073, 18704, 25170, 36591, 36511,    95,\n",
       "         36491, 50615, 67253, 50753, 31208,    42,    41, 50668, 67315,\n",
       "           164, 25632, 66645, 51197, 35847, 37390, 18803, 37357, 37353,\n",
       "         37347, 50051, 66123,  9806,  9821, 37217, 37118, 18756, 18737,\n",
       "           550, 50066, 18749, 37008, 24979, 18068, 18083, 51259, 24993,\n",
       "           443, 30982, 36888, 50206, 66454, 51332,  9306, 49733, 49513,\n",
       "         63999, 39302,  2038, 30464, 49310, 64093, 64143, 21417, 52524,\n",
       "         39037, 49403, 64258, 22055, 16707, 26500, 52478, 38978,  1777,\n",
       "          9185,  1749, 38902, 22080, 63799, 63769, 24346, 16265, 39873,\n",
       "         39826,  2414, 63150, 63192, 34930, 49013, 34933, 26612, 52343,\n",
       "         39723, 39524, 63446, 10976, 63511, 26576, 30412, 63585, 49170,\n",
       "         63624,  2170, 16361, 16809, 45730, 64632, 16852, 38853, 52227,\n",
       "         38652, 22047, 64476, 64423, 10830, 52282, 26280,  1523, 64718,\n",
       "         38752,  9276, 64483, 10188, 46153, 11228, 12734, 32886, 46169,\n",
       "         12729, 47994, 11904, 12715, 31610, 12733, 48559, 21513, 46303,\n",
       "         46481, 21151, 50075, 31373, 12572, 11921, 10279, 32818, 11013,\n",
       "         50157, 49141, 10693, 32852, 46351, 21354, 10235, 46348, 50217,\n",
       "         32066, 32961, 50271, 49096, 32966, 48808, 12850, 48956, 32977,\n",
       "         31863, 32980, 12871, 50607, 45888, 12891, 45765, 32372, 45753,\n",
       "         48927, 45744, 10030, 11078, 31969, 10725, 32394, 50587, 46040,\n",
       "         25233, 49057, 10761, 11151, 21675, 48694, 48723, 47764, 50367,\n",
       "         12797, 50417, 48729, 47866, 48749, 45975, 45954, 31847, 50567,\n",
       "         46102, 31564, 47640, 49178, 48076, 47435, 31561, 47177, 11658,\n",
       "         11639, 49789, 47155, 11730, 47465, 49614, 11572, 49807, 49848,\n",
       "         21401, 47540, 32217, 12208, 12168, 49341, 48217, 47359, 49722,\n",
       "         21158, 11813, 47297, 10617, 21180, 47342, 11762, 12011, 10557,\n",
       "         47287, 21058, 49420, 47348, 32556, 49737, 47202, 47178, 31557,\n",
       "         32683, 46910, 11560, 31473, 49306, 32100, 31466, 49301, 21155,\n",
       "         49491, 11452, 46706, 11418, 48507, 46683, 47611, 21267, 46642,\n",
       "         12501, 12051, 46570, 49259, 11960, 49926, 45735, 48059, 46822,\n",
       "         11553, 21214, 11526, 32704, 32724, 32753, 12269, 10775, 49905,\n",
       "         10414, 12296, 47792, 12317, 12345, 32144, 46728, 32132, 11375,\n",
       "         12302,    11, 12978, 16568, 16552, 35154, 16524, 39373, 35117,\n",
       "         16499, 19222, 35064, 39391, 39395, 39511, 39730, 16342, 39743,\n",
       "         39770, 16484, 16291, 19217, 39134, 16926, 38694, 38715, 16880,\n",
       "         38765, 19167, 38807, 16624, 38827, 38895, 35222, 16740, 16722,\n",
       "         19175, 35178, 39039, 16811, 19155, 34872, 39945, 40663, 34758,\n",
       "         15880, 15842, 40782, 40820, 40843, 40601, 15799, 40909, 15783,\n",
       "         40911, 15742, 41006, 41019, 41031, 40885, 39936, 40443, 40301,\n",
       "         16220, 39970, 16199, 40034, 19416, 34839, 40064, 34776, 16132,\n",
       "         19458, 34836, 40142, 16021, 40161, 19480, 15987, 19451, 41038,\n",
       "         16952, 17000, 36263, 36222, 36843, 18169, 36891, 36913, 36924,\n",
       "         36756, 36054, 37049, 17993, 37221, 37282, 18788, 37339, 35863,\n",
       "         36993, 17880, 18264, 18711, 18614, 18609, 18588, 18580, 36371,\n",
       "         18666, 18564, 18303, 36327, 18450, 18442, 18438, 36612, 36632,\n",
       "         18341, 18335, 18455, 38544, 37443, 17754, 35281, 38178, 17258,\n",
       "         35268, 19118, 17218, 38311, 38090, 17191, 17100, 17097, 38421,\n",
       "         17048, 35234, 38473, 17008, 38333, 17798, 38065, 37976, 37579,\n",
       "         37659, 18890, 37693, 37702, 35662, 18930, 37980, 37766, 35531,\n",
       "         35417, 37899, 17400, 37925, 17371, 35300, 35587, 34695, 34644,\n",
       "         41072, 44375, 20521, 20524, 33484, 44536, 20541, 13711, 13779,\n",
       "         44651, 33323, 33318, 13617, 13611, 44798, 44838, 44840, 44690,\n",
       "         20596, 44343, 44175, 14076, 20282, 43597, 43635, 43664, 33548,\n",
       "         13978, 44179, 43769, 43790, 13929, 13892, 13877, 33511, 20449,\n",
       "         44163, 43787, 43572, 13521, 33243, 13171, 45375, 13157, 45438,\n",
       "         20698, 45503, 13117, 45322, 13111, 45587, 13078, 45593, 45607,\n",
       "         13009, 45680, 12979, 33141, 33251, 45296, 13234, 45002, 33224,\n",
       "         45080, 13414, 13411, 45119, 13339, 45284, 13334, 13287, 45183,\n",
       "         45210, 45238, 20676, 45265, 13237, 20670, 20272, 20215, 43455,\n",
       "         41789, 15027, 15025, 19773, 41804, 41816, 34449, 15047, 14992,\n",
       "         41836, 34436, 34409, 14941, 41965, 14912, 42032, 14965, 34296,\n",
       "         41753, 41627, 15543, 41114, 41167, 41235, 41261, 41263, 15428,\n",
       "         41681, 34540, 15347, 41489, 19760, 41524, 41544, 15210, 41616,\n",
       "         19743, 19849, 14839, 34252, 43000, 43030, 43049, 43246, 43249,\n",
       "         33717, 14322, 14419, 14307, 14209, 43321, 14193, 43356, 43392,\n",
       "         33687, 14142, 33701, 33735, 42975, 42942, 42117, 34213, 14769,\n",
       "         42321, 34061, 42353, 42358, 42448, 42469, 42498, 14616, 42510,\n",
       "         14606, 33920, 42893, 33818, 14455, 45697, 10029, 30657, 10014,\n",
       "         61278,  3974,  3971, 61319,  3892, 23929, 23936,  3861,  3852,\n",
       "         61343, 27350, 61413,  3803, 61477,  3713, 23994, 61511, 61119,\n",
       "         61547,  4021,  4048,  4391, 27639,  4380, 60567, 27634, 60589,\n",
       "         60621,  4271, 23822, 27562, 27546, 27410, 61003,  4097,  4071,\n",
       "          4064, 61071, 61107, 61606, 24033, 61634, 62147, 62301, 62330,\n",
       "         62379,  3127, 62389, 62445, 62453, 62516,  2923, 62531, 24184,\n",
       "         62628, 62641,  2836, 62715, 62717,  3285,  3300,  3330, 24095,\n",
       "          3621], dtype=int64),\n",
       "  'feature_absent_idx': array([40416, 10982, 19294, 19293, 10986, 10987, 49856, 60006, 19290,\n",
       "         10991, 32215, 19288, 32226, 19287, 32209, 26186, 59996, 59995,\n",
       "         45895, 54433, 45899, 59993, 11006, 59992, 32203, 45892, 45900,\n",
       "         60013, 60015, 10943, 45874, 10947, 32245, 60031, 60028, 26173,\n",
       "         45879, 60024, 10958, 26178, 10978, 10960, 10963, 32235, 26180,\n",
       "         10967, 19297, 32232, 60020, 60018, 32230, 32228, 32227, 54430,\n",
       "         60038, 11010, 49854, 59963, 11052, 11053, 11055, 32169, 45929,\n",
       "         32167, 11059, 59960, 59959, 59958, 59964, 11065, 11069, 11071,\n",
       "         26203, 59953, 54445, 59950, 45935, 32158, 11080, 19266, 59945,\n",
       "         59956, 49855, 32170, 45927, 32199, 45903, 45904, 11018, 59987,\n",
       "         59986, 32195, 32194, 59984, 49851, 49847, 19271, 32186, 32179,\n",
       "         19273, 11036, 11037, 32177, 45923, 59971, 11042, 26200, 11044,\n",
       "         11045, 54438, 59944, 60039, 60041, 49885, 10838, 10839, 45824,\n",
       "         45826, 60083, 10843, 60082, 26148, 10846, 32316, 10836, 10850,\n",
       "         10852, 32312, 32311, 32309, 32306, 19339, 54396, 54399, 60073,\n",
       "         19335, 54400, 45828, 10866, 45823, 60093, 49901, 10803, 45809,\n",
       "         60107, 10806, 32351, 49898, 60104, 32348, 54379, 60100, 32328,\n",
       "         26135, 19355, 32340, 26138, 32338, 10821, 10822, 26139, 49891,\n",
       "         19350, 26141, 49890, 49897, 32251, 32297, 32293, 10911, 19318,\n",
       "         10913, 45863, 49865, 60056, 54412, 45864, 60053, 32262, 10921,\n",
       "         10910, 10922, 54413, 45872, 54418, 10928, 10931, 10932, 32254,\n",
       "         60047, 54419, 19310, 10938, 45865, 45843, 19319, 10905, 10874,\n",
       "         45846, 26159, 54402, 45847, 10879, 32287, 32286, 10882, 10883,\n",
       "         45849, 32270, 32284, 54406, 10889, 32278, 10893, 10894, 32276,\n",
       "         60065, 26162, 10900, 26163, 45856, 54404, 32154, 59943, 45939,\n",
       "         59837, 54490, 19197, 46016, 32024, 54491, 46018, 19194, 19192,\n",
       "         11274, 26254, 19199, 11276, 59828, 59827, 19189, 11281, 46023,\n",
       "         59825, 46024, 11285, 32010, 11287, 59821, 54493, 32008, 32030,\n",
       "         59840, 11230, 32057, 26246, 11233, 32051, 59853, 59852, 32050,\n",
       "         32047, 49800, 59846, 11259, 11244, 46007, 11248, 59845, 32040,\n",
       "         46008, 19201, 59843, 11254, 49796, 32032, 46013, 46006, 19207,\n",
       "         46028, 59817, 59797, 59796, 59795, 11331, 46049, 26268, 59793,\n",
       "         31973, 59786, 11340, 54509, 26266, 26273, 19159, 59783, 59780,\n",
       "         11350, 59779, 11352, 11353, 11354, 11355, 54518, 46066, 46063,\n",
       "         59820, 26265, 19173, 32005, 19187, 32000, 19184, 59810, 11303,\n",
       "         46036, 54495, 11306, 11307, 59809, 59799, 19181, 54497, 59808,\n",
       "         11314, 54499, 54503, 26262, 26263, 46047, 11321, 59803, 31982,\n",
       "         31994, 54485, 11226, 32061, 11124, 59922, 45948, 59921, 59920,\n",
       "         26216, 59917, 32126, 19248, 59915, 45953, 11123, 26218, 11139,\n",
       "         59911, 11142, 59909, 54470, 32115, 11150, 32113, 59904, 59903,\n",
       "         59901, 59914, 11159, 32130, 11119, 59942, 11094, 26208, 49837,\n",
       "         54452, 26210, 32146, 54457, 19257, 59936, 32142, 54465, 32141,\n",
       "         59935, 59934, 45945, 11110, 49831, 59933, 49825, 59930, 11116,\n",
       "         26215, 19251, 19256, 59899, 26233, 11164, 32077, 49803, 45986,\n",
       "         11202, 26242, 19216, 54483, 59870, 45990, 59868, 59866, 45984,\n",
       "         11211, 11214, 19211, 59864, 11217, 19209, 11219, 11220, 45993,\n",
       "         32063, 11223, 45994, 26245, 11196, 11194, 19221, 32106, 32105,\n",
       "         45968, 45969, 19234, 59892, 32098, 32096, 54476, 11176, 11177,\n",
       "         32093, 59885, 54477, 32091, 45976, 19228, 26237, 59883, 49809,\n",
       "         32086, 59877, 54480, 11191, 32082, 10801, 19362, 10799, 60113,\n",
       "         10402, 45611, 19502, 54276, 32653, 10408, 32652, 45615, 45616,\n",
       "         26013, 45618, 49994, 45619, 32640, 54280, 45628, 60345, 32632,\n",
       "         60344, 60342, 32630, 60340, 32629, 60338, 45626, 54282, 54273,\n",
       "         45609, 32676, 32675, 10370, 60382, 19511, 10376, 10377, 26009,\n",
       "         60374, 26010, 10383, 19505, 60373, 32669, 45603, 10388, 10390,\n",
       "         10391, 10392, 19507, 10394, 10395, 19506, 60367, 32670, 19512,\n",
       "         49988, 10442, 10478, 19466, 60305, 32585, 60300, 32578, 32577,\n",
       "         10490, 45664, 32575, 10496, 54302, 32572, 19459, 10502, 10503,\n",
       "         26042, 54306, 32567, 60287, 45671, 45672, 26043, 10511, 60292,\n",
       "         10441, 32590, 26033, 54290, 45634, 45635, 60332, 49985, 45638,\n",
       "         10451, 45639, 60329, 26027, 32614, 10474, 32611, 19477, 45643,\n",
       "         54297, 19475, 26029, 32601, 32600, 10468, 54299, 32597, 45652,\n",
       "         19479, 10366, 10363, 60386, 60453, 32757, 19552, 45553, 45557,\n",
       "         19550, 19549, 10268, 45565, 10271, 45567, 32760, 32744, 60440,\n",
       "         54256, 10280, 10281, 10282, 32739, 60438, 60436, 60435, 19541,\n",
       "         10289, 32743, 19540, 10257, 19555, 25971, 19566, 10228, 19565,\n",
       "         60464, 10231, 19564, 32782, 54244, 19562, 54245, 54251, 45535,\n",
       "         32775, 19560, 10242, 25972, 25976, 32770, 45542, 32767, 10249,\n",
       "         10250, 45544, 10239, 60430, 32734, 45573, 45594, 19521, 10336,\n",
       "         60401, 32697, 10339, 32696, 50000, 10342, 10343, 45598, 45592,\n",
       "         10346, 45599, 10349, 32686, 60394, 45600, 10355, 49999, 10357,\n",
       "         60390, 54270, 60387, 32689, 10330, 19523, 25998, 60428, 32731,\n",
       "         19539, 19538, 10299, 10300, 19537, 32726, 45576, 10304, 25988,\n",
       "         60421, 32722, 10308, 10309, 60420, 54260, 54261, 32716, 10321,\n",
       "         45583, 60410, 54266, 10326, 32707, 19454, 46067, 10514, 26044,\n",
       "         26097, 32427, 45761, 32424, 10697, 10699, 32423, 54351, 26098,\n",
       "         60168, 10706, 19396, 54354, 10710, 10711, 32417, 32415, 45769,\n",
       "         10716, 10717, 60164, 32412, 10720, 32411, 10708, 60160, 32430,\n",
       "         10687, 10659, 45743, 60191, 26087, 60189, 60188, 10665, 10666,\n",
       "         45747, 19405, 19402, 32431, 32440, 19400, 45758, 60183, 10677,\n",
       "         49941, 54350, 10680, 60180, 60178, 32435, 10686, 10673, 10658,\n",
       "         10723, 49931, 54361, 10767, 54365, 26125, 10773, 60130, 60129,\n",
       "         60128, 19369, 32371, 10782, 10765, 54369, 10785, 10787, 60124,\n",
       "         32365, 10790, 32364, 32362, 45800, 45803, 54372, 45807, 26129,\n",
       "         26104, 45786, 10758, 32404, 10730, 19386, 32401, 60154, 10734,\n",
       "         32400, 10736, 10737, 32399, 10740, 10763, 19385, 10746, 45779,\n",
       "         32392, 49923, 26115, 19379, 60143, 32388, 60140, 60139, 60138,\n",
       "         10742, 49948, 10654, 19410, 26060, 32532, 19439, 60253, 26061,\n",
       "         10558, 60249, 60248, 32525, 32524, 26063, 10549, 10565, 32518,\n",
       "         60243, 45695, 45696, 32515, 32514, 10575, 10576, 54337, 10578,\n",
       "         10579, 49960, 45699, 10547, 49973, 10518, 45674, 49978, 10522,\n",
       "         60280, 54318, 60275, 10527, 60274, 54319, 45683, 60256, 60270,\n",
       "         32547, 32546, 49976, 19445, 32543, 60260, 10540, 32539, 60258,\n",
       "         32538, 10544, 32548, 60238, 32511, 10584, 45726, 26076, 10626,\n",
       "         32472, 45731, 60210, 10630, 45732, 10632, 10633, 10634, 45725,\n",
       "         26077, 60206, 10638, 10641, 10642, 32464, 10645, 10646, 45736,\n",
       "         10649, 45740, 32459, 60209, 19419, 10618, 19420, 45701, 32509,\n",
       "         60235, 19431, 10589, 19430, 32506, 45704, 45705, 60228, 49954,\n",
       "         45711, 32495, 10602, 32493, 45713, 19423, 45716, 45717, 19422,\n",
       "         32486, 10611, 26075, 32483, 45722, 32562, 32790, 59774, 11363,\n",
       "         18887, 31418, 31417, 31416, 31414, 59274, 59273, 26473, 59270,\n",
       "         59268, 46417, 18889, 12132, 12134, 54700, 18880, 59265, 59264,\n",
       "         59262, 12142, 12143, 26478, 49639, 59261, 26474, 54702, 59283,\n",
       "         59286, 31445, 46390, 26464, 49648, 12087, 59301, 18898, 46393,\n",
       "         59299, 31438, 59293, 26470, 31435, 18894, 49642, 46402, 12104,\n",
       "         31429, 12106, 46406, 12108, 12109, 31426, 54694, 46399, 46389,\n",
       "         26482, 31399, 18855, 54723, 12198, 26492, 26493, 31367, 12202,\n",
       "         12205, 46439, 12207, 18850, 18856, 26496, 31360, 46442, 12215,\n",
       "         12218, 59212, 59211, 59210, 12224, 18847, 31355, 26502, 12212,\n",
       "         54705, 26491, 46434, 54712, 46426, 12158, 46427, 26487, 18867,\n",
       "         59249, 31389, 18864, 54715, 31386, 54719, 46428, 54718, 18860,\n",
       "         12178], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_topic': {'feature_present_idx': array([25854, 15416, 65202, 15488, 54259, 17955, 26017, 25980, 25917,\n",
       "         46122, 46396, 63781,  3983, 46981, 65142, 65108, 59663, 37537,\n",
       "         25697, 59646, 59523, 54539,  8262, 42094, 43127, 17929, 56540,\n",
       "         37544, 54160, 46423, 49736, 20928, 45837, 10054, 37384, 48961,\n",
       "         50002, 49975, 46972, 35135, 53454,  3035, 27494, 53557, 14865,\n",
       "         35265, 56836, 27088, 27001,  6634, 53847, 21189,  9900, 53923,\n",
       "         41874, 21191,  3503, 15355,  6266, 24892, 17900,  4368, 17588,\n",
       "         55392, 39500,  8811, 61291, 49203, 23392, 16930, 23216, 55600,\n",
       "         23188, 56099,  5412, 43536, 55660, 42258, 17047, 64160, 46319,\n",
       "         17093, 63978, 22828, 22120, 43436, 48500, 55901,  5757, 17702,\n",
       "         34945, 55349, 36792,  4381, 21694, 36503, 36536,  4497, 36553,\n",
       "         24609, 24551,  9223,  8331, 48521,  9168, 16270, 42125,  6123,\n",
       "         42170,  9021,  9019, 24031, 23944, 39244, 43633,  8904, 39335,\n",
       "         16651,  5064, 23590, 55341, 44477, 14589, 53093, 31852, 19618,\n",
       "         51491, 19665, 50492, 34000, 61558, 31465, 12375, 38127, 44948,\n",
       "         50483, 31239, 10871, 66700, 10824,  7746, 38678,  1225, 42833,\n",
       "         61756, 34115, 38081, 58372, 20113,  1358, 30571, 31891,  1381,\n",
       "         61469, 46673, 32985, 50854, 11657,  7483, 19296, 50922, 32667,\n",
       "         61233, 51002, 11763, 11825, 32454, 32336, 32331, 51044, 57842,\n",
       "         38295, 47621, 12060, 61440, 32140, 51164, 38183, 51263, 12157,\n",
       "         31993, 50626, 11098, 60821, 57488, 61800, 40306, 30494,  2002,\n",
       "         29498,  2091, 14147,  6976,  2116, 20283, 44697, 63032, 29234,\n",
       "         29198, 50130, 52805, 52872, 50126, 28833, 52940, 60359, 48033,\n",
       "         28411, 65770, 50048, 41702, 40389, 34397, 29560, 58618, 52499,\n",
       "         52525, 66465, 44752, 18502, 29948, 30182, 66408, 13326, 30211,\n",
       "         47871, 29710,  7929,  7956, 52673, 40596, 13092, 29821, 19131,\n",
       "         18186, 58520, 18263, 58446, 48578, 19049, 38945, 18102, 18378,\n",
       "         58564, 17781, 39343, 18921, 18004, 48525, 18386, 18790, 48534,\n",
       "         17793, 17728, 57905, 39210, 18381, 38957, 18926, 23203, 39357,\n",
       "         12978, 40529, 13334, 13390, 60686, 47903, 13610, 14166, 60408,\n",
       "         14352, 60384, 14386, 60319, 14498, 14546, 14582, 48120, 60834,\n",
       "         14757, 47839, 12795, 11562, 11674, 61238, 47533, 61227, 40993,\n",
       "         40905, 61184, 40877, 12160, 12166, 12271, 12347, 61036, 12623,\n",
       "         12683, 47811, 12870, 14807, 14862, 48122, 16192, 39633, 39619,\n",
       "         59325, 59229, 39576, 16524, 39525, 16604, 16652, 48445, 16872,\n",
       "         59063, 17034, 17112, 58976, 17433, 59419, 16083, 59450, 39675,\n",
       "         14959, 60182, 15295, 40042, 15362, 40036, 15377, 15452, 17517,\n",
       "         39968, 15544, 59875, 39840, 59655, 15966, 16004, 48343, 16024,\n",
       "         19208, 19213, 56225, 19247, 27914, 35019, 53215, 50004, 28009,\n",
       "         53086, 28431, 28463, 28641, 52995, 50091, 29266, 50181, 29411,\n",
       "         50183, 34412, 29593, 50196, 29715, 53267, 53406, 27675, 53445,\n",
       "         36107, 54368, 36040, 25830, 54262, 35950, 35928, 26158, 49700,\n",
       "         34370, 26290, 26465, 54005, 26507, 26693, 26714, 26876, 35542,\n",
       "         35273, 27305, 54099, 25675, 34330, 30014, 31945, 51366, 32014,\n",
       "         33811, 32163, 50645, 33728, 32205, 33716, 33686, 33681, 51014,\n",
       "         32512, 50657, 33620, 50899, 32958, 33604, 33408, 31933, 31772,\n",
       "         31695, 51608, 52456, 30169, 52431, 30316, 30491, 34187, 30609,\n",
       "         52321, 50268, 29946, 52193, 52032, 31045, 31108, 51832, 31227,\n",
       "         31362, 31383, 31447, 31466, 52146, 54385, 36148, 54565, 37628,\n",
       "         21000, 56699, 37579, 21279, 21301, 21360, 48993, 56591, 21574,\n",
       "         56522, 37422, 56462, 56458, 56437, 21920, 49030, 49050, 56381,\n",
       "         56927, 20920, 37756, 57157, 48848, 19282, 57707, 48899, 19487,\n",
       "         38289, 19671, 19798, 19924, 21996, 20037, 20115, 20127, 20143,\n",
       "         38071, 20171, 48927, 48929, 57233, 20363, 57486, 56290, 37385,\n",
       "         56165, 24078, 24082, 55244, 24246, 55146, 55142, 24327, 24328,\n",
       "         24331, 24043, 24398, 36554, 24528, 54927, 49416, 36272, 36269,\n",
       "         25090, 25121, 54582, 24418, 48833, 23905, 36781, 49113, 49147,\n",
       "         55997, 55944, 49157, 22720, 22878, 49190, 22963, 49205, 37021,\n",
       "         23364, 23408, 23424, 36917, 36908, 23542, 55386, 23615, 55291,\n",
       "         36988, 61303, 59121, 33313,  8429, 44505, 65739,  8506,  8539,\n",
       "          8565,  8399,  2512,  8776,  8782, 65853, 42181, 62412,  2375,\n",
       "          2407,  8869,  2830, 62622, 63037,  7922, 63034, 63010, 44213,\n",
       "          3173,  8368, 65416, 62727,  2970,  8155, 42366, 44264, 44301,\n",
       "          8091,  2341,  8939,  2333,  1741, 47255, 62236,  1705,  1607,\n",
       "         44782,  1783,  1517, 66496, 41964, 44819,  9800,  9857,  1415,\n",
       "         42003,  1830,  1887,  9520, 45770, 62362, 44678,  2210,  9128,\n",
       "          9145, 62307, 66155, 62277, 66166,  9314, 62274, 45751,  9409,\n",
       "         66174, 44183, 63043,  7739,  3454, 64474, 43743, 46359, 64608,\n",
       "         43755,  6320, 46289,  6323,  6491, 43037,  4726,  4716,  4660,\n",
       "         43875, 43790,  6163, 64427,  6104,  5465, 46325, 64079, 43583,\n",
       "          5707, 43403, 64312,  5220,  5218,  5203, 46326, 63912,  5994,\n",
       "          5147,  6085, 46532,  1398,  4619, 43887,  3777, 63190,  7436,\n",
       "          3752,  7466,  3717,  3848,  7480,  3707,  7540, 42613,  3602,\n",
       "          3455, 63116, 65266,  3974,  3995,  7305,  4550, 42910, 43893,\n",
       "          4402, 64880,  6911, 46562,  6949, 46222,  4178, 65020, 63503,\n",
       "          7179, 65030, 65033, 63590, 41926,  5546,  1237, 62030, 10802,\n",
       "           344,   590, 11255, 10776, 67137, 10232, 10362, 45109,   281,\n",
       "         61388,  1127,   999, 67272, 10039, 67168, 61998, 41633, 44945,\n",
       "            38, 41287, 45287, 41636, 11113, 45521, 61890, 41641, 10166,\n",
       "         44964, 45444, 61773, 44977, 10401, 47368, 45425,  1281,   868,\n",
       "           276, 10624, 10652, 10529, 67079, 10440, 11403, 61570, 47528,\n",
       "         41186,  1297, 61377, 10411,   203, 36212, 54863, 54553, 51006,\n",
       "         49539, 54839, 32447, 32374, 46242, 36340, 36330, 64950, 64958,\n",
       "         64965, 25230, 25295, 54590, 25268, 54801, 44820, 45422, 54533,\n",
       "         54274,  3799, 26094,   388,   394, 51128, 26020, 32172, 26220,\n",
       "         35879, 26241, 35869,  3672, 33786, 67061, 25379,  3846, 46176,\n",
       "         32367,   289, 54526, 33646, 25466, 49545, 54286, 25646,  4077,\n",
       "          4056, 25736, 36049, 25796, 45222, 45225, 24708, 32745,  4476,\n",
       "         33190, 55567, 33180, 55556,  5194, 33165, 33543, 64328, 64372,\n",
       "         33085, 43612, 36817, 23577, 33072, 33558, 64291, 64396, 64280,\n",
       "         23252, 33257, 43530, 64191, 23046, 55655, 23099, 23107, 55651,\n",
       "          5392, 33321,     4, 43606, 45327,  5301, 33206, 36970, 33050,\n",
       "         33045,  5050, 32857,  4706, 32785, 67034,  4622, 50942, 36655,\n",
       "         55039, 32650, 32620, 67197,  4529, 24567, 43892,  4501, 49337,\n",
       "         24250, 32904,  4727, 55337, 23703, 33040, 23800,  5012, 23980,\n",
       "         45416, 54954, 50875, 49233, 67276, 43799, 24103, 55276,  4733,\n",
       "         33617,  4844, 26357, 26575, 26425, 51771,  2257, 29136, 34510,\n",
       "         50174, 29206,  2224, 52816, 52772, 67332, 29344, 31296, 66735,\n",
       "         52710, 31200, 51805, 44925, 66684, 31411, 34689, 44984, 51634,\n",
       "         45787, 28462,   984, 28491, 28492, 50113, 28575, 44544, 34011,\n",
       "         28669, 28675,  2384, 34744, 34731, 28598, 34796, 31094,  1971,\n",
       "         66484, 34117, 50298, 44800, 30219, 34306, 30286, 30029, 30806,\n",
       "         30665, 52387, 66636, 52378, 52371, 66556, 45533, 34247,  1221,\n",
       "         29981, 52574, 44726, 51916, 66308, 29698, 66339,  1805, 52631,\n",
       "         52569, 66357, 29905, 52054, 66668, 30883, 44845, 29953, 52575,\n",
       "         34071, 28334, 53001, 64153,  3366, 26956, 67029, 49829, 66868,\n",
       "         35580, 49845, 26869,  3332, 33813,   614, 65362, 35314, 66858,\n",
       "         33861, 27442, 53673,  3084, 26849, 26784,  3573, 65273, 26524,\n",
       "         53984, 26543,  3438, 49758, 35673, 50631, 26675, 35691, 26708,\n",
       "         53882, 46025, 26753, 26756, 50214, 35161, 27489, 65485, 45041,\n",
       "         44456, 50517, 31648,  2662, 28043, 28050, 33900, 34893, 51530,\n",
       "         51554], dtype=int64),\n",
       "  'feature_absent_idx': array([53212, 13219, 57825, 13221, 29097, 57821, 29094, 46294, 13233,\n",
       "         57811, 29086, 46299, 57807, 57801, 29098, 13243, 57795, 13247,\n",
       "         13249, 46304, 46305, 13255, 29071, 13259, 57782, 46312, 46314,\n",
       "         13269, 13271, 57796, 57772, 13217, 13214, 13167, 57860, 29133,\n",
       "         46274, 29131, 13173, 57857, 13176, 29127, 57856, 29123, 13183,\n",
       "         29119, 57835, 57850, 13193, 29115, 29114, 57846, 29111, 13201,\n",
       "         29110, 29107, 29105, 57840, 13209, 46284, 46287, 13190, 29135,\n",
       "         13273, 57770, 57735, 13328, 13329, 57731, 57730, 46341, 13333,\n",
       "         57725, 13338, 29020, 46342, 57723, 46343, 13322, 46344, 13345,\n",
       "         13347, 29012, 57718, 57717, 29008, 57715, 29007, 46349, 29004,\n",
       "         46350, 46353, 13362, 13344, 13274, 57736, 29029, 29058, 57768,\n",
       "         13280, 57766, 46316, 57762, 46317, 13288, 13290, 13292, 13293,\n",
       "         13295, 29042, 29028, 29041, 29040, 13301, 57750, 29039, 13307,\n",
       "         29035, 13311, 29033, 57745, 29032, 57741, 13317, 46334, 57753,\n",
       "         57864, 29139, 13161, 57975, 57974, 57973, 13014, 57972, 13016,\n",
       "         29252, 57971, 46183, 13020, 29249, 46184, 46187, 57977, 57968,\n",
       "         13029, 29239, 46198, 13037, 57960, 46199, 13040, 29229, 29226,\n",
       "         57955, 57953, 29219, 13052, 13028, 46209, 57978, 29254, 58029,\n",
       "         58021, 12960, 46162, 58017, 12964, 29287, 46163, 46164, 29284,\n",
       "         12969, 12970, 12971, 46182, 12973, 58000, 46168, 12983, 57998,\n",
       "         12987, 12989, 46172, 57991, 57990, 57988, 13002, 13003, 46180,\n",
       "         58006, 29214, 29213, 46214, 29175, 57911, 57908, 57907, 57901,\n",
       "         57900, 57899, 29170, 57898, 29161, 57887, 57885, 46258, 13112,\n",
       "         29152, 29147, 13146, 29146, 13148, 13149, 46268, 13151, 57876,\n",
       "         13154, 46271, 29140, 57867, 13160, 29149, 29177, 13108, 13106,\n",
       "         13065, 29205, 46228, 57940, 29200, 57938, 57937, 57933, 29199,\n",
       "         29196, 57929, 13079, 13081, 29194, 13084, 46237, 29191, 57927,\n",
       "         46239, 57924, 13095, 13096, 29184, 13098, 46241, 13101, 57922,\n",
       "         13103, 57919, 13364, 13365, 28994, 28993, 46480, 28805, 28803,\n",
       "         46482, 46486, 13637, 13638, 46487, 46488, 57480, 46489, 13647,\n",
       "         46490, 13631, 28792, 46493, 13654, 28788, 57468, 46494, 13659,\n",
       "         28784, 28783, 46495, 28779, 28778, 28777, 13671, 28791, 13672,\n",
       "         13626, 57501, 13577, 13579, 13582, 28840, 57526, 28839, 57525,\n",
       "         46458, 57524, 46462, 57518, 57516, 13595, 57493, 57513, 28827,\n",
       "         46472, 13606, 28823, 13608, 46473, 46475, 28818, 28817, 13615,\n",
       "         57502, 28815, 13620, 57511, 28775, 13675, 28772, 57423, 13731,\n",
       "         28738, 57422, 57420, 46538, 57415, 57413, 46542, 57405, 57403,\n",
       "         28727, 28724, 13729, 57401, 46546, 57395, 28715, 57392, 57391,\n",
       "         57389, 28714, 28713, 13767, 57386, 13772, 13773, 13774, 57399,\n",
       "         46536, 57425, 13725, 57450, 28768, 28767, 57447, 28765, 13688,\n",
       "         13689, 57442, 57441, 13692, 46510, 46511, 13696, 28759, 13698,\n",
       "         46513, 13701, 46518, 13705, 57437, 28754, 57433, 57430, 57429,\n",
       "         57428, 13718, 13719, 46530, 57427, 46449, 58030, 13571, 13568,\n",
       "         46383, 13429, 57643, 57642, 57641, 13435, 28942, 46389, 13441,\n",
       "         28940, 46390, 13446, 13448, 13426, 57629, 46393, 13454, 28933,\n",
       "         57626, 28932, 28929, 28928, 13463, 28927, 46399, 13466, 13467,\n",
       "         57611, 57628, 57609, 13425, 13423, 57699, 46361, 28986, 57688,\n",
       "         28983, 57683, 28982, 28981, 28976, 57676, 57670, 57667, 57666,\n",
       "         46382, 13399, 46372, 57662, 13405, 28964, 46374, 13410, 57656,\n",
       "         46377, 13415, 57650, 28957, 28954, 13422, 57665, 28924, 46402,\n",
       "         57605, 28880, 57571, 57570, 13532, 46426, 57568, 57567, 13536,\n",
       "         57566, 46427, 46428, 13541, 46434, 28881, 46439, 28865, 46442,\n",
       "         13551, 57550, 28860, 13557, 46446, 28853, 57544, 13564, 13565,\n",
       "         13566, 46447, 28868, 13524, 28887, 13520, 13476, 46406, 57601,\n",
       "         13485, 57599, 28909, 57596, 28907, 57594, 13494, 13495, 46417,\n",
       "         57591, 13498, 28905, 28902, 28901, 28900, 28897, 13507, 28896,\n",
       "         28895, 28893, 13511, 13513, 28890, 57579, 57578, 13519, 28850,\n",
       "         12952, 12951, 58032, 58476, 12367, 12368, 29727, 12372, 29726,\n",
       "         12374, 58465, 29720, 45892, 58460, 29717, 45895, 12365, 12390,\n",
       "         29709, 29708, 29705, 29703, 45899, 58450, 29701, 29700, 45900,\n",
       "         12404, 29696, 58444, 58443, 12391, 58442, 12363, 29731, 12315,\n",
       "         58513, 12318, 29771, 45863, 45864, 45865, 29765, 45872, 58506,\n",
       "         45874, 58502, 29758, 12362, 29757, 29754, 29751, 12338, 58491,\n",
       "         29750, 58489, 12344, 58488, 12346, 29745, 45879, 12356, 29735,\n",
       "         58496, 58439, 12411, 12412, 12468, 58388, 58385, 58380, 45935,\n",
       "         12484, 29640, 58373, 45939, 12490, 12491, 12494, 12495, 58389,\n",
       "         29635, 45945, 45948, 58364, 58363, 12506, 58361, 58360, 12510,\n",
       "         58358, 12512, 58357, 29628, 58354, 58367, 29654, 29656, 29658,\n",
       "         58438, 29693, 29692, 12418, 45903, 58434, 58429, 58428, 45904,\n",
       "         12428, 12431, 29683, 58416, 58415, 58413, 58411, 29675, 45923,\n",
       "         12446, 12447, 12448, 12452, 29666, 12454, 45927, 29661, 12459,\n",
       "         12460, 45929, 12313, 29624, 29776, 12308, 29903, 29899, 58635,\n",
       "         45779, 58632, 58631, 12158, 29891, 58628, 45786, 29887, 58621,\n",
       "         29883, 12143, 29882, 58615, 29879, 12178, 29876, 29875, 12184,\n",
       "         29870, 12186, 29867, 58601, 45800, 45803, 12198, 29880, 29857,\n",
       "         12142, 29907, 12087, 45726, 45731, 45732, 29957, 29956, 58672,\n",
       "         58671, 29950, 12104, 12106, 29943, 12108, 45769, 12109, 58666,\n",
       "         45740, 45743, 58657, 29929, 45747, 45758, 29920, 45761, 29915,\n",
       "         12132, 12134, 58643, 45736, 29856, 12202, 45807, 29817, 58553,\n",
       "         29815, 29814, 45826, 58548, 12267, 29811, 29808, 45828, 12279,\n",
       "         58538, 29799, 12258, 12283, 58536, 45843, 12292, 12293, 12294,\n",
       "         45846, 45847, 12297, 45849, 29788, 58526, 58519, 29782, 58537,\n",
       "         29822, 12254, 12253, 12205, 45809, 12207, 29851, 29849, 12212,\n",
       "         12215, 29845, 12218, 58573, 12224, 58572, 58571, 12230, 29834,\n",
       "         12234, 12236, 12239, 12240, 29831, 29830, 12243, 45823, 12247,\n",
       "         29825, 58559, 45824, 12251, 12252, 45856, 13776, 29622, 45953,\n",
       "         58151, 29410, 12799, 29408, 29406, 12805, 12807, 12811, 12812,\n",
       "         12813, 46100, 29393, 29392, 58152, 58132, 29389, 29388, 12824,\n",
       "         29387, 12826, 46110, 12829, 29383, 58122, 29382, 58118, 12835,\n",
       "         29380, 58130, 29377, 29413, 58158, 29453, 46066, 58191, 46067,\n",
       "         29444, 58179, 58178, 46071, 12762, 12763, 29436, 29433, 29432,\n",
       "         29414, 12768, 12770, 12771, 46075, 12773, 29430, 12777, 29424,\n",
       "         29423, 29422, 46088, 12782, 58163, 46089, 12769, 58112, 29372,\n",
       "         58110, 12898, 29329, 12901, 29326, 46146, 58060, 29320, 58057,\n",
       "         29317, 12915, 58052, 58049, 58046, 46138, 29308, 12930, 29305,\n",
       "         29304, 29303, 58039, 46158, 58037, 46159, 58036, 12943, 58034,\n",
       "         12947, 12948, 29306, 12894, 29334, 12892, 46117, 58106, 29368,\n",
       "         12851, 12852, 12854, 12858, 46120, 46124, 12862, 58092, 58090,\n",
       "         12865, 29357, 46128, 29353, 29352, 29350, 12877, 12878, 29349,\n",
       "         12880, 46129, 46130, 29346, 58072, 29345, 46135, 29335, 58195,\n",
       "         58349, 12742, 58197, 29572, 12586, 58305, 58301, 29569, 12592,\n",
       "         45990, 12595, 12596, 12597, 12598, 58297, 45993, 45986, 58294,\n",
       "         58292, 29558, 29552, 58286, 29549, 29548, 58285, 29547, 29544,\n",
       "         29543, 58283, 58277, 58274, 45994, 46006, 12583, 12581, 29615,\n",
       "         12527, 12530, 58340, 12534, 58337, 29608, 29605, 29602, 12544,\n",
       "         29601, 12546, 58333, 58310, 12550, 29597, 45969, 12557, 12562,\n",
       "         45976, 12568, 29580, 58318, 12574, 58316, 45984, 58311, 29574,\n",
       "         45968, 46007, 12633, 12634, 29495, 12693, 29490, 12696, 46036,\n",
       "         29483, 58221, 29482, 29481, 12707, 58215, 12710, 12711, 58236,\n",
       "         46047, 12717, 58208, 58207, 46049, 12721, 29470, 12723, 29465,\n",
       "         58203, 29462, 58200, 29461, 46063, 12714, 58237, 58239, 46028,\n",
       "         46008], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_unit': {'feature_present_idx': array([29630, 20592, 12539, 32352, 13114, 57773, 34635, 57448, 12499,\n",
       "         56206, 11928, 55774, 55453, 37268, 11568, 34157, 46502, 33544,\n",
       "          4913, 58748, 32868, 59306, 32565,  3347, 32176, 32020, 60738,\n",
       "         60792, 31422, 30364, 15064, 29912,  3849, 39088, 39280, 39317,\n",
       "          7936,  7771, 45605, 48044, 48104,  8578, 48373, 49008, 44383,\n",
       "         44270, 49161,  6946, 49482, 49559, 43594, 20044, 50090, 53223,\n",
       "         11171, 53154, 40812, 52195, 52029, 15585, 51604, 41387,  5858,\n",
       "         51535,  6126, 41958,  6215, 51595, 29454, 33907, 24281, 63592,\n",
       "         23280, 62567, 66201, 66114,  2120, 23036,   319, 65970, 22637,\n",
       "         65952, 17021, 18893, 23668, 24888, 65145, 25668, 66642, 63628,\n",
       "         23977, 64225, 27005, 63796, 28111, 17664, 18147, 28387,  2386,\n",
       "         61669, 28039, 22499, 41841, 41525, 39767, 39858, 10344, 41422,\n",
       "         40322, 18475, 18654, 41078, 40850, 42506, 18385, 40940, 40230,\n",
       "         42539,  9229, 42701, 20112, 20276, 45757,  8101,  8151, 19826,\n",
       "          8261,  8306, 45418, 45182, 20306, 21061, 45047, 19484, 22475,\n",
       "         44520, 21666, 21885, 44199, 44043, 22367,  9023, 43864, 22452,\n",
       "         43145,  9387, 22462, 43018, 42941, 42874, 44396, 39483, 15739,\n",
       "         11174, 13353, 16969, 33549, 13539, 33145, 25784, 33133, 32682,\n",
       "         25944, 32551, 26021, 32528, 14129, 32344, 32327, 26105, 26620,\n",
       "         31516, 27023, 27313, 14621, 14625, 14926, 27767, 30228, 27949,\n",
       "         15604, 29513, 29366, 13281, 23779, 13275, 34039, 39425, 39334,\n",
       "         23799, 23971, 38584, 11648, 17357, 11727, 36740, 36718, 11993,\n",
       "         24833, 12073, 36129, 35949, 12161, 35854, 12471, 24920, 35084,\n",
       "         24985, 25079, 34575, 12779, 25317, 34531, 13033, 17073, 17071,\n",
       "         34012,  7863,  9181, 20012,  3855, 52936, 58278, 58406,  5472,\n",
       "         52657,  1412, 64132, 52550, 52440, 51680, 51628, 51568,  5661,\n",
       "          5785,  6018,  1229, 51162, 50984,  3705, 50977,  2455, 61530,\n",
       "          5317, 58114, 57259, 57572, 57074,  4537, 62636, 56962, 56664,\n",
       "         56392, 62762,  4614, 61462, 62803, 55472,  1941, 55238, 57810,\n",
       "         63136,  1595, 54150, 60863, 53957, 53915, 56014, 59109,  1265,\n",
       "           558,  3031,  2883, 66073, 49449, 49106,  7006, 49072,  7165,\n",
       "         47213,  7198, 61363, 48141, 61124, 47357, 47602,  2793, 60835,\n",
       "         46751,  2628, 66776, 49817,    44,  7796, 49977,  2568,  6394,\n",
       "         49911,  7783, 65933,  1022, 60288, 49611, 67257, 59732, 65097,\n",
       "         59548, 65196, 61960, 61038, 27657, 60943, 27645, 30519, 30290,\n",
       "         27228, 61840, 27466, 60947, 61317, 61752, 61175, 29355, 29065,\n",
       "         29031, 62085, 28892, 61134, 29530, 28750, 27759, 28720, 28486,\n",
       "         28187, 29781, 61736, 29995, 30088, 28029, 27954, 61740, 28615,\n",
       "         26892, 24750, 26338, 64598, 64745, 23269, 64855, 64952, 22665,\n",
       "         22566, 22538, 65389, 65831, 22447, 22414, 22048, 21673, 66320,\n",
       "         21659, 21540, 66579, 21087, 66687, 20872, 20866, 66917, 67275,\n",
       "         20220, 23329, 64532, 23503, 23530, 62349, 62405, 62772, 25530,\n",
       "         25476, 25399, 62954, 63097, 63230, 63403, 63425, 63541, 62176,\n",
       "         24848, 24519, 24476, 63635, 24322, 63895, 64003, 24268, 24143,\n",
       "         24127, 23999, 64104, 64403, 24707, 30793, 46640, 31030, 50895,\n",
       "         42866, 42811, 42768, 42660, 42163, 41995, 51168, 51194, 40906,\n",
       "         40794, 40743, 50544, 40351, 40072, 40003, 39980, 52854, 39688,\n",
       "         39636, 53188, 53197, 53596, 39315, 54066, 38893, 40283, 50155,\n",
       "         43038, 43441, 46503, 46244, 46235, 46232, 45936, 45715, 46831,\n",
       "         45556, 47390, 45421, 47535, 45419, 45242, 45194, 47813, 45001,\n",
       "         44899, 44168, 44134, 49479, 43983, 43891, 43883, 49749, 43719,\n",
       "         49808, 43505, 38892, 38728, 54498, 38398, 58209, 58238, 33884,\n",
       "         33778, 58730, 33474, 33473, 46707, 33201, 59023, 33011, 32718,\n",
       "         59203, 59375, 59380, 32458, 32368, 59919, 32285, 60091, 60268,\n",
       "         31879, 31364, 31170, 31084, 31068, 31056, 58115, 30923, 57996,\n",
       "         57910, 37423, 54596, 54817, 55459, 55773, 36455, 56143, 36423,\n",
       "         36331, 36278, 56256, 35629, 35606, 35566, 35448, 35391, 35126,\n",
       "         57416, 57702, 57759, 57787, 34489, 34414, 34389, 34317, 57888,\n",
       "         34233, 34086, 33275, 67331, 16990, 10864, 10946,  9101,  8529,\n",
       "         14345,  6287, 11242,  3490,  9892, 14217, 15868,  9682, 14182,\n",
       "         15249,  8245, 13376,  2925, 14140,  8036, 16526,  6602, 14030,\n",
       "          2718,  3889, 16674, 15380, 18044, 15616,  5585,  4708, 14790,\n",
       "          4675, 15460,  5658,  8854, 17797,  4567, 16225,  2671, 17806,\n",
       "          8857,  4742, 17871,  6019, 10437,  6145,  4348, 10728,  6170,\n",
       "          4101, 10793, 15714, 14771,  2555, 13922,  1298,  5354,  7800,\n",
       "         13683,  1094, 13680,   981,  7698,  7392,  4971, 16372, 12518,\n",
       "         12691,   756,   716,  7690,  9259, 16262,  7624,   186, 12918,\n",
       "         13139, 16234,   109,   841, 16047,  1345, 11998,  2410, 19023,\n",
       "          6689, 19114,  9656,  6769, 11750,  7970, 13805, 19312,  2103,\n",
       "         16409,  5562,  4806,  7009,  2005, 12031,  9480,  1626,  7892,\n",
       "          1446,  1429, 19317,  9154, 43657, 19964, 43328, 43532, 19896,\n",
       "          8767, 47009, 46752, 46691, 46644,  7920, 46015, 45942, 45926,\n",
       "          8773, 45897, 45082, 45081, 45019,  8542, 44627, 44611, 44516,\n",
       "          8704, 45165, 45244, 10263, 43052, 38297, 37957, 37945, 37875,\n",
       "         37457, 37414, 11665, 37041, 11747, 36602, 36434, 36394, 36297,\n",
       "         36059, 36046, 12141, 35934, 12466, 35246, 35120, 12685, 34920,\n",
       "         34871, 34717, 12778, 12801, 34443, 12863, 34084, 38566, 43096,\n",
       "         38676, 11376, 42873, 42661, 42175, 42161, 42151, 42111, 41767,\n",
       "         41734, 41688, 41679, 41571, 10072, 10076, 10104, 41308, 10117,\n",
       "         10352, 40837, 10393, 10434, 10572, 10754, 40098, 10812, 11033,\n",
       "         11127, 39603, 39462, 11208, 11477,  7661,  6530, 47360,  2848,\n",
       "         60823, 60693, 60622, 60512, 60110, 60059, 59967, 59947, 59831,\n",
       "         59342,  3416, 59272,  3578, 58975, 58800,  3778, 57154,  4464,\n",
       "          4445, 57543,  4126, 57862, 61205,  4039, 58131, 58336, 58409,\n",
       "         58528, 58602, 58710, 58117,  4519,  2503, 62066, 67205,   172,\n",
       "         66789,   279, 66439,   359, 66287,   867, 65616, 65374, 65175,\n",
       "         65151,  1040, 64706, 64597,  1174, 64333, 62191, 62206, 62299,\n",
       "          2138, 62660,  2084, 61864,  2068,  1837, 63234,  1470, 63914,\n",
       "          1418,  1330, 62935, 57003, 56990,  4571, 51667,  5589, 51517,\n",
       "         51490, 51390, 51350, 50780, 50666,  6255, 50532, 50511, 50097,\n",
       "          6326, 50003,  6348,  6472,  6543,  7568,  7506,  7334, 48279,\n",
       "          7178, 48399, 52053, 48718,  7111,  6952, 49375,  6839,  6696,\n",
       "         49615, 48846, 52199, 52258, 52354, 55416,  4776,  4758, 55546,\n",
       "         55596, 55647, 55340, 55662, 55677, 55720, 55729, 55840, 56217,\n",
       "         56379, 55663, 47346, 55232, 55059,  5540,  5526, 52590, 52703,\n",
       "         52745, 53057, 55123,  5374, 53889, 54320, 54391,  4824, 55017,\n",
       "         55042,  5299, 33626,     8, 24293, 23808, 23920, 31999, 23939,\n",
       "         32013, 17824, 27928, 19448, 27822, 32279, 21567, 67321, 16495,\n",
       "         24473, 21531, 13949, 21361, 21206, 16554, 21142, 32673, 17223,\n",
       "         26740, 24896, 24903, 31794, 13790, 31759, 14403, 29884, 15385,\n",
       "         15241, 29486, 29473, 22964, 29469, 30295, 30347, 29390, 23106,\n",
       "         29082, 14874, 18460, 31033, 14747, 28730, 19210, 28670, 14433,\n",
       "         23580, 31472, 16007, 28401, 28272, 28176, 20877, 29919, 19625,\n",
       "         20136, 33012, 26568, 13517, 26542, 20494, 16992, 16796, 19818,\n",
       "         26137, 20155, 19835, 17192, 13550, 26579, 25286, 13594, 16866,\n",
       "         25284, 25531, 24917, 32951, 20856, 16920, 32939, 32947, 13785,\n",
       "         15905, 23493, 45670,  8905,  8170, 22935, 26095,  8938,  8879,\n",
       "         58353,  2943, 45563, 46074,  3832,  9099, 58250, 25559, 18168,\n",
       "         15343, 43723, 46483, 46583, 46612,  4830, 18189,  3594, 52214,\n",
       "         54076,  8739, 53844, 53894, 44487, 44491,  2961, 60040,  5180,\n",
       "         29583, 15736, 15786,  5356, 44971, 58761, 29091,  3261, 59503,\n",
       "         51781], dtype=int64),\n",
       "  'feature_absent_idx': array([53040, 59783, 53945, 10308, 10309, 53946, 44663, 59780, 59779,\n",
       "         48952, 30881, 48951, 10304, 48950, 10321, 18204, 30875, 59771,\n",
       "         30874, 10326, 48946, 30872, 59767, 10330, 30871, 59774, 44671,\n",
       "         30889, 44659, 44642, 53939, 53941, 48955, 44645, 10280, 10281,\n",
       "         10282, 30901, 18218, 59803, 59786, 30898, 59797, 10289, 59796,\n",
       "         59795, 53942, 24951, 59793, 53943, 18213, 10299, 10300, 59799,\n",
       "         18202, 53950, 59764, 30843, 59744, 53959, 24971, 30840, 10376,\n",
       "         10377, 48940, 59739, 59738, 30837, 10370, 59737, 59736, 59734,\n",
       "         18185, 10388, 30834, 10390, 10391, 10392, 10394, 10395, 53962,\n",
       "         10383, 30844, 24966, 10366, 10336, 30865, 44679, 10339, 30861,\n",
       "         44686, 10342, 10343, 24962, 10346, 44687, 53952, 10349, 59756,\n",
       "         59755, 59754, 10355, 53953, 10357, 30851, 18195, 59749, 30849,\n",
       "         10363, 53956, 30907, 24974, 59808, 10271, 44597, 10177, 59870,\n",
       "         18255, 59868, 18254, 44600, 59866, 18253, 59864, 30968, 53913,\n",
       "         10187, 10189, 10190, 10191, 30966, 53916, 48973, 44607, 24930,\n",
       "         59853, 59852, 44610, 30967, 30957, 30976, 48978, 18267, 48983,\n",
       "         44571, 10150, 30997, 24913, 10153, 24914, 59892, 44577, 24916,\n",
       "         24924, 44580, 44583, 44585, 59885, 44586, 44587, 59883, 30983,\n",
       "         53910, 59877, 44588, 30979, 24918, 30955, 10203, 30953, 10239,\n",
       "         48963, 44628, 10242, 30926, 53929, 18232, 44630, 44632, 10249,\n",
       "         10250, 30930, 59825, 30917, 44635, 59821, 10257, 59820, 59817,\n",
       "         53933, 18226, 18223, 10268, 59810, 44634, 53927, 59827, 59828,\n",
       "         10205, 18247, 30949, 24933, 59846, 44616, 10212, 59845, 59843,\n",
       "         10218, 30941, 10220, 59840, 30939, 10224, 48965, 48964, 59837,\n",
       "         10228, 44621, 18239, 10231, 24940, 18237, 18236, 59809, 44705,\n",
       "         59725, 53964, 10565, 44793, 18110, 18109, 18108, 18107, 44795,\n",
       "         44797, 10575, 10576, 18105, 25031, 10578, 44801, 25033, 48893,\n",
       "         48891, 10584, 25037, 30679, 59573, 30678, 10589, 54024, 10579,\n",
       "         59570, 30698, 30700, 30719, 25023, 59603, 25024, 30716, 54013,\n",
       "         10540, 18119, 54015, 10544, 54016, 18112, 10547, 10549, 59594,\n",
       "         30706, 30705, 59593, 59592, 59590, 59587, 10558, 48896, 30701,\n",
       "         18115, 48888, 18096, 48886, 25049, 10630, 44829, 10632, 10633,\n",
       "         10634, 30643, 30642, 10638, 44830, 10641, 18084, 10642, 10645,\n",
       "         10646, 30637, 59537, 10649, 30636, 30635, 30633, 10654, 18077,\n",
       "         59529, 44834, 10626, 59544, 59547, 44811, 30670, 25042, 30668,\n",
       "         59565, 10602, 59564, 25043, 44812, 59560, 30664, 30663, 54031,\n",
       "         10611, 30661, 30660, 18090, 59555, 54032, 44822, 10618, 18088,\n",
       "         30651, 44825, 18086, 44777, 54010, 59609, 54009, 30796, 30795,\n",
       "         24986, 30792, 10441, 10442, 44737, 53975, 24991, 30786, 44739,\n",
       "         30797, 30784, 10451, 59678, 30780, 59676, 18160, 59673, 30778,\n",
       "         59670, 59668, 59665, 30776, 24992, 59691, 48930, 59698, 10402,\n",
       "         44714, 30826, 18180, 30823, 10408, 24978, 18176, 48936, 44719,\n",
       "         30816, 53966, 59714, 53967, 59710, 30810, 44724, 53969, 44725,\n",
       "         53970, 44730, 30804, 30803, 30801, 44734, 44749, 24910, 24998,\n",
       "         10468, 10502, 10503, 59635, 18137, 48908, 25013, 30737, 48906,\n",
       "         10511, 30735, 30734, 59636, 10514, 30732, 25016, 10518, 10522,\n",
       "         25022, 59618, 18127, 59612, 10527, 18126, 44775, 48905, 30742,\n",
       "         48911, 59638, 30768, 53987, 53988, 18152, 10474, 18151, 30762,\n",
       "         30760, 10478, 30759, 53990, 18149, 30756, 30755, 48919, 53993,\n",
       "         18143, 59643, 10490, 59641, 53994, 44764, 59639, 10496, 25005,\n",
       "         18156, 10658, 31005, 31007,  9786,  9787, 49029, 18389, 53800,\n",
       "          9792, 24827,  9795, 60168, 18383, 31258, 18391, 31257, 60164,\n",
       "         60160, 31254,  9804, 53808, 44372, 31251,  9808, 31250, 53809,\n",
       "          9811, 24828,  9812,  9784,  9782,  9755, 60191, 31282, 44361,\n",
       "          9759, 60189, 60188, 31279, 31277,  9766, 31276, 18392, 53792,\n",
       "          9770,  9771, 31272, 60183, 53795, 44363,  9777,  9778, 60180,\n",
       "          9780, 60178, 31274, 60154, 53810, 44376,  9848, 60128, 24835,\n",
       "         60124, 24838, 53820, 31217,  9856, 44405, 44410, 31211, 53816,\n",
       "         31210, 18361, 44411, 53829, 49021,  9870, 31201, 60107, 53831,\n",
       "         60104, 18355, 44418, 60113,  9846,  9845, 60129,  9816, 53811,\n",
       "         31243, 31242,  9820, 44380, 31240,  9823, 18376,  9826, 53814,\n",
       "         24834, 18371, 60143, 60140, 60139,  9835, 60138, 31230, 31229,\n",
       "         31228, 18370, 31224, 18369, 60130, 53788, 60100,  9753, 18400,\n",
       "         60275, 60274, 60270, 44303, 31355, 44305, 49045,  9666,  9667,\n",
       "         49042, 24797, 31360, 31346,  9672, 60258, 44311, 60256, 44312,\n",
       "         44313, 24800, 60253, 44317, 60249, 60248, 60260, 18426, 60280,\n",
       "         24786, 31386, 53741,  9623, 53743, 60300, 49059,  9628, 18451,\n",
       "         31379, 44295, 24774, 53754, 60292, 24776, 24777, 24778, 24779,\n",
       "         60287,  9640,  9641, 24780, 49053, 24784, 31367,  9634, 53771,\n",
       "          9689, 44320,  9724, 44339, 49037,  9727, 44340, 24814, 31302,\n",
       "         31301, 44347, 53780, 60210, 44337, 60209, 60206, 18402, 53786,\n",
       "         31293,  9743, 44350,  9745, 31291, 31289, 44353,  9749, 53783,\n",
       "         53777,  9721, 49038, 60243, 24803, 18423, 31328, 18422, 24804,\n",
       "         18420, 60238, 53772, 60235,  9702, 44331, 44333, 24808,  9709,\n",
       "          9710, 60228, 44335, 24810,  9714,  9715, 18412, 31312, 24811,\n",
       "          9719, 24820, 53832, 24846, 31194, 59963, 31055, 53885, 31051,\n",
       "         10055, 59960, 53886, 59959, 59958, 59956, 53890, 59964, 44531,\n",
       "         10064, 24893, 59953, 53891, 59950, 44543, 10071, 10073, 31040,\n",
       "         31039, 59945, 44537, 10080, 44525, 18294, 18304, 31076, 10015,\n",
       "         59987, 10017, 59986, 10019, 59984, 10024, 44514, 31069, 10046,\n",
       "         48990, 48989, 53880, 10034, 31060, 31059, 10038, 59971, 10040,\n",
       "         10041, 10042, 10043, 44521, 59944, 59943, 10083, 24901, 59917,\n",
       "         24904, 10119, 59915, 24906, 59914, 53900, 31013, 10125, 59911,\n",
       "         59920, 10127, 59909, 10130, 10132, 53902, 44567, 24908, 59904,\n",
       "         10137, 59903, 10139, 59901, 44565, 59921, 31020, 59922, 59942,\n",
       "         10085, 31034, 10087, 53892, 18283, 31028, 59936, 59935, 44553,\n",
       "         59934, 59933, 53893, 10097, 24897, 10099, 59930, 53896, 10102,\n",
       "         24898, 10105, 24899, 10107, 10108, 31021, 31078, 44510, 24880,\n",
       "         24879, 31161,  9918, 31157, 60065, 18332, 31151, 18330, 60056,\n",
       "         31148, 53850, 31146, 18334, 60053, 53851, 53853, 44459, 31140,\n",
       "         60047, 44461, 53854, 60041, 60039,  9942, 18324, 31145,  9915,\n",
       "         18336, 18337, 24849, 44425, 60093, 24853, 49017, 44431,  9891,\n",
       "         53837, 60083, 60082,  9897, 44432, 18344, 44438, 31178, 31177,\n",
       "         44439, 18343, 49016, 53839, 31172, 60073, 24856, 24857, 24858,\n",
       "         60038, 59899, 44464, 44465,  9982, 31109, 44484, 60006,  9987,\n",
       "          9988, 31106, 49005, 31103, 44488, 31101, 44481,  9994, 31092,\n",
       "         31090, 53868, 10001, 59996, 10003, 10004, 59995, 24877, 59993,\n",
       "         59992, 49000,  9980, 31112,  9978, 60031, 49010, 31129,  9953,\n",
       "         60028, 31128, 31127, 53857, 44472, 60024, 24868,  9963,  9964,\n",
       "         60020, 31120, 44475, 60018, 31117, 44476, 18315,  9973, 60015,\n",
       "          9975, 60013, 24871, 31134, 10659, 54037, 30627, 45243, 17792,\n",
       "         59006, 11390, 30071, 11392, 45247, 59003, 45248, 45249, 11397,\n",
       "         25269, 30067, 11400, 17790, 30064, 45250, 45252, 45253, 25272,\n",
       "         58992, 45255, 11409, 11410, 54251, 17788, 45239, 59016, 54239,\n",
       "         11350, 11352, 11353, 11354, 11355, 48740, 59032, 30097, 11361,\n",
       "         45232, 45237, 11363, 11366, 45233, 54244, 54245, 11371, 30087,\n",
       "         30086, 17800, 17799, 45236, 11378, 54241, 45258, 25274, 58987,\n",
       "         11447, 30033, 17779, 48731, 48730, 58974, 48728, 17775, 11455,\n",
       "         45292, 30024, 45282, 30023, 17774, 54260, 11462, 30020, 17772,\n",
       "         11465, 54261, 48727, 45299, 17769, 25283, 11459, 30035, 30036,\n",
       "         45281, 30054, 11417, 11419, 30052, 45266, 11422, 11423, 17785,\n",
       "         45271], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_wiki': {'feature_present_idx': [],\n",
       "  'feature_absent_idx': array([], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 0\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 0\n",
       "  })}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddab88",
   "metadata": {},
   "source": [
    "## Transform Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6c29574",
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklist = [\n",
    "    sibyl.transformations.text.emoji.emojify.Emojify,\n",
    "    sibyl.transformations.text.emoji.emojify.AddPositiveEmoji,\n",
    "    sibyl.transformations.text.emoji.emojify.AddNegativeEmoji,\n",
    "    sibyl.transformations.text.emoji.demojify.Demojify,\n",
    "    sibyl.transformations.text.emoji.demojify.RemovePositiveEmoji,\n",
    "    sibyl.transformations.text.emoji.demojify.RemoveNegativeEmoji,\n",
    "    sibyl.transformations.text.emoji.emojify.AddPositiveEmoji,\n",
    "    sibyl.transformations.text.emoji.emojify.AddNegativeEmoji,\n",
    "    sibyl.transformations.text.insertion.sentiment_phrase.InsertPositivePhrase,\n",
    "    sibyl.transformations.text.insertion.sentiment_phrase.InsertNegativePhrase,\n",
    "    sibyl.transformations.text.links.add_sentiment_link.AddPositiveLink,\n",
    "    sibyl.transformations.text.links.add_sentiment_link.AddNegativeLink,\n",
    "    sibyl.transformations.text.links.import_link_text.ImportLinkText,\n",
    "    sibyl.transformations.text.negation.add_negation.AddNegation,\n",
    "    sibyl.transformations.text.negation.remove_negation.RemoveNegation,\n",
    "    sibyl.transformations.text.word_swap.change_synse.ChangeAntonym,\n",
    "    sibyl.transformations.text.mixture.concept_mix.ConceptMix,\n",
    "    sibyl.transformations.text.mixture.text_mix.TextMix,\n",
    "    sibyl.transformations.text.mixture.text_mix.SentMix,\n",
    "    sibyl.transformations.text.mixture.text_mix.WordMix,\n",
    "    sibyl.transformations.text.generative.concept2sentence.Concept2Sentence\n",
    "]\n",
    "sibyl_transforms = [t for t in sibyl.TRANSFORMATIONS if t not in blacklist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8374fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-23e9558c4a33dddc.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-4506aec84247c6cb.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-17500acb143a56d3.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-35ddb982460573ac.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-d714243b45b8f28a.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-10a175941082c2bf.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-031a8879e8aeaa6e.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-37ebbd3f73ba4c96.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Fabrice\\.cache\\huggingface\\datasets\\glue\\sst2\\1.0.0\\dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad\\cache-e5416741dbcc910e.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "678487fe7bf14b7bab440002d1af0037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "438e5c78a490426688a17736654fe44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c749cda65f514091b3608ca05c1b989d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36fe5a3688184b09b76f0ceedec59d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bdeb3f58e94f8595a1e89ff67ac890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba6e2eecc754b929e7aab827e38b11b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923ba1595b02404aa1aae947ddddad2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0771aede542e407f8f0de78d783919ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb859a1023e42dabfae43e913871430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff41341c480243f89919b6e814576491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc81e3edf004562adbd23986ffd9d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83797456931246fdae0b8692de1df341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c844132bcaed48658c15a4eb81f7bb25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c074f962c547abbedc1a78ef4cad9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08285e3e816e44ffb2de98e13b472f3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c31f447ececa4e7eb9b2e5472db286bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efffd3c1d83046698250c5ec1a1bd298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59eacbb478d404192df108869ab4843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ac46aaacf042b3abb636b0cdb2db47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ba58ec19204861862cdb4453f6dde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3617660ed89f459f918411e33b9041c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c8a42ed3f294a6aa6233e17239442a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e370fa84a64d413da07113e94bb678cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40d9d0c26504c9db83835bb49eb97b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41537b3716d04a149e9cbedd4263e740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16714fd9a6540679f70bd18d3f2643f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78579fdeb7a46ac85e665f5fa2edda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72070cd30e4c4c2e9efc79b9c789a4bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c589d252614170b7ab4e498dfaaad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5322fdf0004b455b8b755f83a98760c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d3f95b727245f9843331c829558ce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca86afcd2a664a34b7ed7f02b7a4c3a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f0d91885de45dcb02983647c35e680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3815b61566c4687988ce68c57d6cfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5fe50c3de44ad995726b36126804fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76697105858741e186ae48a24b3566f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ac6dbcccf9a480781b9d836cd8e7597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c99ba901f394f0c8fd80cef1e0349d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa64d8a1bd314034a70d48baca29bbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9b8c8c71f69413d8261f2386189c69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2949299858314a8d8faeac9f150e514c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92085baecf9463dac18ab8df3d72617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6736c330229345439e6254c878c0945e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ada4cb9afcf453bbd29a9046f60f4e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67443c627d94bf386a51c004e693c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0043553e3a4143a282b5e54f80b4b08a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64a857351774d3aa1afdfb795df5045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec6585e087c4dfda9014f8f3f34f672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0176f790c34e9a9fa60b3f69e1a394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a786f36c0a44380b18b4b3fe4418e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0322b5d0db5d43929c7efa6cd64ad0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be88b1071954fec818b7e6561ef3ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467cbeeda7734f9e96644b4349d986e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe87a5102114b89970888f3f9da0dbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1f9f7a5a92246df9e625a6a917cf3c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7720b4129247f8b0d1741dd0884cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e767202c03374ba6a6b60105535e0161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7de9b517214e3b861cc13687e20433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4734e20c033242b2bdec7c1a7849ec99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da51bdc71b9e463f8197d695107fcfc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60d0171400b6487e8d971e0b38d883be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a9e1eed3189427398adc61e5c52a68f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2944c41c374d50a225729bbfee682b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4c8a74db4f46f38baf18a386635f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11271571ca1447d9a970a4cb9f42b97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc00ba13b65b472cb4e94275cc8294e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a2f8e56f2584b3abef64bddd76e8e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8497845ef74a3b9c0206ca48b62f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed331b9dfde43c58c1cf7328a578517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f43c9fb0fe54a449fd3debd497a355c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dd0d52ffd14a959eeda6961bc7d210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fff6379322a4b8b837b270dbabf977e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae38bb796d6413d8c1d99112467584d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33d600bfdfd740849bcea5f72ae8bab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff0fb269c6a480f96d2a14745f8d152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9ebb9285914a1aacb6954e7e543bb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1154c9f416042d99731537d0d8c15c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1821ba1b8b1942df99f1e0490afc3073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49afd3dcf9d34085957bd26eb2f0732c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8364565bdbd4b1f9c2ed4499d0b3f21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97fcec77b3345b0b353a5c6933d495e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84f7360a2a174074910f0072bdb5dbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78dfc7f956184f82abef7344206ad898",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fddd4c19641a4c21aec2c76ea4623d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d709ee189702414897e42fc930ca9afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930f81f9e195445e9a74e573d89bf7be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b767680a343441e89d8f1e4e0f55c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593ca793411f4154853d1a33fd2cf380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca62d1865644680a78275ea24b200e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dbdb55f02d849c99531c2002d44433d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f32287dea941e4b2c1fb2b5c06b84e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075e1230671147ddb35aba992e601ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9896e8d4021453aadd38e9d6d3c28b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcebb689654457a93a3a0eec87c4438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf31bca51d3b4a47964cfd29831eba89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51f3ca9bde664166a3ebd5fe62c77c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55e676fcdeec4d0a83a81f5a9643b379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ac447a5cba4436b5ca2bfcda1d9740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a60fe8db3d4c4fab5b82839e4f38c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85f618f77a44f798d4e318ab8dbeaea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88470b314a14d97975d12b920bcebd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3049d6cb648f43fcae14ec4b85c4a23b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8e7275809649c89b105d7e2167b738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369dfa497a9d4421ad06a5e900d56161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1470f374404a18957afe8669f6dcbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e2bb53489846adb2774b530cfdd368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afe143da45e4a7985394d3ddffc5069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3393ada5ae724cbfb5853e60970f1628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e908b46182c4577bf98216af8488654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c29a857ff9fc4543a45e5508a8794091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5194b22939a74837af99f4be1c4967d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222116e5e93947b7bac6646a759775f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc143e638a848ffae6502bd06161d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b003c7c9d65c41ac918cdcbdcaf391ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a98a94409342d59e3dfd70581ef157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff5486e3759442a9ec29b912c512673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f87f4bb4f784a3fa4b9e3ba24c97b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ba4a236d0d4be2a614289c30f4f4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa7498e43ba4922a298fc128312b27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a908f28c9648c6a7572e194215c5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccdccceac24748a0b3b2cab2c9b7a7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840fdc70dc404f74827954b4019c61f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff1b897ad994c55ba2d6456b6584835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57bf1746919443fea2693c9fbb05b698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8fd270f02ad4199825c3dbbfa626352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89c06519c214992b989d9891faa7ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c347d44c8c004bf8aa71bcc39762428b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3da2b813afe4d77b5e33900cd7ea2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717fc8fc781c423dad11d215d28a71b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65c2a8da5f04efbacba9a93430b2119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f50e45bd96d04dfc86a7de657eac39da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5eca45c9ae47808a075c309ae9b643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042241159b4742769676c548b3d35523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947ad2b50bd64d21bbbb3a361b9a25a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b820ba06a84d909bca5ce50b71115d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2827012fdc624c05ac6c0f1199e78352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4782f8e52c884989a7b9a13431ea47ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed68463e83b4f648896d72bb7f54d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939d42b7a58c4482bc9e215aa4cf49de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8367d1a3a2884cef8da57240584a143c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976c303615e14dc4ac5995ff015ad524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46058fca964e4253a64df6021eec09b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b45f9cc32f4d9eb27d1390e3138fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e58281362948f5bb72bc53467796e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d1ce948e33471ea9968a8644099d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b439a796260841f9949e920c4bcbabf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a44edb0c1d4474db8f9683fddff3a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc3560ea0394cf7993752c9e435cd42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ef43d6cf86448f8c4f1338f3f76b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e46e9352484727961339d9d930a980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2142b64d5f54449aa3317e5198240258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a3375962294890aa54f7fbb34e2319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2eba0f2e234103a4d24fc226125dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43cdb66c197d490dbccf14253339ea62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd95d29466514e8bbfdc193a70f3a181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d59b5b8bf9c4cb7ae7f0558542e8c7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aace3d55d9474d249d6944c325709255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c40be41328a4cbd9e8be794f69d8752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48222afb628d4b51bcb793d4056d6ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a7f729dd3d4cc5bad13627ec543f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4beda8efa34ba586b21c43a9a5e732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66f121d739a43799dc895ead4c8c59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b694000ee9dd4865aaf3db8f54c83d27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e79e76626d24dd281a10dc224dab2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6d60feaff24e7c88240665160937d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09748af4bbbe487889cd69cb2ab8b333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c1eacface04c7cafcc50041a5a2dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92c1c8e8a164c989a1342434d64b348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a0e6125d724e6baa49d99d646b0af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645306bf59764f44831ac64a690566f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9eed2a2fab41faac4edbdb6c136fbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3664e49967d4920aca39d4f2dd81c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae43add721d4fcb8e68bf7a15c3c32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eae5dd17aa774977ad931a4da7861c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60905d6cf1454b858048db60d7ef22aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df01dccd9944472baf685172c522df48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35ec285dee6947fb8cb7660a652e7849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea67b1618534be3850584594cd9507e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002844598b2e474eacbb9667e406c5bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40ac31d767b04af8913e4a1e46cb2bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd0bd9b29c64977b43764a3bd34c882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be5a618a6864559be7bed7f77b80882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233f96690d4f40d69ad9e93c735dd816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1663feb64c46609df95958fe1aa847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a10a02c6eb94e1890962f5b0792f2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd24d932b0ea4795bb07248bd8631163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daec46f6a465401f9ee18881d1a421ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290747d7834146ea9e0d8a29b94ae45f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a3d5d9945941e6beedccd8770f221f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f705a8076da4c64924d3cbd297aca93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c4fff9826114592998946097f16dfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8507173a9f4a54a635871df9188695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7b46dee760048c48a5ddc46106b97ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142b74e547dd4973ac7784fa1df925a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca3b02acf8b4d46bf664487c5d6a7cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6268c39ce35b43808823b38c3335055b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ecc4273dc38455d853c35d81a4d82ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc8e1cfe806489d857e8d1e27a9a002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223f6812f58c4713acb65bf521d7f7ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e6afeb7bdff472d840d45985c32ebe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264766e417ad4132b59a70e6e2f08976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1047c08582cf4477aee8fc8b363ca31b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275ccd0e25214b6fa13b76238482c934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89a15559296491ea4c465029b91be7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c64526cc93d400d9cbe20ccf0049a53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee0bc557a6e5436a8fda6bc0ac0cb0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5895fba0ca7047b99f5629d6498c5197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08286ab6c3164ebfb0459d81dbe5cbd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0383c961b0949cfa2ad7fdd0367b131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f9c19acd73487bac0f2388d747b318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09da44505827493f92e08fe83bdf54d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2cc488d1b2402da5af66def735aff2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8000394a3c41fa8f1a624772299136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f669f4573cd34655b8b96f2cbc2b8368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20161bf4ddc048e8b6aa0385811fae25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82a8f13fa75458ca995e2a8bcc94f52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e92c3023eb44eb941bf267f8ae37b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c212d90d4148918a9502da82788978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26f0db34b0984740a5780f0ffd595025",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138e5810bc4945d3a8c31cc9e132b62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87561243cfc04b80abb48f1ea9d2b413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b925f3b9fafa421c8568565bf45aca87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ef5fe2316646e0bb8d718910a79133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a97f92fe106d4e0b8962baf0195817cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e33495e08a34cdf9cc8ad7522a1983d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a132df0eb7e44b893d9ed68b0fd1e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3333c2f492d48b9b0fdeb05c609a7d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8af3e00eca4f38a611a875e6da2855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158877c4562a4f268432fb521535c715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98f85876b2d46cdaeec297cece51936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112daf25f22849e88cd8f8f51eece172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/71 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06f9712a7874afe9e29a1a93634f98e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a477d1c914e4ca7973ff4ec256223dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4b91f90b184895bd6da99961b31dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2abc7b0799244564877dc373f8094392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8d2da03c9914187bfa4434c36da11ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8092e022a442459f190608047eb7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183540a7659149a1b7bdfbd81e7e915f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d256e44293964965b218fece092e4b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc91862ed042dfa4ebf416b7216f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca848343fc647179f3ecc6ab48ae507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d05ee0065f248e0a3c553be1d3b24fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70bb2ac80674c418541622736958203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa85883c0ae9493b8ca1ceb8cb473211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f06b0c7a5042a8ba21da9c406db6eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0faad0becbc443ba066687254d39225",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2607654945964d0585b9d0d388554bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d8ff77e49e4b1ead0536c9accf67be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439b8928745543d1926d07b21e7b66b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f21ef6e3c245b6844b26e462c637c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0bacf0d3924135be298883ee1059e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4024e087f8634f63aad38d58cc02c1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db153f09eac47e29bc26b7adc1b7fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a93e3ead40294cceaa1e053e36049097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41c62d6eadc4d3395767d5a171875ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6ba275d28e4bae9e4ffe1d4d47fae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e51b0738ae5494fb65c31ec4722554e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380f67f33f894a4297305fed8259f64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "253e682b56b44fb2841aeda5ce5f7d48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45999b6260f74000a77a05920f8a2f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3e7310b81742d4a3cf4161741f77bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa3c0b221ec4aac8bcb1d0be6b0d01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238cc3e32ef94e138952aead3e9c9017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1b868b52784174b9e2c2053bf0ca0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b81a41b6615f44e898268996d8941909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc104ec8cf84773b37343fe1736b052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da47b568468e4ef7949513c5514361c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffd7ec6613a4956ad7d3d0de58583ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a248ca68afa4ebbb680749a56e16bc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81fe026594642519964131e8c0fe939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a53b73e03ab408cae8f26b68a422907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1076f95e79444d28929d47ed710a63d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6bb1df400d44d408e62b148337125a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be45309d60e74670b765bf4a62d28ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd94e202e4d64fef8c718b3d6fe9a7ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9ad56a845884aaa976100e73346b152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50613d50b5804a25bf51317d09b2ce8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3487213771664b4d897da3db2a2f6497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001f7ed04c974df0b8fd54a55ee9b537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7551d851754c4ba227ab9fb7b24a77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6771fbd1188e4b919f5b0739a8dcae3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb5f30c1ef843ea90d941f3616f6432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb14e7ea2194a41a59944cf09034527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940d56dfa7ef4f7097779fcf7cc55695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe3cbb41cbc4a0288c21f30691a05b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfb772e021c473988790650c8e8ab61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2b2b418966f4044820fb667e1227369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3290271fa4a44addaa73eab218945f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a7617e4b2e45d7b52fc813dab72448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e6f80bb4fd446fa32addb3c42dfd35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43676beb2a3b45728bbecfb6b28aafb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfd06996729434f924686f9828a06e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74c054159ad415bbc1256b3b263f88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950650ac30294e33914d6f84acb93993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad4ab4233f74fee8088a00c43dd5faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f221ab0c764c969a0c54172ad40a9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7991b9962b9946fab7db33f390f0a19c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff490ec599be4c458b0a351c66a3606b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d852b30caf54c52831a973a0685d6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cde4467662ce471c809e72b9125db1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6943e8e6878490aad27724c67c7a6ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08f966924d24181a6765965e84f488f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7216b50e580a48d0a0ec7968580b677e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121a883cd17640a587bd33f0207a5b50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74e00825f8e4b3dbd8daf8422d9e8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f091f6e50f84ddea9dbc662b0ac6f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a04e9d097b402da56d4888de19aaaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a6d513786d4813a115c9296d93fd49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31098779638d4b9d99778ab7e621bbd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f43eb768c09400d90c6e1b7fdfe010d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1650e744fc984335a1659c2659fde731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96b376d21551482cbb8b1ea05bd691cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38f8be7c2bd4c65b1bb0c9a810298d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a621d65154549b699505470185f63df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f07b3bdef07f440faaddf53c8d27ab0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4d08a102cb4637bdf4cc99cc6910cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998a2b842c234ec69b3674e4a6f73d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45b5ce0da36473f9361b8fcf34edf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e0b0263127481e9274da70ebae8fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aaea77408da4cda859c2a8f3f758f95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5ee23ad7044d618b6f73669ba21fc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "634c14a160214192a9bef3e9fd436b36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05439172bae4c939ae2beef7cf99674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6297c48a876b4343a3a8a088cff28f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf187d2444246bbb5b9dea8537cc06b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946b89b50616455498389f699c4bbd5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1259464babcc4ca9956c7b27fe84df33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25309ac4a0204f358e3da32360e12816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab9ebb632d34aa09fce677ffed84088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798c6d084be14b93b543f670a7b126b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ce69ef61894624b1d7639242d0eedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef668645478744f890cf8a42e48b98d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adfc486740174acda3131513dabcc108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b528285ffe14e1193ab5cb7d9154359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1053334c4a3b4dff9473f54408f8b77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6ead20ee3e5476293f7c9f248d86bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb33cafd680847e1a7927d0f7f666dfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823f3c8c78054a45a04bc57679d0d9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d8ec4565dd946cb9d6ceb91c5414bca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d945f365390420eb9b206fbd8640416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4337d0093e1e41039e05c87194fafff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54ce19fac22d4d02b6613b9449320a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946bb82e35fd4caba4c0cb42c5bf8d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fdc480858a4995893b44fbde2b9217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255deab4575c4390b6cbdf4accd5be03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a33eb85c7ef4a75a9bcab9e6a35aa5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1f8fee3d0c4262842c153ef94ef5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04b3c2746484e03aa31a974be8f8dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2968807b3748cd9da367cca2c54796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73565a2ab1be49a583d5944039c69f39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665e032b4db64eb9be171ee025f5726e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e10e5d9beed442738665e8ffaf07dc9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a98805ef7464b339d85cf152947946a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f9e83c0e6e4d2aaefa69ffe2d2bffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550019370c744ff69315eadc1e42c1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7921a64db704377b9f57f63fd750875",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ce4d3a70dfc4eb28e4c0b1986c0531e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2ec9a29d9c485cbd958c3e32cce8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e46c7cb2e74fc2a83fa2f25281c39d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a15b9915ab4b5a8f6dfb1db764ae17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0eab50a49864ed587b24ae0800f4672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81b662e8f674c89908b4e6beb499414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c515bb16334c7eb38532c458f7cb0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95859461042f44a79cc9a9ae200b7d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a99a7d24d1ca4cb8a150868e51e01d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e296a1b37dda4d21baa39aaead33c8a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f96027d8511d4c77a84b0d15c6be469c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b2c341b350e406085d30d1f9bfb1a04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9bcd57f7a7a47acb9c948d0bb994fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9103f3264ae84548979b5753854ec268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c729ed327c314535a8c13bc073b26d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a9046bb80b54517afe424efb6d536b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5e00de40564595a93b1597a24f6b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f7bc8faaf749569ba9ffa2364f40f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcce971804a84ecdad59ef081d4c0b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96d178540744205b653aea16d12db80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab5dbb22f88645d18ff10c4017a206bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e13ca95162349778cea33db86264e59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e786aab327440bab699ed6d5e798163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79fe1d25626a49a5814118e3b2d644ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e72397965e4b94a17bebfa88790e8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e624a2987245448c3478a8f277eeda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebb693aa2fa4ba5801fd3c56c595b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c9dde58e67a44ad85c0d996e5fde816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "998cd601e57c4476bec1c03706ae77b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de8a9f4b30443c9852e7123cb1de460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bfa8e6a44ae4258a18fd3a2062a8b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023c06079f6e4270a11ab9a562723e3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0065b5620ae84ca189fe8905c8285d66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b452814834904bba825d7585d036f5a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb302e17537b4487a702ad6b2e0a5088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e288183964c54c209ee81b28f5718f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e31fc86c33449c88a53554f69362df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa09f700bea49ab89947367bf9e2f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffeb4d2d52247ceb3bae713e24800bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6adbfaffb3174cc78028d582ff0c116e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62543c185cad436899dbf5fe0140cbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3a163efa534a9d9961bbc609b8cad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2e080a39e74ca0b9a63d7a97168c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a31e70c5bf4247afd7be4080b90769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8baff0244dea4bb88daac596db765238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f4bbb0fae840ce969c1dbbe64bcaf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "098677d7fe7b4b00aedd73814c00762a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8954c9e47cc949f1907b98df65b549b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5ee47bfc2c4b1bb581b002c9cd6d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c835b74cc1a94d62b0f91e8ba30ad24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85387cf2c67041ea9db362051ee5c1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b374b8391d9b4bd88527ba89d17fcee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6ba41b94bf44c8bcc8d8a36c110c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1632338f7c42e0b480d4a431700adf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c44a8cae24b4533ae9b21cfb238d843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3ef4da09d74c72b0cb89002dee2804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac0429f89534dbeb1add760ae538139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a375ae12fee4207a9caedaa50b39759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2bfa629f770498ebbb994d9a4b9ccbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0716e79f91f4b749373ff7672b736f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8ddfa24ed244cdbd50586cfdbd2642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa421d4364d4ceea933fd02c4e2c849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942e80153c2b40ef9fe8ee33b115e20a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed8277078cf417fb05aaac5dbbe3885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ef89e14ef94e60934d35c946c47445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f758f2363d94f6ea494f4390d27598a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01503e51c86c459b9f123f285203fc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a319f80ed8b2489cb566c67b47de57fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9858e313757749f09bddd6905dc0403f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e72b9734094773a02a48f0f11bf7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32a0645e9ac411e8c69bb563525c4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ace0ba1d23942428d6eaa8de6d8243c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e1959b331042f08bc7e96a8b9c16c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3c140ede074a87b71230e3486fb6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66750ffb9796451d994252872be04065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/54 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60886444f6354b2894e530533ea076cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd492a1ae2d142edbb9aecc942f51cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c62f0840bbd4b6bb98be81a6449d64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3444774789e245f0be4b358ccee26dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ab88aaba6fb45e1a17dfb147c3d9104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97b37ea0d828453887edf205913c8bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe2b9604c2c4a2a8f40e3a6cedb3d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed34f8671294080b861803ca0974fd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09f8436b8841488786709ce9e7348251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1bc8f993354332981a6295420b12c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a5b331e424346009a7a2a68f2ae5113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4e5b749d204c4b953176359fe10c95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae6cc5ffacf46008921339985a5d750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c799c7d57e4a32ac1eac57c90e4162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9863bb1bb1740dfabcff82910aa2ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a20412a68348fbb5409b3152fef955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "804cae183e154196a08c12b3c714ba50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63446195ba2241c8bb7a82140e5c8ebd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2de7d7713c446ea2dcec62a2c72ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b273f807de64ec2b66bbce8f392092d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb10239c28e14562bcf5b463b99c4587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef0e0cbd9e3b474dbc7dc23778646721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6120f97a00da4769bca2a8ecc65330c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55baaa27cc654bb18244aa4149cb6532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aa46f14baae483a84bb78535a065bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6af9cb814f49a28ea2e840e40e70fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d05eed16972420dab87f54b42a50a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be6611515204996aff73042298bf013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe9e003b33d491baca8e6998d11cd6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f411f62e83064e1f84d639f46719f69f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b1b3fe90a048589dfeed9c7a2d1bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed5914e8aba48899d625fc84130d165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e02defaa0338499db68ccca4b50f27a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3267f331700c4d82a0c278b84905e7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c3cd5d31f448b996c43f49b85c7547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18777c5b0ac94ca9bbd80dd94fb73ab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a38901e48dc4fc7920ff7415652f9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf411c37c5c4af7b2f010ee9bfc36fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2fc983d9c65443fa6e899fe18258f38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e8f4c4f6a6f43f88f7c842929f765b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/75 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43377fced74244d792ae5debd5b03208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c41e6070fa7435d8d2ce3b4274cf33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfcbcdf7c8e43b9b70c348ab222ad20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4ad40561fc44068e4268e3b98520c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f10ed93f6c5416c8eab6c42aadea1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6131a2073834ab5a1fcf7f697097456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c23d2ccbd342d9bd85901f59f94b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcebbb1bace43d195fd052de899a747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b50ca6489249c39d2138521eb6b282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84119de7cbdb4312b94e250d44d45189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c46f8212ec40d0bb692483da4b2819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3633e42ebda84eb2ad72240551f6f2f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e88c336d19546b38f1437578a5ce3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ccb989465c4a8e91c6765c993f8895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be5b54f6f29b4aaea5023a9491635274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b545853a9b94de8884ea198badffea8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71cb3785b8b24dae9752389bbfe6b722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6eecf7806f4e02b23bc4f8ac3690f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c0abdb21c44dc0a5583db7da1fca82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f592449b8e41da8f023d094cdb352a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f39bf65f1d94f80a4a42bc91a9d37ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b94af0c5bd9249b794f2844f1870845a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9eb5a43c59349189a464aee149a949f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e8808c844f041d0baed2e359e710cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc9900b80ee4424a8c1cc9df1452c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36956953c4294561b760e05ce7034eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48b4872fdff74b6ea9f578bef57665af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c258644b3a9d4b78b1858a1de3c393f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd45dad5e234ffb836a1905a200e90b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1b570ac4654717933d816dd1ed2fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e94691a6e3874339b0b81ee3e46f146e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98570ef080c94778b2625f54ac5f1ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf3463e2d2c4328941abc2631b432b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8e8a49308442b092588c8edc192d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a55564f11844049ac67e8058afd063d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "904c620314dd4c6cbb2a28a10cc49ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bebf8b72b646f4b73668d9323295a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c06408151e3d4b6a885a913641136e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476d81904c41496ea1c11306fecf71d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04c2176d7ff94a6eabc7ae875e43b6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78566313390147d78de62b1f39dae94e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed6c5f195ccc4c24bb36cee79f3525a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "443f1191f70b42a5adb40e2376b7d7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfe7ad5c84e4a979528c6bf9ac0fa13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdec31ed5aa540df820b0d5aa9902013",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89bddcdf12704d83911f0c77f0cbd56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3b25ea89e1347e2bb38a8fb3fb87b4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a55a37c6664959bc7005067def9936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677de20102a24c199d8d10bd74ab161e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5cb89bc4024799904fd1fa17823b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c090a9215074e3c8c5eb514b9f518e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774ccc119cde435aadf89071e55d9bb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac2724903f14b62923fd0b61d927d2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9fcc5d2e1544de8fd36278491a6f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2749b1af7f46239b5d59dd1286b9c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b625b249d0b54f528c9041397022509d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8afb74b3d4464747852a10ea11d94ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad95b8f9d60944258761bee4563c4abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60edc6338fbb41dbae5ab7b0907d9529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a2440464614b69a7e25f100a7a8cf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa12ff850442421b8bc7411616f8afae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "961e250254b3425c92bd8ac05b92ba6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60925ffb4d04c4bab377a8b3de87251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5ec4b073f88415291117d2dcd419718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e416add10cc84a9ba28d844de294a1d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229396f76e4b4489ab0296373b467420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb34ba55ea24a2e8bb4fb7dcbbec5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8880eadabab54e778482f6c034dfd89e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ad8476d9a34658a121ecfae68fc171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6df684bda36d472a88d345f8a7b19407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e1f9b94f2147b4867b2bf2714ab962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e330c801b37947d6a56749ae25fb2ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79118d2beed64b14bb943187c64578c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37870d71322e4a35a406cdccce5232d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692224e04f534ab3b0d08481d94d922a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21168256ea824f738ebfa413eb6c6377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a461d51cce4cb796a8756140a49116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db62792e50943feaf100d703e3c63fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b240df8b894546c4bfb2e8388e16eef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f35f990ccf74f099791dff56960e72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/89 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7e3a9bdbda4a199c92de222a92aa5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "354f2580af674669980eed684e5c61bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb50071d589b4796abebf00f80bf0f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb548c1714b94caaba0c10b99d0f0c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4353d04752641ad856dd8792bbe8b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f84c1fcb194e69a2472d928749cb33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac44019691c14582a424c8f85e1dd3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d11880feec49c4b1e51d60dd988f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce910bb3e4cc4b95bd819fe56cc1016b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec61c051dfe40158f32f15ecc2dd09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d96861d485d47c799ebfc514ed67ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6358988510b746ecb90ab07789a3888f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3299e01d2884809af137d8ff938d4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb3ba980eeb54326ba7fc68f67f00a43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2b8584223b4728a54a10820221b26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a36b832ac8490fa47e304de28f0e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa6e37d4950d4dd38616708c6bd6a142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f38af1ecc9a54f13afd4f47837412c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf91002a39d24c2ebc34c80aff0213aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9778c7b8b0460c9019a4f3fbcfc183",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e331d13a7b784072a1fb3349b22f267d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe729a426ae4452fb87b7b84970c3a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7d77297075433a968ad3d83df55b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6cdda6ab7d4871bb1a3f03bd50d5bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58b7999045f4eeea586680b76bbaa3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888f9fda5a4346199b588d53a5e8c98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb069f850b1e4f01b953d27e747257fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae98524f60e4b62bbd4738e82e6d44a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6922d43b884c7e9145d73ec3918b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4d15ffd861540b885d86f724de9a605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5720cbaf04494969b5bee4a86ada42e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520be3d4cb814adc8ef6e46a1c0273c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45597768598475d9588cfe61993fc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04ceb63521b422ba331d2cc9ded1505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016ab32c19394f75b581c8c6f905ef11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69d0e8b0c0e4346b099aeb6936b263d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "609c09b7b4bc4855b14fa83e6b08e006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55bfd586ca64f1abbfbae87c7ae91b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e35b121d786498eaddf377c836a9426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493303786fbd4261828a6592b7bb6456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d8be04fd3d4c7798635ac425faee19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1bc2ed21a14d2784f8f954159c7c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f829ab5d9647d8a31ea5b346816d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e1133547e24aa9885225c99cddc35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733a170d09394499a31ee4b96bf7bd58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8050327f552443379b6ea64dc69837c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6242456140a146dcafe2d333cfb920f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69607a85e52e4c5397b271ec86c21858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bcd65326e54c53bfab0c321821e0cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefea7fec0de4920a41402762b58a931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0658bb77db48f5b98ae2ba882b6afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2164ec9ce4eb4fdfb42cc5a795565017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "675095d3740541af899a2447923634a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9daffb4cb5ed476b91d0af5dbb582dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df07d23aac543949657ff153cd7f1ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5078251553fa4e22a7e9074e9dfeb58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea6d9dd2e1f4416e88ea81a8cc2de370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ebf42aa6504b7ab1c5302e1a1a1c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f08731d3b1d4a22b1cd7c2f0e4c276a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1518ac6b791945ab9fccd6b4bf56c215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aebc0416c8f64abab941f6d9c5abe9ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72abe5f0d7074cccb1f83eb0e8e60514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ca15a1bb684c2484f5e65f546e04f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9fdabff177d4ffabd7c2cb25befd38c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f59b016f71ed485891a0801047b01d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f956f15dabe4ca3ada5aeb3fab0e4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a99c810f1c14da1a246c6b0d05130fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b383562f334ccdb740d2fb1e409d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ecefb802954805af2b4042f069f6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6857dd421d34172ba6f1569f7e1aa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a612e616ea84ed99b41a43f3e607480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ee8bfcc487042b5bc5da7e576083c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06407abd2827489dbfcf5d2960db8335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ec5a1dbdcb647028ee6c065ba2f2823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bc597c4baff470ebbecdb44da1f342c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da513f096724b77b4e6885073fb2d23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461aed0ea9984e918bf435e8c4a30b63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80b3b92e3e949a19a1fea80baa86ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26725c6c400544989f5556ea67271252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb132306e594f4e8add9c375a78e82a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/14 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d046b305c8234026a871e7c671efe80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bd5e684c8524a048179a397f7d4a920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c67a2ceab2e94cee953ca9cef69a1baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5126331123584b5dbbd58e9305bdd2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0adc0dda67504e2ab9649fdd51f100ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "676488c25a0a446589a1c9938eed0420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e918c810c7944a3b5658e50d610fa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a844d0daa083445dad920bc287dbd350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72886afa76844043a0d993edef4e5689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d3643272ac04f6bb751fdd0f7a36de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f205d59438134216872d4368fc963cef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "107cfd1bbfef418093891d1e2378f305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8999588752e34e75959487b50645afe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcaa5ff2bde4fd783287ab119c30161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9fb7f6b64bc47a7b97561d5013741c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ff96f3ce6e4053a19a8d9ca86c290d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e73db3073b4ddc9573f152fb67e283",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f256d12ec074c86b448852fadaa75ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206eac3a6f424b4a901d1890d17546be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33f6ec973ec74ca79dd11eae65325ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e26b67096f946c081188a1f5c64bb89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca08d30a727e477ab04cedce0f718f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9b1e27cd3c431ebbeebbf8cdcf0217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37641d92794e4da2a7fd2d4cb1a7e0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4da7117742034ef2b1625898f73995f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e163662a8574b5c95b556b45b0fc802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef361719f0b452b9755be0c60bcef90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df2ba81b43134f0abd5ace0193f81ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c314e0ca8c84a31a6c9aeacd5067fc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9461c7eb51c245ebbf0ac6b83512d89c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9302d12454db42ed8a1b5a17ae670c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353d4628510a47be83f5e17663ba75bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4c434447bd4b2bb20fbc9a3d400dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d498b56ed9294856ae0059f115d0a24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84894933b78147f19d30f4c15519323e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77f6013dba2046309a905cd268cce6ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf729c5e7314213bedb9d7c96a84c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f5feaf19174ea493a182deb9d551b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58c54b2af9f4ee488ff089db090917e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba17d43cd963454db94013d92675ebef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/58 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3909a4574c8f4e9d952c4aac2ecd6a73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db13aa81ce67416daebcf923bd4748d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb846a15305b4cf484cccb46ce800c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4321ff1c09d34a8c889851ad3e107d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d069278e539430b888b60ca28e0cc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37771e55703849bca5dc610781e81607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da69b794455b4f9a9df94df95949e84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8f3ccfb2dd422c862ea123fbf1b89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf269c243d8a49df813f6aa632983e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780b4da4837c4095bf666e911218c955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9392cc072db74a7f8f6c9a7b1c7b8bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb631ebef86e464b9e1682d30210fc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c467120f8e47bab1bf793e83fbfe12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8742ab3c1f704f509932c300f8ae23aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826cd59b6f284f2aa8bd3876d176fd87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f7cf889006a494b99866d5c3c4bb646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee505c784894e50b7b42283a7b3bd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9079dfbc1a4236b57fdc4770c36c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0c9f3502714f328f5c87c4cbcfe732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe484df76c74a78b17d1483105fda7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7bb7f5934c4d36ba0c6462d7788138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6913f1af8c24d569d2130e68600181b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a57677adb14b91a634d0d94b69be62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "218f97a225cd4d17900882c96e459154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4bcbaaab43d41b189d8bb1d12a72a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f5a57f573a41c99166191818996714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ce7b5753ca453a85145810dcbb8ad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95fcd75f95d64a2a9dfc948f22728979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a55a64610d8b440099156b51fbb617ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b66ae0ef274fccab6ea5abbe1d61f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f72d3061c15c496c9de92f534b6de3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c047c275e44b25ae764643705f7702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1656a32de7514116a34db2c723d965a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca162eb333e47f49f0a5d1d9263ee2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d33971c736a45ad9b077f92db5f6fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e3dc392bf44d21b705b96662f19c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fe46bee1e94cf194a2568e01ba8aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511ee1d0164a47dda1ed48bd3c540e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ffcbab1ca9c45c1b958e85d2aab8472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca70c6f3198141e5b0a5ff05384e8576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32af20ac8dab4adfbdb551951851e817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50105262bde34ae78f763ce7f6d8504f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822534c6bf8143efa0e6ee5ffa66a0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c05716bfe68145c3898adfda2c8e365c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1cd66051bfe4a23bf506c1809502e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49e1215a62c4d04b745df54d74f9cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bb76da022a4554afbe3898b8ef4f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91ac0920199d4f6382bbbf4aa2357378",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81b5f8504994b8a915f2ed4464d56e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78de44d3686b47d1a8f7c4faf68647bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9692f67e0a9f49b7bbeca6b198643d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf2859462d94bb28be73c7dfcaaca57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb1077ed4aac4006bfac80e3abcc3ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3c152c2fa84c7785a0b581fb704031",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "022dba60db904afdb615ced2bac2a192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4a71d3649b4e73887cd44044f9ccd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53e53680570424a9c1671e39aa12a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188983efc9294389aad1ade734827c03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90e271b1b58049de86b4ce694dc3ec86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "730a62e48d70485f8cd7151286695a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bcaeb319504a2cbd78ddce3dee19ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7f92b03a02f43c68691d77398cca6ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6da8119df1a54dbd9a0d86a49ab840eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79a073d743ee494fbb0ba07c7b666bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d2c8683a224be7a0391ac2e3b4437a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "047528509fd54e16a9ebb9329f4fb97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e826e53e057541c5b845750ff80ba292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d1756f7f7b4fcfb407c55753427986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9caaeb5fe9f34dd990faf28cf0f4fd9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7059e8fd69c451d9737c73727d816c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5626b8b8f9e7433785d33d66082f0da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46758fbaaa64d3289d13f1dd9640a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b9ec9bed294350835b8858c6f7315b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04e6ceb627894f3f8398a96aeedebeae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8534a9450c00427c88a95fad1b520af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f735f420b3aa4a3c9a86b02a0e4cb976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5f9201c89744aa89640b093444ca16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42789f7ab70f4197b7a7766d1664ac18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e5dcdc91c422caf61e8b9182670d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa5cb4a221d4d41912f8a56374cd7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/93 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789e914d34d3469b96ad73e23d9292fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb954d01b49e49c29bb5a37880437e5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf676131edda4f7c9e78bd8223c024e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c20ee62bd604ec6b24efe1e4b7b0d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c00db856334049b19eed1bad0dc8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bcbae2aae3c4db2a5c78f54a425fd03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02521b870ab74f04bf01dd4261e2369c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c042a3113f0647dd81ae969909b365bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3323dddbdd064ca8bd351744e83d14ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a210faeb99439385d9c0bd3344265d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e346981010b46d8bb26b6183a812e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778c6339da2c43439a524ef2da6f13e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c57a492ec9e441af8aa07049b658a0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a56d4d8356b4044b0c712fd82266967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23797b8c32b47d4a0274ecfafd98246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1b441a0666d4402b838f866feac1ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778b839f74d043a6a66c543adc42957b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e011819a6847e6850f921760537f25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4f6f824fea46a197a076fe0a291dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec5fa26bb2b4db6b5c4a198e4bfda01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0339e2dbccf34178a60354773b13c61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7902e5e0ebc44b1b911bb49b448987a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9913cb15f0d741198e3c782609de9462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ef98217f054018af1c079a53ab5d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6227ce96a04149a18a6e52036692361f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0e95084e36415cb3dde995ed8aedf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcda02eb07c4a389d9bc3b068d28b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8327af20d7e34ee6bdbac7620ea08da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32e860afca3c44fcb5c093a7f9cf61f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0acadf85c15d4d8480f2d3114beab3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1579ece06c894763bb7d755c9fa7d6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4175673eebc14c9392453a7de2b4e90d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc323abadbf47d9953d324be93a9d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04675df6b7cc4756897e18672fd0cde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a1eabaa5574f98b911669483481c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f2d6e96cbeb426d8777a70400a5f3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be44c2c81096462ea89c5db6401276fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67fac94196694cb5b2bb5cce36264bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845343f68e8d454f96bf44fcc7eb545b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e357bd0d5454f4195b3aed4c08a17f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446de64f95404798879858b0c2a03ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2439deaa87684cbeb60365bf63dce2ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0325e43c1004016a3766e72453a481a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4094ab29f4204687aa41d2fe340897e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4886dea1a10f437da974cb1d9c11c8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1f29279a7749e2846cb4e04163caa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff8bd46bee14bbb894804e6343198ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38df1bad9818475a984246ebbf24a556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a76a7324813148f797d2a1136215c189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d34cbbf8cef4738bad015721cb73c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b5602fda0440a4bf33fcf9831a57e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f0d00b55da4f1ab49b44bf9bec074e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f8527be84b47ed940c2827a5763f73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f24d01caf69f4357a3ba3c44496db4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a41d15f1b04423892eedd50c843d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6f6ff396a6432da5069455c716ba97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a067735b18dc47ca9b6df427acc479a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b0365480b914d08892e38ca857e4b54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e47f8c5b5cf843b69d331e4e5d377e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cda164a5b80a457ea3fee88371478766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6034c222ff4ad3a0b5fd70d05a3779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c5f21950d0494bad3a43c415c6b4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7436a898552475189f9e1e75e381cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff102281ff248ebbf244fb04926de7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f75a00953284a84b3913fc5f7d2e376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c182305b7e4c62b91b630e1be1427b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fa007039374ab6a0c20f040ce3a641",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5502901d4f534e68b90677c33bbf5f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b2ae18b681431b90fc9ef9a67d9227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeee64cf7a4a4de1849a6e89a34ff4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c95b140f809141758180a8be98edf6b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3db16b354dc14a3f9ae9aefa2815d4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a02e294e7940ebbd9b69afb04ff839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80ddd23aa1354224b18fb98cf3adfc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c68603ef84543219d048616c1c3b2b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c1fb7d8215e4f19ba2c24b2c4bef3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83be95f0da844383ad9afbd73a1a9e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20c12b62638845799799eb148330159b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa1b58c2336437b8eef8fae22cd59fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f61887df4d4c6483413c9e3664cd84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58e42678551438193742901d126be07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d094779bb6424a3e8edac3c45176e5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb919a0397b44f539692ba5d40e032d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8202829166148edad1fb6e08e0bd973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad021a6e7514aaaa291a7a16ee13b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad48da11b63d46cfb599e638fcc393b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a322ce089e4389ae57422c433f1afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bcc45b9fbbb47149274420007b96657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec6bc8b33a8e4b529d364955452481e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a3bddbb7514d138064b00797156edc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a65426b91f24de795110513cb273de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ece2d225f994751bcfebb58cbfd1ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0ee467a00b49328b8ab0bcc421d870",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69257c383cb34b00b9bd6fb418b29595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209554cfc44a4a37b198db16e13e31c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e288984380541268eb2d54f41d77c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56e9ed3843443bb86f5bdfa204e1924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edd776227cb340d9a9ee074b136c9f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a2666fa4384a0c927b792f49dc7979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431377baa163463eb019835bf2018fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f50905041d491a93b8add635275a0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7e4a801f53489cad98421580bfe55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db655d715c5a43ebb834932eba4b4816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65c7bd3376845f99314fb2d6482a763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25462c5c092b44768e6cd611628ba930",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9814ae5781ab45088af267beb63290dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8864fd25654479c885e1da7773f84b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01825dd6650d4eb29a5a09ffeb634fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7182e1853d4715abfa55fd6ba1bcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be0fa92655e418e98f38388c6f1b6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7a481f5ebc48f6a8a2ef7f9aa04155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e392d1ce912048dc87b55d7fd46d8322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b881f3f13d94c1894f5e2fac2dacf96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851f00753aed4e99914c06f6c3d24281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99a127ad576a465aae5f046d7a6a6f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b33da41c024adaa3a2563ba67ebaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c55d99a41554aa69161d3f2bc2d105e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9299eb7d49284cfb9ec53235f45a8e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f693f57dcaee43199a1bdac32bbd27fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c25298de384fdfa3a43044a95659ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "348b83ae4fc547b099cae033477b6b33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9609a3acf5bd4e378678987bb936a21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b90672d9ff46448bad34c1f681e245af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7560d277de1849549b8342f195397cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c8d416125c44d1a7f01cfd65d3e209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bc8d2f2d2ac4380bbb718ce8587bfb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0008f0465ce74fa8a13a8e86db0f64f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb20876c3d1d46559381217cff56c5f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e3bae26c1e4e5b9347edd5cfe1a762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f63cb61b64409cb5e2ae800f092fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d48428e3b2840028af283da499b0d0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f61e7386ae9b4d829243b2a80a574edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d043c0e4aab4d3b81294d32fb45308f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c1a6ea5ea7b4ae599f760a983d57647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bc2192e35744b392264dd94a7b3a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833d3e17b45b4ac5908cf797288b3caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb1493cbc224bc4af479774bb90535d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "791c8d7dd4cd4773b01f3219c0ca4444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9e30e5db604d1fa0c712595b7d33b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6cd1eb279d4154a67003980fb037cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d489ba2dee084b33b332462872d7e4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2afd0d44e2d54679b11ff90900d65d1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a5e1542dca47a785f21e3cd198a3f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784e96cc94e943729adf14e6bb462224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "187d0b8bc859403894df4964d2a53d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dded5f7708374694998e16f832a9df7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d3036daa67249c9b5a75f0c358b6465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73090684c6fc45f8806777745061eefc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f78c6d2c41c4a1dbf0de07a9bb1b810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c59ea39b1ab4433a5886f2b1a3eb8a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597d7d0ba05d46ad9c1724d908a3388f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce2ff2773bd41f3a62fa03a08608ca5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7273413ddefb43afa951fb330ae26bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e8268a0ab4467c986b5a400a53a5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f360b8778c4d8085c2ea35e245294d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0d131e70af4902ac80be34c0496d3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15704abc1b854fd48511c95904d56674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85db88d5a5f14dd485853f1ea155f92d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4579e3ebfb4babb5a83da8582f5eda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b775118712c44cce9e70458ef38e4108",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3acc91878aee4c67aa0b5310a7619096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac46fbf8c814142a87a882af6c12950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97beaf1c21d84ca89feac940f9c8baf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513f405d6025443f9e3c2136992000e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "004daa8ca2c94836ba43ac41788b7d25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d071cb9f8e4670a87580d5b1abda4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "062957065f0b42f9ad0d59bc11049af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b941aaa556408fa2738bef156e3def",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15798b11d36476eabab3e4243137061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e92ad50872415c8ac8a43a03f0a08b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b56b9eea65c4ba2ad8c5af97ad1cdd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e30f35947f143ae858ff63d06b59156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c81799ec50a5433facfd333b81caf082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5f928402a049448653d7e4505204e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abc765285a1e403eaec89a2b80004606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f414f8d73b2e4519aba160c806d5baea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d13e0f8114be429aad69fc0aa3cc4e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42caa67a1a25439e99bbe69fed739c9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9873ad8e7a1841d692128ff2ec79d0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb289c719ea4fb0a660e56c8b74853d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63944ceb58c40e2bc311d12ff710d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d681e480224445ab6d5fc28d1d1d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbaf53f569247d980e62507eee6c4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdae52ce0e0a46b092df4fb254134057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb89c6c938e486494cd3d243cde86f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8f53e542c443c69ee719eca1714d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a331219e6e32426ea374010c74413085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70a61298596c4ce4a373bf2a3625a504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b5ade8b36d4b239e852b75f083d02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b89e0d4da9402ab573596eb55ca136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb25208ce48b48e2886795e9d2e782c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741b564de4204ba5916808ddc5f948dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd41268e2024f86b45965d4f5bb8ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85b0f2d51e4345d38f278b64e76080f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656d424792cd476797609f5d1e5fb079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5823632ee23343babe005540b7caffce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16e954f02bf44868b86171669d96df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db75d8fe8004239848d91428a503351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482b47ced0eb4123b5af60c9c1e7eb29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42de22948cdf44ad8c2b76a06d3fd1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad3cd0ce3574476acb42315460bca85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a56aeee9e4134dbaa3f1df912ba4eb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6163e573b0eb48e59537d4706f53472e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6ab9ddd2fe4179bc5819833f578a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "738ae670ec324098b0c1a15e5193b61c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7f90a4cc4c4088a1b2b8389ef27b16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129ad9a2acde4826ac27f0d3d94e53a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ec329069bd4b349ffab693ab383702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b04226d19a4341898ca71d36b887df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c376df7cba69476cba4a8bae2b0e05a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9281dbb0254f4555b2fc5ad3efa15035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0e31ac908e4b60bb2b892d3d52fa51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ecc67cea7c45339b5cbf415b063a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db3c2a82c1b433898bffacddbe9d003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa2854fc9d9a4d02b2a000421f04f676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a69fd1dc4d34ceaa8fa21086583afef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e284a457fab54bc1b44ea22ce4a5e6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097b7066ecfd45319c5b903065406310",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb9488130524a4ea0d7f1f1ca980f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0a9db2a9b6a43daac857d749b412c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55dac77e63fe456d86946036b9b30ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0b26f66a6e43faa2ee5d28f8c76aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834fa096d2104d12aa52ebf9486f617b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1615f5d6ab434a9c8df7d1b6d9caecba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf307616f11b4a5ab241051f096d037c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f10e4e38eb4a209a976fe539c40617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b18e84d2d545f5aa6b58d304542d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a27a97b11d94bc7a15e4a4e352102f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3153d8f0c90643e3a1e8753f8fce6f80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09813a938dd4879896b9a548ca5908c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ef7e98c90d4553b8d9170b68720038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1297a60b64e432b9cdc8bd68ea87f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c709b8d3953649edaf83a6500c90e64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddbc8d5acd5c417ea4431a5505755e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b6cbf596df54294b221f20cf831d3b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54c21107bf345618eb3a8ae2a62c028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13513fcba33438abdea254161b5b019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58348d87e984631bb95012feb9fe329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ecc537ab0fe43eca1e6d19b45de996b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32aac7746f9e47bfa1df991d5dea7cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4782369f14ed43a682689720c23b6fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14f364cec304894bd0036eefa72716d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f49aa5fc2a94de5a153ad38362c2e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a682491cc7b84382844a6a3506e2e2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2638d57646d64bb39b6e6488cf785547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb0a6b7b2314d4e8ef31deafee283e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea08bc355c31436abf856664a64606a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c4eb797d004f7c9bad9a564077cab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8db8d2eb344ee195282a33c0d790d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480e95b93b1f41cda3ceff8a02f59337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a504f0ddaaf0486eb2b0508b1da2d31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d499d357bbcc431fb2efb5f93d4fd2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174251e13553459897ab32ac1803710b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd0c1bfac69f48b9ba3e49a7ee94feac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20474d0473624c439c118167f060f032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67bb1b082b142738f51d4aed99da5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e53be4c20b94478955d47fd6b5db667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b15ff65463234e199018dfa26b4b0cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90dc11c96b174c5694118f6858c0e086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "903cb6ca72934f3ba7bcce3f7cb25dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c0d43a0b704913b1c7ea1469603625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d7c27e3b644f02bc7a549c0466fcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92829445149c49519679c470c92a38ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1d6542d7ff49099a89f746963abe80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf82c7f1f0544448b4272671f09ed8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b089252d4d4db59f67e65d68c3bb2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d56608d3eb1400d99f2923d548c6deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ced43dd67f04a79811a70cf21e8591c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8e44222a0d4feea992f35e72aca232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f21a32fc80c47479f0d0905fc7d9b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14341d3ce4df4194af21671ce66ff55a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd994c541844d1ea2e2eff9b0da1965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c5bba106d354bbdb10ed0d7281fde73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb72c8dc59546099e162d3a4bc31f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e9984dbd1d94ebb8912205dce3cb004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f9d640a2704d239f7643c211dc348d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be32572818f643519d40f59eb19fa743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c47eef4144949ea8faee2180c016737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ab832781c74b9494470d63499219d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa4b0f6e8224460a30ac9dd80647eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "366c7de18d7141eba47a613f6b882fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe4fc7224987436bb1ab8028eb9bf04c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6da997ee05b47e99b29ffb962499035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dda20e704c524bf9911351130be0f868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0f096c3022422bad62d3699f6e42ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c865ccd155c46749407a04bdeb8922c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe0f4683f1148a888d5a42198daa49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d5ba57d83e4f2da999e12d7da29a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c8dc919149c409a93d983847a0b5168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c32ffdbcf6b4429b18912f65c2d2297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e77a04f8f5194c22a17744f4ab79fef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f146caddfd2e4a588d3e7747df06d297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ca2be32b194b5388f1032300cec9fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f518186fca04f3786701a3280129982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "627aac669d9342509e1c2e911f3f8937",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3b16bf9768401999ab51848a75709e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29d6102ac804717aa69fef09c705b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7443bb960741549fd64c2aeaa747ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d3765e18d641ae88c382673382cb61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5332cf19872248c09d25dd35084333f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f44cae015c9488ea728826f69fd0901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60028e88c34d49119134a08afa784bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc3b3069abe441a83863735ee625ad0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8bff05c8ef444686aae7720b82910b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de27f91db71043c7854ad621d811d2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d04ebae78889497595b300361b19ef16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "202fec65ce0b4c2eb2d799ec9eadb2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "156637dde02b458bb6d6f514dad9d0b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55961a5e7167407db000bfe34c019dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eb0d13f4aa647088aa1296905d31438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9c38362aaac47abadd17182fdcd7ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f3a2e7d860b4839b7cc895bd0d9cd43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251db98d205b43b89841878e98d1a652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71808e30c7f4ebe82820d63b7256aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69df993c9b78482e8c813d83523f1657",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa71c32ed3044ecbb1677c666a8fe5c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c375709d554caba1ad1a1223a6f171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feded5e3f5d74497ac4842c07a14f82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b580ff8d7ea24fd58146cce0fc90db95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e66655b7930480989e63cbc39aba860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65667f832d3c4808a27f5ecb8dc0572c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97336f94b2494b1c8642f003d3e37390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56e73bf403f43a99b012f7f89aa35bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833556fcad3f47fc9b1ee55899aa7dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e5857472d5642508e17dcbc94498662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97519094a0e1445484930894c1a88c36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832b4a291cde4924bc74eb3b9d193721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ebbcc76a37484b9a30ed44adce5acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9780134968c942ac85db0aef714887fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3944e92a6ddb4212a322855311725951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322bd3addb2543d59211ce0fdae9c22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08859285ded41dca09028ee6ffc8a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c95eeaab584a849a892af7bbf84edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971f85b3302b48919870cfd797f56242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de54eb8dd7042ea8ce5ac064b9de3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07c2639581c4d2cb5fcedc86f992e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0647fde8704f9b80e9a9aae161939b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c462eb7a1848eda9ae5e25ae7b07a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e5178a25b0c4cb6afc2b8ec328fe91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36449f39b286426989df6bb0d009f6a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1993ed70ec65417889411873e2806f5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5992e87d95594b4cbaf953287949786e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2093820d06cd472ea075afc02768d5ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4822422b457f438985d63609804360a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7a5c5d4163e47b4bd4d58ee2fb29229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53ff7c31ab004438831b75579c1e5693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45222b091987450780763f3a395a193c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e13e5ed30b64cf1af0a0618e54e1331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6326f3cc7ed74c90971ae557c2b5191e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bdac0a8380e4df5a95040bbfa606268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fead1962d2be4876a773dc36c809e773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc3539b0527430492bf56fe5596284b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9331d62369504551b1d3fc0915ff97e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe6bcff8a0b441d833111c835291fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c6c5e763cf4969b12477355fc56c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82ae9a868694315a67ab7e6ee4a46b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2dc4c87b824d7bb05a3905633d2092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad93264f9514ba0afdf54f71e494f18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82ceef148fe4119b195ec2085c51cd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08dc9dc7aa74365938955a515b9d669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "037e4a4a2b234645af6a054d57db4eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12deb0d1bf144b43943fc9b3420f1bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6648e1b1f942dfa4e2ac44a89cb6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b645b3bcad140e8a0e39e813f7c823d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de13768db09a46929ab402f3ae4472a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576716a197db453e8d0db912f040b128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc02fd743d62479499a00977c9864b73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9954ad73d29e43ffaaf4fd65582bdc8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f48292d9b64461872390ed880019cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3a8b0aa30c49518d6b2e91c86a644b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe5c36582454402869ef8ed4c7aaa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992e46d9839040ea9b0a206462dbad36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "997b90eede6c47f39f0aeabee8bf06a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fe9538f07e435885e11b0129640236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdefaf6040b54918afe5ccbd2c1656e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fd35ec1f4a41fca196abfd7f593c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6eed37d285469d99f26a5a1d57c9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "108eb986fc174eaf9d7df112aca9f9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b5599365334b639c1f53e97bce7598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab8b2548d13c4aebafc3a4c7ee3ec27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432056d6376447f5ba0cd6190c59d9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b27ff7406f46f695d15557e69d60cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d3c3e6443a4b01a3e2500c1266d0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472a309d77e5428eb8111e7e6d45aeeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef4ab48bed03425f8bd11c35153f5685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dd80ce2da7478f8b04e4b4830b5a7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b5cf0a60ac4d2d95f80cf2cfd3a8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43769d65a9e489b9f293469987a9865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e6616f0ed04005bbb09ac2ff74c725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "129245a9bf0b4bf3868f9cb33d3d0425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e2904de20a42fab6d1e5b272381489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d86a7e7300d482ba27fb79eca62802d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d5792b975949e5a6ec00655fa704eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3f0fcc1356453f85b26fc5dce40027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2aa5b250fb54a098b6ad20e1c80f019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b044adc3fe6649cab024ecead9283e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a57a4909c4e4d90944e25bb588e35a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c19ae2770e4bf5830537ce2b41b640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53d7e5774c1449096d488fc280344d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89cd45b8e49d43ad8399d6d0b6f319fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "507b852a727a4cefbaca27a1e92b4285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5811d35337d24a26b0151c2d2a956aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9828d1614504775bef9b21b0f669a4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51049ea1785402c9000764433e35d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ad80e047af044139f45e7caa087b017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fcc25f406347e4bf41036d98d6ffb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e770775fd41a4fb880567632dc7e72f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb3f8b71f23b4ec6b20ca32ee94eec1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7defa048ebe49f98d57ea3b0b5b6e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3472d89df4a4dceb8892f0e8bb244dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ff92f35e5b4c149ad2cb65f4629fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839dc871eb0b4cee935028c686545e08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbd9316ecbc4e14bd3cee55fa3edf11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca5d383ce1b4a1892b71e9e96615a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6728726760143ad92b7db53450c1209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332df4d04ffa4075a00b6b513bb19299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b1ca2d6c71f40b886bf35ea4745fbef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c36eb1b043a5402a8ce3f1de86890afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9aec61c30164bf9ac8f7520e9a73566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07084e6d1c141e8b1342d1c8801dad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c860d8c83b4000899c29f62e942f9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad27280f2104b17a89b18ba665b673d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c4bdc2044e4a4b989686935e1dd85c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041d5f974e434bf596935343964d8826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59a172255974228acaf99cc07806d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a11fb9c6e4d476bae8f5b2d200bf65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ea7e94fb5545a598a151e8cb3538bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734d616dd6ef4495b007c52d07567510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49edcc6663af4bcb8f10d66d090443d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006a7b07cb024cfda85463b0c8de9fa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793c0438a80547dc8f9df3b62e853b18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "747744fbc183471b8886cd0bceeb0f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52a28fbed154401b9333fb496a70966",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baa4629d4b7a41a48cb195ab9494d0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577dd42e8d6148ca8d513ff31e07bab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beb6def3b8f6456ab37cf4063eb46eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8807b1ea2d614a569f883bc3c0d997cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f663e5fe8d419d948b54be3a75f8ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa08d7d49feb4d82b7c87623a3ca9de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57b46a68c7f9408aa38794c8434d7f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/65 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e92e518fd504c9b8e26592a886a4d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b04daf6eb344b74807ce2b0b8e3bab3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "199d43051e584afdbd09f88aa56cc48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65c7cec3e7a14e4d892ee0c15b3ee38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8889f57f8045c0b1825247d8865e79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eca60f6a3074464944842c74629b4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b025087eadb8419489fd1cfd7a9c7a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0fc67fd92f9460ba489e7b0d30ec214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21876a6eaae6488aad02669058d333b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680f142524e4420e9436f9ec29a621c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72bc7bde09ca484381f95a0d6b538bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7caecf82d714b20ad22880d7e7978ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6ed5b3c9d848d4b0a76cdfda9a8fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8762a6f4702496b87d508f8f5144a5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f254bdad8fe8459caeba665254f6a7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f668707514f43daa7069634ff2e8ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b37076f91924926ab5a1136d332b494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b1f9727f3ab4110a93b668223edbd18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f72f4e20714dc58e46f3a487b63a26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c695c10285046a39e4324e486415fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92eb0414a9fd4d2f985d31a45b41e5f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf142b49c4f4ac7b8789c10e2705515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e43eaaf5c3d46948cdcdce17aed3616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628d584d2c5f40f7bc1d92c3ad86e20c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03fbbc2744cb456dbe153dfe3edcdc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d8483c83a8149509081bcfb9d737b80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1f5a66ed554868b1c88233d4533e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb84fc94425b490f8744c80f4dec94c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28dc617b40d4008aed89ee607386ddb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49bfcaf7726646d98623a5b58451f1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89a05c8053547f090688e6a59132c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f1994a22adf4f93ab40194f8f0cefff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b8359143344dd9b0dfe013375e43b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645ff2b522c7490d93ecd76434d9b0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8334d255a354560a3d6a2c0f23a5650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c9e5de432a433eb029eabb489a09d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb29d7e2c584e71869f7b6486d689ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76fa52f723394b928b949540de0a4a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "227461b0768d43218b19d1111cdec3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4830838c2344f93b03dd483aa288dbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1364aff96634fa289a93a1497bce0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2009fdb115b40b59f2c2feef7f4ae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42150fe76f042d482901cd1db8bc029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ed6100175b94ddd92e508e77aff3664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8990ed5d2bd4e328f07c55a53d5d194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "802b9325af1d4749b67f32405903ef3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9efdc7c649475393f0ff397fbc2c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99db44f3e7774853987f1f9ff6cb6a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47096f3a6a1d42b38a451c56f0802dcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8c6220ff384e999dc2607bf038a732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa5363afb724287ada2388a3070d027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ffdaa3ca6e2441988370b880ebdd4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7bd34025f3456cbd637c43e066c754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b007b48f16418c82601d2d702b9f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7eb5e2cae8542a28f6656899b725b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "940090d1cc6f44b790d08e1d087c9c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c94c82b69794ecc838f76a8f64809fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcf106de093444f87ab1e5ab60ac61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca18f0de097430f88864ab858ee5414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f87b7f32fc24c31b17c8e3d1d0d2ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5073a555b73543cbb030d483e2d68a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf5363d20014b65a5bee4242519f0f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dae67b545d487eb6929f1c55234888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f7db77c8714e08a6a077b96b9bdc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95b28ed3bcc04e1194ecd444f7d70f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88d481401692479fa02a521b051598a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c5f6a3f7e44b23a6de8acd94d7fe69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e602da0607944d449db61bad5865cf55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ffd85e518a4ab19db34dfc87ed3ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c11d6fc1d5f40cbb1408b025aafdc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b28cbc5913f475a883eca72a4b30b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb702b3711d402d9393bb92d3522d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cdbd5af2594e4a80926f02ae5cf182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d24f80134eb4d4e813cad15f7b4eff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e8119e4d5240eb9bb109340ab45953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3ba38d2b604829b0e61a6e4030f010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258f0164fdd740fe88ee1379ad720d80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906e147cec544222bf8d2f5179264660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5c6479a08f4f05b7d250fb72d057ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e158c505353a47d78fc8f69b7bab9fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecd8b8ad6721464da086e0b966740292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5edd53966a49d5a63ee9b4c421b8d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b5f0f80dfb414686f2db0919a1cd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573961c1a3eb42d3a4d115d4e3517f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4091c140d11e47439e1d256d0a19f7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138aa21fddd848779be9c5cb64a62996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573d7c9205534c7e98fedab52758e2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9588aae75a6945ce8fd5a25b5b355b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26bf140cb814372a01fe42debdfe104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b41d95f9144433b1e265bf35123b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931b4b870f05416388ae7e38162f651f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5892a78b39ca4b109a5be9b8bf1832f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d02eb7c8de4818959a0fab2de82661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71bdd58eb1234767ae2246a2c2621c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bb77cf5b004dbe88acb7284733e1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14846d732b774c42bc37b54e5745a15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8faf8f25b95c40a1834204b4897da7e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe53893d4c4a49709bb14743e9e6854e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3cb98380e82465d89f8ebec249213cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bef586ce5e04508916ef52d169bfd6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6470bc1fbd440ca1411b9847b52b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3775cb1173fc44128562270877a16748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16347b43dc144c5bd6a503e02757745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c41fd4773ca640e3ab6f345cb7c63b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "206676d401f14e778b7216f20b486637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdcad11def84a49919a69fa8227f17e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527b7cb466624374bcac3666328cab1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ac90ddb4f8437bad5642f5df425719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e8c06d19a304e8a925182a580e5086d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b580a8ac1bdc4c02976c0ae16d139940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c50308e7c541518444f141114311cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b97960bb7f374f60986e9df60f41919b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b39ae0e6c84b1cbf3f891c49955844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fea8a4c0dd4deca6e48db22c12b2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b559d3d7c8914552925af78ac75f7626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66923af0e17f45bb9aa4e03034b49494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aed9fc03d64e10b30b2c76f908d806",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36581e21e12144b7a659bf608acf43e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87840f403c3c43839f35f65b297826f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add5b7c5ee944d608b2c16391857d918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cafacff674e246af8e28f36ce19148e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1b4005d698b4bcbb0bbd1bf265c6ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "411b049064214a818d94aeecaac8058e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec52534aa464eb68090e9d3f83710c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c0018aec48f4d8fa043e8ebc3a10f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3152a4817ab544e39b5b8a9cd2d3048b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5062af9724b2414bb982fd18bdd3c13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd81301c2e684b10b7939e8e58bfb917",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b960a5ed0008485480f0d43d403afac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16aab0b4af6244de812cab50998c495e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab93f0f78bcc4981a1fbfe81cdb3c21e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960b83f34e2d48c780a1c3979b39f32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f1cf9d9cb904b878eeea4406abbe0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5801b953d7c4eae99db797a54e7f155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be497f730784cae87117cdfa067e9ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ef756f230d4ead88e0fead1be2e858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77a1e48c70af4dc1b01a502530fd07f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c41b8ec0cb84bd9b0452e89ee7dcebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2782d2cb81be4ab89e5dbb34de10fb80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df720b20e014f39bb9828cd55d1c1f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd157474e72f4dbbab408dc46c8601c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd92e82c762466d9e180b9ee153e9b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc4f29d2c894df189d98de9e8dfdcd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "865555d727da4f32b3cc30067db47c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0acb72de88475a9f9783c5acd96e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12e99ec8f937479a9ca9bd8489933361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "352f31241e974ce5936cf08df45afa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92f6712b604147cf94d81a040988171a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3ca303e34a4eee9fcfe9a8faaa43ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4f8aa49160422aa356a972ac325673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37c26a2386254abeadf39e2401fd8b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9cd2e06a26b4ceea10a659d24cb11de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9c9329adb92493cbc53540148d61b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2448a506f2ec4c2d892df0fb8d9b9885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e436f7e5744c6294b6ee82c1563c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "758dd2c6a67c4232b7d575981e042d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed120431cfa24e188b158759d0f22345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ffc116bcb04455acb788f38e76f6f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcaaad92e4342c797c00b44f4c8f919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b243fce4744a42eab52679b5d25511b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c72267dd43c4901b06629dd112de169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0448728bced44eae8a96340ecddd6ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f05c743badf4a6e9463017a923e0701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f022d4fdcce34fbcb8187fb9667af0bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19294f738503431dbd4437fff7b15dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e349d9f3ec524043a7025f7377706ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bebc6052c814a45a1c9aa9dd837f9ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4b431da22c442ba87fe6970d675d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e1bb16b0ae94ea19ddb175da9027d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a38d8f4b2c94781a1951fa1e7b41905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5613f16bd0944f509e566be7f6f89ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec9663ce400a40e2a5a044118c88f9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511e400fe16b41f384cf83998e0e7bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6c55a9e64c2423299ef382eca370acf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4076cc0085ba4072a61ccde0bd151424",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1905e22db82462e89b0dc9945af8c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1764021e66a444c09dfdfc02232be4f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc9dab6a29d48c5a67e5d676e424b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56730ae15394189a470afe14b79abb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30a35aa873e04c6a85ab13857d6dcb3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e8f051f0f24cce888df8cae573c1c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4717981f2164869b329430f00de7132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ec55d68d98442f9b7e31d4f8148fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59d11e823234ab4993e7422c3393077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaa95ed2f4414b918d7e170edac47b2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc50942ebcf467a8cf0259cd5c5fa47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08da979203d94da2b1a2130c05bd5618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6d73b32e264eb78ac482cae008cd10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4180fc1ac2eb47f8881850f2e15e673d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fec09c89614386a4ca796ba35d6a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df104647550c48f1ad34ae525162b8d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a3313380f86477e901a0bc620d62976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f731f88f2e024ab796f5feff06f9f1eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16463de5b4542f4874261a3dc2fc1a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d9d37787d8481798c7a9b840ceb7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab4f12becb7d474cb65c86e13c04c933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47098e340ee9443eb8ce80d0fab0793b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088a4f9cf79b4a6fb2cdf591817bcaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bed37c834d540ebae2481f3369badab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773a7693e2e64255b5a18bee33738850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45dc965efbf408fba2adecd9e5caba2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9070b69d5373485fa359bbbedd036a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45ed6bc4029f487e8e11f708643d0493",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dc94a3e036040f8ada1bb586ced6d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec488eb1dfa46b1b6f04d2ce8cf7ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133295fdb9e642bfa9402dab5f0a3289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c3346a307f4857ab10db73b6b026e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15379774dbff4132a2c7444d88c9f571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "426727b41482430eb8ecc2d6b6f8a461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae963779f5b84504aec6b196657ea5be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2392678adb2c4b05b248a4d7c9612f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39aea08b0e844c4291e26208fe9775af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "105d39245718473886c199b5dc11c573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01bc2a106af403689e99d742a9471f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "575d925892464224ae3ed397a26079d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c46be0a16940eb91a54f1a8398fb26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a36bd06db949a4a35ce7f833174b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd57ae1f004b4eb184703208fdd8f57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d86308b4c24090996ac62f3e25a362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7843963ad2441eab6e2ce8534a6d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69d699e6fe64775bd858d8b3ab05dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db31d2bab9d74eebb1bd7120e31af532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80854e2b8cdf42a38c1baab95f97b176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3b7b15e99024367b933383382fd7c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a52c10b3deb342b488f3a6e8e28f9a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b5004d46356485d90718d8ca5ecb0a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ac6b4faf2342b59d12ec177fe692e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c65b31b8fe245a6aaaa297b160cd44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6074cdeb29be40748b32bcc6003613fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7732187265d04b87b217289f375fdabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd595679fc94876a80272c3e7c0740d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2991cf7423144e4d9d152b4cd53d6233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6dbe573277455e9a7ddfc8482f703e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "901b9f2139f04a838a3e65ac1e27e401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab157e3da9b240928de3fba23660c975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953cff31433e4a3f8b842a669a63c024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "642dad518265452f937f3a61de556430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be0abc58c794ccab62a3c970424316b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e973752b56b54aedad74e2db8cba2a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d70ac7012bc4dfab10f90a2f8dbcc6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be62b1c6790b4101a368cc0c81be1210",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21b0ab538aff4d0cacf8377175538880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2254e208c3f4cc3b669cac3e05c61dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11717fe9087c41e4a8ae782566ee7387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f751f5073f4bb8b8bc2ee0e6a1006c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25703c4e6274fde96b05a0dbb188798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1dfff5619c4b7895ea0e1ede52a860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09b186498554c6ba2ffa377101c245a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fab47512554e1fae5e3db3c04aa7ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbc74865c284f43a9c5445d44d12aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5716d3ad03f459aa2123f08480de379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7296872602d453782c16b8fe13a96e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024d13774a85448bb0907d484876d9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0741682eaa54823a07c631342eb701f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba2d6669823493da1cc831615c6ca79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb0883edf5d24c77a2de91a41154579f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "316a804461774b4fa91f851b902bfc38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac9b7b944164270836c68a9faa2a042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06425ec13e524503a27d5dd8230c64e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90a884da24a74667a039e05788df01fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718a9ab082b64641bb556dfc1945de16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9f6765beba414fa3ab263a9905192e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f752cf1b3ad644118131e3b3bc5ca0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e24299113e545d7b186ae4a78534f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fac79b1ecc4c4cadce1082d944c891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36838d3e8563480688924edbf4664b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "870ffdddeaec4536b0753cfeb54f0008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54bc53665d0470594ab06b8b76bdb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4baf892d51c455ca0273a1b0f92f440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6f9d805c9c44f0adfe5650b89e8ba3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3fed3b1ec14901822e0812a9762bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee09882e07b46fcb733fd41ed8003dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944159096c6b4e838fac2a9c5e1d0916",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e56f52c9a3dc4f40a8b5fa8662b1133c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07827189b55b44d586a56d4d595d91cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a88bcec1ba48c8b0a10b8e4704a6c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae1974f54c79417a8034065ce45e4598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64f8e93490d4bce9bce4590e87a7d82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e349839d85b40d6943c5bfb0548edf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cef29c55f124d789bf88513462b345e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c745061bd2924726a645100070996fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd99d30fca1419ab5ee212b93a30523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad27755245014602a71eacfb1dc28728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32452910c5748c5af1e249fb107d2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977297b508784f4ea12fe0e6ed098309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523a7743e6c442b88f5956129cb1666d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42b2c09eeb3453180f277c7cbb64890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16e0f63c49544748fdb3a8bd65fde32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9f5150aecb49349a74101a36c43565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f98280db944d909f14da4e88c7038c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ab5203c95744639e14e9d312007799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59f5d056ebc42e58cc857e0686c2398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479aa15b7daa4b4b8570525a652fd7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5006bfcbfc1f4a84a2c14118b16a2291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f94ff43c51e4873b14827e4961d455b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685168fc3e474c6bb2ec00a8b3156bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a19bb0d25b6452c9b86e03e36289280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c422b5cb084e5e8147f3b4823d14d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3031989efe04482b80cf71b3439696ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e037370683d7472185b92fa120080c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ff2a1407b849dba8216d3e68ca780b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03c0768c18141d690750d8050f5f73a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b17b053f366c4567b923e15fd69868af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efa496483fb46aea433469923360715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2ddd0470e742e9af0d93441185c5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3700f0cf4747739c5b70d61b8fd6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cf3b63ec004176bef2749e51ae74fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc00d3467334925a50c4a186bbd4f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52be31c7aadb4660ac2ac2dbf4f691fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba317f93e9724bbe86b6481918bc69d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef7764fc9b07446dbf6b12dcb97a0327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0066775f97ed40b793ecf6060ffb0f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bde0f4ce9304adab1ebb30adfa01113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "793af0cac9b14e6aa7a632a09ca2564b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38f26052e7440c7bcc33459e941c7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2895fe0516f5434f84a40bd2cf4e2327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28ac84a04ad7474ab5b028e541e31a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87dcc3d6e4b04afd838f2067e5ea294d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b74524d21ae418f8c16ca0066bd2996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c61a4520343408bb80e96074ab2acf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c8c9287d9a047f5828696bfa0d55b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3b9f9b1f8fd40f08772d850a2d283a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb064d996d4b48cb999d80fe9fec2bff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c501d0526a542db94ed9657ada3e80a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e915da1d664d1bac72ec927bb52cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e30fbdb802437399f0a54589944014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1482b47ce4d4a3f8fc1219e323db39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42c33423f1a4e6f8ef05a26529493f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125db357ff9d4e23bf7edd3f83b3222d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9d4abf28164fd4910c0c5744bf3d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b599d5af060841c885d6a8fb7875d34a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef2736ff94a4eff9ae07a46252f9a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f34ed2d00d27438ea1021360bb544783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23165d7c4c52428eb259eedec05cb5b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22bc1f57349f47aebbd193f1a644df81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716b985a6777483aa6a6c98167f732c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6445349e1874e34b6c54220b47aea5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1be9c7ee9a246549be35587e09b1a29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2812c8d5f14230b5567c25d54b4d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eed68bec9d674d31bf1ba9dfcadb099e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcb100110214c219b67cc713ce2aa9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd832417364244f190d00cdf416a288d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea333ba5c539479d8a21ff0fa3485e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e435864aa084b3fac949be29272be5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4ab1e5b54404c51a3cedca04aea0f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d32f79ecdfc414eadefcda860f8aa2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8ef649afec479693a97620ded76d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91ba713ff4b48c2b7f8513396e25204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ccad2c691942479c6120ed871841a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb4df6ad4ed449691795c53919b17db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0239d081c2a840e89e7c9d1a126661a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8590a2ba1d7f44ecb303014a5f960d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d3b8c1a76a4a9786d37b2cdb2cf406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60471e63b0d48669ce53a113dc13e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88c15cb9325445bbb693fc6ebbeff747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c95825d03e04e4bba46fb69f16c676d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8448c8303c844d8801b8ccc131fed9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47c795cda710446da52fcc236079f6d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a24737497a324df5afefac235d32108d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb99449800b7402c9436a7a3bd015ff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b129c98a7f8540dd8b2d6cb41accd33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a342764bea3b497bbe2822dcc80972a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61e63e6805b0451b925d812bf37b61f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a9947e2cf7471f87bdd5805885e3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6c0f2516a54b17a4e90c3c47dc2b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257d86731c7e4b81aa27f6225c1e74c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d19182bcd967498bbe7ece080616cd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30ceabb5b3e643ffbfc6c2444db714d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fe82bb53714be08afcc7a782b974a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a40872e7a0542dda166582f7ef0cf77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51564fc4d67c4a15b6fbfa3879701098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b227243edd8742f991582c43c697baca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e275ad9e039240dca7d3ef0d0b3b9872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cdd7b13de864c2cab6095cad48bd506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea8fc8ef8ca4037a5da67d63bb07127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5d695e8fd947dca9b6650a1e54a193",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6002728fe0248ca89f197404ed74468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "943c216521f4434e901fb4e51a6424ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3998d43be2e4349a342ee31658cf4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f8ffc05d394bff981df009e0ccefd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57be4a786f1a4f9498856086b59fb0eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f7d37d34404566ae4045432150ebbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdaf973f7e5f433d8cb023a149a029fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8373075ed24117b0efba4dfadce044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de43faf5867e44a6a4fa3709c6d181de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71305bf68a5044769f8ab7facb20888d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2c87fb48584837b88c96c3bbf7579f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b91a4c19264812ab13b0145bb130de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86c08a1b376d4fa48793055803285ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ec993c2e82b4f9fb949eb58c38a183f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9c18dfc8564c6cbf59f9f8751ce692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31668b267d364579a08908c23a382c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bae1803d72453db68e66d0f2cbdf75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eab86bd7c1049759f8aa37372c7f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3907463c404366a49ecfceb1696a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad21a2c8453496a80a013047638e77d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4536561caf34bdfa3dd83c009e9e1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a74f04a3041c45ffb31d2e83b950b436",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4a1076f35c4ea5adbf0dfca7b80f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0f616bee7e4e8f9ba8f242e2915c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f15b740787e40cf91afeb0eb0e387c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0b4664113249b3b498948611947d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bf994b85712468bb1270584430e75ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6954e2203a1144e3adb9064b64b2bca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b15e62aa95b41f2877194c3575aaa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47119cf86f68420198c39355ea23f482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee77392c861144998e0d438f808a4609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdf942a963244e6ea1214819ce2030a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b04c016b0c4e46b74ddbea3dce86e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039fafae2ad548efaeb1ed0f58773821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53a8a1f03664999a68e7887c85e5d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75da76d45aa5434fb35ed8c71a31e1ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d21fa071114ce48af3cd3935fb78b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1be17dadbb2948f482438054d39e99e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12650de194ce453c80e4b05b6a7577be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe198f5802d48b39e81ac9946125f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d092e5e29bc04fb89509b93e20e22082",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9eb469cb2c401685616bf39dd082fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78d1b619bb8462fa86db83e837dcb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8e9b0cb16b4f36b608eef2316d370b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4044510dbee7485aa57ded3aa2e95f33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8114311787c442528ab3b5ade274b0de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fdd2452b6841758599cc70747d0971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3986d35ee7874d80b965e3233dd5e72a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2871ba5b68574b91b02f4a4e6fb60c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc321a6c2e140eb99203233bbbd7149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9697b337221848738cf110739ca901e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa871fdcbf214615b2bd87c6b63d626c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03b7990e30314dca88912c1602df92c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f34defcdf64d58a0ea609b4a45eb44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26996efe71c4b9e95d7424387f75433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc870d3a29b40e49fb65384c8f9b050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f086e67109464945a274ab4a453cf9bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "808120f8ae0a499b9c9ee6711853570f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393a8b3156c7435cbf1c1cc104c0a818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23404706ff9e4d19ae69a243f150e504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5499d05f4340c1b0554f1ea2960a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9573ac422e8340b38bd4d387a5ecd34d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd9201b7a174d2baa812d282787157f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8ed5a5682394a1dba36314304f6a50c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7b2718f14c345ceb0c0530db80a6925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2558a78f8c4ca48bf66f76f73c96a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6cc85d01b04f4388dc7c96ffa99676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bdaddbb43144a268f7f6c18f98594ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20543cbd710843f780be860b350760c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35de45486b1b4660ae0d3d4ec5b19fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c876c9789c34354a8e4048fbbc6193b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc3bdb673d84cbda7670fe87ee49470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e4fbda0d554da9823715c554e36544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560483e342a845a495ee73ac183e4b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de52ddb0cd248919ae381bcdd96c74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1140f710e3d94982a33f2e01c135694d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868b47847ba34ffa9bbf0683dc13ebe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d553abee74e45c3a38afac7e729e27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8c5ed584004e44a4f97e3be94ba91b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "249261b5620b4e26a5148b0d17f927eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "719be5efec914a0d8fcf5f87320d74fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d9c9cbfdcf4f7dbffe3e7112fde2ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb121674bb404902a2b9a6182aef352d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39eff093160241d4ab552dcaf312ae0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd78cdbdd3804a21922f2b1576dde012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c01b304a50d474aa1457c96cb568e40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce5621c45f0432688caca55b241f131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4256d81ca0452e96dc73fff97c48b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bf542fc73304b0c9b40f4009b067b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e83e63dd114ef286d69233d87465fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3fc02245c94f4aa7860385f985d7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d105b27faa7e41999ba837fb5a1ce9de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1abfa05c2050404fb5514c959464fa6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf9b1795183d46188df77b6a9255b82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b187527fca51456e8faa044332d5265c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f2e1750d804b64b3e2116a4bc43f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b96e9f3a80db472a8427b20458a17ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbf5f57d340d48cbbc22b0f715da1694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df75dc8103144a2acd2d4318f6b0993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ec75e91cf34606bade74c942192369",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e557c888364ef9bbffc0f24958c5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5fe00d850d410398f7681fc1e86271",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1bc83b3ffc400680bcc31af2ceb2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c0f34b030a447b5828b65cbe6e84496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10bb93f4128f4a0280ef2c541fbd6ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0700458493c947b483e46d825c72775e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22753909a904e5397b0b946fff76ffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e32f97898cf41f59a89430074329740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c2fa69b40143ffb37342914bc0f2cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "540cf9cf19d848f78904a1049154b27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499639d7a13740259482ee76b03d2541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d0d21b0cbb4cdfa8ec0147b8cd6c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33318ff910bc46b0a33959736c8e2338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "006b5c4b6fa64c1c9de1a3d2e67a1756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba20f4e4a864f73a2aff50c1449b55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e067135fbe475cb974bfb8401e98f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02795f4d5c64836aefa09615bf10bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fba94dcc7c074a8880bfd7bcc7ed5f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f232413416844fdb58eac3c2a2ff64f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca10946037d84e1f84ca23d58bef292a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21926e051904579a844b84390096797",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37464958f03344d6b025290481618f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216c0d4af08d4beebe038cfd47dc66d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "082136d1202047c7bd5753c78ed210d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a1423ffcca4c30b9e7385dcba01dd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14478471f6aa4278ad9f7e652b0d55a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b2ae33fc9944b6a0357d68994cb524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edc7f5dbb604a26be59298225fa1b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47f51acc59b740438dbb80a0664a5d13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe3f7f1ca7394cbc8a7eeb299a5f230a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a1e91fc19043f0a34209a890734d60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b45a2e2c254c76bd900a5d7635dfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba326dcfa0849278e13fd062f423bd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac39bf2cd980472b8e83133dd6265fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38877650dec9419f8ef371f665aaee0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f9f5ae7e304926851039b8d790b350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe5804112e3843eb8ba2647fb75c6cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac4111f884e46d291c0ffa00c9b4dd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d6844b3d4a5440481cc88849eaaa3d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07338d6be47e4400a8862eed04d7d6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407c90e156f44c5fb992bb518d7898d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0655a6a2084d7bb9fc4fb4c707be77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65e6b6c3ca7b4438afe16ed697a1758f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68e5e7532c2c458ab3a308469b8cafaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3667832789a244f59d5e783aec059f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7158de31e5354927a9789f1285885d76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b702c0bf7ef4853b0ca104e38dcb895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "631e93b06b834045bdd86b6a615dd416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71e503d973142a88f22e7c44b980476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c812203c574b91b111b319dc481f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273ea30a2f6b4948bb60cfaee970c42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b77af5a69bd49d893af9bcf16a2f921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792633efa524491b99bd5eaf7586f5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1dcc63dd40c4a44936691beeeb6fe06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3674708e32340db970275afcab5cca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d299234068e94143a65311d9a5dc737b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c50a9f2910244b209c3dd10be1f52e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd7518380ddc48678e590fc1cfa74ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1686f4545dfe4bdeb0e4bf80ccf753e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d11be8b3afa47589c88e79f682965f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ccdc3512ed848e09275d097852aed44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8a5736a750940a9a20ac262e7dba72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4634fda0d7e47e58682469b64f1d406",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca38b416332147acbaf1a5afcc379579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e9829ae17e54989b11db8a85a56f68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cad19f7b535c491f9f422d17382a6bcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27cc3d15374b4177bf656335df826bf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a8bc6e07804e24b09f6e6b2da3416b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c757d51a951448aa5a12d45b090da09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9768bff2064e34b7390caa709ea330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4708cbd8a1ba4397a07f9d75badad2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803cd3ccc7b144e992d2ad72dcc78681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "221ddc04731c4d4bb3ffdc38708aa93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ed12b70c9a47b08f26df7f16eef476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19f435017624483a0103ed6ae01ec62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95e8722ff6a04493b28a00ced85f36e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e78fcbc9c794bd89f086878fcda3380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff0f133b3a240c1b7706150404938dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8270f2caee4b27a280b4de11d0708f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b690a3329ef4273a2381573f6f987ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb303d01015b4daca851e6aa9a68e76c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92e0847a2b22486b8af599bde767838f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b087553c116947d39ad79a15dd8fb411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b5012f7e8184b10959c7a39916f1ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n",
      "initializing class with task_name='sentiment', return_metadata=True\n"
     ]
    }
   ],
   "source": [
    "keep_originals = False\n",
    "batch_size     = 10\n",
    "task_name      = \"sentiment\"\n",
    "\n",
    "for f_name, f_data in feature_datasets.items():\n",
    "\n",
    "    transformed_datasets = {}\n",
    "    for t in sibyl_transforms:\n",
    "        \n",
    "        aug = partial(augment_data, \n",
    "                      transform=Transform(t, task_name=task_name), \n",
    "                      keep_originals=keep_originals)\n",
    "        \n",
    "        feature_present_aug_dataset = f_data[\"feature_present_dataset\"].map(aug, batched=True, batch_size=batch_size)\n",
    "        feature_absent_aug_dataset  = f_data[\"feature_absent_dataset\"].map(aug, batched=True, batch_size=batch_size)\n",
    "        \n",
    "        transformed_datasets[t.__name__] = {\n",
    "            \"feature_present_aug_dataset\" : feature_present_aug_dataset,\n",
    "            \"feature_absent_aug_dataset\"  : feature_absent_aug_dataset\n",
    "        }\n",
    "        \n",
    "    feature_datasets[f_name][\"transformed_datasets\"] = transformed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89affb93",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains_imperative': {'feature_present_idx': array([    0, 37052, 37166, 63623, 37169, 19311, 59715, 63680, 10356,\n",
       "         10324, 37512, 37564, 52061, 10175, 51849, 37589, 63782, 37658,\n",
       "          9933, 64067, 37737, 28958, 19471,  9748, 55875, 63725, 59905,\n",
       "         10805, 36871, 36271, 11942, 29172, 11918, 29081, 11859, 63050,\n",
       "         36426, 29070, 11631, 23682, 11552, 63208, 55863, 11316, 36727,\n",
       "         11090, 63440, 11060, 11034, 11031, 52135, 11007, 36776, 10950,\n",
       "          9708, 52179, 59438, 64190, 39316, 28143, 39468, 28130, 20241,\n",
       "         59341, 27976, 39812, 20329, 54979, 64563, 56161,  8024, 51100,\n",
       "         20511, 40234, 40412, 64685,  7724, 56389, 27566, 40555, 56475,\n",
       "         40668, 40037, 28186, 51399, 56031, 38109, 19605,  9279, 28755,\n",
       "          9196, 51645,  9167, 38430, 64234,  8971, 19703, 38545, 19718,\n",
       "         51561, 51501, 51476, 28662, 28611, 64424, 28511,  8655, 51410,\n",
       "          8538,  8492,  8489,  9644, 12002, 36246, 52196, 15752, 54142,\n",
       "         32646, 17840, 15526, 61383, 54110, 17893, 32873, 33008, 33033,\n",
       "         30302, 33113, 60583, 33319, 55285, 30260, 15208, 33357, 33410,\n",
       "         53789, 33477, 18197, 33651, 33210, 30310, 15793, 54328, 31154,\n",
       "         30970, 30933, 60620, 55045, 16831, 16577, 54534, 16535, 60925,\n",
       "         16375, 16323, 60593, 60948, 31769, 17548, 30587, 16202, 32073,\n",
       "         54411, 30548, 55173, 32155, 15874, 61148, 53546, 33719, 61951,\n",
       "         30056, 13439, 53043, 35389, 62573, 35516, 13303, 18713, 35570,\n",
       "         35609, 18863, 52865, 29546, 18949, 35761, 62887, 35823, 12590,\n",
       "         18975, 35907, 52737, 29409, 12304, 59983, 12124, 12096, 62340,\n",
       "         20678, 53052, 34993, 14538, 34010, 34167, 53505, 34211, 53467,\n",
       "         60519, 14196, 14155, 14153, 60471, 34419, 18259, 53416, 13994,\n",
       "         62157, 13928, 29973, 13847, 18528, 13714, 34934, 34961, 62324,\n",
       "         55494, 35287, 27485, 27964, 43932, 22086, 47212, 65764, 40880,\n",
       "          3479,   801,  3437, 58025, 44545, 25661,  3584,  3248, 25594,\n",
       "         65925, 25505, 47105, 44818, 49945, 44935,   856,   865, 48724,\n",
       "         44619, 44988, 50063, 44289,  4214,  4189, 43964, 26012, 57307,\n",
       "         44044, 25911,  4092,  4007,  3959,  3605,  3957, 57326, 66775,\n",
       "           767,  3794, 22063,  3760, 57372,  3732, 44223,  3644,  3930,\n",
       "          4228, 47021,  2840, 48941, 49612, 49599,  2200, 66275,  2062,\n",
       "         45893, 45931, 45947, 22659,  1235, 57877, 46178,  1605,  1286,\n",
       "         49064, 24706,  1579,  1507,  1482,  1380, 22770, 57886, 45000,\n",
       "         45571, 49697, 23017, 22332,   925, 66039, 66051,  2754, 58640,\n",
       "         45091, 58453, 66094, 22618, 45093,  1020, 46937, 49788, 48773,\n",
       "         57608, 25365, 66105, 25077, 45361, 66433,  2669,  4285,  1374,\n",
       "         50697, 58362, 26944,  6095, 67102, 50870, 50868, 47906, 26834,\n",
       "         42250, 42285,  5869, 47893,  5867, 58368, 26587,   727, 66939,\n",
       "           345, 47855,   124,  6248, 48593, 51015, 20955,  6748, 48209,\n",
       "          6725, 41316, 56609, 64876, 56642, 59148,  5619, 41579, 65010,\n",
       "         58326,  6561,  6970, 27139, 65080,  6475,  6977, 41821,    34,\n",
       "         42507, 21318,  5479, 23180, 65417, 27302, 65442, 21799, 43540,\n",
       "         23987, 26055, 43609, 43643, 58077, 23059, 65523, 43808, 43809,\n",
       "         43870, 50272,  4374, 43906, 50321, 59136, 20892, 43189, 65259,\n",
       "         47818,  5255, 47727, 26336, 42673, 23844,  5055,   520, 50549,\n",
       "         50472, 66842, 42832,  4968,  4947,  4938, 21555, 20868, 43108,\n",
       "         26196, 66838, 23715, 55365, 30253, 30927, 23837, 55076, 24507,\n",
       "         55120, 55132, 55279, 30388, 30321, 23792, 56539, 57390, 30128,\n",
       "         26183, 29002, 26270, 55894, 26331, 28766, 26417, 57215, 57211,\n",
       "         55927, 28701, 26763, 28586, 56011, 26891, 56034, 56074, 27103,\n",
       "         56772, 28112, 27158, 27263, 27889, 27794, 56285, 56424, 27321,\n",
       "         26164, 55411, 57246, 57258, 30058, 24667, 55417, 57935, 30008,\n",
       "         30006, 24983, 29960, 57555, 57497, 55554, 29768, 29685, 29684,\n",
       "         55560, 25483, 57462, 29579, 29537, 55579, 29374, 29283, 25734,\n",
       "         25742, 26022, 26037, 29030, 29003, 31179, 36531, 31315, 50891,\n",
       "         50876, 42074, 50782, 42343, 42396, 42442, 42583, 42593, 41881,\n",
       "         50551, 42691, 50444, 43001, 43160, 50440, 43340, 50317, 43538,\n",
       "         43546, 42625, 43547, 50913, 50932, 51196, 51116, 40172, 40207,\n",
       "         40434, 40503, 40542, 40652, 51063, 41792, 40821, 40912, 40930,\n",
       "         40941, 41273, 41393, 41396, 50948, 41439, 41459, 51054, 43802,\n",
       "         50240, 44034, 49556, 49514, 49300, 49292, 49119, 48913, 46948,\n",
       "         46989, 47119, 46017, 47237, 47399, 47412, 48671, 48598, 47942,\n",
       "         48042, 48570, 48196, 48505, 47383, 45981, 45537, 45424, 44041,\n",
       "         44085, 44096, 44106, 50111, 44122, 44169, 44382, 44529, 50034,\n",
       "         44707, 44756, 44936, 44981, 49900, 49894, 49811, 45144, 45227,\n",
       "         45277, 45330, 39993, 31216, 51203, 39686, 53734, 33534, 33588,\n",
       "         53693, 33610, 33929, 33940, 34277, 53449, 33452, 34458, 34767,\n",
       "         53315, 53298, 34932, 34971, 35054, 35343, 35522, 35551, 34698,\n",
       "         52988, 33347, 33220, 31378, 31437, 54919, 31505, 31514, 31560,\n",
       "         54798, 54531, 31779, 67249, 31939, 32107, 32119, 54362, 32160,\n",
       "         54333, 32489, 32591, 32659, 32736, 32103, 35586, 35632, 35665,\n",
       "         51728, 38281, 38452, 51596, 38622, 51525, 51465, 38874, 38884,\n",
       "         51764, 51444, 39119, 51347, 39266, 39272, 39283, 39364, 51281,\n",
       "         39616, 39647, 39089, 38098, 37908, 37874, 35696, 35709, 52812,\n",
       "         52758, 52656, 36007, 52554, 36104, 52204, 36289, 36419, 36460,\n",
       "         36633, 52067, 37203, 37373, 51967, 37558, 37722, 51780, 37830,\n",
       "         51251, 23611, 48337, 66258, 16570, 16632, 16795, 60779, 60775,\n",
       "          6837, 16304, 60669, 17051, 60630,  6637, 17119,  6566, 66760,\n",
       "          6767, 16269, 60952,   821, 15332,  7933, 15358, 64587,  7712,\n",
       "         61273, 64689, 61194,  7644,  7569,  7455, 66652,   883,   839,\n",
       "         61002,  6503,  7962,  6342, 65098, 65241,  5489,  5313,  5169,\n",
       "         65272, 18918,  5805, 60175,  5033,   599, 19065, 59940,  1742,\n",
       "         19275, 18966, 18351, 60437,  5838, 17464, 66432, 60592, 65125,\n",
       "         17610, 17635, 17700,  6066, 60570, 18027,  1739, 18055, 65140,\n",
       "         18183, 65201, 17358,  7969,  8057,  8158, 62872, 12836, 62863,\n",
       "         13071, 13107, 62827, 58244, 13252,  9253, 62563, 64245, 64286,\n",
       "          8876,  8871,  1582, 12337, 12147, 12076,  1355, 10683, 63483,\n",
       "         10979, 11122, 10421, 11364, 11583, 10294, 11714, 10227, 11930,\n",
       "         10222, 11986, 12019,  8863, 13710,  2278, 13712, 61988, 14831,\n",
       "         14881, 64471, 14949,  8346, 61778, 15076, 64533, 15087,  8249,\n",
       "         61685, 61605,  8208, 64544, 14734, 59596,  8365, 62144,  1238,\n",
       "          8809,  8798, 13858, 64398, 14000,  8740, 14022, 14108, 66437,\n",
       "          8698,  8646,  8568, 14128,  8440, 14472, 19364, 17573, 66834,\n",
       "         21873, 67161, 21740,  3679,  3737, 59004, 65760, 21396, 21312,\n",
       "          2219,  4102,  2204,   113, 66395, 59042,  4144, 67072,   242,\n",
       "          4335, 21090,  4337,  4383, 20962, 59131, 20957, 59228, 20750,\n",
       "            77,   383, 21935, 22045, 23444, 66239, 66126,  2497,  2519,\n",
       "          2622, 58396, 58484,  2682, 58549, 66087, 22742, 66079, 22548,\n",
       "          2829, 66038, 65962,    46,  3085, 22515, 22438,  2226,  3177,\n",
       "         65900,  3288, 58793, 58807, 21943, 20722, 10598,   511, 65409,\n",
       "         19588,  4818,  4814,   388, 59418, 20382, 19965,   395, 59355,\n",
       "          4752, 65446, 19851, 19723, 20243, 59332, 20114,  4513, 20223,\n",
       "         20537, 20567,  4415, 59442,  4549, 20013,  4842, 20719, 59429,\n",
       "         59256, 38124,  5485,  9170,  4735,  9506, 38229, 43496, 44623,\n",
       "          9247, 65862, 44898, 64215, 38453, 44941,  4643, 65232,  3094,\n",
       "          9600, 50007, 50763,  8827, 44807,  4710,  3111,  3160, 38377,\n",
       "         50026, 46078, 38083,  2580, 45194, 65378, 37517, 49762,  2420,\n",
       "         37489, 10157, 10387,  4987, 37336, 10456, 49193, 45433, 45434,\n",
       "         45445, 45341,  5086,  1429,  2656, 38053,  9670, 49826, 45075,\n",
       "          9737,  9767, 37791,  9954, 64182, 51835, 64168, 37734, 63902,\n",
       "         65278], dtype=int64),\n",
       "  'feature_absent_idx': array([33689, 60248, 60249, 18898, 60253, 18894, 42450, 18889, 51358,\n",
       "         18887, 42454, 18880, 60256, 60258, 42459, 60260, 18911, 42460,\n",
       "         18912, 42440, 42430, 60235, 18954, 18953, 18952, 18951, 18948,\n",
       "         18947, 18946, 18942, 60238, 18938, 42437, 42439, 60243, 18919,\n",
       "         18960, 18867, 18864, 51352, 51351, 18808, 60300, 42483, 18796,\n",
       "         18794, 18791, 42489, 60305, 42490, 18783, 18778, 42492, 42493,\n",
       "         60292, 51356, 42475, 60287, 42462, 18860, 60270, 18856, 18855,\n",
       "         18850, 60274, 18847, 60275, 18841, 42470, 60280, 42472, 18832,\n",
       "         18830, 18826, 18773, 42428, 18973, 42382, 19127, 19124, 19123,\n",
       "         19119, 60178, 51377, 51376, 60180, 51375, 60183, 19103, 42392,\n",
       "         19088, 19087, 19132, 19086, 19135, 19149, 19187, 19184, 19181,\n",
       "         42363, 60154, 19173, 60160, 42368, 51384, 60164, 51382, 19159,\n",
       "         42372, 60168, 42374, 42377, 42424, 19085, 19083, 42411, 42412,\n",
       "         19001, 18998, 42415, 42416, 42418, 18993, 18992, 60228, 18989,\n",
       "         51370, 18980, 18979, 18977, 42410, 19084, 42409, 60210, 19080,\n",
       "         19079, 60188, 60189, 19074, 60191, 19052, 19051, 19045, 60206,\n",
       "         19040, 19038, 19036, 19031, 60209, 19021, 42495, 18765, 42496,\n",
       "         60421, 42592, 60428, 18469, 60430, 42597, 42600, 60435, 51303,\n",
       "         18451, 42604, 60436, 60438, 60440, 18426, 60420, 18423, 18487,\n",
       "         42585, 18531, 18529, 18521, 18520, 42573, 18518, 51317, 18516,\n",
       "         42576, 60410, 18511, 18501, 42582, 18494, 42584, 42586, 18535,\n",
       "         18422, 42612, 18361, 60464, 18355, 18344, 18343, 42644, 42646,\n",
       "         18337, 18336, 18334, 18332, 51286, 18330, 60469, 60472, 18369,\n",
       "         18420, 18370, 42632, 18412, 51300, 42618, 51299, 18402, 60453,\n",
       "         18400, 18392, 18391, 42624, 18389, 18383, 51295, 18376, 42631,\n",
       "         18371, 18536, 18542, 60401, 60338, 18694, 42521, 18691, 60340,\n",
       "         60342, 60344, 60345, 42522, 42524, 18678, 42525, 18670, 18668,\n",
       "         18665, 18700, 51337, 18707, 18714, 18761, 42497, 18750, 42500,\n",
       "         51348, 51344, 42509, 18733, 18732, 42511, 18727, 60329, 60332,\n",
       "         18718, 18715, 18712, 18661, 18660, 18656, 18596, 60386, 18592,\n",
       "         60387, 18589, 42559, 42560, 18584, 60390, 18578, 42564, 42565,\n",
       "         60394, 18551, 18550, 42554, 60382, 18610, 18616, 18650, 18648,\n",
       "         60367, 42536, 42537, 18640, 51333, 19189, 60373, 18630, 42541,\n",
       "         18624, 18623, 18622, 18619, 18617, 60374, 51389, 19192, 19194,\n",
       "         59950, 19739, 42174, 59953, 42176, 19726, 19725, 59956, 59958,\n",
       "         19719, 19717, 42177, 59959, 19714, 59960, 42171, 19709, 19745,\n",
       "         19750, 59934, 59935, 42160, 19779, 59936, 51469, 19770, 19765,\n",
       "         19763, 59942, 42168, 19758, 59943, 59944, 59945, 19748, 19791,\n",
       "         59963, 19701, 59987, 19646, 42194, 19640, 19639, 19636, 59992,\n",
       "         51459, 59993, 19630, 59995, 59996, 42204, 19621, 19615, 19651,\n",
       "         19706, 59986, 51463, 59964, 19697, 19696, 19695, 19691, 42182,\n",
       "         19687, 59971, 42184, 19677, 42187, 19663, 19661, 19660, 59984,\n",
       "         19654, 59933, 51473, 51474, 19956, 59877, 59883, 19943, 42102,\n",
       "         59885, 19933, 19930, 42109, 19928, 42110, 42112, 19915, 59892,\n",
       "         19902, 19972, 19899, 42091, 19989, 20028, 20026, 42070, 20022,\n",
       "         20019, 20011, 59864, 42078, 59866, 42081, 59868, 19999, 19996,\n",
       "         19994, 59870, 19983, 51489, 42121, 42123, 19841, 19839, 59914,\n",
       "         19833, 19832, 19831, 59915, 19825, 59917, 59920, 59921, 59922,\n",
       "         59930, 42153, 19802, 59911, 51482, 59909, 42137, 19893, 42126,\n",
       "         19889, 19886, 19885, 19882, 19880, 42206, 59899, 59901, 19868,\n",
       "         59903, 19866, 59904, 51485, 51484, 19875, 18324, 51453, 42210,\n",
       "         60093, 19339, 42304, 19335, 60100, 51415, 19319, 19318, 60104,\n",
       "         60107, 42313, 19310, 60113, 19297, 19294, 51419, 19293, 19350,\n",
       "         60083, 51427, 19405, 19402, 19400, 19396, 60073, 51425, 19386,\n",
       "         19385, 19379, 19369, 42293, 19362, 42295, 60082, 19355, 19410,\n",
       "         19290, 19287, 60139, 60140, 42341, 19221, 19216, 51392, 60143,\n",
       "         51391, 19211, 19209, 19207, 42351, 19201, 19199, 19197, 60138,\n",
       "         19288, 19228, 51402, 42318, 51411, 19273, 19271, 42326, 19266,\n",
       "         60124, 60128, 19257, 19256, 60129, 60130, 51403, 19251, 19248,\n",
       "         19234, 42280, 51428, 19419, 19560, 19555, 42223, 19552, 19550,\n",
       "         19549, 42226, 19541, 19540, 19539, 19538, 19537, 60024, 51446,\n",
       "         19523, 60020, 19521, 19562, 19565, 19602, 60006, 51452, 42215,\n",
       "         19590, 19584, 60013, 19581, 60015, 19578, 19577, 19576, 19570,\n",
       "         60018, 19566, 19564, 51440, 60028, 19512, 19459, 19454, 60053,\n",
       "         60056, 19445, 42269, 19439, 60065, 19431, 19430, 42274, 42276,\n",
       "         19423, 19422, 19420, 60047, 19466, 42257, 42256, 19511, 60031,\n",
       "         19507, 19506, 19505, 51439, 19502, 19606, 51436, 42249, 60039,\n",
       "         60041, 42252, 19479, 19477, 19475, 60038, 20029, 42652, 42653,\n",
       "         17241, 17240, 60864, 17235, 17228, 17227, 51136, 43024, 60871,\n",
       "         60872, 51135, 17216, 17215, 60877, 17209, 17244, 17208, 17247,\n",
       "         17252, 17296, 17293, 17288, 17287, 17286, 51148, 17278, 43009,\n",
       "         60852, 17266, 17265, 60856, 43012, 60859, 17254, 17248, 60842,\n",
       "         43029, 17204, 17159, 17156, 17154, 43051, 17152, 43053, 17148,\n",
       "         17146, 60891, 51127, 60892, 43055, 60894, 17139, 60895, 60888,\n",
       "         60878, 17161, 17163, 60880, 17201, 43034, 60881, 43036, 17184,\n",
       "         17179, 17177, 43041, 17173, 43044, 17169, 43047, 17165, 43048,\n",
       "         17162, 60899, 51151, 42991, 60788, 17449, 42953, 17439, 17438,\n",
       "         17437, 17435, 51159, 17429, 17428, 17424, 17423, 17421, 17420,\n",
       "         42958, 60786, 17417, 17458, 17465, 60764, 42933, 17502, 51167,\n",
       "         17497, 17492, 17491, 60772, 17478, 60777, 17475, 60781, 17471,\n",
       "         17469, 17466, 17462, 60837, 17415, 17408, 60817, 17353, 17344,\n",
       "         17343, 60820, 17338, 60822, 17330, 17324, 17322, 17321, 17319,\n",
       "         17318, 42987, 42990, 17355, 42960, 60816, 17369, 60803, 17402,\n",
       "         17401, 17399, 17396, 17392, 17389, 42968, 60806, 60807, 17384,\n",
       "         42971, 60812, 42972, 42973, 17367, 17132, 17125, 43061, 16830,\n",
       "         43177, 16827, 16824, 61011, 16813, 16812, 16808, 16807, 61016,\n",
       "         16802, 16797, 16794, 16792, 16788, 16835, 16786, 51079, 16847,\n",
       "         51091, 60991, 43157, 43159, 43161, 16876, 16874, 16873, 43164,\n",
       "         16871, 16867, 51086, 16856, 16855, 16849, 16844, 16889, 16785,\n",
       "         43192, 16748, 16747, 43204, 43205, 43206, 16736, 16732, 16725,\n",
       "         16721, 16719, 61046, 16715, 16712, 16711, 16709, 16750, 16782,\n",
       "         16752, 43203, 16778, 16776, 16775, 51068, 16771, 16770, 16766,\n",
       "         43197, 43198, 61026, 61027, 16760, 61028, 51066, 43201, 16755,\n",
       "         43149, 16893, 60986, 60924, 17056, 17055, 17053, 17050, 17037,\n",
       "         43094, 17027, 43095, 17019, 43097, 51112, 60937, 17006, 17001,\n",
       "         43081, 60939, 60921, 60920, 17118, 60906, 17116, 17113, 17111,\n",
       "         43066, 17105, 43069, 17090, 60913, 43073, 17080, 43076, 17077,\n",
       "         17072, 17070, 16996, 43103, 16991, 60968, 51101, 43132, 43133,\n",
       "         51098, 43138, 43139, 16919, 43143, 60982, 43144, 16905, 16901,\n",
       "         16898, 16897, 16935, 16937, 16943, 60965, 16989, 16986, 43107,\n",
       "         16981, 43112, 16973, 43114, 42932, 16970, 43115, 43116, 43117,\n",
       "         43118, 51108, 60961, 16955, 60953, 17512, 17513, 42931, 18077,\n",
       "         18073, 18067, 60571, 60572, 60574, 18061, 60577, 18056, 18054,\n",
       "         42745, 60579, 51248, 18042, 18037, 18084, 60587, 18086, 18090,\n",
       "         42723, 51260, 60558, 18119, 42726, 18115, 60559, 18112, 18110,\n",
       "         18109, 18108, 18107, 18105, 18096, 42735, 18088, 18126, 18031,\n",
       "         60595, 17971, 60611, 42769, 42770, 60613, 17958, 60619, 51234,\n",
       "         60625, 17948, 17947, 42776, 17940, 60632, 17936, 17977, 18023,\n",
       "         17978, 42766, 18013, 18012, 18011, 18010, 60598, 18006, 42758,\n",
       "         42759, 17996, 42760, 42761, 42764, 17984, 42765, 60608, 42767,\n",
       "         18127, 60552, 18137, 18255, 18254, 18253, 42679, 60498, 18247,\n",
       "         51274], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_exlamation': {'feature_present_idx': array([24600, 66290, 45167, 35890, 35721, 35621, 34876, 33272, 33245,\n",
       "         33213, 32441, 36036, 32418, 32207, 32102, 31717, 31625, 31600,\n",
       "         32837, 36480, 34257, 36514, 42056, 41152, 40927, 40818, 38974,\n",
       "         38894, 38416, 38179, 38007, 37688, 37604, 37250, 37205, 36976,\n",
       "         36969, 31080, 30422, 30351, 30301, 24296, 24269, 24240, 24182,\n",
       "         23947, 23739, 23435, 22978, 22911, 22613, 22575, 22276, 22220,\n",
       "         21856, 21822, 24396, 42148, 24493, 24711, 30294, 30261, 29812,\n",
       "         29714, 29415, 29267, 28802, 28028, 28001, 27481, 27193, 26255,\n",
       "         25926, 25278, 24958, 24606, 42303, 44110, 21336, 58732, 57987,\n",
       "         57324, 57273, 57104, 57033, 56730, 56662, 56412, 56339, 56330,\n",
       "         56175, 55902, 55525, 55361, 58927, 54662, 59049, 59653, 67038,\n",
       "         66923, 66260, 66181, 65449, 65135, 65006, 63428, 63196, 62785,\n",
       "         62688, 61831, 60483, 60416, 59835, 59461, 54407, 54103, 53976,\n",
       "         47908, 47787, 47700, 47439, 47318, 46590, 46471, 46346, 46190,\n",
       "         46167, 45950, 45303, 44842, 44788, 44504, 48051, 48054, 48107,\n",
       "         48827, 53533, 53327, 52719, 52555, 52425, 52041, 51892, 43512,\n",
       "         51342, 50772, 50510, 50332, 49914, 49763, 49285, 48915, 51328,\n",
       "         21162, 67243, 20956, 14639,  8061, 14725,  7686,  7387,  7363,\n",
       "         14758,  7124, 15169,  6780, 14595,  6544, 15938,  5982, 16169,\n",
       "         16218,  5286,  5121,  4941, 17121,  4860,  4357, 15924,  8119,\n",
       "          8222,  8456, 12220, 12336, 12219, 12150, 12066, 13297, 11728,\n",
       "         11690, 13447, 11604, 13528, 11577, 11345, 13691, 13700, 10794,\n",
       "         13733, 13979, 10741,  9643,  8719,  8676, 14460,  4163,  3521,\n",
       "         16105, 12312,  1083,  2803,  2841, 19772, 19357,  2709, 18181,\n",
       "         18523, 19392, 20137, 17561, 19122, 18874,   396,  3140, 18813,\n",
       "         20235, 46539,  9921, 46596, 46300, 63870, 47900, 63834, 63620,\n",
       "         48014, 63589,  8269, 48069,  1271, 48631,  8142,  1348, 46837,\n",
       "         46085, 64516, 64201, 39011, 66986, 39653, 40313, 40632,   413,\n",
       "         40873, 40916,   487, 41810, 41885,   747,   807, 66133, 42936,\n",
       "         66122, 44304,   878, 44539, 64972, 10797, 64255, 45624, 64038,\n",
       "          8084, 58869,  1728, 54091,  5853,  5704, 54516, 54531, 55041,\n",
       "          5559, 55486,  5307, 59371, 56367, 60052, 59149, 56551, 59054,\n",
       "          3068, 56780, 56838,  4089,  3918, 57458, 57936,  3580, 58119,\n",
       "          4904,  1480, 60310, 53727, 49861, 49913, 58892, 50172, 62163,\n",
       "          7591, 51172,  7242, 51682, 51884,  1973, 38961, 61380, 52083,\n",
       "         52156, 52293, 52326, 61152, 52504, 60782, 53450, 60656,  2198,\n",
       "         53525,  7093,  8060, 11778,   151, 18066, 14775, 14752, 32461,\n",
       "         25174, 25120, 32906, 32940, 33027, 24794, 33115, 27595, 67220,\n",
       "         34361, 34469, 35045, 35069, 35091, 18939, 35661, 35746, 25340,\n",
       "         31464, 15512, 30603, 27821, 28023, 28181, 27269, 28242, 17155,\n",
       "         29125, 29156, 27157, 27043, 19265, 29259, 26713, 26494, 29468,\n",
       "         29631, 30102, 26422, 38744, 26293, 15587, 17699, 16240, 35767,\n",
       "         34203, 27301, 36972, 23981, 37627, 12686, 37988, 37741, 36944,\n",
       "         19414, 19995, 22649, 22208, 20245, 36008, 20067, 13392, 36907,\n",
       "         22471, 38425, 36087, 38319, 36576, 21500, 36425, 20765, 38340,\n",
       "         41089, 25977,  6694, 20569, 54756, 15680, 38492, 37660, 31102,\n",
       "         27651, 25930, 16933,  6494, 53676, 39490, 29791, 26479, 16255,\n",
       "         38083, 55323, 54428, 55280, 66458, 20600, 40698, 40326, 30105,\n",
       "         26520, 46149, 32021, 35719,  9713, 36517, 46657, 45286, 14459,\n",
       "         46960, 35375, 62122, 34476, 44750, 31989, 61775, 48635, 61460,\n",
       "         48466, 14814, 32500, 50832, 14743, 25242, 59862, 63964, 42645,\n",
       "         32608, 43901, 11683, 13393, 24279, 63518, 27180, 63158, 62928,\n",
       "         61442, 24716,  3939, 26305, 19316, 24713, 66365, 21843, 19452,\n",
       "         61448, 66637, 21844, 38624,  5182, 34132,  8535, 17130, 46204,\n",
       "         45902, 11380, 44186, 51488, 43593, 12783, 41751, 41597, 12587,\n",
       "         40205, 39019, 38485, 37331, 15511, 53112, 54897, 54332, 52420,\n",
       "         29458, 52908, 53362, 30449,  6500,  5654, 54674, 12148, 24305,\n",
       "         46814, 41048, 21018, 40772, 28734, 39807, 49573, 66665, 66730,\n",
       "         50682,  2379, 21809, 56933, 15667, 25783, 42025, 25848, 57720,\n",
       "         66752, 55549,   960, 22660, 53985, 44443, 25193, 14289, 62812,\n",
       "         62686, 14631, 33850, 34109, 52031, 51380, 18171, 24530,  8686,\n",
       "         42322, 22757, 49830, 32656, 54489, 37540, 10185, 10700],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([52728, 57594, 57591, 28378, 12768, 12769, 12770, 12771, 12773,\n",
       "         28374, 45634, 12777, 45635, 28371, 12763, 28370, 45638, 45639,\n",
       "         57579, 57578, 28361, 57571, 12799, 57570, 57568, 57567, 57566,\n",
       "         12805, 12807, 12782, 45643, 12762, 28382, 28416, 12714, 12717,\n",
       "         12721, 28410, 12723, 45615, 28408, 28407, 57629, 45616, 57628,\n",
       "         57626, 57596, 45618, 28398, 28397, 12739, 12742, 57611, 57609,\n",
       "         45626, 57605, 45628, 28388, 57601, 28383, 57599, 45619, 28350,\n",
       "         12811, 12812, 28299, 12877, 12878, 45695, 12880, 45696, 57502,\n",
       "         57501, 45699, 57493, 45701, 12892, 12894, 57511, 45704, 12898,\n",
       "         12901, 45711, 45713, 28274, 45716, 45717, 28267, 12915, 28265,\n",
       "         57480, 28264, 45722, 45705, 57513, 57516, 57518, 12813, 45652,\n",
       "         28341, 28337, 12824, 45664, 12826, 57550, 12829, 28333, 28331,\n",
       "         12835, 57544, 45671, 45672, 45674, 28316, 45683, 12851, 12852,\n",
       "         12854, 28310, 57526, 12858, 57525, 57524, 12862, 12865, 28304,\n",
       "         12711, 45725, 12710, 57641, 28529, 12562, 28525, 57753, 57750,\n",
       "         12568, 45535, 28521, 28520, 28519, 12574, 57745, 57741, 28530,\n",
       "         12581, 57736, 57735, 12586, 45542, 57731, 57730, 45544, 12592,\n",
       "         12595, 12596, 12597, 12598, 45553, 12583, 28504, 12557, 28536,\n",
       "         57807, 57801, 57796, 12506, 57795, 45509, 45511, 12510, 12512,\n",
       "         28562, 57782, 28558, 12527, 28534, 12530, 45520, 57772, 12534,\n",
       "         57770, 28548, 28544, 12544, 57768, 12546, 57766, 12550, 57762,\n",
       "         28537, 28552, 45557, 57725, 28501, 12667, 28447, 57676, 28445,\n",
       "         28441, 45598, 12675, 12676, 28439, 57670, 57667, 57666, 57665,\n",
       "         28448, 28436, 45600, 57662, 57656, 12693, 28429, 12696, 45603,\n",
       "         57650, 28421, 45609, 57643, 57642, 12707, 45599, 12664, 12663,\n",
       "         28450, 57723, 28500, 28498, 28494, 57718, 57717, 28493, 57715,\n",
       "         45565, 45567, 28487, 28482, 45573, 28478, 28476, 12633, 12634,\n",
       "         28473, 45576, 57699, 12644, 45583, 57688, 12653, 45592, 57683,\n",
       "         45594, 28452, 12661, 45611, 57811, 45726, 45731, 45856, 57257,\n",
       "         13173, 57256, 13176, 45863, 45864, 45865, 57254, 57252, 13183,\n",
       "         57251, 28064, 57261, 28063, 57247, 13190, 28056, 13193, 45874,\n",
       "         28051, 13201, 28047, 45879, 57237, 28042, 13209, 57232, 45872,\n",
       "         13214, 13167, 28078, 57303, 57301, 57299, 57297, 28097, 45843,\n",
       "         28093, 28091, 45846, 57283, 28088, 45847, 13146, 28076, 45849,\n",
       "         13149, 28085, 13151, 28084, 57271, 13154, 28082, 57266, 57265,\n",
       "         13160, 13161, 28080, 28079, 13148, 57230, 28034, 13217, 13280,\n",
       "         45935, 45939, 13288, 13290, 13292, 13293, 45945, 13295, 27967,\n",
       "         45948, 27963, 13301, 45929, 57156, 27958, 13307, 27957, 27955,\n",
       "         13311, 13317, 27946, 57133, 57131, 13322, 57130, 45968, 13328,\n",
       "         45953, 45927, 13274, 13273, 57227, 13219, 13221, 57224, 57221,\n",
       "         45892, 28026, 57218, 45895, 13233, 28018, 45899, 57209, 57208,\n",
       "         13243, 28013, 13247, 45900, 13249, 45903, 45904, 13255, 57188,\n",
       "         13259, 27994, 27992, 45923, 13269, 13271, 57305, 57468, 57306,\n",
       "         28109, 45758, 12973, 57430, 57429, 57428, 57427, 28213, 57425,\n",
       "         57423, 12983, 45761, 28209, 57422, 12971, 12987, 12989, 28207,\n",
       "         57420, 28205, 57415, 57413, 13002, 13003, 57405, 57403, 57401,\n",
       "         57399, 28191, 28208, 57395, 12970, 28218, 45732, 12930, 28248,\n",
       "         28247, 45736, 28241, 28240, 28238, 45740, 12943, 57450, 28233,\n",
       "         57447, 12969, 12947, 28232, 45743, 12951, 12952, 57442, 57441,\n",
       "         45747, 28225, 28224, 57437, 12960, 57433, 12964, 12948, 45769,\n",
       "         13014, 13016, 28140, 13079, 28136, 13081, 28135, 13084, 57336,\n",
       "         57334, 28128, 28126, 13095, 13096, 28124, 57339, 13098, 45824,\n",
       "         13101, 57329, 13103, 57325, 13106, 45826, 13108, 28117, 45828,\n",
       "         13112, 28114, 28113, 45823, 57341, 57344, 45809, 28188, 57392,\n",
       "         57391, 13020, 57389, 28182, 45779, 57386, 13028, 13029, 45786,\n",
       "         57381, 28173, 13037, 13040, 28167, 57367, 57366, 57365, 13052,\n",
       "         57362, 45800, 57359, 45803, 28150, 45807, 57352, 13065, 57350,\n",
       "         28108, 12495, 12494, 45504, 58239, 58237, 58236, 45172, 28994,\n",
       "         11952, 28993, 45178, 28986, 11959, 28983, 28982, 28981, 58240,\n",
       "         28976, 58221, 11975, 11976, 45188, 58215, 28964, 58208, 11984,\n",
       "         11985, 58207, 11987, 28957, 58203, 11968, 11994, 58242, 11939,\n",
       "         29032, 58283, 29029, 29028, 11902, 45148, 58277, 58274],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 557\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 557\n",
       "  })},\n",
       " 'contains_negation': {'feature_present_idx': array([25342,  8916, 44753, 56681, 56714, 19156,  8887,  8865, 19165,\n",
       "          8835, 56809, 56825,  8921, 28965, 56855, 44693, 56876, 44692,\n",
       "          8735, 34027, 44677, 19230, 44660, 34018, 57007, 19166, 33979,\n",
       "         19130, 44771,  9189,  9188, 56300, 56326, 18943, 44875, 18982,\n",
       "         56404, 56409,  9115, 44865, 26666, 37090,  9094,  9078, 19013,\n",
       "         56517, 19035,  9045, 19068, 37101, 44828, 56575, 56613, 56507,\n",
       "          9210, 57050, 19277, 57322,  8367, 19470, 19472, 44428, 57421,\n",
       "         57440, 33924,  8323, 29157, 57490, 44474, 44415, 33895, 44390,\n",
       "         57542, 57546, 57573, 57602, 44336, 33874, 44329, 19587, 44309,\n",
       "          8290, 44601, 57300, 57291, 57070, 57081, 44594, 33959,  8621,\n",
       "          8619, 37171, 44568, 57118, 44556, 29060, 19461, 19368,  8499,\n",
       "         33945,  8471, 26605, 44519, 19446, 26598,  8427,  8424,  8411,\n",
       "         33944, 19376, 57726, 44916, 56244, 10151, 18248, 55223, 45581,\n",
       "         55289, 26816, 55313, 10093, 10070, 34381, 28679, 55193,  9972,\n",
       "         18444, 18453, 26792, 45420, 28692, 55642, 18471, 45394, 55666,\n",
       "         34371, 18524, 45450, 18526, 55174, 18240, 54832, 36842, 45906,\n",
       "         18053, 36881, 10449, 54931, 45817, 18082, 28614, 10425, 18242,\n",
       "         45798, 28619, 45721, 45694, 36887, 18172, 10307, 55095, 18179,\n",
       "         28673, 55144, 45662, 55005, 44918, 28707, 55757,  9526, 45099,\n",
       "          9489, 26751, 34263, 56063, 28807, 56081, 34245,  9419,  9418,\n",
       "         56009,  9379, 34216,  9351,  9339, 34193, 44990, 26727, 56157,\n",
       "         56216,  9256, 18910,  9230, 34219, 34364, 56000, 45143, 45312,\n",
       "         55792,  9799, 34354, 18559, 34308,  9741, 37004,  9735,  9734,\n",
       "          9725, 18731, 18599, 28741, 55845, 18628, 18634, 26771, 55905,\n",
       "         55910,  9609, 45176, 45173,  9588, 18607, 44298,  8167, 19629,\n",
       "         59250, 26437, 20653, 43301, 20679, 37403, 59308, 59314,  6531,\n",
       "         20688, 29642, 43339, 43275, 59367, 33615, 43230, 26413,  6437,\n",
       "         43185, 59458, 59507, 59524, 20830,  6360, 43265, 33513,  6583,\n",
       "         59225, 20539, 20543, 20549,  6812, 43408,  6794, 20562, 43404,\n",
       "         67339, 59118, 59125, 43354,  6730, 59135, 29590, 59152,  6646,\n",
       "          6641,  6639, 59177, 29596, 37355, 43358, 29613, 20581, 37341,\n",
       "          6354,  6337,  6010,  5990, 60037, 33402, 21153, 42775, 26314,\n",
       "         21183,  5906, 42751, 37649, 42794, 26294, 60198, 26288, 33372,\n",
       "         60241, 60269, 37664, 26277,  5770, 21256, 42611,  5759,  5857,\n",
       "          6341,  6039,  6045, 20853, 33486, 59688, 43071,  6270,  6267,\n",
       "         37534,  6250,  6249, 20925,  6240, 21126, 42996, 33454,  6169,\n",
       "         59860,  6136, 26341, 42906, 26339,  6073,  6064,  6062, 33416,\n",
       "          6217, 20527, 59082, 29551, 58162, 43910, 29282, 58190,  7822,\n",
       "          7812, 58225, 43890, 19903, 33777, 58257, 29279, 58264, 58345,\n",
       "         19916, 29298,  7708, 43868,  7679, 43867, 43861, 19925, 58390,\n",
       "         43841, 29291, 58408, 58150, 43927, 26586, 44216, 44161, 19662,\n",
       "         44138, 44086, 44083, 44061,  8032, 29222, 57944,  7857, 19767,\n",
       "         19784, 58015, 43977, 58062,  7905, 19844,  7876, 58100, 58123,\n",
       "         43934, 58137, 57984, 29318,  7550, 58447, 33703, 37291, 20312,\n",
       "          7183,  7172, 43489, 58777, 43482, 20368, 20375, 58854, 20279,\n",
       "         20383, 29501, 43442,  7057, 20400,  7049, 58916,  7011, 58968,\n",
       "         20460, 59051, 59074, 43449, 29464, 20207, 58722, 19946, 19952,\n",
       "          7517, 58477, 49652,  7504,  7478, 58500,  7476,  7463,  7427,\n",
       "          7403, 29371,  7391, 43610, 37287, 58641, 20159, 20160,  7324,\n",
       "         20173,  7311, 29439, 58705, 58716, 18028, 42606, 45944, 34565,\n",
       "         13461, 51340, 13436, 48244, 48233, 15932, 48226, 15949, 15951,\n",
       "         48212, 15973, 13478, 51420, 15977, 16008, 13310, 48170, 51544,\n",
       "         51556, 51569, 13232, 51582, 16096, 36133, 13360, 27940, 13486,\n",
       "         13496, 48612, 36071, 13721, 48576, 51089, 13694, 35432, 15720,\n",
       "         13648, 35431, 27324, 36112, 13628, 48545, 36076, 51161, 36101,\n",
       "         48483, 15759, 27311, 15804, 15830, 13506, 35368, 51140, 48618,\n",
       "         27942, 13155, 51889, 12843, 16368, 51902, 36192, 47723, 47706,\n",
       "         12787, 47675, 47650, 47605, 28027, 27197, 47589, 47584, 12713,\n",
       "         28048, 36216, 12699, 28057, 12660, 47532, 52062, 16472, 51979,\n",
       "         51676, 35245, 12874, 13120, 13080, 51733, 13057, 48074, 47983,\n",
       "         47979, 27241, 13017, 51775, 12993, 51863, 47923, 47856, 51839,\n",
       "         35259, 27240, 12923, 27984, 47807, 47790, 47789, 36185, 47780,\n",
       "         47862, 16478, 48643, 15691, 15055, 49407, 50072, 14509, 27668,\n",
       "         49384, 14485, 15095, 15096, 15101, 50175, 14569, 50185, 35889,\n",
       "         35636, 49364, 50208, 50229, 35902, 15147, 49338, 49336, 15177,\n",
       "         49326, 15114, 14364, 35672, 35683, 35738, 14816, 14852, 14861,\n",
       "         14868, 49585, 14787, 49702, 27540, 27588, 35708, 49951, 49533,\n",
       "         27615, 35697, 27632, 49494, 14660, 35814, 14652, 14648, 49902,\n",
       "         27640, 49473, 14934, 13755, 15201, 14339, 48944, 48942, 50671,\n",
       "         36000, 35562, 50754, 15552, 50755, 50756, 13914, 15562, 14036,\n",
       "         13902, 50810, 48797, 50846, 48782, 15580, 13832, 15605, 27781,\n",
       "         15638, 13789, 13781, 27774, 35909, 27752, 50519, 15230, 49297,\n",
       "         14274, 49265, 49261, 49245, 50325, 14234, 50331, 49236, 49229,\n",
       "         35573, 49188, 35599, 49103, 50387, 35969, 49002, 14060, 14057,\n",
       "         35984, 50473, 50486, 50487, 50337, 47480, 12627, 35219, 46619,\n",
       "         17285, 11277, 46594, 11251, 53776, 17323, 28369, 11229, 11213,\n",
       "         17346, 11305, 17349, 34791, 53867, 17372, 26961, 11153, 46504,\n",
       "         17425, 11088, 46464, 54004, 54052, 11201, 11030, 11327, 46629,\n",
       "         53334, 34921, 53396, 27017, 53437, 17120, 46734, 11509, 46723,\n",
       "         46676, 53460, 46620, 11458, 11433, 11426, 53554, 11404, 46650,\n",
       "         46649, 53624, 17243, 28329, 17256, 34856, 53500, 53307, 17516,\n",
       "         46420, 17829, 17855, 54421, 54440, 54459, 54514, 10672, 34596,\n",
       "         54610, 10656, 54630, 28528, 17908, 10612, 10604, 54660, 28591,\n",
       "         10545, 10535, 10534, 45992, 54740, 10493, 54749, 10620, 17552,\n",
       "         36754, 17780, 54132, 34726, 10985, 17594, 54157, 46371, 46363,\n",
       "         54186, 10940, 54212, 10936, 17787, 46345, 34687, 54247, 46264,\n",
       "         17695, 10857, 34675, 17703, 17723, 26929, 46238, 46224, 26942,\n",
       "         34924, 46786, 53269, 28129, 36385, 52407, 52412, 16730, 52477,\n",
       "         12237, 52497, 16768, 36413, 52557, 47268, 52561, 27100, 12154,\n",
       "         52598, 12137, 52612, 12117, 36437, 16840, 27090, 12107, 36470,\n",
       "         35155, 12091, 52332, 52327, 47425, 12614, 27176, 36239, 47389,\n",
       "         16520, 36279, 16542, 25349, 16545, 28104, 12343, 16563, 12508,\n",
       "         36288, 52242, 35180, 52250, 47324, 12429, 52268, 47302, 52300,\n",
       "         12400, 52213, 52681, 47071, 52694, 17010, 53016, 11840, 17039,\n",
       "         11808, 53041, 35026, 11753, 46859, 53088, 11735, 46925, 11725,\n",
       "         11719, 53098, 53108, 34962, 34952, 46807, 17078, 17082, 53206,\n",
       "         11621, 53262, 11723, 35038, 53000, 52960, 52699, 35130, 52726,\n",
       "         35128, 52762, 28170, 16921, 36521, 12005, 52781, 11988, 16953,\n",
       "         11955, 36552, 52850, 46947, 52851, 52874, 35053, 16985, 36564,\n",
       "         11901, 35046, 52954, 11889, 54773,  5755, 58480,  5741, 30667,\n",
       "         23211,  2866, 64128, 64146,  2844, 64186,  2820,  2786, 23175,\n",
       "         25815, 23294,  2745, 23312, 23323,  2722,  2719, 40391, 40375,\n",
       "         32269, 23268, 23353, 30653, 64046, 63733, 63775, 40612, 23032,\n",
       "         23041, 23050, 63807, 40566, 23053,  5753, 38142, 63878,  3053,\n",
       "          3047, 63909,  3016, 63945, 30632, 40497, 23140,  3062,  3157,\n",
       "         40362, 32253, 25740, 32136, 64626,  2383, 64633, 40050,  2346,\n",
       "         40048, 40022, 32166, 40008, 64709,  2251, 64743, 64759, 64771,\n",
       "          2207, 64807, 31991, 64843, 23548, 40299, 25763, 64510, 64355,\n",
       "         32223, 64367, 32222, 30749, 40279,  2601, 23406,  2588,  2441,\n",
       "          2578, 40266,  2563, 40245, 23459, 64467, 40214, 64502, 30753,\n",
       "         40208,  2573,  2130, 40659,  3169,  3926, 41161,  3884, 62977,\n",
       "         41149], dtype=int64),\n",
       "  'feature_absent_idx': array([52160, 60143, 11668, 11669, 33114, 60140, 11672, 11673, 60139,\n",
       "         11676, 60138, 54655, 11679, 33112, 33111, 20302, 33109, 20301,\n",
       "         20300, 46712, 20299, 60130, 33104, 11695, 33117, 50448, 33120,\n",
       "         11659, 11630, 20316, 33136, 33135, 20315, 54646, 11636, 33130,\n",
       "         11638, 33129, 20313, 11696, 11641, 11644, 11647, 54650, 11649,\n",
       "         54651, 11651, 11653, 50450, 46703, 11656, 54653, 60154, 60129,\n",
       "         11699, 11700, 33079, 33077, 46729, 46730, 33073, 46731, 60107,\n",
       "         27111, 60104, 11749, 33070, 11739, 54666, 60100, 33067, 11758,\n",
       "         46737, 50434, 27113, 27114, 33059, 11765, 11766, 33057, 46735,\n",
       "         11629, 11738, 11736, 33100, 11704, 20294, 11706, 11707, 11708,\n",
       "         60128, 50446, 11711, 50442, 60124, 11737, 27104, 33093, 33092,\n",
       "         11722, 54665, 33086, 33082, 20281, 11731, 60113, 11733, 11734,\n",
       "         20290, 11628, 60160, 11626, 20350, 60235, 46609, 11530, 27066,\n",
       "         50462, 46617, 11534, 11535, 33209, 11538, 33218, 11539, 33203,\n",
       "         60228, 46632, 11546, 11549, 33196, 46638, 50460, 54629, 11557,\n",
       "         33191, 33207, 11559, 50463, 11520, 46588, 60258, 46589, 60256,\n",
       "         33241, 11493, 33239, 33238, 11498, 60253, 11501, 20352, 11502,\n",
       "         60248, 46591, 54623, 27061, 54625, 50465, 11513, 60243, 46602,\n",
       "         46603, 60238, 60249, 60093, 33187, 27075, 11598, 33162, 60183,\n",
       "         46671, 33158, 60180, 54639, 11607, 60178, 20321, 33152, 11597,\n",
       "         11611, 54641, 11615, 50452, 33143, 60168, 33142, 46688, 20317,\n",
       "         60164, 33139, 33138, 46679, 46647, 46670, 50457, 60210, 11565,\n",
       "         27076, 11567, 60209, 60206, 33181, 50459, 50458, 11573, 33178,\n",
       "         11591, 11575, 27080, 20331, 60191, 27081, 60189, 11584, 60188,\n",
       "         11586, 27082, 20327, 11589, 54632, 11486, 54670, 20267, 54723,\n",
       "         59971, 46832, 11975, 11976, 50406, 50405, 59964, 59963, 32914,\n",
       "         11984, 11985, 59960, 11987, 20197, 59959, 59958, 59956, 11994,\n",
       "         11995, 46835, 20196, 59953, 27171, 54719, 54718, 11968, 11931,\n",
       "         59992, 46812, 46815, 54705, 46816, 11939, 11940, 27160, 59987,\n",
       "         59986, 46844, 59984, 54712, 11952, 46818, 32936, 32935, 27166,\n",
       "         11959, 32931, 54715, 32926, 32925, 27164, 59950, 32899, 50403,\n",
       "         12045, 12046, 12047, 27183, 50400, 59922, 32876, 59921, 12056,\n",
       "         32875, 59920, 32880, 12059, 12062, 54735, 12064, 20181, 59917,\n",
       "         54736, 59915, 20179, 59914, 32867, 59911, 46863, 59993, 59930,\n",
       "         59933, 32896, 46851, 12013, 12014, 12015, 12017, 59945, 20191,\n",
       "         59944, 12022, 59943, 46862, 59942, 46852, 12029, 32891, 32890,\n",
       "         12033, 27181, 59936, 59935, 46860, 59934, 54734, 54730, 59995,\n",
       "         59996, 20219, 33025, 46759, 20252, 11817, 60065, 11821, 20249,\n",
       "         20248, 11826, 11827, 11828, 11811, 60056, 33014, 11832, 20246,\n",
       "         11834, 60053, 50427, 46769, 20244, 54688, 20242, 33007, 11830,\n",
       "         60047, 27129, 11806, 60083, 11777, 60082, 11779, 27121, 11781,\n",
       "         50432, 11784, 11785, 54675, 27123, 11809, 46747, 46749, 27126,\n",
       "         60073, 50430, 33036, 33035, 46755, 11802, 54678, 11804, 11805,\n",
       "         20261, 20268, 33004, 11850, 27156, 32974, 32971, 60015, 60013,\n",
       "         11902, 20224, 54700, 11906, 32965, 20222, 60018, 60006, 46802,\n",
       "         11914, 32959, 20221, 46804, 32956, 32955, 11922, 11923, 54702,\n",
       "         32953, 32963, 11848, 46787, 11885, 60041, 60039, 60038, 27143,\n",
       "         27144, 60031, 60028, 54694, 11861, 32998, 32996, 60020, 46783,\n",
       "         50424, 60024, 11874, 46784, 11876, 27147, 32986, 27148, 32983,\n",
       "         11882, 50422, 32993, 12075, 11484, 11482, 33555, 11065, 33553,\n",
       "         11069, 11071, 26936, 46406, 50555, 26940, 60478, 60477, 11080,\n",
       "         60475, 20501, 60472, 50554, 50553, 60469, 54542, 33537, 46417,\n",
       "         11094, 50552, 33556, 46402, 60489, 11059, 33575, 20520, 20519,\n",
       "         20518, 46389, 33570, 50558, 46390, 11036, 11037, 60498, 33532,\n",
       "         46393, 11044, 11045, 26932, 60495, 60494, 11052, 11053, 60492,\n",
       "         11055, 46399, 20508, 11042, 54546, 33530, 33528, 11139, 60438,\n",
       "         60436, 11142, 33497, 60435, 60430, 20475, 11150, 46434, 20474,\n",
       "         20478, 60428, 33485, 11159, 46439, 20472, 46442, 11164, 20471,\n",
       "         60421, 60420, 46446, 46447, 33489, 33577, 46428, 60440, 60464,\n",
       "         54547, 26948, 33523, 11110, 20488, 50541, 33516, 11116, 33515,\n",
       "         33514, 46427, 11119, 26965, 54550, 11123, 11124, 20482, 50535,\n",
       "         33507, 33506, 33505, 46426, 33501, 60453, 33578, 60515, 60517,\n",
       "         20559, 60579, 10905, 26905, 26906, 10910, 10911, 50564, 10913,\n",
       "         60577, 33637, 50566, 60574, 10922, 60572, 54503, 60571, 46361,\n",
       "         33633, 10928, 10931, 10932, 20552, 20551, 10921, 26910, 10900,\n",
       "         54499, 10866, 54495, 46341, 46342, 33679, 20575, 46343, 10874,\n",
       "         46344, 60587, 26897, 46353, 10879, 10882, 10883, 33664, 33663,\n",
       "         46349, 46350, 54497, 10889, 33653, 10893, 10894, 26899, 46449,\n",
       "         10938, 10943, 10986, 10987, 60535, 60533, 10991, 60531, 33594,\n",
       "         33593, 20530, 60529, 60526, 33596, 60524, 33590, 60523, 11006,\n",
       "         46382, 11010, 20525, 46383, 33583, 54525, 33581, 11018, 54520,\n",
       "         54509, 10982, 20533, 60559, 10947, 60558, 46372, 60552, 60551,\n",
       "         26915, 10958, 20540, 10960, 46374, 26920, 33609, 33608, 10967,\n",
       "         20538, 26918, 50561, 54518, 54519, 33601, 46377, 10978, 60547,\n",
       "         10963, 60260, 33471, 20469, 11371, 33330, 20396, 33327, 46546,\n",
       "         11378, 33324, 54587, 50493, 33315, 11390, 27037, 11392, 33306,\n",
       "         33305, 33304, 11397, 60305, 46558, 11400, 33302, 33300, 60300,\n",
       "         33334, 46542, 27022, 11366, 33363, 60338, 33362, 20411, 11340,\n",
       "         20409, 33356, 50498, 27013, 46530, 60332, 11409, 11350, 11353,\n",
       "         11354, 11355, 20403, 60329, 27018, 46536, 11361, 11363, 46538,\n",
       "         50496, 11352, 11410, 33295, 50479, 46573, 33269, 11455, 46575,\n",
       "         50475, 11459, 33266, 33265, 11462, 33263, 54614, 50476, 11465,\n",
       "         54616, 60275, 60274, 11471, 33256, 46582, 11476, 60270, 33249,\n",
       "         33248, 33246, 60280, 20412, 60287, 33276, 11417, 60292, 11419,\n",
       "         46563, 33290, 11422, 11423, 46564, 33288, 11427, 11428, 46572,\n",
       "         11429, 11432, 11434, 33287, 11437, 33283, 20374, 33280, 27046,\n",
       "         33278, 20372, 11447, 11430, 11331, 60340, 60342, 26982, 26983,\n",
       "         11217, 11219, 11220, 54562, 33438, 11223, 50523, 11226, 54564,\n",
       "         11214, 11230, 11233, 60394, 46480, 33429, 54566, 33426, 20439,\n",
       "         46482, 11244, 33421, 46486, 26987, 11248, 46475, 20452, 11176,\n",
       "         11177, 26974, 20465, 46458, 54558, 50527, 60410, 54559, 54560,\n",
       "         50526, 11211, 11191, 20456, 11194, 33453, 11196, 46462, 33451,\n",
       "         11202, 20454, 46472, 46473, 60401, 33456, 33470, 60390, 11254,\n",
       "         20426, 33387, 54571, 46510, 33384, 54573, 20423, 11303, 50507,\n",
       "         11306, 11307, 60367, 33380, 46513, 20420, 20419, 11314, 20418,\n",
       "         50506, 33367, 11321, 60345, 60344, 46518, 46511, 33418, 33390,\n",
       "         33394, 60387, 60386, 46487, 46488, 11259, 46489, 46490, 46493,\n",
       "         60382, 46494, 33407, 27000, 50515, 11274, 50512, 11276, 60374,\n",
       "         60373, 11281, 20430, 11285, 33396, 11287, 54568, 46495, 33689,\n",
       "         59909, 12079, 12877, 12878, 32328, 12880, 47238, 59426, 19899,\n",
       "         47240, 47244, 54922, 32316, 12892, 47249, 12894, 47251, 32312,\n",
       "         12898, 32311, 47253, 12901, 32309, 27401, 32306, 27399, 59435,\n",
       "         27398, 19902, 32348, 54907, 47218, 27394, 54909, 54912, 59456,\n",
       "         59454, 27395, 59452, 12851, 27402, 12852, 12854, 59449, 47227,\n",
       "         12858, 32338, 47229, 12862, 59444, 12865, 54915, 59441, 32340,\n",
       "         47264, 59412, 59411, 59387, 12951, 12952, 32278, 59385, 59384,\n",
       "         59383, 12960, 32276, 27413, 12964, 47282, 19875, 12969, 12970,\n",
       "         12971, 47286, 12973, 59368, 59363, 47289, 59358, 59357, 27417,\n",
       "         32270, 59460, 12948, 59389, 19893, 47269, 32297, 12915, 59406,\n",
       "         19889, 32293, 47274, 19886, 19885, 32287, 12947, 12930, 50273,\n",
       "         32284, 27408, 59395, 59393, 19882, 59392, 19880, 59391, 27409,\n",
       "         12943], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_conjunctions': {'feature_present_idx': array([26169, 41912, 16226, 41918, 16212, 16211, 55436, 16244, 16200,\n",
       "         16177, 16174, 16168, 41966, 41967, 41977, 16193, 16249, 16258,\n",
       "         62494, 41760, 16400, 55465, 41801, 16337, 41824, 16324, 41829,\n",
       "         41833, 41846, 55457, 16309, 41864, 41865, 41869, 16145, 16144,\n",
       "         16124, 62519, 15854, 15847, 15807, 15797, 31721, 15770, 42255,\n",
       "         62626, 15726, 62631, 15708, 15706, 42290, 15663, 15659, 42186,\n",
       "         41754, 42167, 15911, 55421, 62525, 42007, 62527, 16062, 42021,\n",
       "         42030, 16029, 42072, 15993, 42079, 42090, 62571, 15928, 42141,\n",
       "         15889, 16433, 16439, 62419, 41363, 16960, 41381, 16949, 16942,\n",
       "         41411, 16917, 62259, 16904, 16899, 62270, 16864, 16862, 62285,\n",
       "         62291, 41357, 16833, 16965, 62223, 41251, 17109, 17102, 17095,\n",
       "         17083, 17058, 17054, 55606, 17025, 17018, 41323, 41325, 16995,\n",
       "         41353, 16983, 16975, 15642, 16815, 16789, 16550, 41648, 62371,\n",
       "         62382, 16527, 62384, 41677, 41683, 41690, 16475, 55473, 41712,\n",
       "         16467, 62411, 16451, 55489, 41463, 16608, 41590, 16773, 62319,\n",
       "         41491, 41508, 41514, 55553, 41519, 41527, 16704, 55551, 41547,\n",
       "         16688, 16678, 16659, 41588, 55518, 17150, 15608, 15601, 62960,\n",
       "         43067, 14777, 14776, 55092, 43085, 14795, 62973, 14736, 43124,\n",
       "         14724, 14720, 43129, 63006, 43090, 43064, 43060, 62953, 42980,\n",
       "         62933, 42989, 14913, 14902, 62938, 14880, 14876, 62945, 55109,\n",
       "         43017, 43021, 14841, 43040, 43050, 14699, 14683, 14682, 14676,\n",
       "         14519, 55044, 14516, 43299, 14475, 55034, 14456, 14450, 63068,\n",
       "         63071, 43325, 14391, 14375, 43363, 55027, 14520, 42977, 43261,\n",
       "         14556, 14672, 14666, 14650, 14646, 43172, 14618, 43174, 43175,\n",
       "         43179, 14597, 14591, 14588, 14579, 43207, 43218, 14532, 14939,\n",
       "         42959, 14955, 15427, 42540, 15420, 42542, 15403, 42587, 42599,\n",
       "         42609, 62746, 15350, 15349, 62756, 42662, 42675, 42695, 42529,\n",
       "         42700, 15449, 42478, 42355, 15581, 15574, 62646, 15570, 62659,\n",
       "         15548, 55283, 42405, 42419, 62665, 15522, 15503, 15496, 15471,\n",
       "         15455, 62645, 15278, 15268, 55130, 42904, 62876, 15035, 15022,\n",
       "         62880, 42927, 15001, 62886, 62891, 14984, 42947, 14970, 62897,\n",
       "         42954, 55136, 55191, 15079, 55150, 15237, 15232, 15231, 15222,\n",
       "         15203, 62800, 62819, 42736, 42744, 42803, 42839, 15123, 15117,\n",
       "         42848, 15110, 42876, 14300, 17151, 17183, 40026, 40035, 19063,\n",
       "         40049, 19048, 19024, 19081, 40079, 55907, 18987, 18983, 61784,\n",
       "         18957, 55891, 40082, 40006, 19095, 19097, 39897, 39911, 55941,\n",
       "         55940, 19219, 39950, 19203, 19186, 39953, 55935, 39959, 39982,\n",
       "         19153, 19136, 19126, 18935, 61797, 61805, 55889, 18747, 18739,\n",
       "         40291, 40295, 18709, 40332, 61843, 40376, 40383, 18633, 40395,\n",
       "         40399, 18625, 18618, 40417, 40286, 39896, 18757, 18766, 18895,\n",
       "         18882, 18878, 40164, 18845, 18837, 40224, 55869, 18822, 40231,\n",
       "         18804, 18793, 40242, 18781, 40281, 18762, 19276, 39893, 61691,\n",
       "         19749, 19738, 19728, 39662, 55990, 61551, 19705, 61552, 39695,\n",
       "         19682, 61555, 61556, 19653, 61564, 39722, 39635, 19628, 19761,\n",
       "         19769, 39565, 39568, 39579, 39581, 39584, 39604, 19845, 19843,\n",
       "         19822, 56021, 56008, 61524, 19797, 19789, 19781, 39634, 55838,\n",
       "         55985, 61574, 19388, 19387, 19384, 39841, 19382, 19378, 19372,\n",
       "         61670, 39871, 61680, 61681, 19307, 55957, 39891, 19292, 19397,\n",
       "         61571, 19424, 61652, 39742, 61580, 39755, 61593, 19536, 61600,\n",
       "         19508, 19503, 39794, 19497, 19496, 19492, 19483, 39815, 39833,\n",
       "         39836, 17166, 18577, 61875, 40908, 55714, 55711, 17662, 17644,\n",
       "         17641, 17706, 17639, 62063, 17628, 17622, 17621, 17604, 40983,\n",
       "         40955, 17712, 17717, 17738, 17890, 55745, 55743, 17877, 62036,\n",
       "         17860, 40800, 55724, 17843, 17811, 40845, 17801, 17795, 17760,\n",
       "         55719, 40985, 55693, 62071, 41026, 17304, 62135, 41182, 17290,\n",
       "         17284, 41191, 17250, 17249, 41221, 55640, 41230, 55629, 17200,\n",
       "         17188, 17186, 17305, 62014, 17332, 41148, 17565, 17551, 17501,\n",
       "         17496, 17479, 17463, 17451, 17436, 41111, 62097, 17403, 17390,\n",
       "         17374, 62115, 41136, 41162, 17907, 17917, 17930, 55821, 40494,\n",
       "         18382, 40512, 18360, 40514, 18347, 18338, 40524, 40526, 18317,\n",
       "         18312, 40541, 18286, 18285, 40487, 18268, 18416, 55825, 40420,\n",
       "         18556, 18555, 40422, 40423, 18500, 61900, 40442, 18467, 18463,\n",
       "         40456, 40464, 18456, 40471, 18430, 18418, 55830, 40556, 18231,\n",
       "         18034, 55767, 55761, 18020, 18016, 40669, 18000, 61993, 61994,\n",
       "         55756, 17975, 40695, 40701, 40703, 40728, 18035, 18245, 61987,\n",
       "         55789, 40572, 18219, 40579, 18192, 61971, 40608, 18162, 18148,\n",
       "         40615, 18134, 40631, 18099, 18092, 18079, 40645, 40651, 14299,\n",
       "         14282, 63094, 54324, 54307, 10360, 10322, 10315, 54305, 45797,\n",
       "         54304, 10269, 10261, 10254, 10247, 10246, 45861, 10276, 10407,\n",
       "         10410, 45794, 64193, 10551, 54356, 45702, 45707, 54352, 10512,\n",
       "         54345, 64210, 10483, 10471, 10470, 45745, 45764, 45782, 10221,\n",
       "         10208, 45881, 10201, 46033, 46057,  9984, 64371,  9968, 46064,\n",
       "          9958, 46094,  9922,  9914, 64387,  9911,  9910, 46112, 46127,\n",
       "         10036, 54358, 10052, 10079, 45889, 45890, 45891, 45894, 10179,\n",
       "         10165, 64317, 45910, 54292, 45925, 45937, 45958, 45973, 45978,\n",
       "         45979, 45991, 10566, 45668, 10573, 64048, 10983, 10969, 10968,\n",
       "         10965, 45472, 64059, 10907, 45492, 10899, 10890, 10881, 10880,\n",
       "         10875, 10868, 45412, 10860, 45408, 11009, 11165, 45314, 11133,\n",
       "         11106, 11104, 45325, 45336, 11083, 45362, 45380, 45392, 11028,\n",
       "         45399, 11017, 11014, 64031, 46139, 10851, 45519, 64156, 64158,\n",
       "         45617, 64167, 64173, 45623, 45627, 45633, 10600, 10596, 10594,\n",
       "         10586, 45656, 10581, 64179, 45614, 45514, 45585, 64147, 64087,\n",
       "         10826, 10823, 10816, 10814, 64095, 45534, 10783, 10781, 45539,\n",
       "         10751, 10748, 10731, 64144, 45559, 45569, 54427, 46142, 46157,\n",
       "         46715,  8868, 46722,  8841, 64772,  8831,  8877, 46750,  8804,\n",
       "         46776,  8786,  8783,  8780, 46788,  8826,  8906,  8909,  8910,\n",
       "         46600,  9065, 64698,  9039, 64702,  9013,  9000,  8988, 46645,\n",
       "         64711,  8957,  8955,  8944,  8943, 46681, 46797,  8761,  8759,\n",
       "         46801, 46915, 46918,  8570,  8564,  8562,  8561, 64865, 46920,\n",
       "          8533,  8521,  8509, 46950, 46951, 53998,  8477,  8576, 54119,\n",
       "          8587,  8631, 54034,  8753, 64804, 54028,  8713,  8710, 46824,\n",
       "         46834, 46839, 64825, 46848,  8652, 54023, 54008, 64837,  8600,\n",
       "          9110, 54121,  9139, 46240,  9663,  9660, 54201,  9652,  9636,\n",
       "         64519, 46275, 46281, 46310,  9548,  9545, 46327,  9534,  9531,\n",
       "         64495, 46328,  9690,  9722, 64436, 46161,  9854, 46170,  9830,\n",
       "          9814,  9809,  9798, 54236, 54234, 64470,  9757,  9740, 64484,\n",
       "         46213,  9720, 46147,  9516,  9484, 54177, 46461, 46465, 64624,\n",
       "          9264, 54151, 46477,  9248, 54126, 46527, 46535, 46541, 64661,\n",
       "          9142, 46554,  9318,  9501,  9336, 46443, 64559,  9465,  9452,\n",
       "         46357, 46362, 64571,  9427, 46369, 46376,  9415, 46378,  9396,\n",
       "         46392, 46418,  9349,  9337, 11184, 54431, 45289, 13200, 13196,\n",
       "         13177, 13169, 63434, 54803, 13203, 44114, 13100, 13085, 13077,\n",
       "         54790, 44172, 63470, 54797, 13212, 44057, 13227, 13373, 43973,\n",
       "         13363, 43991, 43998, 13318, 44003, 13306, 54818, 63395, 44037,\n",
       "         44048, 44054, 13239, 44055, 44182, 13023, 13021, 54771, 44290,\n",
       "         54728, 12830, 63531, 44319, 54725, 44354, 12775, 12766, 44358,\n",
       "         12754, 12740, 12736, 63553, 44367, 12893, 63351, 12895, 44268,\n",
       "         44191, 12995, 44194, 12984, 12981, 44200, 44209, 44221, 44226,\n",
       "         63507, 44229, 12938, 12933, 12932, 12925, 44283, 54841, 13419,\n",
       "         13442, 43514, 14061, 43517, 14048, 13966, 13959, 63187, 43574,\n",
       "         13931, 43595, 13906, 13893, 43608, 13876, 13874, 43511, 13865,\n",
       "         43510], dtype=int64),\n",
       "  'feature_absent_idx': array([13565, 58941, 33888, 58937, 16458, 58935, 16462, 33887, 33885,\n",
       "         58933, 33883, 16474, 33880, 16477, 33878, 58928, 33875, 58925,\n",
       "         16490, 50016, 33867, 16493, 16494, 16496, 50021, 58919, 16504,\n",
       "         33860, 16453, 50024, 33889, 16444, 33932, 16378, 16380, 16382,\n",
       "         49999, 33927, 50000, 16393, 16394, 16397, 58966, 16401, 16407,\n",
       "         33916, 33914, 16414, 16415, 16420, 16422, 16424, 33904, 16428,\n",
       "         33903, 33902, 58951, 58950, 16443, 33892, 16376, 58915, 58914,\n",
       "         16579, 33817, 50046, 16585, 16586, 16588, 50049, 33808, 33804,\n",
       "         33802, 58865, 33798, 33797, 16607, 58859, 50055, 33792, 33790,\n",
       "         33788, 16626, 16627, 33787, 58851, 50058, 50060, 33783, 58842,\n",
       "         16578, 16510, 16575, 58884, 58912, 16517, 33855, 58907, 16522,\n",
       "         16532, 16533, 16534, 33840, 16537, 58897, 16539, 58894, 16543,\n",
       "         16544, 33836, 16551, 33835, 33834, 16560, 33827, 33825, 16564,\n",
       "         16566, 33821, 33820, 58885, 58882, 50062, 49994, 58974, 16173,\n",
       "         49931, 16178, 34066, 34065, 16182, 34064, 34054, 59073, 16196,\n",
       "         34053, 34050, 16201, 49941, 16203, 34047, 34046, 34043, 16216,\n",
       "         34040, 16219, 59058, 34033, 16222, 16223, 16227, 34029, 59087,\n",
       "         34026, 59088, 16165, 16117, 49891, 49897, 49898, 16122, 16123,\n",
       "         16125, 16126, 16129, 49901, 59112, 59110, 16135, 16136, 16138,\n",
       "         34093, 34092, 59106, 16142, 49923, 16151, 59104, 16155, 34077,\n",
       "         59093, 59092, 16164, 59089, 16373, 49948, 59045, 33970, 49976,\n",
       "         16321, 49978, 33966, 33961, 16332, 33960, 58992, 16339, 16340,\n",
       "         16343, 49985, 49988, 16347, 33954, 58987, 16350, 16356, 58982,\n",
       "         16358, 58981, 16360, 16364, 33939, 33937, 16369, 16316, 34022,\n",
       "         16313, 33975, 16241, 16242, 59043, 34013, 16250, 16252, 59040,\n",
       "         49954, 59038, 16260, 59037, 34009, 34005, 16266, 59032, 49960,\n",
       "         16278, 59016, 33996, 33995, 16285, 33989, 16294, 59006, 16300,\n",
       "         59003, 49973, 16308, 16640, 33779, 16644, 33577, 16991, 33575,\n",
       "         16996, 50165, 58672, 58671, 17001, 33570, 17006, 50176, 58666,\n",
       "         50180, 17019, 33556, 33555, 33553, 17027, 50184, 50194, 33537,\n",
       "         17037, 58657, 50200, 33532, 33530, 33528, 16989, 17050, 33578,\n",
       "         16981, 58714, 50154, 58713, 16919, 58712, 58708, 33609, 33608,\n",
       "         16935, 16937, 33601, 16943, 58697, 33596, 33594, 33593, 16955,\n",
       "         58694, 33590, 50161, 16970, 58687, 58684, 16973, 58680, 33583,\n",
       "         33581, 16986, 58718, 33523, 17055, 17116, 17118, 33471, 33470,\n",
       "         17125, 50232, 17132, 58601, 33456, 17139, 33453, 33451, 17146,\n",
       "         50241, 17148, 17152, 17154, 17156, 33438, 17159, 17161, 17162,\n",
       "         17163, 17165, 17169, 58573, 58572, 17113, 17053, 58615, 50223,\n",
       "         17056, 50203, 50205, 33516, 58643, 33515, 33514, 17070, 33507,\n",
       "         17072, 33506, 58635, 33505, 58632, 17077, 58631, 17080, 33501,\n",
       "         33497, 58628, 17090, 33489, 58621, 33485, 50215, 17105, 50218,\n",
       "         17111, 50151, 16905, 16901, 16719, 16721, 16725, 50084, 58799,\n",
       "         58797, 58796, 50087, 16732, 33727, 33726, 16736, 50092, 16747,\n",
       "         16748, 16750, 16752, 50103, 16755, 16760, 33710, 58781, 16766,\n",
       "         58780, 50104, 16770, 16771, 16715, 58779, 33734, 16711, 33772,\n",
       "         16654, 50070, 58827, 16661, 50074, 58821, 16668, 58820, 33751,\n",
       "         16675, 33748, 16681, 58814, 33747, 16685, 16692, 16694, 33739,\n",
       "         58809, 16697, 16698, 16699, 16702, 33737, 33736, 16709, 16712,\n",
       "         16775, 16776, 33706, 16847, 50139, 16849, 33653, 50141, 16855,\n",
       "         16856, 58747, 16867, 58746, 16871, 16873, 16874, 58744, 16876,\n",
       "         33637, 58741, 58740, 58739, 50142, 16889, 33633, 16893, 50143,\n",
       "         16897, 16898, 50145, 16844, 50131, 33663, 33664, 16778, 58776,\n",
       "         16782, 16785, 16786, 16788, 16792, 16794, 33700, 58770, 16797,\n",
       "         58769, 33693, 49890, 16802, 50112, 16807, 16808, 33689, 16812,\n",
       "         16813, 33679, 50122, 16824, 16827, 58754, 16830, 16835, 33692,\n",
       "         17173, 34116, 16108, 15433, 34543, 34541, 15437, 15440, 49661,\n",
       "         59486, 59484, 59479, 59473, 15459, 15462, 49666, 59467, 34526,\n",
       "         34524, 59460, 49667, 34522, 49668, 49677, 15485, 59456, 49678,\n",
       "         49679, 59454, 15490, 34546, 15493, 15429, 59499, 15364, 15365,\n",
       "         15370, 15372, 15376, 34583, 59519, 15383, 34579, 49648, 59515,\n",
       "         34573, 15392, 34572, 34570, 49649, 59509, 59508, 15406, 49654,\n",
       "         15410, 34556, 59500, 15417, 34554, 34553, 34552, 34547, 34587,\n",
       "         59452, 59449, 15576, 15577, 49703, 59395, 15586, 59393, 34462,\n",
       "         15590, 34457, 15592, 15594, 49707, 15598, 49708, 59392, 15602,\n",
       "         59391, 59389, 34445, 34441, 34440, 59387, 59385, 59384, 15619,\n",
       "         49712, 49713, 34468, 34512, 15571, 15563, 59444, 15509, 49686,\n",
       "         59441, 15514, 15516, 15519, 34500, 59435, 15524, 34498, 59426,\n",
       "         15530, 34495, 34493, 15534, 15535, 49691, 34488, 15541, 59412,\n",
       "         15547, 59411, 34483, 59406, 15560, 49696, 15566, 59383, 59529,\n",
       "         15354, 15172, 34703, 15176, 34702, 34701, 59618, 15182, 15188,\n",
       "         59612, 15190, 15195, 59609, 15198, 34691, 59603, 34688, 15205,\n",
       "         49586, 34685, 49588, 15212, 34679, 49590, 49594, 15217, 15220,\n",
       "         15226, 15171, 15227, 15170, 49578, 34740, 34738, 34727, 34725,\n",
       "         15134, 15136, 34722, 49570, 59643, 15144, 59641, 49572, 34714,\n",
       "         15149, 59639, 15151, 59638, 15154, 34710, 15157, 15159, 59636,\n",
       "         15161, 49574, 15165, 15166, 59635, 49579, 49642, 15228, 15235,\n",
       "         15299, 15300, 34628, 59570, 59565, 59564, 15315, 15316, 15320,\n",
       "         34612, 59560, 59555, 34611, 15326, 34607, 15330, 34605, 59547,\n",
       "         15336, 15337, 34600, 59544, 34598, 49639, 34593, 59537, 15353,\n",
       "         34634, 59594, 15290, 15284, 15236, 15239, 59593, 59592, 59590,\n",
       "         15246, 34664, 59587, 15250, 15251, 34663, 34661, 34659, 15255,\n",
       "         15256, 15257, 15260, 15263, 49605, 49606, 15266, 15267, 34650,\n",
       "         49609, 15279, 49610, 15281, 59573, 15624, 34434, 59368, 15931,\n",
       "         34235, 59198, 34227, 59195, 59191, 15942, 15943, 34218, 34214,\n",
       "         34212, 15957, 59183, 34207, 34205, 34204, 15964, 49825, 15968,\n",
       "         59179, 49831, 15972, 34198, 59178, 49837, 15984, 15988, 59199,\n",
       "         49847, 59206, 15922, 59243, 34274, 49800, 15872, 59241, 59240,\n",
       "         59237, 59236, 15881, 15882, 34269, 59235, 15887, 15891, 34262,\n",
       "         49803, 15898, 15901, 34253, 49809, 59212, 15908, 59211, 34243,\n",
       "         59210, 34241, 15921, 15925, 15863, 15994, 15997, 16070, 16071,\n",
       "         16072, 34139, 34138, 59134, 16078, 34136, 16081, 34134, 34133,\n",
       "         34131, 49885, 16088, 34128, 16091, 16092, 34127, 59128, 34126,\n",
       "         34123, 16098, 16099, 16103, 16104, 34120, 59123, 16067, 34179,\n",
       "         59139, 34147, 49851, 59170, 59168, 34174, 34173, 49854, 49855,\n",
       "         16016, 49856, 34168, 59163, 34164, 34162, 59158, 59154, 16033,\n",
       "         16036, 49865, 16040, 16042, 16044, 34153, 59147, 16050, 34149,\n",
       "         16056, 16057, 34145, 15862, 49796, 34282, 59326, 15688, 34393,\n",
       "         59323, 15694, 49732, 59320, 34382, 15704, 15705, 34380, 15709,\n",
       "         34378, 49739, 49742, 15722, 15723, 15724, 15727, 34366, 15730,\n",
       "         15731, 15732, 15733, 15737, 34362, 59301, 15686, 49752, 34395,\n",
       "         34399, 34433, 15630, 15632, 15634, 59363, 15637, 34427, 34426,\n",
       "         15641, 34422, 34420, 59358, 34417, 59357, 15652, 49725, 34413,\n",
       "         15656, 15657, 15660, 59349, 59348, 15670, 15676, 59339, 15679,\n",
       "         59330, 49729, 59299, 34359, 34357, 15802, 15803, 34316, 15808,\n",
       "         15812, 15813, 34314, 15815, 59265, 59264, 15823, 59262, 59261,\n",
       "         15826, 15827, 15829, 34304, 34302, 15834, 15835, 34298, 15837,\n",
       "         15843, 15848, 34285, 59249, 34283, 15800, 59268, 59270, 34319,\n",
       "         34353, 15750, 59293, 15754, 15756, 49760, 59286, 49761, 59283,\n",
       "         15766, 15768, 34338, 34335, 34119, 15773, 34334, 15777, 15780,\n",
       "         49767, 49768, 34328, 34326, 34325, 15787, 34324, 59274, 59273,\n",
       "         49771, 15774, 34741, 50245, 17177, 57898, 50672, 32590, 57887,\n",
       "         32585], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_interrogative_clause': {'feature_present_idx': array([66745, 38631, 39392, 49591, 16437, 54056, 57672, 58691, 26559,\n",
       "         60865,  8777,  8428, 10297, 64994, 64338, 16314, 31518, 12393,\n",
       "         15689, 22089, 52727, 66371, 45297, 33603, 60061, 41905, 62732,\n",
       "         29772, 57729, 39724, 45905, 32055,  6030, 11246, 10918, 24382,\n",
       "         21348, 20969,  9262, 18476, 20515, 20039, 19411, 13094, 52459,\n",
       "         59404, 16972, 43557, 49394, 37986, 36296, 35521, 32788, 65185,\n",
       "         30237, 57155, 12352,  2917, 46668, 48561, 57872, 30146, 29990,\n",
       "         56445,  9141,   169, 53349, 51146, 16541, 60695, 19330, 38408,\n",
       "         54238, 30862, 16502, 25048, 26565,  1533], dtype=int64),\n",
       "  'feature_absent_idx': array([38026, 57568, 57567, 57566, 28248, 12707, 28247, 12710, 12711,\n",
       "         45576, 12714, 28241, 28240, 12717, 57570, 28238, 12723, 28233,\n",
       "         28232, 57550, 45583, 28225, 57544, 28224, 45592, 12739, 45594,\n",
       "         28218, 12742, 12721, 28213, 45573, 12696, 57609, 45535, 57605,\n",
       "         12653, 57601, 45542, 12661, 57599, 12663, 12664, 45544, 12667,\n",
       "         57596, 57571, 28274, 57591, 45553, 12675, 12676, 45557, 28267,\n",
       "         28265, 28264, 57579, 57578, 45565, 45567, 12693, 57594, 45598,\n",
       "         45599, 28209, 12799, 28173, 12805, 12807, 28167, 12811, 12812,\n",
       "         12813, 45626, 45628, 57480, 12824, 12826], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 78\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 78\n",
       "  })},\n",
       " 'contains_question': {'feature_present_idx': array([67304, 30335,  8182, 17677,  7867, 17730, 45181, 17377, 18354,\n",
       "         25737, 61799, 28326, 20561, 51808, 41298,  6213,  8421, 59876,\n",
       "         35393, 32552, 13483, 56966, 11768, 11633, 42474, 11341, 43286,\n",
       "         58230, 41988, 10121, 34482,  9733, 31593, 55548, 20820,  3529,\n",
       "         57289, 23512, 23649, 65462,   535,  2201, 26590, 48472, 48832,\n",
       "         64955, 66383, 46867, 24654, 43450, 31821, 56247, 55919, 44496,\n",
       "         16804, 31043, 16886, 48918, 30947, 55055, 48943, 44891, 46795,\n",
       "         44906, 30456, 44723, 15506, 48705, 27286, 13387, 48121, 26224,\n",
       "         13547, 57197, 13596, 57057, 57018, 26290, 14272, 48443, 14318,\n",
       "         25390, 14523, 32302, 56925, 56741, 14632, 42966, 47291, 32065,\n",
       "         56250, 44952, 50971, 17654, 28596, 46026, 50266, 19960, 20015,\n",
       "         20147, 20153, 20528, 28038, 22889, 20799, 22583, 51801, 28087,\n",
       "         46549, 51206, 21852, 22565, 21963, 21979, 21985, 51022, 22258,\n",
       "         52139, 50500, 19694, 52920, 27648, 27902, 27966, 45029, 17781,\n",
       "         23330, 17882, 54033, 18278, 53751, 23289, 45485, 53580, 18696,\n",
       "         28010, 18854, 28992, 23173, 53173, 19182, 19235, 52999, 45933,\n",
       "         52858, 38879, 47911,  5691,  5361, 36443,  5548, 36414, 36356,\n",
       "          5664, 57541,  5803, 36325, 36314,  5229, 36242, 37429, 36074,\n",
       "          6654,  2293, 61054, 35951, 60815,  6959,  7206, 60627,  2449,\n",
       "          2766, 61871, 62035, 40199,  3042, 40311, 64266, 64101, 36787,\n",
       "         36723, 36679, 37113, 40899,  2459, 63219,  2569,  4029, 41092,\n",
       "         62940, 62890, 62842, 62528,  4669,  4823, 36448, 63105, 37582,\n",
       "         65187,  7382, 41682, 10106,   784,   628, 58085, 37984,   248,\n",
       "         11132, 11547, 11726, 11800, 66406, 33329, 12043, 38070, 12353,\n",
       "         33189, 12609, 12615, 42504, 57545, 10008, 65981, 34208,  8848,\n",
       "         59645, 41980, 35572, 35133, 60177, 35610, 34978,  1551,  8358,\n",
       "          9239,  8113, 65646, 58792, 58755, 60353, 40179, 47709, 46626,\n",
       "         37913, 37618, 39630, 26272, 37748, 39955, 26651, 47309, 47183,\n",
       "         39250, 40116, 37552, 42528, 28044, 67232, 32490, 42783, 42233,\n",
       "         33535, 33619, 33823, 33861, 34158, 32003, 31827, 34514, 31510,\n",
       "         34673, 36970, 34937, 35316, 35490, 35649, 30083, 41479, 45456,\n",
       "         45665, 29136, 36161, 28330, 46216, 40902, 36648, 36655, 34987,\n",
       "         32666, 53289, 38459, 58875, 65576,  9304, 58586,  9992, 10092,\n",
       "         58570, 10543, 10718, 57931, 25671, 10997, 11579, 11872, 12414,\n",
       "         12624, 12764, 13181, 13391, 13634, 14067, 14544, 63996, 59008,\n",
       "          2499,  8889, 59220,  2933,  3360, 63674, 63400, 63035,  4110,\n",
       "          4133, 62080,  5379,  2685,  5645, 56299,  5942,  2600,  6069,\n",
       "          6224,  2585,  7270,  7380, 60626,  8258,  8345,  8389, 59259,\n",
       "         61642, 14961, 56486,  1305, 19377, 52086, 51934, 51865, 19909,\n",
       "         20444, 51795, 51288, 50485, 23278,   456, 23485, 23566, 49328,\n",
       "         23979, 24579,   144, 24821, 25036, 25197, 48275, 25482, 25537,\n",
       "         16031, 66315,  3090, 55931,  1004, 16513, 16345, 16679, 16759,\n",
       "         55445, 54954, 17221,   922, 65784, 55778, 17555, 56069, 54417,\n",
       "         54312, 17846, 53768, 53702, 18605, 53470, 17477, 64503, 39215,\n",
       "         38959, 39715, 39405, 65519, 39158, 65621, 38931, 40005, 47353,\n",
       "         63698, 48772, 48783, 49600, 50250, 50707, 53459, 45848, 54733,\n",
       "         55686, 44326, 43941, 43367, 57816, 58521, 41834, 58948, 59095,\n",
       "         41783, 61041, 61174, 61703, 63735, 57823,    63, 32881, 22388,\n",
       "         30186, 22330, 30586, 30863,  3791, 22008, 10842, 30025, 21658,\n",
       "         31403, 31517,  3344, 20980, 17281,  3165,  8978, 32231, 21466,\n",
       "         22527, 23081,  8586, 24719,  6785, 24869, 25400,  6714, 25664,\n",
       "          6793,  6024, 26221,  5555,  7236, 26403, 10919, 26668,  5167,\n",
       "         28074,  4654, 17968, 12680, 32243,  2855,  9037, 32874, 36890,\n",
       "         32555, 36929, 13187, 37211, 37367, 18955,   916, 37699,   441,\n",
       "         37782, 10236, 18078, 37930, 38023, 38119, 18819,  1027, 24694,\n",
       "         33442, 36542,  1755, 35040,  9137,  1979, 35886, 19731,  2783,\n",
       "         17844,  9426, 10171, 17773, 52049, 10918, 24483, 54225, 19856,\n",
       "         18480, 52264, 49368, 52420, 23474, 53308, 49670,  9907, 59408,\n",
       "         52668,  8535, 23065, 58619, 58789, 19328, 23639, 38676, 28490,\n",
       "         24713, 55988, 33481, 42041, 65157, 34209, 16326, 41751, 36508,\n",
       "         40898, 65652, 40390, 40205, 13549, 40075, 37614,   815, 37762,\n",
       "         39369,   157, 56378, 38990, 64386, 24666, 64345, 64058, 25862,\n",
       "         25945, 55123, 47245, 46998, 27244, 46523, 57615,  3866, 31733,\n",
       "         29154, 29612, 45085, 30199, 16558,  3671, 31300, 16334,  3320,\n",
       "         29187, 54097, 57364, 58001, 57456, 61786,  9368, 66863, 66163,\n",
       "         66109,  2301,  2717, 64589,  3657, 63544, 58250,  3788, 62689,\n",
       "          5554, 13809, 60783,  8114, 59549,  8879,  9175,  4412, 13905,\n",
       "         38371, 34073, 19449, 47299, 42101, 42242, 31923, 51864, 43652,\n",
       "         51782, 21849, 43818, 50080, 43824, 44366, 44717, 44824, 48695,\n",
       "         45723, 28734, 27245, 19152, 19139, 14571, 18310, 14702, 37788,\n",
       "         15696, 16348, 39402, 39446, 18657, 37028, 16972, 37062, 17076,\n",
       "         53844, 36459, 35882, 17206, 64358,  3397, 40785,  2236, 44779,\n",
       "         43734, 65956, 66564,  4629,  2771, 28318,  4973, 39164, 26634,\n",
       "         53189, 19888, 19598, 58402, 57473, 10375, 20779,  8690, 54876,\n",
       "         49850,  7456, 52625, 17110, 49298, 24420, 25473, 57720, 16622,\n",
       "         61085, 47421, 12886, 26320, 14631, 19768, 40664, 58016, 65516,\n",
       "         12864, 14222, 14762,  5983,  4280, 31245, 61783, 23425, 15448,\n",
       "         64174, 52031,  8282,  3091, 34564, 62926, 40611, 62554, 65556,\n",
       "         36644, 67055,  4985, 49206, 29057, 32378, 43054], dtype=int64),\n",
       "  'feature_absent_idx': array([29915, 12813, 57611, 57609, 28436, 45674, 57605, 12824, 57601,\n",
       "         12826, 28429, 57599, 12829, 45683, 12812, 57596, 57594, 28421,\n",
       "         28416, 57591, 28410, 45695, 28408, 12851, 12852, 57579, 12854,\n",
       "         57578, 28407, 12835, 45696, 12811, 12807, 57650, 12762, 12763,\n",
       "         45652, 12768, 12769, 12770, 12771, 12773, 12777, 12782, 57643,\n",
       "         57642, 28439, 57641, 28452, 28450, 57629, 57628, 28448, 57626,\n",
       "         28447, 12799, 28445, 45671, 45672, 12805, 28441, 45664, 12858,\n",
       "         45699, 12862, 45726, 12915, 28361, 57526, 57525, 57524, 45731,\n",
       "         45732, 57518, 12930, 28350, 45736, 57516, 45725, 45740, 57513,\n",
       "         28341, 57511, 28337, 12943, 45747, 28333, 12947, 12948, 28331,\n",
       "         12951, 12952, 57502, 45743, 28370, 28371, 45722, 45701, 12865,\n",
       "         45704, 57571, 57570, 57568, 57567, 57566, 28398, 28397, 45705,\n",
       "         12877, 12878, 12880, 45711, 28388, 57550, 28383, 12892, 28382,\n",
       "         12894, 45713, 12898, 28378, 12901, 45716, 45717, 28374, 57544,\n",
       "         28473, 57501, 57656, 28478, 28592, 28589, 57772, 45592, 28583,\n",
       "         57770, 28580, 57768, 45594, 57766, 57762, 45598, 45599, 45583,\n",
       "         45600, 12634, 28562, 45603, 57753, 57750, 28558, 12644, 28552,\n",
       "         57745, 12653, 28548, 57741, 45609, 12633, 57736, 12598, 12596,\n",
       "         12550, 28630, 45565, 57811, 12557, 45567, 28624, 28622, 12562,\n",
       "         28621, 57807, 57801, 12568, 12597, 57796, 12574, 28612, 45573,\n",
       "         45576, 12581, 28605, 12583, 12586, 57782, 28602, 12592, 28595,\n",
       "         12595, 57795, 57735, 28544, 12661, 45628, 12714, 57688, 12717,\n",
       "         28504, 12721, 12723, 57683, 28501, 28500, 28498, 28494, 28493,\n",
       "         12711, 57676, 45635, 45638, 12739, 28487, 45639, 12742, 57670,\n",
       "         57667, 57666, 57665, 28482, 57662, 45643, 45634, 12710, 45626,\n",
       "         12707, 12663, 12664, 57731, 12667, 57730, 45611, 57725, 28537,\n",
       "         12675, 12676, 28536, 57723, 28534, 45615, 45616, 28530, 28529,\n",
       "         57718, 57717, 57715, 12693, 28525, 45618, 12696, 45619, 28521,\n",
       "         28520, 28519, 57699, 28476, 12546, 57493, 12960, 28124, 28117,\n",
       "         28114, 28113, 13233, 57271, 45923, 28109, 28108, 57266, 57265,\n",
       "         45927, 13243, 28126, 57261, 45929, 13249, 57257, 57256, 57254,\n",
       "         13255, 57252, 57251, 13259, 28097, 57247, 45935, 28093, 13247,\n",
       "         28091, 13221, 13219, 13167, 45879, 13173, 13176, 13183, 28150,\n",
       "         57306, 57305, 13190, 45892, 13193, 57303, 45895, 57283, 57301,\n",
       "         28140, 13201, 57299, 45900, 28136, 57297, 28135, 13209, 45903,\n",
       "         45904, 13214, 13217, 28128, 45899, 45939, 13269, 13271, 13317,\n",
       "         28056, 13322, 28051, 57188, 13328, 13329, 28047, 45968, 13333,\n",
       "         45969, 28042, 13338, 57208, 28034, 13345, 13347, 45976, 28026,\n",
       "         45984, 45986, 28018, 13362, 13364, 13365, 28013, 57156, 45990,\n",
       "         13344, 13311, 28063, 28064, 57237, 13273, 13274, 28088, 28085,\n",
       "         57232, 28084, 13280, 57230, 57227, 28082, 57224, 57221, 13288,\n",
       "         28080, 13290, 28079, 13292, 13293, 28078, 13295, 57218, 28076,\n",
       "         13301, 45945, 45948, 45953, 13307, 57209, 28167, 45758, 45874,\n",
       "         13160, 28264, 57437, 13028, 13029, 45807, 57433, 45809, 13037,\n",
       "         57430, 13040, 57429, 57428, 57427, 28265, 57425, 57423, 28247,\n",
       "         13052, 57422, 57420, 28241, 28240, 28238, 45823, 57415, 57413,\n",
       "         13065, 45824, 28248, 28233, 45803, 13020, 45761, 12964, 28316,\n",
       "         12969, 12970, 12971, 28310, 12973, 57480, 28304, 45769, 12983,\n",
       "         28299, 28267, 12987, 45779, 57468, 45786, 13002, 13003, 57450,\n",
       "         28274, 57447, 13014, 57442, 13016, 45800, 57441, 12989, 57405,\n",
       "         57403, 28232, 57362, 45846, 45847, 57359, 45849, 28191, 57352,\n",
       "         57350, 28188, 57344, 45856, 57341, 57339, 57365, 28182, 13146,\n",
       "         57336, 13148, 13149, 45864, 13151, 57334, 45865, 13154, 45872,\n",
       "         57329, 28173, 57325, 45863, 57366, 57367, 45843, 57401, 57399,\n",
       "         45826, 57395, 45828, 13079, 13081, 28225, 28224, 13084, 57392,\n",
       "         57391, 28218, 57389, 13095, 13096, 13098, 28213, 13101, 57386,\n",
       "         13103, 13106, 13108, 57381, 28209, 28208, 13112, 28207, 28205,\n",
       "         13161, 57821, 12544, 28634, 29041, 58243, 29040, 58242, 29039,\n",
       "         12013, 12014, 12015, 45233, 12017, 58240, 58239, 58237, 29042,\n",
       "         12022, 29035, 29033, 29032, 45236, 12029, 45237, 29029, 29028,\n",
       "         12033, 45239, 45243, 58221, 29020, 58236, 45247, 58246, 45223,\n",
       "         58301, 58297, 58294, 58292, 29086, 11952, 45197, 11959, 58286,\n",
       "         45199, 58285, 11968, 58283, 45232, 29071, 58274, 11975, 11976,\n",
       "         58267, 45212, 11984, 11985, 11987, 29058, 11994, 11995, 45220,\n",
       "         58254, 58277, 45248, 58215, 12045, 28986, 28983, 28982, 28981,\n",
       "         45281, 45282, 28976, 12104, 12106, 12108, 12109, 45292, 58163,\n",
       "         58178, 58158, 45299, 58152, 58151, 28957, 45304, 28954, 45305,\n",
       "         45310, 12132, 12134, 28942, 28940, 58132, 28964, 58179, 12087,\n",
       "         45275, 12046, 12047, 45249, 45250, 45252, 58208, 58207, 45253,\n",
       "         29012, 12056, 45255, 12059, 58203, 12062, 29008, 12064, 29007,\n",
       "         58200, 29004, 58197, 58195, 45258, 12075, 58191, 45266, 12079,\n",
       "         45271, 28994, 28993, 11940, 58130, 11939, 29094, 29200, 58416,\n",
       "         58415, 58413, 58411, 29199, 29196, 29194, 11802, 11804, 11805,\n",
       "         11806, 45135, 11785, 29191, 11811, 29184, 11817, 11821, 58389,\n",
       "         58388, 11826, 11827, 11828, 29177, 11830, 58385, 11832, 11809,\n",
       "         11834, 11784, 29205, 11739, 58465, 45111, 45113, 29229, 58460,\n",
       "         11749, 29226, 45117, 58450, 29219, 11758, 29214, 58428, 58444,\n",
       "         58443, 11765, 11766, 58442, 58439, 58438, 45122, 58434, 11777,\n",
       "         58429, 11779, 45128, 11781, 29213, 58380, 29175], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 709\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 709\n",
       "  })},\n",
       " 'contains_coreferences': {'feature_present_idx': array([20751, 45961, 59415, 58102, 22240, 40621, 58742, 56156, 52691,\n",
       "         50136, 25990, 49557, 60565,  8758, 49248, 26309,  8504, 61001,\n",
       "         26411, 26584, 26946, 48744, 27352, 27915, 48102, 47872,  7123,\n",
       "          6963, 25116, 20658, 59826, 15357, 52307, 57354, 57434, 14404,\n",
       "         21815, 57995, 56292, 58024, 12516, 24584, 52161, 11383, 20170,\n",
       "         58445, 10980, 10975, 58646, 10727,  6891,  9639, 11384, 62290,\n",
       "          8270, 36785,  4299, 32856, 33038, 64098, 33862, 34379, 44612,\n",
       "         62386, 32320, 37338, 65903,  2252,  1997, 42814, 66815, 41202,\n",
       "         41619, 42156, 37391,  4400, 55301, 63631, 31415, 46974, 46686,\n",
       "          5653,  5587, 55178, 52516, 52460, 21287, 42265, 21534, 40644,\n",
       "         42212, 21862, 21899, 43137, 28991, 21398, 41892, 41241, 43361,\n",
       "         54397, 54198, 17894, 41735, 29367, 53761, 53603, 19807, 19819,\n",
       "         20107, 29176, 20406, 41291, 20455, 52951, 29023, 22407, 30122,\n",
       "         26501, 35283, 34674, 24627, 44711, 50410, 44742, 50778, 25528,\n",
       "         27598, 31330, 33172, 27093, 45658, 32210, 25753, 38918, 28234,\n",
       "         50834, 51906, 47391, 38459, 51855, 37916, 23151, 24025, 30271,\n",
       "         23290, 28332, 35732, 44540, 51519, 23525, 43819, 29463, 32260,\n",
       "         41946, 60133, 60125,  9091,  9098, 59630,  9432,  1328, 61275,\n",
       "          9668, 10169,  1325, 11349, 58101, 12786, 13320, 13366, 58875,\n",
       "         61562,  8199,  7736,  2763,  2827,  2832, 65133, 64513,  3510,\n",
       "          2030,  4771, 63294,  6685,  6695,  6888,  7048, 66328,  7404,\n",
       "          7520,  7715, 13724, 66957, 65541,   103, 14444, 56493, 56723,\n",
       "         56170, 15160, 67135, 56278, 56792, 15824, 56035, 31562, 31868,\n",
       "         31895, 30852, 39482,  1872, 31281, 45778, 31029, 30916,  5214,\n",
       "         63708, 13884, 39639, 46034, 54453, 47257, 29900,  5788, 30012,\n",
       "         54638, 30538, 46360, 30204, 46313,  5618, 30419, 30523, 45637,\n",
       "         30201, 43188, 39219, 32236, 17044,  3063,  2127, 44374, 44276,\n",
       "         44118, 65094, 43451, 16918, 37147, 15917,  2581, 37864,  2556,\n",
       "         16945, 44688, 17115, 34657,  4325, 32648, 45075,  4292, 63958,\n",
       "         45043, 39079,  3670, 44898, 44863, 34156, 17292, 15876, 34450,\n",
       "          3460, 45552, 29285, 17830,  6819, 23935, 23999,  9656, 24092,\n",
       "         56242, 50774, 23930, 24537, 14985, 53183, 50297, 53254, 66568,\n",
       "         25208, 14755, 29262, 20381, 14614, 20980, 21581, 21594, 41367,\n",
       "         57559, 57669, 51418, 22039, 41469, 66909, 22418, 11542, 23138,\n",
       "         11004, 22200, 50026, 59829, 42192, 29171, 56976, 28990, 62088,\n",
       "         47859, 54174, 28720, 28395, 18063,  7585, 28148, 28138, 48519,\n",
       "         53300, 48555, 40180,   518, 60293,  8963,  1726, 60959, 49228,\n",
       "         53926, 49222, 18256, 66547,  7964, 43496, 48783,  7845, 49126,\n",
       "         42672, 43015, 43491, 42711, 42199, 55303, 44029, 54969, 56062,\n",
       "         53858, 53318, 56774, 52754, 56982, 57223, 58050, 58610, 59307,\n",
       "         50285, 60594, 61584, 49100, 48625, 61970, 56027, 63234, 46059,\n",
       "         45719, 63462, 63894, 45219, 64021, 64429, 65424, 43624, 62078,\n",
       "            48, 28812, 26740, 26867, 12884, 27180, 12599, 11747, 10762,\n",
       "         10450,  9620, 19356,  9089, 29659,  9053, 30533, 30876, 26317,\n",
       "         26225, 13400, 25418, 19625, 19649, 20466, 20937, 17316, 21192,\n",
       "         22528, 31181, 22662, 14492, 14425, 24382, 13985, 24878, 24976,\n",
       "         25191, 14704,  8277, 18138, 40453, 36002, 36654,  4238,  4907,\n",
       "         35407, 37076, 35025,  5712,  1411,  5874, 40019, 40507,  3511,\n",
       "         33915,  1833,  7269,   967, 37719, 40705,  1804,  7357,  8176,\n",
       "          7685, 38608, 38020, 15363, 14643, 55370, 15710, 61057, 17220,\n",
       "         16664, 55253, 14346, 66665, 54895, 66863, 54469, 41709, 17870,\n",
       "         17923,  1054, 18133, 55330, 14325, 57249, 64978,  8526, 60954,\n",
       "         60644, 61712,  8751,  8825, 60555,  8966, 60086,  6444, 59373,\n",
       "         59361,  5799, 10848, 63408, 12619, 57982,  3940, 57767, 57527,\n",
       "         64658, 13809, 13843, 57205, 57088,  2980, 41535, 67310, 33098,\n",
       "         28734, 44273, 50602, 35918, 43845, 50599, 39613, 50286, 27879,\n",
       "         25361, 42301, 47121, 23572, 29932, 44420, 38681, 67183, 32715,\n",
       "         48686, 51781, 49915, 32162, 50080, 21062, 21329, 34480, 46653,\n",
       "         11329, 58314, 27234, 11064, 47267, 58622, 58752,  4491,  9433,\n",
       "          9224, 59728, 29586, 30265, 63243, 31742,  8318, 45439, 45110,\n",
       "         64282, 27137, 28793, 16224, 19003, 53386, 19582,   291, 66981,\n",
       "         17410, 20815, 17311, 55038, 40920, 51765, 16448,  1499, 51573,\n",
       "         15178,  3348, 12957, 49773,  3306, 50179, 39426, 50981, 24239,\n",
       "         14055, 51550, 63896, 34109, 44804, 38993, 65475, 34294,  2487,\n",
       "          2361, 40108,  4620,  3403, 66422, 41274, 36262, 17809, 32212,\n",
       "         53160, 53085, 52889, 22757, 51609, 15875, 51575, 23343, 23393,\n",
       "         56482, 56603, 56845, 13930, 57538, 45015, 13261, 27115, 28030,\n",
       "         30526, 10162, 30163, 53427,  8984, 57621, 31324, 51745, 19109,\n",
       "         28851,  4344,  4278, 57382, 47894,  8342, 26291, 35310, 42748,\n",
       "          9117], dtype=int64),\n",
       "  'feature_absent_idx': array([19123, 30459, 10137, 10139, 17905, 53687, 53688, 44250, 48583,\n",
       "         48581, 59643, 59641, 30460, 17899, 53694, 10153, 48580, 59639,\n",
       "         30446, 59638, 59636, 59635, 44262, 24612, 30442, 10150, 53700,\n",
       "         44248, 10132, 53679, 10105, 44236, 10107, 10108, 48600, 24595,\n",
       "         59678, 59676, 24598, 59673, 48592, 44239, 10119, 59670, 44242,\n",
       "         59668, 17912, 17911, 10125, 59665, 10127, 53684, 10130, 44241,\n",
       "         30438, 30436, 44267, 10203, 59593, 10205, 59592, 59590, 44285,\n",
       "         53718, 30404, 30403, 10212, 59587, 48573, 53719, 10218, 10220,\n",
       "         53726, 44295, 10224, 53730, 30389, 10228, 30387, 10231, 30385,\n",
       "         30398, 24622, 59594, 53712, 24616, 17888, 59618, 53703, 59612,\n",
       "         10177, 30429, 30428, 48574, 53705, 59609, 44272, 24618, 30420,\n",
       "         24619, 10187, 59603, 10189, 10190, 10191, 44277, 53708, 44279,\n",
       "         30414, 24620, 10102, 48603, 17921, 10099, 10004, 44193, 59764,\n",
       "         48633, 53660, 30546, 48630, 30543, 30542, 10015, 59756, 10003,\n",
       "         10017, 10019, 59754, 44198, 53662, 10024, 59749, 44203, 48628,\n",
       "         30535, 30534, 44204, 59755, 30552, 10001, 59767, 30576, 17971,\n",
       "         24550, 24552,  9973, 59783,  9975, 53652, 59780,  9978, 24553,\n",
       "          9980, 59779,  9982, 48641, 59774,  9987,  9988, 44189, 30559,\n",
       "         30558,  9994, 53657, 59771, 17958, 17948, 48564, 17947, 10034,\n",
       "         30506, 17934, 10071, 10073, 44222, 30499, 59714, 17932, 10080,\n",
       "         59710, 10083, 17936, 17928, 10087, 30489, 30488, 24589, 59698,\n",
       "         17924, 24590, 59691, 44230, 10097, 30483, 10085, 30508, 10064,\n",
       "         30510, 53664, 30527, 10038, 24569, 10040, 10041, 10042, 10043,\n",
       "         30524, 59739, 10046, 59738, 59737, 59736, 59734, 44212, 48624,\n",
       "         10055, 44214, 17940, 24576, 30513, 24577, 30511, 59725, 59744,\n",
       "         59786, 59573, 44303, 59435, 44405, 17799, 24689, 30248, 59426,\n",
       "         30247, 30246, 44410, 44411, 53800, 17800, 30241, 24693, 30236,\n",
       "         17792, 59412, 59411, 48514, 17790, 59406, 30232, 44418, 53808,\n",
       "         24690, 17788, 30255, 48517, 30276, 59456, 10383, 59454, 30272,\n",
       "         53783, 59452, 10388, 30269, 10390, 10391, 10408, 10392, 10394,\n",
       "         10395, 24684, 53786, 59444, 53788, 59441, 10402, 53792, 53795,\n",
       "         30257, 59449, 24696, 48513, 59395, 30209, 30208, 53811, 10474,\n",
       "         24699, 59363, 17775, 10478, 30203, 17774, 30200, 53810, 44431,\n",
       "         59358, 59357, 17772, 53814, 44432, 10490, 59349, 59348, 30191,\n",
       "         44438, 44439, 48511, 17779, 10468, 59368, 10441, 10442, 17785,\n",
       "         30224, 59393, 44425, 30222, 59392, 30221, 10451, 59391, 17784,\n",
       "         17783, 59389, 17782, 59387, 59385, 59384, 59383, 30217, 30216,\n",
       "         53809, 48512, 30213, 30212, 44380, 10377, 10376, 59460, 10271,\n",
       "         30352, 44320, 59547, 59544, 10280, 10281, 10282, 30346, 30345,\n",
       "         30344, 59555, 30343, 59537, 10289, 59529, 24652, 30334, 44331,\n",
       "         10299, 10300, 44333, 10304, 17838, 53754, 24643, 10268, 44317,\n",
       "         44305, 10239, 17862, 53735, 10242, 30375, 59570, 30373, 30371,\n",
       "         10249, 10250, 44311, 30367, 30366, 59565, 59564, 10257, 44312,\n",
       "         44313, 59560, 53741, 17856, 48560, 53743, 30358, 44335, 30383,\n",
       "         24656, 10309, 30300, 10346, 59486, 59484, 10349, 44361, 30297,\n",
       "         24669, 59479, 10355, 44363, 10343, 10357, 59473, 24675, 10363,\n",
       "         53777, 10366, 44372, 53780, 10370, 59467, 24678, 44376, 30292,\n",
       "         10342, 44353, 10339, 59519, 44337, 30325, 59515, 53771, 44339,\n",
       "         44340, 53772, 59509, 10321, 24659, 59508, 24660, 44347, 10326,\n",
       "         17828, 30312, 10330, 30311, 48548, 59500, 59499, 44350, 10336,\n",
       "         30306, 10308, 10496, 30577,  9963, 60053, 44014,  9616, 53570,\n",
       "          9618, 18088, 30804,  9623, 60047, 30803, 30801, 30810, 18086,\n",
       "         44023, 60041, 60039, 60038, 53571,  9634, 30797, 30796, 30795,\n",
       "         18084,  9640,  9628,  9641, 18090, 44012, 30834, 44002, 53561,\n",
       "         53562,  9585,  9587,  9589, 44006,  9591, 30826,  9593, 60056,\n",
       "         53565,  9596, 53566, 30823, 18096, 44007, 60065, 24464, 44009,\n",
       "         30816,  9608, 53568, 60073, 44026, 30792, 60031, 48697, 53582,\n",
       "         53584, 30762, 59996, 44047, 59995, 30760, 59993,  9689, 30759,\n",
       "         30768, 59992, 30756, 30755, 53590, 59987, 59986,  9702, 18061,\n",
       "         59984, 53591, 53592,  9709, 18067, 18073, 60006, 24477, 44030,\n",
       "         24469, 24470, 60028, 44031, 24471, 60024, 30786, 30784, 44035,\n",
       "         24472, 60020, 60018, 30780, 48702, 60015, 30778, 18077, 30776,\n",
       "          9666,  9667, 60013, 44038,  9672, 44042, 44001, 53560, 60082,\n",
       "         30837,  9487, 60143, 24438, 60140, 60139, 60138,  9494,  9495,\n",
       "         48727, 43956,  9498, 30907, 30901, 18127, 43961,  9503, 43962,\n",
       "          9505, 18126, 60130, 60129, 53547, 24444, 43966, 30898, 48728,\n",
       "         24436,  9483, 24423,  9453,  9456,  9457,  9458, 60168, 24426,\n",
       "          9461, 30930, 43933, 60164, 18143, 60160,  9467, 30926,  9469,\n",
       "         24431, 18137,  9475, 60154, 30917, 43947, 48731, 48730, 43951,\n",
       "         30889], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 622\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 622\n",
       "  })},\n",
       " 'contains_number': {'feature_present_idx': array([32942, 37010, 32408,  5274, 21268, 43757, 16605,  7396, 57308,\n",
       "         12038, 32396, 62679, 52830, 43098, 57103, 11795, 53037, 30349,\n",
       "         43925,  1651,  1407, 57739, 65065, 12741, 53368, 22914, 10719,\n",
       "         11782, 12629, 49243,  4291, 34762,  7264, 64717,  3301,  5327,\n",
       "          9847, 19975, 57045, 57032, 52151, 20593, 31753, 51126, 17445,\n",
       "         60884, 38327, 10973, 25204, 41460, 17688, 33893, 51534, 51917,\n",
       "         33897, 41345, 38171, 17347,  4783, 21025, 31052, 25867, 25790,\n",
       "         10211, 42929, 31189, 25895, 25707, 23314, 23325, 52505,  4919,\n",
       "         11369, 32239, 50964, 31195, 29764, 49081, 53621, 28451, 58248,\n",
       "         55383,   494, 61569, 35486,  8679, 15080, 47656, 27436, 15204,\n",
       "         29744,  5826,  6683, 19905, 45306, 27441,  8729, 35802, 27584,\n",
       "         58614, 22265, 46748, 67250, 58598, 22329, 46999, 46077, 28103,\n",
       "         58575, 14168, 58511, 61794, 35784, 66952, 66947, 54980, 22557,\n",
       "         45226, 39978, 61048, 27072, 44424, 39257, 48665, 53918, 19961,\n",
       "         48741, 46699, 48482, 35203, 19921, 33259, 59536, 21707, 16128,\n",
       "         21791, 23945, 48056, 48831, 35468, 35402, 48222, 36433,  4175,\n",
       "         44932, 24047, 29240, 56072, 39252,  8584, 55506,  8578,  8056,\n",
       "          8515, 56087, 19800,  8400, 19804, 39231, 55453,  8648, 20044,\n",
       "         39144, 55728, 19901, 56064, 55873, 55702, 39312,  8317, 55787,\n",
       "         38865, 38634, 55580, 39280, 39088, 21606,  7995, 36728, 21469,\n",
       "         57747, 57755, 36649, 57771,  6988, 57773, 36612,  6946,  6922,\n",
       "         36411, 36328, 58041,  6706, 58063, 58087, 36140,  6632,  6618,\n",
       "         58088, 36066,  6495, 35929,  6417,  6416,  6398,  6370, 22238,\n",
       "         21457, 21404,  7204, 36940, 38478, 20371,  7936, 56206, 38348,\n",
       "         38255, 38237, 56511,  7771, 20813, 37668, 37644, 20897, 56770,\n",
       "         56128, 56935, 37522, 55188, 21114, 21243, 57287,  7424, 37268,\n",
       "         57340, 37093, 57412, 57448, 21351,  7317,  7255,  7634, 57198,\n",
       "         18497, 55006, 49208, 49183, 44163, 49075, 49022, 49008, 44213,\n",
       "         44270, 48900, 44351, 48815, 48733, 44383, 48589, 48578, 49221,\n",
       "         49256, 49318, 12548, 49873, 16846, 49755, 43594, 49587, 49559,\n",
       "         49482, 44452, 49465, 16483, 12380, 49447, 43976, 43985, 12499,\n",
       "         44063, 16501, 49899, 13224, 48458, 47407, 15064, 47363, 15047,\n",
       "         45733, 14115, 15002, 45770, 14166, 45928, 14313, 46292, 14330,\n",
       "         46502, 46587, 45729, 13938, 15121, 45605, 13276, 48373, 44906,\n",
       "         15674, 15585, 13574, 48104, 48460, 45155, 47819, 45425, 47792,\n",
       "         15274, 47725, 13837, 47601, 48044, 11928, 43154, 43088, 40838,\n",
       "         53466, 53322, 53223, 18671, 18580, 53154, 18569, 41059, 41091,\n",
       "         58629, 41192, 41217, 18340, 41261, 40812, 53651, 53815, 18893,\n",
       "         54997, 19734, 54960, 39658, 19591, 19525,  9041, 18147, 54589,\n",
       "         40115, 40235,  9299, 40637,  9416, 40660,  9449,  9145, 52200,\n",
       "         52195, 10431, 17328, 42376, 11309, 17312, 42469, 42581, 50745,\n",
       "         17371, 50700, 50428, 50366, 50261, 11568, 17021, 50128, 50090,\n",
       "         50641, 55063, 11187, 42188, 41387, 52029, 17989, 41840, 51604,\n",
       "         51598, 51595, 11171, 51535, 17674, 17664, 51184, 10955, 11050,\n",
       "         42143, 51119, 41958, 58662, 14551, 58725, 63303, 25277, 32066,\n",
       "         63199, 32075, 32087, 63306, 32176,  3011, 32183, 62795, 62726,\n",
       "          6233, 24888, 25032, 24866, 25280, 63358,  2386, 63796,  2411,\n",
       "         31422, 31428, 31431, 63340,  2545, 63592,  2589, 25403, 31819,\n",
       "          2704, 32020, 63628, 24859, 62567,  3304, 24281, 32957, 24237,\n",
       "         24202, 33075, 61671,  3971, 61669, 24168,  4190, 23994, 23977,\n",
       "         23852, 23832, 61616,  3969,  3872, 32868,  3342,  3347, 32410,\n",
       "         32504,  3456, 32565, 24554, 62044, 24515,  3682, 24514, 61894,\n",
       "         24402, 61821, 24383, 25668,  4309, 64124,  2180, 28819, 27475,\n",
       "         28969, 27420,   754, 27350, 66587,   786, 66132, 27276, 29186,\n",
       "         65974, 65970, 65952, 66201, 65915, 66628, 28427, 28039, 67244,\n",
       "         27788, 67163, 27741, 66992, 66642, 66966,   207,   250, 66859,\n",
       "           319, 28387,   419, 28282, 27110, 27098, 65575, 30364, 64595,\n",
       "          1792, 64591, 30617, 30676, 26497, 30902, 64395, 31004, 25936,\n",
       "          2120,  2129, 25886,  1942, 26505, 30287, 64829, 27005, 29454,\n",
       "         26895, 65145, 65136,  1384, 29912, 30003, 65022, 26625, 26608,\n",
       "         64939, 64880,  1528, 30096, 64225, 33544, 32352, 22936, 59175,\n",
       "         34163, 34379,  5156, 34157, 34944,  5159,  5140,  5537, 60717,\n",
       "         34396, 59144, 34537, 60279, 59719, 59070, 34877, 23414, 23253,\n",
       "          5069, 59401,  5748, 60701, 22544, 60728, 23280, 60738, 60792,\n",
       "          5054, 60818, 35473,  5056, 59306,  5858, 60858,  5893, 35215,\n",
       "          5263, 34839, 59686, 22637,  4523, 58917, 22317, 61076, 61059,\n",
       "         33907,  6126,  6031, 22982, 22256,  5441, 22303, 60105, 23036,\n",
       "         34635,  6215, 61184, 23680, 35491, 59069, 23668, 34796, 35243,\n",
       "         26620, 43145, 21666, 16276, 44199, 21677, 22648, 25944, 36740,\n",
       "         43083, 36896, 21709, 29770, 31048, 36213, 16184, 16969, 22685,\n",
       "         16684, 35162, 16630, 26105, 30611, 36718, 21527, 43554, 34829,\n",
       "         26219, 16829, 16505, 43864, 30522, 30914, 35084, 43318, 26558,\n",
       "         22868, 30228, 30181, 44043, 30176, 30124, 16307, 22712, 36429,\n",
       "         16906, 26607, 26021, 34812, 20012, 35430, 22203, 22367, 22452,\n",
       "         28685, 35853, 27493, 45546, 28321, 35949, 15196, 22462, 22475,\n",
       "         35974, 29030, 36099, 45418, 22016, 21949, 45754, 45757, 27844,\n",
       "         27794, 14621, 14625, 46403, 46300, 35691, 35575, 28046, 27767,\n",
       "         14782, 14835, 14926, 45775, 35754, 14957, 46084, 29733, 27343,\n",
       "         21924, 44541, 27150, 15918, 44520, 27106, 27092, 15974, 44576,\n",
       "         43018, 16041, 27023, 44396, 27002, 29429, 16111, 26966, 29418,\n",
       "         15474, 29338, 15833, 45251, 27313, 21915, 21885, 29126, 22499,\n",
       "         27232, 44667, 15604, 27212, 21845, 45055, 44950, 36129, 15739,\n",
       "         44747, 45069, 29366, 42627, 17071, 32637, 19065, 40322, 40292,\n",
       "         19169, 23438, 19193, 38460, 34072, 40230, 40174, 40150, 19280,\n",
       "         24512, 40099, 32682, 19242, 40097, 38385, 24583, 18682, 18697,\n",
       "         40914, 24791, 34171, 40850, 40844, 40702, 32528, 32551, 18769,\n",
       "         24667, 18859, 40747, 32581, 24628, 18753, 40917, 40096, 24434,\n",
       "         38686, 38785, 24170, 39015, 33133, 33145, 24036, 19869, 33695,\n",
       "         23971, 33483, 33495, 33519, 23857, 23779, 33549, 33654, 40059,\n",
       "         20225, 20276, 34039, 19484, 24405, 20306, 34012, 39858, 39824,\n",
       "         39334, 39767, 38584, 24324, 32815, 38625, 39488, 33819, 23634,\n",
       "         19686, 22953, 23381, 40940, 31432, 17357, 31516, 25486, 31659,\n",
       "         34455, 31776, 25546, 17543, 42107, 42096, 17624, 31949, 32007,\n",
       "         25317, 32025, 23156, 41938, 34555, 42506, 17073, 34724, 42941,\n",
       "         25784, 25755, 42874, 42862, 34575, 42809, 31345, 42733, 25605,\n",
       "         23799, 34642, 25598, 42539, 25660, 34259, 41928, 17749, 32271,\n",
       "         32327, 41219, 24920, 32344, 18385, 18443, 24985, 20861, 37817,\n",
       "         37831, 41014, 24833, 24831, 40966, 18654, 18475, 41909, 18144,\n",
       "         34275, 37404, 23204, 41841, 32052, 21061, 41713, 41525, 18142,\n",
       "         41512, 25261, 37493, 41422, 34360, 25079, 41348, 37531, 41473,\n",
       "         13759, 27949,  6613, 56014, 63336,  8261, 63400, 55946,  8306,\n",
       "         55849, 63509,  8540, 55482,  8592, 55472,  2628, 55409, 55350,\n",
       "         55275,  2568,  8760, 55238, 63654, 63669,  8202, 63334,  8151,\n",
       "          2883, 57074,  7580, 62762, 56962, 62766, 62769, 56664,  3031,\n",
       "          7740, 62803, 54964, 56602,  7796, 62835, 56479,  7863, 56392,\n",
       "         56240, 63088, 56203, 56197, 56177,  7783, 62740,  2455, 63747,\n",
       "         64296,  9592,  2020,  9758,  1941,  9794, 53275, 53273,  9867,\n",
       "         53213,  9940, 53174, 53077, 53066, 52936, 10078, 52921, 64493,\n",
       "         10195, 10210, 52732, 53915, 53957, 53972,  9403, 54788, 54716,\n",
       "          9023, 63749, 63883, 64044, 64132, 64214, 54425, 61040, 63718,\n",
       "          2230,  9229,  9251, 54136,  2185, 54095, 64283, 53999,  2148,\n",
       "          9387], dtype=int64),\n",
       "  'feature_absent_idx': array([25272, 31258, 11164, 43418, 43416, 60018, 11176, 11177, 60020,\n",
       "         43397, 43395, 31272, 20452, 43393, 31276, 43386, 20439, 60024,\n",
       "         43380, 11191, 31277, 11194, 31279, 11196, 43372, 31274, 31257,\n",
       "         20454, 11159, 11123, 11124, 65527, 43476, 43475, 43472, 43470,\n",
       "         20465, 60006, 43456, 43454, 11139, 65524, 11142, 31250, 31251,\n",
       "         60013, 31254, 65522, 11150, 43437, 20456, 43435, 43433, 60015,\n",
       "         43370, 43368, 11202, 31282, 20423, 43311, 62073, 43305, 11244,\n",
       "         20420, 20419, 20418, 11248, 43297, 43296, 31301, 31302, 43288,\n",
       "         11254, 62072, 11259, 65514, 20412, 20411, 20409, 43278, 43276,\n",
       "         60038, 43273, 60031, 31243, 60028, 43333, 43364, 43362, 43360,\n",
       "         11211, 65520, 43357, 11214, 43355, 31289, 11217, 43353, 11219,\n",
       "         11220, 43351, 31291, 11223, 43345, 43344, 11226, 20430, 43341,\n",
       "         62075, 11230, 31293, 11233, 20426, 43481, 31242, 11119, 20518,\n",
       "         43634, 11010, 31161, 43632, 43631, 43630, 43629, 43627, 11018,\n",
       "         63918, 59992, 43623, 43621, 43617, 59993, 43611, 31172, 20508,\n",
       "         11036, 11037, 43601, 31177, 11042, 31178, 20519, 11044, 11006,\n",
       "         43644, 43688, 63916, 59984, 20533, 10978, 43682, 31148, 10982,\n",
       "         43678, 20530, 10986, 10987, 31151, 65554, 10991, 43672, 20525,\n",
       "         43669, 43668, 43666, 59986, 59987, 62101, 31157, 43647, 20520,\n",
       "         60039, 11045, 20501, 43522, 43521, 43515, 31224, 11094, 20482,\n",
       "         31228, 31229, 31230, 20478, 43499, 43498, 43497, 65533, 20475,\n",
       "         20474, 65530, 11110, 20472, 20471, 65529, 20469, 11116, 31240,\n",
       "         43486, 31217, 59995, 43531, 31211, 59996, 11052, 11053, 11055,\n",
       "         43578, 43576, 11059, 43575, 31194, 43569, 43567, 11065, 65540,\n",
       "         43566, 43561, 11069, 43560, 11071, 43556, 31201, 43551, 43542,\n",
       "         11080, 31210, 20488, 43533, 31312, 11274, 11276, 43012, 11482,\n",
       "         43009, 11484, 31435, 11486, 31438, 60083, 42991, 42990, 11493,\n",
       "         42987, 65488, 20321, 11498, 11501, 11502, 31445, 65487, 20317,\n",
       "         20316, 42973, 42972, 42971, 11513, 60082, 42968, 20327, 31429,\n",
       "         43061, 11447, 43055, 43053, 43051, 31414, 43048, 43047, 11455,\n",
       "         60073, 43044, 43041, 11459, 31416, 31417, 11462, 43036, 31418,\n",
       "         11465, 43034, 43029, 20331, 11471, 31426, 43024, 11476, 43066,\n",
       "         20315, 20313, 11557, 65482, 11559, 31469, 63948, 42911, 20294,\n",
       "         11565, 11567, 60100, 20290, 11573, 11575, 42897, 60104, 42891,\n",
       "         42890, 60107, 42888, 31477, 42885, 11584, 42883, 11586, 42881,\n",
       "         31467, 31453, 42919, 20299, 31455, 11520, 42960, 31456, 42958,\n",
       "         63944, 42953, 11530, 60093, 11534, 11535, 11538, 11539, 20302,\n",
       "         42933, 42932, 42931, 20301, 42928, 11546, 20300, 65483, 11549,\n",
       "         42925, 42924, 42920, 43691, 43069, 31399, 43203, 11321, 43201,\n",
       "         43198, 43197, 63931, 43192, 62056, 11331, 60053, 31355, 65505,\n",
       "         43177, 65504, 62055, 11340, 63933, 31360, 43164, 43161, 11350,\n",
       "         43159, 11352, 11353, 11354, 43204, 11355, 43205, 11314, 20403,\n",
       "         60041, 11281, 62068, 43248, 11285, 43244, 11287, 43243, 43241,\n",
       "         43239, 43237, 43235, 65508, 60047, 31328, 20396, 43226, 11303,\n",
       "         43222, 11306, 11307, 43220, 62058, 31346, 43206, 11437, 65503,\n",
       "         20374, 60065, 31386, 63937, 43097, 43095, 43094, 11409, 11410,\n",
       "         65495, 31389, 11417, 20352, 11419, 43081, 11422, 11423, 20350,\n",
       "         43076, 11427, 11428, 11429, 11430, 11432, 43073, 11434, 43103,\n",
       "         43157, 11400, 11397, 31367, 20372, 11361, 43149, 11363, 60056,\n",
       "         11366, 43144, 43143, 11371, 43139, 43138, 43133, 11378, 65500,\n",
       "         43132, 31379, 43118, 43117, 11390, 43116, 11392, 43115, 43114,\n",
       "         43112, 43107, 42880, 43692, 31146, 10575, 10576, 44132, 10578,\n",
       "         10579, 59899, 30941, 44127, 44125, 10584, 44124, 44133, 44123,\n",
       "         10589, 59901, 59903, 44112, 44111, 59904, 44108, 44105, 44100,\n",
       "         30949, 10602, 44119, 63891, 30939, 44143, 20701, 30898, 44189,\n",
       "         30901, 30907, 20694, 10540, 59892, 10544, 30917, 65622, 10547,\n",
       "         10549, 44171, 30926, 44160, 20685, 44158, 10558, 44156, 65618,\n",
       "         30930, 44151, 44148, 10565, 44097, 44095, 30953, 44091, 10645,\n",
       "         10646, 62131, 10649, 20650, 59917, 30976, 10654, 30979, 44047,\n",
       "         44042, 10658, 10659, 65609, 62129, 44038, 20646, 10665, 10666,\n",
       "         44035, 44031, 44030, 59920, 59921, 10673, 62132, 44193, 44058,\n",
       "         10641, 30955, 30957, 10611, 20664, 20663, 10618, 59909, 62133,\n",
       "         20659, 59911, 44069, 10626, 30966, 59914, 44065, 10630, 59915,\n",
       "         10632, 10633, 10634, 30967, 30968, 10638, 44059, 65612, 10642,\n",
       "         10527, 30889, 44198, 44340, 44339, 59870, 44337, 44335, 44333,\n",
       "         44331, 30823, 30826, 44320, 44317, 44313, 44312, 44311, 44305,\n",
       "         44303, 10441, 10442, 20746, 30834, 20744, 44295, 20743, 30837,\n",
       "         44285, 59868, 10451, 59866, 30816, 44380, 10376, 10377, 20773,\n",
       "         44376, 30804, 10383, 44372, 59864, 62170, 10388, 30810, 10390,\n",
       "         10391, 10392, 10394, 10395, 44363, 20768, 44361, 20767, 44353,\n",
       "         10402, 44350, 44347, 10408, 44026, 20739, 44279, 44230, 20720,\n",
       "         30872, 10496, 30874, 44222, 30875, 10502, 10503, 62154, 59885,\n",
       "         62153, 20712, 44214, 44212, 10511, 65626, 10514, 30881, 62152,\n",
       "         10518, 20707, 44204, 44203, 10522, 30871, 30840, 10490, 30865,\n",
       "         30843, 44277, 30844, 44272, 44267, 63884, 65635, 44262, 30849,\n",
       "         30851, 10468, 59877, 20731, 20729, 10474, 62158, 65631, 44250,\n",
       "         10478, 44248, 30861, 44242, 44241, 44239, 59883, 44236, 30983,\n",
       "         44023, 10677, 59960, 62111, 31092, 10874, 31101, 43803, 43798,\n",
       "         10879, 62108, 31103, 10882, 10883, 43794, 43791, 31106, 31109,\n",
       "         10889, 43784, 62107, 43780, 10893, 10894, 59963, 31112, 59964,\n",
       "         65579, 10900, 20575, 10866, 31069, 20584, 10836, 31076, 10838,\n",
       "         10839, 43839, 65583, 10843, 31078, 10846, 65582, 65581, 43833,\n",
       "         10850, 43831, 10852, 59956, 43828, 43827, 43825, 20577, 31090,\n",
       "         59958, 59959, 43816, 59953, 31117, 43767, 43732, 43728, 10938,\n",
       "         31134, 10943, 10947, 31140, 43715, 20540, 62102, 43711, 20538,\n",
       "         65559, 43707, 10958, 43706, 10960, 43705, 43703, 10963, 65558,\n",
       "         31145, 43701, 10967, 43700, 43733, 43768, 31129, 10931, 65572,\n",
       "         10905, 20559, 43762, 43761, 43759, 10910, 10911, 43758, 10913,\n",
       "         31120, 43751, 62104, 31127, 20552, 10921, 10922, 43742, 20551,\n",
       "         43740, 59971, 43738, 10928, 31128, 43735, 10932, 43694, 43852,\n",
       "         43860, 43986, 10716, 10717, 10720, 31007, 65597, 10723, 63898,\n",
       "         43970, 43966, 10730, 31013, 43962, 10734, 43961, 10736, 10737,\n",
       "         43956, 10740, 20622, 10742, 20620, 43951, 10746, 31020, 43987,\n",
       "         43947, 31005, 10711, 59922, 65604, 10680, 20641, 20639, 44014,\n",
       "         10686, 10687, 44012, 44009, 65602, 44007, 44006, 44002, 44001,\n",
       "         10697, 20635, 10699, 30997, 43996, 65598, 10706, 10708, 43993,\n",
       "         10710, 43992, 43856, 59930, 59934, 65589, 10790, 43898, 59944,\n",
       "         43895, 20601, 10799, 43888, 10801, 59945, 10803, 31051, 43882,\n",
       "         10806, 43879, 20599, 59950, 20597, 31055, 31059, 31060, 65586,\n",
       "         65585, 10821, 10822, 10787, 59933, 10785, 43904, 59935, 59936,\n",
       "         31021, 10758, 43933, 31028, 62121, 10763, 43928, 10765, 31034,\n",
       "         10767, 63903, 43921, 43918, 65591, 10773, 20608, 31039, 65590,\n",
       "         20606, 31040, 43908, 59942, 10782, 59943, 30803, 11589, 42877,\n",
       "         31904, 41856, 19972, 41853, 41851, 41850, 41848, 41847, 31905,\n",
       "         41844, 41843, 12374, 31907, 12391, 31910, 41832, 41828, 61957,\n",
       "         31918, 60287, 41818, 41817, 12404, 65326, 12390, 12372, 31902,\n",
       "         31898, 60275, 61963, 41899, 41898, 12344, 41897, 12346, 41896,\n",
       "         31882, 65335, 60280, 41887, 41884, 31886, 12356, 19983, 31888,\n",
       "         31889, 41867, 12362, 12363, 12365, 12367, 12368, 31897, 41807,\n",
       "         65324, 12411, 12412, 12454, 41744, 41742, 41741, 12459, 12460,\n",
       "         41738, 19933, 41731, 41729, 31973, 12468, 41722, 19930, 41719,\n",
       "         41718], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_accompanier': {'feature_present_idx': array([48840, 40407, 25521, 63754,  2544, 62778, 48572, 23131, 25243,\n",
       "          1586,  6768, 28633, 30987, 31771, 33192, 57868, 67295, 21997,\n",
       "         62683, 20523, 20009, 19634, 17498, 17099, 15935, 15229, 12977,\n",
       "         23966, 66921, 35941, 34751, 57026, 55358, 54726, 58587, 53270,\n",
       "         51588, 48059, 47488, 47014, 46051, 60560, 42923, 42278, 39536,\n",
       "         38920, 61828, 61855, 37272, 37019, 35989, 64359, 62309, 64680,\n",
       "         28123,  5769,  9138,  4377,  6001,  2688,  5110,  6851,  2368,\n",
       "          7372,  3934,  1001,  7831,  4054, 38164, 35174, 61929, 35671,\n",
       "         62017, 38102,  4457, 12067, 33148,  6551,  6727, 30578, 29704,\n",
       "         29688, 28433, 62735, 26650, 25465, 11835, 38553, 39745, 39278,\n",
       "           486, 55588, 55258,  1472, 58819, 53077, 52109, 59340, 51305,\n",
       "         60010, 60017, 49908, 38635, 49613,  2007, 48693, 60221, 48369,\n",
       "         48142,  2548,  3412, 45789, 45328, 43409, 43257, 24850, 49371,\n",
       "         24427, 65549, 17329, 21375, 21090, 20204,  9240, 19010, 18724,\n",
       "         18687, 17315, 17142, 64708, 15510, 10583, 15206, 11286, 64218,\n",
       "         11415, 11671, 12125, 12084, 21510, 21737, 58073,  8512, 23792,\n",
       "         44680, 58861, 43319, 17239, 52809,  3838, 12922, 28146, 41414,\n",
       "         53343, 53819, 39443, 63776, 39146, 38979, 15384, 18070, 40629,\n",
       "         26304, 26247,  3282, 23382, 15187, 14755, 16204, 64007, 13981,\n",
       "         50881, 59801, 47718, 47490, 64215, 16787, 46710, 60299, 46456,\n",
       "         63240, 46080, 66512, 54982, 63736, 20076, 56211, 56268, 34996,\n",
       "         31233, 65007, 56508, 27189, 18250, 62569, 31868, 33457,  5827,\n",
       "         31880, 56549, 34520, 27288, 27750, 35601, 18554, 37848, 12382,\n",
       "         55262, 29108, 55404, 30928, 29518,  7354,  5188, 35680, 21278,\n",
       "         18976, 32615, 57674, 57756, 54969, 58387,  8176, 52264, 59307,\n",
       "         58420, 56003, 53114,  1778, 23433, 24743, 24511, 54601, 12188,\n",
       "          1834, 54620, 45219, 10037, 18241, 38417, 23012,  4505,  4511,\n",
       "         26754, 18875, 35558, 19279, 62045, 22218,  5583, 33274, 64946,\n",
       "         32192,  8615, 29625, 18214, 65574, 39304, 61702, 48590, 48317,\n",
       "         16312,  2454, 16413, 46701, 46254, 46156, 26114, 63871, 63811,\n",
       "         43023, 62815,  8483, 61451,  9617,  4066, 43873, 63518, 60783,\n",
       "         34629, 27779, 34647, 25363,  8637, 40377,  9955, 20481,  8626,\n",
       "         17236, 18050, 51090, 51648, 52285, 16254, 52630, 54207, 50480,\n",
       "          5554, 12582, 63493, 13075, 63103, 26320, 27247, 35557, 35148,\n",
       "         12963, 37401, 38551, 39461, 42697, 65648, 46520, 48626, 59238,\n",
       "         54166, 34264, 12781,  4280,  1169, 56357, 21734, 56701, 50837,\n",
       "         24325, 36744, 45964, 16978, 33339,   106], dtype=int64),\n",
       "  'feature_absent_idx': array([50750, 48510, 17828, 44151, 10097, 59603, 10099, 44156, 10102,\n",
       "         44158, 30325, 10105, 48511, 24518, 10108, 24520, 59594, 44160,\n",
       "         59593, 59592, 59590, 53652, 59587, 48502, 10119, 10107, 48498,\n",
       "         59609, 48512, 10064, 30352, 59636, 59635, 17838, 10071, 53641,\n",
       "         10073, 53643, 30346, 30345, 30334, 30344, 48514, 10080, 44143,\n",
       "         53645, 10083, 59618, 10085, 48513, 10087, 59612, 44148, 30343,\n",
       "         24529, 30312, 10125, 59560, 53662, 53664, 59555, 24546, 17800,\n",
       "         44198, 17799, 44203, 59547, 59544, 44193, 30276, 24547, 30272,\n",
       "         59537, 10177, 24550, 30269, 59529, 24552, 17792, 44212, 44214,\n",
       "         44204, 53660, 10153, 59564, 30311, 10127, 44171, 24531, 10130,\n",
       "         10132, 24534, 30306, 24535, 24536, 10137, 59573, 10139, 30300,\n",
       "         48494, 59570, 30297, 24539, 53657, 24540, 59565, 30292, 44189,\n",
       "         10150, 24542, 53639, 59638, 59639, 53638,  9964, 53613, 30420,\n",
       "         53617, 53619,  9973, 59714,  9975, 30414, 59710,  9978,  9963,\n",
       "         24488, 17862,  9982, 44091, 24491, 44095,  9987,  9988, 44097,\n",
       "         30404, 30403,  9994,  9980, 24477, 30428, 30429, 44058, 59744,\n",
       "         44059, 24470, 24471, 30446, 53600, 53601, 53602, 59739, 59738,\n",
       "         59737,  9942, 30442, 59736, 24472, 59734, 44065, 30438, 44069,\n",
       "         30436, 48548,  9953, 53606, 59725, 59698, 24553, 44100, 17856,\n",
       "         44125, 10034, 30375, 30373, 10038, 44127, 10040, 10041, 10042,\n",
       "         10043, 30371, 44124, 24502, 30367, 30366, 44132, 53636, 24506,\n",
       "         44133, 10055, 48517, 30358, 59643, 59641, 10046, 59665, 44123,\n",
       "         44119, 30398, 10001, 44105, 10003, 10004, 24496, 44108, 53626,\n",
       "         44111, 44112, 30389, 59678, 53627, 30387, 10015, 59676, 10017,\n",
       "         24498, 10019, 59673, 30385, 59670, 10024, 59668, 30383, 59691,\n",
       "         24469, 10187, 10189, 10349, 44285, 59392, 59391, 30145, 59389,\n",
       "         10355, 30144, 10357, 30143, 59387, 59393, 24590, 59384, 10363,\n",
       "         30141, 59383, 10366, 17731, 48444, 10370, 53718, 53719, 30133,\n",
       "         59385, 24595, 59395, 30147, 30168, 53705, 44272, 10321, 17743,\n",
       "         17742, 53708, 59412, 10326, 59411, 44277, 10346, 17740, 30157,\n",
       "         59406, 44279, 10336, 17737, 10339, 17735, 53712, 10342, 10343,\n",
       "         24589, 10330, 59368, 10376, 10377, 48433, 44311, 59330, 48431,\n",
       "         59326, 30103, 44312, 59323, 53735, 44313, 59320, 53730, 17710,\n",
       "         17708, 44317, 24612, 30087, 30086, 44320, 48424, 53741, 53743,\n",
       "         10441, 10442, 30097, 59339, 10408, 44305, 48441, 30130, 59363,\n",
       "         44295, 10383, 59358, 24598, 59357, 30126, 10388, 10390, 10391,\n",
       "         10392, 17721, 10394, 10395, 59349, 59348], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 330\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 330\n",
       "  })},\n",
       " 'contains_age': {'feature_present_idx': array([27711, 60720, 23624, 44495, 62843, 12259,  6693, 62067, 58291,\n",
       "         11140,  2920, 15258, 34068, 33285, 39334, 25944, 13033, 42019,\n",
       "         59109, 42539, 55472, 39432,  9402, 55238, 11993, 57141, 50984,\n",
       "         60863,  5885, 67114,  5472, 65133,  3855, 36664, 29818, 64201,\n",
       "         49977,  2455, 21223, 22677, 23329, 43451, 23083, 42768, 44374,\n",
       "         39636, 41995, 25476, 40155, 40003, 45421, 39315, 28187, 38398,\n",
       "         36121, 29261, 30088, 35126, 23549, 45936, 67229, 19114,   186,\n",
       "         64532,  2555, 63230, 62772, 61736,  7970,  8528, 59380,  9441,\n",
       "          9480, 59203, 19312, 56033, 14217, 32285, 46244, 15714, 16047,\n",
       "         16409, 31879, 18720, 50155, 14345, 32947, 66287, 65616, 33626,\n",
       "         65175, 64706, 45019, 41734, 63783, 48279, 50511, 50780, 51390,\n",
       "         52745, 55546, 44631, 57862,     8, 31688,  5540, 20856, 20494,\n",
       "         20136, 19625, 26137, 26568,  7661, 10104,  7568, 11477, 17824,\n",
       "         29082,   131, 31500, 10393, 31033, 44491, 50937, 56627, 58761,\n",
       "         17206, 45670,  8938, 19325, 45206, 18189, 15736, 28820,   918,\n",
       "          1796, 13497,  2271, 34390, 27236,  2943, 41788,  4412, 23493,\n",
       "         62670, 26157,   128, 55784, 55785, 66752, 12621,  7456, 57506,\n",
       "          2737, 63989, 65956, 61630, 16772, 43764, 22787, 50346, 28145,\n",
       "         52419, 25473, 47047, 16890, 31873, 21993, 22011,  3978, 39177,\n",
       "         37407, 34684, 33573, 23150,  9586, 31504, 18043, 55868, 55347,\n",
       "         45759, 54489, 33776, 52715, 30595, 28837, 55440, 14186, 52787,\n",
       "          3536, 16541, 43065, 11134, 47660, 16421, 46506, 16502, 25048,\n",
       "          1533, 26565], dtype=int64),\n",
       "  'feature_absent_idx': array([19040, 30297, 17800, 10083, 59603, 10085, 17799, 10087, 24496,\n",
       "         30292, 53645, 44143, 10080, 24498, 10097, 59593, 10099, 59592,\n",
       "         59590, 10102, 44148, 10105, 59587, 10107, 10108, 59594, 17792,\n",
       "         59609, 53643, 30325, 24491, 59636, 44119, 10055, 59635, 53636,\n",
       "         53638, 44123, 44124, 44125, 30300, 53639, 10064, 30311, 44127,\n",
       "         53641, 59618, 30306, 10071, 44132, 10073, 59612, 44133, 30312,\n",
       "         44151, 17790, 44156, 48478, 30248, 30247, 10150, 30246, 59555,\n",
       "         10153, 17775, 44189, 17774, 30241, 17779, 48477, 59544, 17772,\n",
       "         44193, 30236, 53657, 17769, 59537, 48475, 30232, 59529, 48471,\n",
       "         59547, 59560, 30255, 30257, 30276, 44158, 24502, 44160, 30272,\n",
       "         10119, 17788, 30269, 17785, 10125, 59573, 10127, 17784, 17783,\n",
       "         10130, 44171, 10132, 59570, 17782, 53652, 24506, 10137, 59565,\n",
       "         10139, 59564, 59638, 59639, 10046, 24488,  9953, 30389, 48513,\n",
       "         30387, 53617, 30385, 53619, 59714, 30383, 59710,  9963, 44059,\n",
       "          9964, 44069, 17838, 48512, 30375, 30373,  9973, 30371,  9975,\n",
       "         59698,  9978,  9980, 44065, 48514, 44058, 53613, 59749,  9918,\n",
       "         44035, 53600, 44038, 30414, 53601, 59744, 17856, 44042, 53602,\n",
       "         59739, 44047, 59738, 59737, 59736, 30404, 59734, 30403, 53606,\n",
       "         24448,  9942, 30398, 48517, 59725, 30367, 53660,  9982, 30366,\n",
       "         10017, 30345, 10019, 30344, 30343, 44097, 24477, 10024, 44100,\n",
       "         48498, 44105, 59665, 30334, 10034, 44108, 44111, 44112, 10038,\n",
       "         59643, 10040, 10041, 10042, 10043, 59641, 48494, 10015, 30346,\n",
       "         44095, 24464], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 200\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 200\n",
       "  })},\n",
       " 'contains_beneficiary': {'feature_present_idx': array([   75, 41159, 22656,  2869, 32544, 23123, 52985, 30777, 52704,\n",
       "         42822, 38517, 41080,  4458, 50259, 50011, 49653, 12458, 28811,\n",
       "         47624, 26363, 47010, 46959, 27384, 50620, 56080,  2489, 20631,\n",
       "           135, 67113,  9555, 14355, 14351, 17261, 64303, 14303, 37229,\n",
       "         62882,  2077, 33635, 61356, 57700,  8962, 20062, 20034, 11002,\n",
       "         14070, 40396, 45428, 18071, 39908, 28894, 32769, 35712, 28756,\n",
       "         28356, 32128, 29732, 24990, 26904, 16611, 17385, 17460, 17482,\n",
       "         17687, 18827, 18896, 19542, 27479, 20554, 21676, 22968, 24008,\n",
       "         24172, 24787, 25025, 26184, 26278, 21174, 37607, 41651, 38533,\n",
       "         53864, 54765, 55906, 56133, 56164, 56680, 57030, 57181, 57941,\n",
       "         58226, 58399, 58510, 58623, 59107, 62677, 63406, 63859, 65009,\n",
       "         65981, 66725, 67105, 53766, 53062, 53046, 52934, 38683, 38740,\n",
       "         39946, 40831, 41570, 16253, 42383, 42860, 43541, 44126, 38138,\n",
       "         44225, 46561, 46726, 46974, 47496, 47679, 48246, 49840, 50684,\n",
       "         52359, 52683, 44787, 15122, 67346,  6478,  2967, 13640,  9888,\n",
       "          4030,  1322,  1109,  9257,  3830,  9195,  1461, 11268, 13341,\n",
       "         11479,  6399, 12392,   664,  1539, 11460, 29156, 35728, 35283,\n",
       "         57692, 54026, 33901, 33858, 54609, 33161, 10856, 32593, 55028,\n",
       "         12295, 27093, 32489, 11170, 27716, 28183, 46665, 11231, 30275,\n",
       "         28625, 56672, 32663, 31524,  3946, 37152,  5093, 41842, 42113,\n",
       "         42207, 49200, 42756, 14932, 42998, 44004, 44170, 44821, 44985,\n",
       "         45182, 45344, 43979, 53380,  4703, 40821,  3886, 37995, 25420,\n",
       "         51883, 51776,  9402,  4461, 38796, 51568, 39259, 39432, 50950,\n",
       "         39776,  4433, 38878,  1557, 41285, 65072, 58539, 21630, 66375,\n",
       "         23049, 62388, 22922, 66252, 12926, 58805, 21935, 65928, 14763,\n",
       "         13304, 22457,  1360, 22268, 21899, 62003, 17956, 21515, 60476,\n",
       "         12779, 60097, 15369, 18775, 16825, 18362, 66578,  9468, 61887,\n",
       "         50653, 39196,   756, 60684, 52808, 13542,  9399, 38777, 18466,\n",
       "         52221, 18433, 62183, 38639, 38205, 12589,   685, 45560, 67142,\n",
       "          6374,   225, 45035,  6201, 15649,   672, 47037, 47219,  5339,\n",
       "          5303, 15753, 41089, 66493, 43555, 47914, 43513, 43462, 43317,\n",
       "         42878, 48422, 42408, 48662,   675, 41672,  8696, 16482, 47910,\n",
       "         57958, 53183, 31450, 13027, 13123, 12788, 27112, 32099, 12034,\n",
       "         11936, 12844, 27899, 31972, 54990, 36364,  2445,  2232, 31191,\n",
       "         31018, 28403, 13104, 56644, 30350, 30227, 22929,  1680, 32763,\n",
       "         12098, 26631, 53686,  2825, 25727, 53932, 35480, 12518, 57451,\n",
       "         21098, 34951, 34909, 60007, 21099, 34832, 10691, 54854, 57190,\n",
       "         21382, 26358, 13007,  1555, 34777, 54167,  1554, 56999, 47457,\n",
       "          1627,  5701, 56861,  1619, 57166, 60162, 48607, 53226, 53114,\n",
       "         61155,  1324, 52051, 51828, 54320, 60061, 51635, 54965, 62601,\n",
       "         62652, 63239, 59359, 64386, 55215, 64581, 64701, 55729, 50037,\n",
       "         65021,  5142, 56287, 48068, 55840, 14924, 16157,  9430,  9578,\n",
       "         38506, 38481, 38216, 37945, 15965, 10178, 36388, 16063, 19838,\n",
       "         34544, 33262, 16334, 32097, 32059, 16591, 31506, 46398, 30134,\n",
       "         17210, 14341, 27727, 24961, 22727, 22680, 17507, 21546, 18314,\n",
       "         15841, 15725, 19151, 41573, 42291,  8452, 15561, 41201,  6573,\n",
       "         15145, 44963, 45538, 39655, 43917,  9263, 40804,   871, 47114,\n",
       "         64185, 44584, 56894, 11783,  7847, 26264,  5549, 64589, 16683,\n",
       "         57388, 15710, 25639, 13385, 13351, 17923, 45011, 14141, 24854,\n",
       "         26232, 58353, 58001, 14278, 57952, 25105, 44219, 25520,  6942,\n",
       "         14643,  8052, 31329, 66017, 15979, 49838,  3181,  8825, 37494,\n",
       "          3832, 10060, 52724, 66428, 52564,  8833,  8834, 38498,  4460,\n",
       "         53293, 56109, 36251,  8549, 51078, 42898, 11103, 66830, 36060,\n",
       "          2586, 33539, 33759, 34438, 65427, 10546, 54722, 32740, 14235,\n",
       "         64094, 16297, 62484, 64556, 15178, 17294, 45684, 20867,  8318,\n",
       "          5189,  8433, 50993, 38815,  3397, 36806, 36709, 53509, 35875,\n",
       "         54918, 67226, 31762, 30831, 30439,  1977, 24428, 22009,  1702,\n",
       "         25050, 57400,  1935, 57067, 28145, 26979, 34781,   969, 13416,\n",
       "         23425, 38046, 22169, 39230, 56198, 13713, 13642, 46878, 13268,\n",
       "         11896], dtype=int64),\n",
       "  'feature_absent_idx': array([59089, 12769, 12770, 12771, 28378, 12773, 45638, 45639, 12777,\n",
       "         57599, 28374, 12782, 57596, 57594, 12768, 57591, 28370, 45643,\n",
       "         28361, 57579, 12799, 57578, 12805, 12807, 45652, 28350, 12811,\n",
       "         12812, 12813, 28371, 57571, 45635, 12763, 12717, 57643, 57642,\n",
       "         45619, 12721, 28416, 12723, 57641, 28410, 28408, 28407, 57629,\n",
       "         57628, 57601, 45626, 45628, 12742, 28398, 57626, 28397, 57611,\n",
       "         57609, 28388, 45634, 57605, 28383, 28382, 12762, 12739, 57570,\n",
       "         57568, 57567, 12880, 57516, 28299, 57513, 45699, 57511, 45701,\n",
       "         45704, 12892, 45705, 12894, 12898, 45711, 57518, 12901, 57502,\n",
       "         57501, 57493, 45716, 45717, 28274, 12915, 45722, 45725, 28267,\n",
       "         45726, 28265, 28264, 45713, 12878, 12877, 45696, 57566, 45664,\n",
       "         12824, 28341, 12826, 12829, 28337, 45671, 12835, 28333, 45672,\n",
       "         28331, 45674, 57550, 45683, 57544, 12851, 12852, 12854, 28316,\n",
       "         12858, 28310, 12862, 12865, 28304, 45695, 57526, 57525, 57524,\n",
       "         45618, 45731, 12714, 28421, 57762, 12568, 28529, 28525, 12574,\n",
       "         45542, 45544, 57753, 57750, 28521, 28520, 12581, 28519, 28530,\n",
       "         12583, 57745, 45553, 12592, 45557, 12595, 12596, 12597, 12598,\n",
       "         57741, 45565, 57736, 57735, 28504, 12586, 45567, 57766, 12562,\n",
       "         57811, 12506, 12510, 57807, 12512, 57801, 57796, 57795, 45520,\n",
       "         28562, 12527, 28558, 12530, 57768, 12534, 28552, 28548, 12544,\n",
       "         28544, 12546, 12550, 57772, 28537, 57770, 28536, 12557, 45535,\n",
       "         28534, 57782, 57731, 57730, 28501, 57683, 28450, 28448, 28447,\n",
       "         12675, 12676, 28445, 45603, 28441, 28439, 57676, 57670, 57667,\n",
       "         28452, 57666, 28436, 12693, 45609, 12696, 57662, 28429, 45611,\n",
       "         57656, 57650, 12707, 45615, 12710, 12711, 57665, 12667, 45600,\n",
       "         45599, 28500, 28498, 57725, 28494, 28493, 57723, 45573, 28487,\n",
       "         57718, 45576, 28482, 12633, 12634, 28478, 57717, 57715, 28476,\n",
       "         28473, 12644, 45583, 57699, 12653, 45592, 45594, 45598, 12661,\n",
       "         57688, 12663, 12664, 45616, 57821, 57480, 45732, 45865, 13183,\n",
       "         57271, 45872, 28064, 28063, 57266, 13190, 57265, 13193, 45874,\n",
       "         28056, 45879, 45864, 13201, 28051, 57257, 57256, 13209, 28047,\n",
       "         57254, 28042, 13214, 57252, 57251, 13217, 13219, 13221, 57261,\n",
       "         45892, 45863, 28076, 57306, 28097, 57305, 57303, 57301, 13146,\n",
       "         45849, 13148, 13149, 57299, 13151, 28093, 57297, 13176, 13154,\n",
       "         28088, 13160, 13161, 45856, 28085, 28084, 28082, 13167, 57283,\n",
       "         28080, 28079, 28078, 13173, 28091, 57247, 28034, 45895, 13288,\n",
       "         13290, 13292, 13293, 45935, 13295, 45939, 13301, 45945, 45948,\n",
       "         13307, 45953, 13311, 27992, 27967, 13317, 13322, 27958, 27957,\n",
       "         27955, 13328, 13329, 57156, 45968, 45969, 13333, 13338, 27946,\n",
       "         27963, 57188, 27994, 13280, 13233, 57237, 45899, 28026, 45900,\n",
       "         45903, 57232, 57230, 13243, 45904, 57227, 13247, 57224, 13249,\n",
       "         57221, 28018, 57218, 13255, 13259, 28013, 57209, 57208, 45923,\n",
       "         13269, 13271, 13273, 13274, 45927, 45929, 45847, 12930, 45846,\n",
       "         28108, 57437, 57433, 28213, 12983, 28209, 28208, 12987, 57430,\n",
       "         12989, 28207, 57429, 28205, 45769, 28218, 57428, 57425, 13002,\n",
       "         13003, 57423, 57422, 57420, 57415, 57413, 13014, 13016, 28191,\n",
       "         57405, 13020, 57427, 28188, 45761, 12971, 45736, 45740, 28248,\n",
       "         28247, 45743, 57468, 12943, 28241, 28240, 28238, 12947, 12948,\n",
       "         12951, 12973, 12952, 28232, 45747, 57450, 12960, 57447, 28225,\n",
       "         28224, 12964, 45758, 57442, 57441, 12969, 12970, 28233, 45779,\n",
       "         57403, 13028, 28136, 57350, 28135, 45824, 45826, 57344, 13095,\n",
       "         13096, 13098, 28128, 13101, 28126, 13103, 57352, 57341, 13108,\n",
       "         57339, 28124, 13112, 45828, 57336, 57334, 28117, 28114, 57329,\n",
       "         28113, 57325, 28109, 13106, 45823, 13084, 13081, 13029, 57401,\n",
       "         28182, 57399, 45786, 57395, 13037, 13040, 57392, 57391, 57389,\n",
       "         28173, 57386, 28167, 13052, 57381, 45800, 45803, 45807, 45809,\n",
       "         13065, 57367, 28150, 57366, 57365, 57362, 57359, 13079, 28140,\n",
       "         45843, 57825, 28580, 12495, 28993, 58243, 11959, 58242, 28986,\n",
       "         28983, 28982, 58240, 11968, 58239, 58237, 28981, 58236, 28994,\n",
       "         45188], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 532\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 532\n",
       "  })},\n",
       " 'contains_concession': {'feature_present_idx': array([23226, 35633, 63486, 50914, 54074, 16851, 51364,  1370, 23819,\n",
       "          9326, 33632, 57148, 62215, 22099, 52389,  9604, 18117, 38465,\n",
       "         56194, 44767, 13082, 43776, 37332, 28618, 42918, 44919, 36048,\n",
       "         37513,  8464, 19774, 31463, 19786, 38762, 17575,  7268,  6244,\n",
       "          8406, 56827, 16777, 16765,  6070, 53233, 17839, 54524, 17879,\n",
       "           167, 52292, 14077, 12327, 12140, 43564, 45875, 45998, 43424,\n",
       "         11605, 11512, 14796, 42426, 39151, 15423, 48201, 42012, 41990,\n",
       "         48926, 50909, 41076, 40712, 39943,  9272, 51497, 51601, 47846,\n",
       "          5750, 13370, 33364, 34671,  3027, 31110, 31266,  2698, 33674,\n",
       "         31835,  2564, 23708, 63786,  2139, 57171,  2065, 63602, 32950,\n",
       "         24187, 63399, 28941, 35009, 21839, 60255, 66573, 19365,  4887,\n",
       "         57964, 59035, 28011, 20848,   341, 59708, 24302, 65537, 43212,\n",
       "         14454, 27842, 32446, 13629, 43502, 31965, 44115, 13891, 31917,\n",
       "         14018, 25332, 28045, 41800, 43167, 14413, 31614, 30974, 28037,\n",
       "         43422, 43982, 14872, 36894, 15578, 38797, 17043, 17573, 35106,\n",
       "         21001, 17646, 34860, 38234, 36599, 18811, 19450, 18871, 36817,\n",
       "         19112, 35690, 41563, 16891, 22182, 41413, 66977, 33021, 40565,\n",
       "         39872, 16205, 21709, 23212, 16306, 22956, 39761, 33950, 38822,\n",
       "         22269, 16276, 18594, 12119,  5211,  6108, 51331,  9614, 51502,\n",
       "         57710, 53184,  8612,  3293, 53778, 53917,  8174, 54360,  7596,\n",
       "         51097,  1738,  7303,  7263, 54850, 63322, 63287,  6875, 63049,\n",
       "         56134,  2173,  2283,  5100, 57471,  2668,  1805,  1013, 58877,\n",
       "         10335, 60266, 45262, 66124, 12757, 60087,   297, 45679, 65948,\n",
       "         12044,   516, 11990, 46432,  3092, 46936, 11401, 65359, 47248,\n",
       "           980, 50035,  4157, 64252,  3551, 64893, 44942,  3208, 47829,\n",
       "         59394, 47431, 48469, 61999, 33771, 61939, 34182, 34662, 33766,\n",
       "         33963, 63342, 62661, 26927, 27738, 28004, 65682, 65333, 29964,\n",
       "         30469, 62176, 64056, 31650, 63947, 63766, 63720, 63520, 62968,\n",
       "         62885, 31591, 61300, 45228, 60516, 39780, 40527, 50954, 40851,\n",
       "         41264, 49258, 48931, 48851, 48436, 51455, 42306, 46823, 46265,\n",
       "         45708, 26893, 45590, 45358, 45291, 44639, 44666, 47134, 51536,\n",
       "         52433, 53680, 35104, 35406, 59347, 35937, 58850, 57805, 36790,\n",
       "         57636, 57406, 56508, 37397, 56231, 56151, 56149, 37573, 37723,\n",
       "         38012, 55998, 55507, 54591, 54545, 61146, 26706, 32937, 17902,\n",
       "         12920,  1492,  4136,  8397, 13379, 16383, 16112,  3635, 16043,\n",
       "          3310, 24863, 12788,  9252, 14497, 22476, 14617, 15903, 22870,\n",
       "         18150, 23385, 24353,  8234, 15635, 15529, 24826, 21273, 21642,\n",
       "         25545, 11107,   402,   526,  6079,   813, 26068, 20473, 17704,\n",
       "         23902,  1244,  4257,  4515, 37611, 15542, 53699, 37675, 11054,\n",
       "         37808,  8216, 39552,  8130, 39329, 40932, 15725, 16531, 38249,\n",
       "         56399, 54175, 39587,  6839, 16013, 56347, 54317, 40338, 56287,\n",
       "          6361, 39741, 16188,  5951,  6530, 42993, 52952, 49496, 12303,\n",
       "         12018, 49438, 11776, 46062, 46188, 46194, 46218, 45453, 11652,\n",
       "         11406, 46993, 11356, 10810, 48853, 10895, 47955, 48816, 48237,\n",
       "         49283, 13048, 45163, 50037, 42423, 52278, 51970, 15140, 43078,\n",
       "         43096,  9118, 43236,  9238, 43447, 43524, 43636, 14399, 14324,\n",
       "         44066, 44120, 10037, 13726, 10176, 10415, 50449, 15435, 18403,\n",
       "         10908, 57270, 25284,  3230, 29458, 24124, 24104,  3235, 33042,\n",
       "         29164, 33262, 23889, 29148, 60823, 22717, 60663, 60604, 32449,\n",
       "         31268, 61491,  5365, 25035, 31451, 25001, 24843, 31620,  2626,\n",
       "         24768, 25191, 30745, 32028,  2138, 32038, 32089, 32097, 63210,\n",
       "         61644,  3260, 22374, 64645, 36094, 65406, 20334, 58802, 20991,\n",
       "         27797, 28918, 21022, 19493, 27724, 27983, 58336, 65986, 21196,\n",
       "         34838,  4108, 26048, 66147, 36915, 59658, 25905, 28142, 25609,\n",
       "         66607, 63594, 66768,   237,  4662,   537, 62873, 63582, 50382,\n",
       "         49073, 10513,  1583, 64100, 49359,  1190, 49623,  1453, 49476,\n",
       "         10546, 51229,  2881, 62464,  7149, 55999, 59512, 56109, 59373,\n",
       "         59019,  6755, 56153, 60229, 59011, 56691, 56698, 57000, 57115,\n",
       "          5063, 57527, 57476,  5146, 58756, 51335, 55046,  7358,  9354,\n",
       "         62370,  2644,  2661,  2845,  9144, 51651, 51797,  7150,  9035,\n",
       "         61221,  8626, 53605, 61093, 61077,  3309, 60259,  7497,  8700,\n",
       "         26582, 67046, 25915, 14654, 15009, 43006, 36638, 42517, 15162,\n",
       "         24559, 26229, 27747, 31754, 15419, 31329, 41786, 14400, 18840,\n",
       "         41504, 26107, 15603, 18818, 41226, 37822, 37888, 40263, 40094,\n",
       "         38436, 38511, 17504, 39734, 37340, 26264, 24435, 13762, 26550,\n",
       "         21983, 32224, 32972, 33379, 33433, 12407, 11682, 46829, 34480,\n",
       "         11149, 22007, 47916, 11084, 11558, 32550, 12291, 29934, 32273,\n",
       "         35208, 44446, 13639, 44691, 35152, 21583, 13215,  1924, 30183,\n",
       "         35466, 35557,  1977, 58624, 17040, 19768, 31836, 17889,  2389,\n",
       "         60161,  1719, 48579, 58299, 35061, 62736, 34759,  2104, 33853,\n",
       "          5200, 16486, 43077, 44050, 27223, 66347, 51129, 10035, 50993,\n",
       "         45025,   183, 49881, 49773, 49487, 26481, 26484, 49397, 10537,\n",
       "         49139, 11261, 11125, 65812,  8724, 27512, 64094, 34060,   936,\n",
       "           656, 41236,  1565,  1239, 39932, 27802,  6898,   746, 15431,\n",
       "         39721, 64271, 28190, 29786, 63424,   745, 66422, 25216, 28005,\n",
       "         32190, 27488, 63350, 28967, 33857, 48690, 40108, 15929, 34048,\n",
       "         40080, 53427, 53361, 52890, 52527, 52446,  6241, 42414, 17809,\n",
       "         52010, 37881, 40515, 37354, 45200,  3403, 59879, 34619, 49460,\n",
       "         14762, 21734,  7909, 13163,  9833, 44103, 19270,  5090,  4280,\n",
       "         53349,  9752, 53742, 11896, 42773, 34564,  1335, 35913, 19620,\n",
       "         57621, 19109, 38408, 59623, 39003, 56262,  6593, 39868, 22900,\n",
       "         28851, 28658, 39071, 32822,  8105, 30279,  8342, 25068,  4856,\n",
       "         15651, 27515, 55501, 45461], dtype=int64),\n",
       "  'feature_absent_idx': array([18529, 12763, 61709, 12768, 12769, 12770, 12771, 41762, 12773,\n",
       "         12777, 27776, 49503, 12782, 49500, 12762, 41772, 64797, 27763,\n",
       "         49493, 41775, 41776, 49490, 12799, 41777, 49489, 27758, 64792,\n",
       "         27757, 12805, 41773, 12807, 49507, 49509, 41747, 12710, 12711,\n",
       "         57329, 27820, 12714, 61700, 12717, 49532, 12721, 12723, 49529,\n",
       "         27811, 49508, 49526, 49523, 27805, 64806, 12739, 27801, 12742,\n",
       "         27799, 27796, 49516, 61704, 27792, 27791, 49511, 49524, 12707,\n",
       "         49486, 12811, 49450, 27712, 49446, 49445, 27710, 49444, 12877,\n",
       "         12878, 57339, 12880, 27708, 27707, 49439, 27713, 64779, 64778,\n",
       "         49437, 57341, 49434, 12892, 27703, 12894, 41802, 27701, 64776,\n",
       "         12898, 12901, 41807, 61724, 27754, 27715, 41798, 12812, 12813,\n",
       "         61717, 57334, 58897, 58894, 12824, 49474, 12826, 57336, 12829,\n",
       "         49471, 12835, 12865, 27735, 27731, 49468, 49466, 49463, 27726,\n",
       "         27725, 12851, 12852, 27723, 12854, 49456, 12858, 12862, 27733,\n",
       "         27693, 41744, 49546, 27946, 12544, 12546, 12550, 64851, 27937,\n",
       "         64850, 12557, 27931, 12562, 64849, 64847, 12568, 41671, 49610,\n",
       "         64845, 12574, 49606, 58915, 58914, 12581, 64840, 12583, 49605,\n",
       "         12586, 41694, 41695, 12592, 49609, 27910, 27955, 27957, 27992,\n",
       "         12490, 12491, 57303, 12494, 12495, 49654, 49649, 41649, 49648,\n",
       "         41650, 12506, 41653, 12534, 12510, 12512, 41655, 49639, 41658,\n",
       "         27967, 57305, 41664, 27963, 12527, 57306, 58919, 12530, 27958,\n",
       "         49642, 61698, 12595, 12597, 64820, 64819, 27861, 12661, 27860,\n",
       "         12663, 12664, 12667, 41729, 49560, 41731, 12675, 12676, 27863,\n",
       "         27845, 49558, 41738, 41741, 64814, 57325, 12693, 41742, 49549,\n",
       "         12696, 49548, 27831, 61695, 27828, 64816, 12596, 64821, 12653,\n",
       "         12598, 27908, 41697, 49594, 49590, 64833, 49588, 41703, 27891,\n",
       "         64831, 49586, 41706, 27883, 27864, 58912, 12634, 27877, 49579,\n",
       "         49578, 58907, 41718, 12644, 41719, 49574, 41722, 49572, 49570,\n",
       "         64822, 12633, 49431, 58885, 27688, 13173, 41913, 64725, 13176,\n",
       "         41914, 49271, 49269, 13183, 27486, 41916, 61765, 61766, 49263,\n",
       "         49272, 13190, 13193, 61767, 41922, 61771, 27471, 13201, 61772,\n",
       "         58865, 64721, 41929, 27464, 13209, 49255, 41919, 13214, 13167,\n",
       "         27500, 27531, 41896, 27527, 64730, 49309, 57362, 41897, 41898,\n",
       "         41899, 27516, 49294, 64728, 49291, 57367, 49290, 13146, 13148,\n",
       "         13149, 41908, 13151, 49284, 13154, 61762, 57365, 49281, 57366,\n",
       "         13160, 13161, 27506, 27535, 27459, 49254, 49215, 27409, 64699,\n",
       "         27408, 57381, 13288, 13290, 13292, 13293, 13295, 27402, 27401,\n",
       "         27399, 49216, 27398, 27395, 27394, 13307, 49202, 13311, 27389,\n",
       "         27388, 57386, 13317, 27386, 41970, 49196, 13322, 13301, 13217,\n",
       "         13280, 27413, 13219, 27458, 13221, 41932, 27451, 41935, 27449,\n",
       "         13233, 58859, 27439, 49241, 13243, 41949, 41962, 13247, 27431,\n",
       "         27430, 49235, 13255, 13259, 49226, 27417, 64704, 13269, 13271,\n",
       "         13273, 13274, 49219, 13249, 49315, 13112, 13108, 12960, 49400,\n",
       "         12964, 61737, 49398, 12969, 12970, 12971, 27641, 12973, 41843,\n",
       "         49391, 27638, 27650, 27637, 41844, 12983, 27631, 12987, 41847,\n",
       "         12989, 41848, 49383, 41850, 41851, 27625, 27624, 57350, 61739,\n",
       "         64756, 61735, 27653, 27686, 41817, 41818, 12915, 61727, 49425,\n",
       "         58884, 49424, 27676, 49421, 61729, 49418, 12930, 61734, 41828,\n",
       "         57344, 61730, 12943, 49411, 64766, 41832, 12947, 12948, 27658,\n",
       "         12951, 12952, 61733, 27656, 58882, 41853, 49378, 49377, 27586,\n",
       "         49345, 27582, 27581, 49340, 27576, 13065, 27573, 27571, 27568,\n",
       "         27567, 61751, 27561, 13052, 13079, 27557, 13084, 41884, 57359,\n",
       "         27548, 13095, 13096, 13098, 41887, 13101, 64737, 13103, 13106,\n",
       "         13081, 27590, 49350, 27591, 61742, 13002, 13003, 57352, 27621,\n",
       "         49374, 49373, 27620, 49369, 27616, 13014, 13016, 27612, 41856,\n",
       "         13020, 27607, 49362, 64749, 27606, 64748, 13028, 13029, 27605,\n",
       "         49360, 64747, 13037, 13040, 27593, 41867, 12484, 27994, 64866,\n",
       "         49661, 28448, 28447, 28445, 57237, 11902, 49978, 49976, 11906,\n",
       "         28441, 28439, 49973, 64988, 11914, 28450, 28436, 64984, 11922,\n",
       "         11923, 28429, 41416, 49960, 28421, 11931, 41419, 28416, 49954,\n",
       "         11939, 11940, 41406, 64981, 28452, 61565, 28494, 28493, 28487,\n",
       "         65004, 61557, 57232, 11848, 11850, 28482, 65001, 61559, 50000,\n",
       "         49999, 49985, 28478, 28476, 11861, 49994, 64997, 28473, 64996,\n",
       "         11874, 61563, 11876, 49988, 11882, 58966, 11885, 41389, 11834,\n",
       "         28410, 28408, 41444, 28361, 64964, 12013, 12014, 12015, 41448,\n",
       "         12017, 61582, 49901, 12022, 28350, 49898, 57247, 49897, 41455,\n",
       "         41457, 57251, 12033, 49891, 49890, 28341, 64956, 57252, 28337,\n",
       "         12045, 12046, 12047, 12029, 49948, 64967, 11994, 28407, 11952,\n",
       "         41429, 28398, 28397, 11959, 49941, 41432, 61578, 28388, 41436,\n",
       "         11968, 28383, 11995, 28382, 11976, 49931, 28378, 41440, 41441,\n",
       "         28374, 11984, 11985, 61579, 11987, 28371, 28370, 49923, 11975,\n",
       "         11832, 65005, 11830, 57221, 11679, 28592, 28589, 61537, 50084,\n",
       "         61538, 28583, 28580, 11695, 11696, 65025, 41346, 11676, 11699,\n",
       "         41347, 57224, 11704, 11706, 11707, 11708, 41349, 11711, 41351,\n",
       "         11722, 28562, 50074, 28558, 11700, 50070, 50087, 11673, 28621,\n",
       "         11636, 61527, 11638, 61528, 11641, 41331, 11644, 28612, 50104,\n",
       "         11647, 50103, 11649, 28595, 41333, 11653, 11656, 58974, 11659,\n",
       "         28605, 57218, 65036, 41337, 50092, 28602, 11668, 11669, 11672,\n",
       "         11651, 11731, 11733, 11734, 11785, 28525, 41369, 28521, 65012,\n",
       "         28520, 28519, 57230, 50024, 50021, 11802, 41375, 11804, 11784,\n",
       "         11805, 41376, 11809, 11811, 11817, 50016, 28504, 11821, 28501,\n",
       "         28500, 11826, 11827, 11828, 28498, 11806, 11781, 11779, 28529,\n",
       "         11736, 11737, 11738, 11739], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 742\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 742\n",
       "  })},\n",
       " 'contains_condition': {'feature_present_idx': array([47560, 38572, 51255, 41352, 52650, 34451, 31876, 15175, 49321,\n",
       "          5415, 18566, 58348, 20666, 66616, 40388, 27340,  1486, 28539,\n",
       "          1395,   140, 26971, 27307, 51818, 37270, 62692, 63105, 20791,\n",
       "          8976, 25337, 47426, 64082, 39102,  6776,  6512, 11759, 24303,\n",
       "         13356, 26188, 61261, 14279, 67003, 55725, 60945, 60352, 17868,\n",
       "         21425, 29671, 19129, 58934, 55122, 23336, 60830, 52402, 65063,\n",
       "         48970, 66545, 49470, 66591,  1136,  4025, 45234, 66332, 65131,\n",
       "         41037,  3278,  5621, 45712, 45999, 17610, 60046, 17376, 17331,\n",
       "         13934, 17273, 30654, 17133, 61173, 17128, 14321,  3159, 42265,\n",
       "         31083, 16869, 14629, 16025,  2585,  2827, 32720, 31673, 54067,\n",
       "         49210, 31315, 59616, 30055, 56136, 24158, 24005, 46412, 25282,\n",
       "         22881, 47593, 26762, 55478,   371, 27053, 22064, 21965, 59814,\n",
       "         57272, 27833, 44595,  1975, 44288, 54986, 19829, 59335, 29373,\n",
       "         18708, 18590, 54205, 13913, 29824, 44756, 53682, 24613,  6888,\n",
       "         51738,  8309, 10372, 62604,  4443, 64610, 37435,  9916, 39173,\n",
       "         49943,  9668, 51827,  9603,  9249, 39047, 40902, 64425, 37731,\n",
       "         38169,  7457, 64131,  8490,  8243, 38744,  9557, 40539, 39016,\n",
       "         52206, 49388, 39855, 11216, 13225, 39582, 65825, 35144, 41882,\n",
       "         12883, 64891, 41410, 35914, 36200,  5693, 35319, 28216, 49928,\n",
       "         44589, 25144, 40344, 27572, 55245, 39688, 39892, 26056, 39506,\n",
       "         55323, 45308, 39405, 26992, 26356, 26591, 50191, 40216, 53608,\n",
       "         29746, 40723, 33826, 53240, 32806, 42232, 53187, 32721, 53095,\n",
       "         34941, 34996, 53841, 31899, 31699, 36621, 36660, 31292, 30963,\n",
       "         37167, 28746, 50679, 42907, 54711, 54538, 49754, 28744, 42073,\n",
       "         30069, 51424, 37449, 30201, 41145, 30909, 42790, 32421, 67008,\n",
       "         62001, 10141, 10842, 10956, 62143, 11108, 11643, 61501, 61304,\n",
       "         63263, 13748, 14580, 14928, 15695, 15991, 16357, 17134, 17268,\n",
       "         60196, 13765, 59466,  8827, 63897,   150,  1547,  2177,  2826,\n",
       "         66046,  3460,  3465,  4283,  8586,  4473, 65519,  5328,  5632,\n",
       "         64754,  6232,  6359,  6439, 64512,  4518, 18637, 23935, 57327,\n",
       "         22665, 24063, 22527, 22508, 21814, 22800, 23477, 56816, 19351,\n",
       "         57319, 22192, 21838, 64946, 65175, 39550, 49979, 26225,  5824,\n",
       "         64615, 22989,  5914, 55497, 19096, 50380, 37762, 54926, 63346,\n",
       "         38246, 50811,  8615, 38382, 56779, 38821, 50568, 39017,  7389,\n",
       "         39111,  4794,  7113,  6926,  4754, 56111,  4343,   777, 47793,\n",
       "           389,   246, 47670, 66880,  1516, 24486,    68,    56, 46484,\n",
       "         46701, 46790, 47046, 45830, 24673, 56440, 48258, 65667, 41490,\n",
       "         41901,  3847, 42218, 25286, 23746,  2986, 42596, 49167,  2486,\n",
       "         66356, 66439, 48404, 48266, 25862, 22218, 22290, 24610, 34516,\n",
       "         18058, 27724, 27793, 58735, 34085, 33998, 37641, 57798, 53812,\n",
       "         55155, 13826, 61044, 20937, 61029, 32505, 28176, 60993, 32184,\n",
       "         53888, 32031, 31946, 15041, 15085, 30940, 54116, 15734, 17002,\n",
       "         28490, 20761, 34623, 30034, 34690, 10072, 37322, 19057, 18875,\n",
       "         27108, 57140, 62061, 36751, 11664, 36523, 36354, 52246, 59427,\n",
       "         36247, 12701, 29794, 24526, 12599, 18138, 34802, 34898, 52258,\n",
       "         12425, 61504, 12286, 12180, 61965, 12068, 52260, 11970, 19856,\n",
       "         60622, 47704, 59642, 47992, 62710, 48071, 62266, 50874, 50599,\n",
       "         63919, 56627, 52742, 48006, 55777, 53314, 55815, 61181, 65771,\n",
       "         48686, 60954, 55260, 65525,    21, 22403, 17585, 17923, 18003,\n",
       "         18158, 18189, 19334, 19668, 20373, 21849, 17076, 21926, 25412,\n",
       "         26843, 27245, 28149, 28551, 28667, 29340, 29795, 31824, 22596,\n",
       "         16916, 15831, 15019,  2972,  3216,  3835,  4155,  4830,  5501,\n",
       "          5622,  5703,  5799,  5878,  7693,  8040,  8905,  9764, 10318,\n",
       "         11322, 11900, 12470, 12980, 14346, 14739, 33013, 34388, 32728,\n",
       "         38870, 38371, 38042, 35864, 38903, 37788, 34713, 45112, 38324,\n",
       "         36797, 44109, 36836, 43092, 36928, 40263,  8318, 58314, 58874,\n",
       "          9732, 42812, 51573, 64271, 58626, 50537, 17410, 39205, 39461,\n",
       "         15767, 15178, 40681, 13750, 13699, 13487, 49881, 10213, 41933,\n",
       "         41236, 20913, 64285, 57066, 28736,  1987, 31742, 47978, 35345,\n",
       "         54812, 53828,  7432, 36211, 36341, 27673,  3997,  1924, 26385,\n",
       "         34192, 34331,  5193,  5200, 43255, 25106, 56572, 45684,   183,\n",
       "         62019, 34801,  2239, 42400, 64435,  2415, 45200,  3978, 62974,\n",
       "         44260, 65516, 42414,  6935, 62845, 10365, 34684, 49460, 53024,\n",
       "         32864, 53887, 32139, 55385, 51953, 26110, 55882, 55918, 10992,\n",
       "         21993, 58095, 24289, 40727, 20180, 19963, 37645, 57621, 62554,\n",
       "         14088, 52715, 29341, 40611, 44718, 42635, 18655, 43781,  8691,\n",
       "          8282, 51745, 36982,  7444, 21750, 25470, 45482, 26291, 12115,\n",
       "         29057, 35310,  2437, 32378, 43054], dtype=int64),\n",
       "  'feature_absent_idx': array([15619,  9161,  9162, 55939, 50943, 23501, 23502, 45282, 17928,\n",
       "          9169, 45281, 17932, 29532,  9173, 14365, 63820, 29529, 25921,\n",
       "          9178, 17924,  9180, 29526, 29525, 50688, 55938, 38072, 25919,\n",
       "         38066, 17940,  9135, 29558, 49771, 14369, 24760, 17936, 53418,\n",
       "         29552, 45292, 17934, 38068,  9147, 29549, 29548,  9150, 29547,\n",
       "         63833,  9153, 52562, 29544, 29543, 55943, 63840,  9184, 29522,\n",
       "         17911,  9215, 40167,  9217, 45266, 25924,  9220, 58283, 29495,\n",
       "         16067, 17912, 63804, 17905, 49796, 63800, 29490, 25927,  9231,\n",
       "         42883, 52080, 55960, 29483, 60421, 24758,  9211, 29504,  9187,\n",
       "         29521, 17921,  9190, 38075, 45275, 14363, 55948, 29516, 60420,\n",
       "         58286, 55950, 58285, 45271,  9201, 55951, 40169,  9204, 55954,\n",
       "         29508,  9207, 14362, 24759, 42194, 29482, 63841,  9129, 23470,\n",
       "         40184, 58301,  9056, 45317, 38044, 55911, 38045, 29608, 25906,\n",
       "         29615, 42184, 38049, 16057, 29602, 29601,  9069, 14380,  9071,\n",
       "         25908, 14378, 29597, 29605, 55908, 42182, 63884, 63891,  9027,\n",
       "         60401, 17978, 49760,  9031, 29628, 17977, 51747, 16056, 29624,\n",
       "         14384, 49761, 29622, 45323, 23467,  9042, 14383, 17971, 58305,\n",
       "         45321,  9047,  9048, 51753, 23495,  9076, 17958,  9106, 63850,\n",
       "         17948, 55926, 38059, 17947, 29574, 63849, 29572, 42885, 55925,\n",
       "         49767, 29569, 45299, 58292,  9122, 14371,  9124, 63843,  9126,\n",
       "         55933, 49768, 58294, 29580, 63852,  9102,  9079, 38054, 38055,\n",
       "          9082, 45310, 55916, 55917, 25909, 25910, 58297, 23484,  9090,\n",
       "         42187,  9092, 63860, 60410, 24763,  9096, 55922, 45305, 45304,\n",
       "         23486, 61115,  9077, 45331, 63795, 45258, 29393,  9375,  9376,\n",
       "         29392, 17856, 29389, 29388, 63738, 29387, 56004, 42223, 63737,\n",
       "         43456, 25946, 29383,  9389, 29382,  9391,  9393, 29380, 24756,\n",
       "         56006,  9385, 57365, 45212,  9370, 29413, 60438, 29410, 45223,\n",
       "         52547, 29408, 45220, 58267, 29406,  9356, 42881,  9358, 17862,\n",
       "          9360, 38113, 50930, 38114, 38115,  9365, 57366, 56001, 63742,\n",
       "         60440, 29377,  9346, 25949, 42880,  9428,  9429, 17838, 24755,\n",
       "         63717, 29353, 29352, 50923, 29350, 29349, 52543, 52085, 29345,\n",
       "         63715, 14319,  9443, 63713,  9445, 57359,  9447, 14317, 40146,\n",
       "         29346, 29357, 50462,  9424, 29372, 63728, 63727, 23557, 40151,\n",
       "         23559,  9407, 29368, 45199, 57362, 52544,  9412,  9413,  9414,\n",
       "         51770, 45197,  9417, 25952, 50465, 50463, 56013,  9422, 61808,\n",
       "         42226, 29481,  9345, 29414,  9268, 38094,  9270,  9271, 45247,\n",
       "         39327,  9274, 55976, 55977, 49800, 29461, 55978, 49803, 51767,\n",
       "         38095, 63772, 63771,  9285, 29453, 17888, 63768, 60430, 45243,\n",
       "         29462, 23528, 60428, 52081, 61801, 38085, 17899, 45255, 25931,\n",
       "          9246, 23523, 55970, 40162, 29470, 45253, 63784, 45252, 58277,\n",
       "         52556, 50689,  9258, 45250, 45249, 45248, 50938, 29465, 63767,\n",
       "          9344, 42204, 16070, 29432, 25940, 45233, 45232, 29430, 55989,\n",
       "         61804, 60435, 38105, 52548, 29433,  9331, 29423, 29422, 55993,\n",
       "         60436, 42215, 14340, 39322, 25942,  9341, 49809, 29424,  9319,\n",
       "         50934, 16072, 16071,  9295, 45239, 25937,  9298, 29444, 42206,\n",
       "         57367, 43454,  9303, 45237, 63761, 42210, 23536, 45236, 63759,\n",
       "          9310,  9311,  9312,  9313, 58274, 29436, 63758, 63765,  9450,\n",
       "         55904, 58310, 49725, 51731,  8730,  8731, 29857, 29856, 42891,\n",
       "         37963,  8736, 14427, 40218,  8738, 18090, 49729, 29849, 23388,\n",
       "         18088, 29845, 64009,  8747, 14426, 18086, 29851, 23383, 18096,\n",
       "         64017, 18105, 55820, 29883, 29882, 37956, 29880, 29879, 64022,\n",
       "         25874, 23376, 29876, 29875, 52604, 25875, 52603, 16042, 29870,\n",
       "         25877, 40219, 29867, 61765, 61766, 55824, 58340, 61762, 18084,\n",
       "         61767, 29817, 50953, 29815, 29814, 23401, 29811, 61123, 18067,\n",
       "         29808, 49739, 55834, 23403,  8793,  8794, 42890, 63982,  8797,\n",
       "         63981, 55837, 14417, 60367, 55839,  8792, 58333, 16044, 18073,\n",
       "         45415, 45414, 64001, 45413, 14424, 25879, 64000, 29834, 58337,\n",
       "         45411, 45410, 63994, 14422, 29831, 49732, 29830,  8770, 18077,\n",
       "         23397, 42153, 29825, 25880, 29822, 23391, 37975, 29887, 55817,\n",
       "         18137, 60340,  8622, 45457, 16040, 14443, 40226,  8627, 57392,\n",
       "         49707, 23358, 23363, 60342, 49708, 60344, 29929,  8636, 50962,\n",
       "         18127, 18126, 14441,  8641, 55790, 60338,  8617, 29943,  8591,\n",
       "         64070, 52619, 45467, 55779, 29957, 29956, 14448, 55781, 14447,\n",
       "         29950,  8602, 23355,  8604, 45462, 18143, 64062, 49703, 45460,\n",
       "         39711, 45458, 52616,  8614, 37939, 18107, 64045, 50961, 55805,\n",
       "          8675, 55806, 29903, 23371, 57391, 18112, 29899, 64037, 64036,\n",
       "         18115, 23373, 18110,  8687, 49712, 18109, 37951, 49713,  8693,\n",
       "          8694, 18108, 29891, 55813, 64040], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 608\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 608\n",
       "  })},\n",
       " 'contains_consist_of': {'feature_present_idx': array([56146,  3253, 65940, 65743, 38657,  4006,  4403, 51994, 51614,\n",
       "         27463, 50965,  5634, 16022, 27925, 60616, 28891, 11058, 29520,\n",
       "         61172, 34641, 34484, 56410, 30332, 61955, 33221,  5920, 44441,\n",
       "         32033,  1194,  1024, 18498, 41758, 21620, 20753, 55961,  1759,\n",
       "         19855, 17957,  1086,  2016, 42922, 29132, 50277, 11898, 21810,\n",
       "         50397,  8975, 28502, 28431, 50744, 27993, 31861, 31924, 11278,\n",
       "         49964, 31002, 60870,  9051, 20126, 49711, 27917, 61544, 19707,\n",
       "         20609, 30226, 61595, 61844, 20018,  9635,  9602, 31652, 21179,\n",
       "         54517, 17771, 59027, 54552, 57547, 24607, 58830, 58678, 22930,\n",
       "         25223, 24256, 16559, 16648, 24177, 16968, 24046, 23906, 17394,\n",
       "         54051, 42863, 53340, 15004, 13490, 21903, 27339, 59657, 13848,\n",
       "         52307, 27028, 26131, 26928, 26809, 52483, 21977, 67211, 26518,\n",
       "         52848, 26171, 18377, 14368, 61633,  6498,   661, 40134, 38184,\n",
       "         63109,  1442, 49050,  6678,  2618, 37835,  1566, 36021, 45692,\n",
       "         41341, 63487, 46352, 37247,  4747, 36257, 66173, 64753,  4989,\n",
       "         66326, 45884, 39691, 42034,  1002,  2863,  8502, 62225,   174,\n",
       "         62347, 43033, 33291,   267, 48061, 62505, 42185, 47666, 62619,\n",
       "          7780, 47625, 47041, 39573, 34653, 34321, 45384, 42055, 40483,\n",
       "         39731, 24728, 24525, 40069, 24377, 40106, 39336, 24574, 39844,\n",
       "         24806, 53714, 39750, 48675, 23793, 42466, 42146, 42120, 55609,\n",
       "         55220, 21328, 21541, 55218, 21805, 43195, 41800, 43318, 40350,\n",
       "         22141, 22432, 22470, 54597, 54590, 39185, 41456, 41096, 23094,\n",
       "         41041, 23213, 23284, 54416, 22202, 39027, 38048, 25757, 28603,\n",
       "         50383, 46514, 35659, 46652, 46654, 29399, 34749, 34743, 49882,\n",
       "         29702, 49774, 34742, 29989, 30032, 49735, 49543, 47537, 33767,\n",
       "         30472, 30696, 30946, 31299, 49099, 31795, 33124, 48473, 28561,\n",
       "         25384, 36028, 28334, 25765, 52867, 45192, 38404, 26306, 26386,\n",
       "         38185, 52509, 26715, 38129, 26796, 37958, 37716, 27078, 52276,\n",
       "         27309, 45870, 36894, 51393, 45914, 51051, 51034, 27876, 45974,\n",
       "         46039, 50809, 36218, 50735,    25, 54986, 20326, 10110, 10161,\n",
       "         61435, 10361, 10403, 10439, 61136, 10923, 11062, 60669, 11609,\n",
       "         11818, 11852, 12175, 60227, 12333, 12785, 15303, 14770, 14756,\n",
       "         14408, 14154, 14137, 20340, 14121, 13944, 59578, 59687, 13304,\n",
       "         59854, 59912, 14074,  9768,  9444,  8919, 66008,  2554,  2373,\n",
       "         66239, 66392,  1975, 64836,  1387, 66472, 66508,   532, 66611,\n",
       "           148,    60,  1385, 15391,  3880,  4686,  8605,  8436, 62599,\n",
       "         62920,  7294,  7208,  4328,  7140,  6525,  6426,  6310, 63608,\n",
       "          5557,  5313, 63322, 59223, 61660, 15967, 16175, 18754, 58275,\n",
       "         16743, 18503, 19091, 18685, 18905, 15836, 17189, 18449, 56570,\n",
       "         19698, 18170, 18483,  6645, 56829, 47162, 55115, 46109, 63522,\n",
       "         45983, 36749,  5485, 18604,  5046,  4987, 55216, 37275, 36156,\n",
       "         34662, 25186, 21931, 54799, 32994, 48610, 18250, 48394, 48341,\n",
       "         62360, 62503, 53353, 47865, 54826, 33585, 62852, 22015, 62921,\n",
       "         47490, 47448, 47225, 18357, 34376,  7245, 34557, 37533,  7154,\n",
       "         45710,  4185,  4515,  2481, 21223,  2285, 21217, 40658, 41322,\n",
       "          1799,  1744, 41531,  2483,  1458, 55949, 19359,   610,   553,\n",
       "         43147,   523, 42271, 43035, 42531, 21002, 40104, 44710,  2607,\n",
       "         64764, 45660, 56731, 62009,  3925,  3896, 45551, 38323, 21416,\n",
       "          3623, 38562, 38810,  3462,  3429, 39260, 65480, 39514, 39530,\n",
       "          2959,  2652, 39759, 64761, 49080,  8139,  8689, 51372, 53940,\n",
       "         27888, 60007, 12648, 12589, 12194, 28293, 32181, 51383, 17430,\n",
       "         12039, 57752, 11716, 28878, 11680, 28925, 57697, 28968, 23352,\n",
       "         12129, 13470, 13480, 13641, 59130, 15466, 25376, 53400, 25485,\n",
       "         15272, 15130, 15067, 14785, 24750, 59231, 52551, 14411, 26589,\n",
       "         59468, 14311, 53572, 27012, 58497, 27262, 59591, 60805, 23351,\n",
       "         28373, 42746,  9859, 31558, 31540, 49382, 49195, 18008, 22912,\n",
       "         17897, 61859, 18155, 57564, 30791,  9486, 60975, 18235,  8885,\n",
       "         17572, 31334, 57691, 31031, 43999, 48068, 47919, 43917, 44402,\n",
       "         56697, 43820, 59126, 59427, 48274, 54786, 43458, 42899, 48958,\n",
       "         56111, 55964, 48771, 53297, 62005, 53542, 53284, 43184, 62206,\n",
       "         61965, 55663, 43234, 49127, 43322, 53477, 58866, 60901, 49163,\n",
       "         63046, 63209, 60612, 54389, 46957, 63280, 63341, 46526, 49769,\n",
       "         63346, 55205, 49843, 64597, 46225, 55190, 57275, 57756, 45645,\n",
       "         57162, 59561, 52287, 66120, 51949, 61743, 49167, 58381, 52449,\n",
       "         47485, 65207, 51080, 44963, 61644, 64963, 49257, 45406, 47328,\n",
       "         53737, 32031, 42704, 27793, 27528, 27433, 27178, 27131, 27108,\n",
       "         27928, 26780, 26048, 24798, 24768, 24460, 42743, 24214, 26429,\n",
       "         28159, 28535, 28812, 33274, 33186, 33123, 33048, 32588, 32402,\n",
       "         31743, 31268, 30980, 30077, 30070, 29930, 29737, 29390, 28966,\n",
       "         23433, 22837, 22780, 22155,  9558,  9255,  9158,  9118,  8006,\n",
       "          7389,  6926,  6842,  6246,  3847,  3468,  2531,  2229,  2181,\n",
       "           237,  9827, 33277, 10629, 11054, 22102, 21836, 21758, 21326,\n",
       "         20944, 20387, 18146, 17937, 17833, 17578, 17456, 16971, 15760,\n",
       "         13786, 11970, 10648, 33335, 67348, 33443, 34745, 42404, 38557,\n",
       "         35710, 37900, 36116, 36310, 42161, 34690, 36489, 36793, 36800,\n",
       "         38376, 42069, 41643, 37137, 37599, 41796, 36658, 34667, 38246,\n",
       "         42596, 33459, 34172, 33938, 40578, 33957, 44653, 44345,  8549,\n",
       "         11322, 15447,  8457,  8407, 45267, 45324, 12181, 14654, 22282,\n",
       "         14325, 38332, 41717, 12800, 23673, 54267, 54162, 54117,  8335,\n",
       "         21582, 21563, 38436, 44706, 61387, 44605, 44219, 16053, 10640,\n",
       "         10318, 61535, 18541, 10147, 15992, 33376, 19154, 56647, 44273,\n",
       "          9807, 20342,  9442, 11046, 41320, 20677, 61870,  8924, 17455,\n",
       "         44185, 40107,  3377, 34110, 27618, 51335,  3317, 27870, 49112,\n",
       "         50920, 46414, 34079, 31070, 28526, 46467,  2852, 49963, 30681,\n",
       "         42330, 49607,  2182, 46459, 66497,  1155, 65478, 42004, 37651,\n",
       "         33182,  6404, 32622, 48509, 47696, 52789, 48604, 27004,  5651,\n",
       "         32978, 32924, 65293, 64149, 25150, 66560, 60167,   656, 12732,\n",
       "         63103,  9946,  2610, 13210,  7658,  7769,  6568, 63493,  6012,\n",
       "         64292,  4419, 42319,  8613, 41550, 41358, 65911,  7070,  3306,\n",
       "         42912,  6656, 56707, 20192, 19808, 56492, 24239, 27247, 20594,\n",
       "         55833, 26420, 21643, 26409, 54813, 25279, 22511, 24668, 13750,\n",
       "         38269, 27255, 18642, 24665, 17925, 47729, 13818, 33849, 30183,\n",
       "         30129, 15424, 27453, 29753, 15467, 34854, 29539, 15948, 35148,\n",
       "         27881, 63722, 52403, 36963, 25731,  3645, 30450, 24737,  6869,\n",
       "         46269,  5806, 59782, 23399, 53817, 13855, 14401, 12016, 16012,\n",
       "         16392, 44827,  7052, 40693, 20756, 55752, 10051, 21117, 62919,\n",
       "         21734, 45475,  8034, 52787, 14088, 49273, 11134, 25470, 53876,\n",
       "         45263, 36485, 27689, 39992,  8350, 44498,  7968, 44970,  4613,\n",
       "         45013, 15573, 51811, 34226, 59622, 35310], dtype=int64),\n",
       "  'feature_absent_idx': array([52990, 21019, 32276, 51721, 41932, 21016, 51718, 32278, 15365,\n",
       "          9407, 51712, 21020, 51709,  9412,  9413,  9414, 21011, 51705,\n",
       "          9417, 32284, 32286, 32287, 41935, 15364, 51727, 51731, 32270,\n",
       "         41916,  9370, 51767, 32251, 41919,  9375,  9376, 32254, 21030,\n",
       "         51753, 15372, 32262, 51747, 41922, 51743,  9385, 51742, 21026,\n",
       "         15370,  9389,  9391, 41929,  9393,  9422,  9424, 32293, 32297,\n",
       "          9458, 51660, 20988,  9461, 15353, 20985, 20984, 51646,  9467,\n",
       "         20983,  9469, 32338, 51638, 20981, 32340, 51632,  9475, 20979,\n",
       "         20977, 41962, 51620, 32348, 18283,  9457, 51770,  9456, 15354,\n",
       "         37057,  9428,  9429, 37054, 32306, 51685, 32309, 32311, 32312,\n",
       "         32316, 41949, 51675, 32328, 37051,  9443,  9445, 51671,  9447,\n",
       "         51669,  9450, 20990, 51665,  9453, 51661, 21036, 15376,  9365,\n",
       "         51922,  9285, 32186, 51915, 51914, 41884, 21071, 51909, 32194,\n",
       "          9295, 21068, 32195,  9298, 51900, 51895, 21066, 32199,  9303,\n",
       "         21064, 15392, 51886, 41887, 32203, 51924, 51878, 51928, 51935,\n",
       "         51977, 21083,  9258, 51972, 51968, 32167, 51958, 51957, 32169,\n",
       "         51954, 32170,  9268, 37083,  9270,  9271, 32177, 51945,  9274,\n",
       "         37081, 51943, 51941, 32179, 51937, 51933,  9483,  9310,  9312,\n",
       "          9341, 51810,  9344,  9345,  9346, 51809, 41908, 51807, 51806,\n",
       "         37069, 51799, 51793, 51791, 51788,  9356, 37067,  9358, 51785,\n",
       "          9360, 51784, 41913, 32245, 41914, 32235,  9311, 51819, 15383,\n",
       "          9313, 51877, 21060, 32209, 51868, 51867,  9319, 32215, 51859,\n",
       "         51856, 41896, 51853, 41897, 41898, 51848, 41899, 18267,  9331,\n",
       "         32226, 32227, 32228, 32230, 32232, 51820, 51978, 32351,  9487,\n",
       "         20909, 51358, 51356, 42009,  9634, 51352, 51351, 51348, 51344,\n",
       "          9640, 42008,  9641, 42011, 51337, 51333, 15320, 42014, 42015,\n",
       "         51317, 32459, 42016, 51303, 20907,  9628, 20911, 37024, 51415,\n",
       "         51411, 32435, 15326, 51403,  9608, 51402, 20916, 51392, 51391,\n",
       "         51389, 51384, 51382,  9616, 51377,  9618, 51376, 51375, 42006,\n",
       "         51370,  9623, 20914, 32440, 32464, 15316, 51300, 51299, 51248,\n",
       "         42031, 32506, 42037,  9689, 51234, 42039, 32509, 20879, 32511,\n",
       "         32514, 32515, 32518, 20874, 42050, 20871,  9702, 51199, 37012,\n",
       "         32524, 51195, 51190, 32525, 37014, 51419, 32495, 20888, 15315,\n",
       "         51295, 51286, 51280, 18294, 32472, 37022, 51275, 51274,  9666,\n",
       "          9667, 37017, 51269, 51268,  9672, 51267, 32483, 51264, 20891,\n",
       "         51262, 32486, 51260, 42024, 32493, 42005, 32431, 32430, 15337,\n",
       "         32388, 32392, 15336, 41989, 51540,  9525, 37031, 20948, 20947,\n",
       "         32399, 20945, 32400, 51526, 51523, 32401,  9535, 32404,  9537,\n",
       "          9538,  9539, 41992,  9541, 51552, 51513,  9515, 37036, 37040,\n",
       "         41970, 51593, 32362, 51585,  9494,  9495, 32364, 32365,  9498,\n",
       "         20965, 41971, 51578, 32371,  9503, 51572,  9505, 37039, 41973,\n",
       "         41976, 20959, 51558, 51557,  9514, 20972, 20939, 51506, 51453,\n",
       "         51452,  9576, 20929, 51446, 32423, 51440, 51439, 20927, 51436,\n",
       "         20926,  9585, 32424,  9587, 32427,  9589,  9591, 20922,  9593,\n",
       "         51428, 51427,  9596, 51425,  9573, 51508, 42001,  9570, 41994,\n",
       "         41996, 32411, 32412, 32415,  9551, 51489, 51485, 51484, 51482,\n",
       "         20933, 15330,  9559,  9560, 51474,  9562, 51473, 51469, 32417,\n",
       "          9566, 51463, 51459,  9569,  9571,  9709, 21084, 21086, 52503,\n",
       "         31918, 52501, 18223, 21228,  8947,  8948,  8949, 52493, 52492,\n",
       "         21231, 21227, 37126, 52481, 52480,  8958, 18226, 21221, 21220,\n",
       "         31934, 21218, 52468, 52486, 41747, 52508, 52518,  8913, 52544,\n",
       "         52543, 41741, 52541, 31904,  8920, 52539, 52537,  8923, 31905,\n",
       "         52535,  8927, 41742, 31907,  8930, 31910,  8932, 21235, 21234,\n",
       "          8935,  8936, 41744, 31935, 52465, 21215,  8969, 52406, 21200,\n",
       "         41762, 18232, 52396,  9006,  9007,  9008, 31973, 18236, 52385,\n",
       "         41772, 41773, 31982, 41775,  9018, 41776, 52376, 21188, 52369,\n",
       "         41777, 52364, 18237, 21202, 21242,  8998,  8996, 52462, 52461,\n",
       "         31937, 31938,  8974, 52452, 52450, 52445, 52444, 15462, 31943,\n",
       "         21209, 31944, 52429, 31948, 37122, 52418, 15459,  8990, 52414,\n",
       "         31954, 52409,  8995, 52408, 52547, 52548, 31902, 41703, 31837,\n",
       "         52695, 37135, 41706, 31845, 31846, 31848, 52680, 52679, 21275,\n",
       "         52676,  8842, 15485, 52671,  8845, 31854, 52669, 52664,  8849,\n",
       "         52662, 52661, 21271, 52698, 18218, 15490, 31828, 31803, 52740,\n",
       "         41695, 52738, 52734, 52733, 31806,  8807,  8808, 31807, 52728,\n",
       "         52725, 52721, 31811,  8815, 52718, 52714, 41697,  8819, 18213,\n",
       "         15493,  8822, 31826, 37139,  9027, 21269, 52640, 52596, 52595,\n",
       "          8888, 37128, 52591, 21251, 52585, 31888, 31889,  8895, 52581,\n",
       "         52580,  8898,  8899, 41738, 37127,  8902, 31897, 52562, 31898,\n",
       "         21244,  8907, 52556,  8884, 41718, 31886,  8881, 31859, 52637,\n",
       "         21266, 52635, 41719,  8862, 21264, 52627, 41722, 52623, 52620,\n",
       "         52619, 52616, 31866, 31870, 31872, 31874, 41729, 52604, 52603,\n",
       "         41731, 31882, 52599, 37129, 21085, 31994, 32000,  9173, 52119,\n",
       "         32098, 32105, 52115,  9178, 52114,  9180, 32106, 21116, 32096,\n",
       "         52108, 52103, 52102,  9187, 52096, 15417,  9190, 52094, 52090,\n",
       "         52085, 41844,  9184, 52121, 21122,  9169, 52160, 32093, 52153,\n",
       "          9147, 21129, 52149,  9150, 52148, 21128,  9153, 52143, 52140,\n",
       "         52136, 41843, 21125,  9161,  9162, 52131, 21124, 52129, 52127,\n",
       "         21123, 52124, 32113, 52081, 52080, 32115, 41853, 52037, 18255,\n",
       "         21100, 15406,  9231, 32141, 52023, 32142, 41856, 52016, 32146,\n",
       "         52011, 37088, 32154, 37086, 41867, 51998,  9246, 32158, 51992,\n",
       "         37085, 51987, 41851, 32091, 52043, 52046, 18253, 52074,  9201,\n",
       "         18254, 52072,  9204, 52071, 41847,  9207, 32126, 52063, 32130,\n",
       "          9211, 41848, 41850, 52057,  9215, 52055,  9217, 52050, 52048,\n",
       "          9220, 52047, 15410, 32086, 52170, 52172, 41807, 52312, 52310,\n",
       "         52305, 52303, 32024, 21165, 21164, 15433,  9069, 52296,  9071,\n",
       "         32030, 32032, 41817, 32040,  9076,  9077, 41818,  9079, 52279,\n",
       "         52277,  9082, 37107, 37104, 52318, 52323,  9031, 52349, 37110,\n",
       "         52346, 52345, 32005, 21178, 52342, 52341, 32008, 41798,  9042,\n",
       "         21175, 52335, 32010, 15440,  9047,  9048, 37109, 52331, 21171,\n",
       "         41802, 15437,  9056, 18239, 32047, 52270, 52210, 52208, 52207,\n",
       "         32077, 52202, 52201,  9122, 52194,  9124, 52192,  9126, 37098,\n",
       "         41832,  9129, 32082, 21137, 52181, 37097, 21135,  9135, 52176,\n",
       "         21134, 52173, 52212, 32050, 41828, 52219, 32051, 32057, 52265,\n",
       "          9090, 52263,  9092, 15429, 52254, 32061,  9096, 52249, 52248,\n",
       "         52243, 21149, 21148,  9102, 32063, 52237, 21146,  9106, 52225,\n",
       "         52224, 37099, 18247,  9710, 42053, 51183, 20597, 10308, 10309,\n",
       "         50273, 33014, 36905, 15166, 50262, 15165, 42274, 36906, 42276,\n",
       "         42280, 10321, 50249, 15161, 18361, 50245, 10326, 33035, 50241,\n",
       "         20584, 33025, 20599, 10304, 50279, 10280], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 888\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 888\n",
       "  })},\n",
       " 'contains_degree': {'feature_present_idx': array([35893, 58860, 52697,  9864,  9819, 58886, 42937,  9776,  9763,\n",
       "         52689, 22719, 42870,  9696, 47905,  9654, 58903, 58855, 22730,\n",
       "         52739,  9909, 16790, 10118, 28215, 10096, 58765, 16801, 42985,\n",
       "         22706, 58771, 28386, 52796,  9991, 42956, 16860, 58826, 22767,\n",
       "         28308, 42787, 58910, 28601, 59151, 42519, 59172,  9243, 47969,\n",
       "         28852, 22627, 28785, 28861, 52540, 48002, 17214, 28972,  9109,\n",
       "         28977, 28999, 42457, 58711,  9386, 28774, 47951, 28626, 58986,\n",
       "          9594, 22672, 28704, 42689, 59124, 59044, 28729, 17041, 42544,\n",
       "          9436,  9435, 28769, 42533, 42685, 43079, 28127, 43087, 10885,\n",
       "         10884, 10859, 58231, 27736, 27746, 10784, 43488, 22991, 22983,\n",
       "         16583, 10749, 58266, 16592, 10639, 27823, 58245, 58407, 58205,\n",
       "         43506, 11057, 57918, 27526, 47529, 23054, 57999, 58043, 58194,\n",
       "         58059, 27589, 47565, 27642, 10944, 43579, 53061, 58192, 43619,\n",
       "         22535, 10564, 47638, 28003, 28015, 28036, 43211, 52873, 10233,\n",
       "         16693, 10284, 47746, 10200, 52866, 43151, 58690, 10184, 43123,\n",
       "         22795, 22813, 16616, 58647, 10320, 10523, 22932, 43401, 58485,\n",
       "         52886, 58525, 43289, 43214, 43287, 10418, 10404, 27924, 10369,\n",
       "         43242, 47742, 43221, 10426, 43674, 59443, 59470, 60564, 41500,\n",
       "         30009,  7763, 41478, 17550, 48405, 22274, 22225, 60702, 30090,\n",
       "         41407, 52177, 52175,  7629, 41526, 29962,  7829, 60549,  8007,\n",
       "         60456, 29852,  7989, 60480, 48278, 22342, 60762, 41642,  7945,\n",
       "         41617,  7924, 60520,  7896, 60530,  7865, 29866,  7618, 60776,\n",
       "         30173, 52130,  7423, 30318, 41228,  7361,  7338, 17718, 48440,\n",
       "         60992, 41203,  7232, 48446, 22165, 61042,  7174, 48462, 22186,\n",
       "         60449, 52133, 17691, 24224, 41377, 60809,  7574, 41334, 41324,\n",
       "         60840,  7452,  7554,  7523, 35900,  7514, 41272, 17666, 17685,\n",
       "         60912, 30214, 29810, 60399,  8023, 17334,  8766, 29321, 59970,\n",
       "         60019, 42150, 29343, 59815, 42128, 60076,  8671, 60089, 29370,\n",
       "         29376, 17365,  8582, 42115,  8530, 42245,  8872, 48046, 42317,\n",
       "          8999, 42289, 48091,  8970, 29167, 59694, 42272, 29179, 42268,\n",
       "         42263, 29228, 29257, 29268, 29270, 59588, 17230, 17368, 29416,\n",
       "         60346, 29647, 29673,  8149,  8141, 41880, 29711, 29618, 29724,\n",
       "         60371, 48261, 60391, 29783,  8071, 41748,  8025, 41806, 29405,\n",
       "         41953, 60262, 42057, 52432, 42017, 29493, 22380, 29507,  8395,\n",
       "          8240,  8385, 41984, 29575, 29578,  8313, 52360, 60246, 52317,\n",
       "         29512, 43679, 11100, 27447, 25207, 13665, 45840, 25240, 13630,\n",
       "         25250, 25309, 47118, 25339, 54036, 13560, 25353, 23659, 55563,\n",
       "         55583, 13702, 13758, 25185, 45901, 23821, 55374, 45997, 13915,\n",
       "         25098, 47038, 13885, 55634, 13879, 55408, 13859, 13854, 15553,\n",
       "         13836, 55471, 45930, 55395, 23643, 55653, 55664, 53931, 13204,\n",
       "         13185, 47173, 13174, 45471, 45468, 55836, 55942, 15735, 13097,\n",
       "         25721, 45448, 13058, 13053, 13049, 23597, 25074, 13222, 53949,\n",
       "         15620, 25426, 45669, 13433, 25490, 25522, 45601, 15683, 53981,\n",
       "         45580, 55758, 25561, 13298, 25582, 45568, 55819, 55750, 54094,\n",
       "         46090, 23869, 54731, 46727, 54747, 46282, 54760, 54769, 14812,\n",
       "         54729, 54793, 46280, 24484, 54869, 54874, 14688, 54888, 24045,\n",
       "         24451, 14664, 15286, 24351, 24231, 24126, 15100, 46537, 15023,\n",
       "         46474, 24079, 15265, 24068, 46386, 14946, 54607, 46717, 14920,\n",
       "         54617, 24340, 15225, 15749, 14658, 46247, 15411, 23924, 55087,\n",
       "         24793, 24809, 15434, 46144, 46911, 24884, 24943, 23886, 55221,\n",
       "         54217, 14072, 55257, 46113, 46137, 24549, 24747, 24736, 14613,\n",
       "         46233, 46231, 14575, 14567, 54913, 54941, 24742, 24614, 46778,\n",
       "         14513, 15387, 24653, 24658, 24702, 14397, 46775, 53787, 56005,\n",
       "         47188, 26777, 26795, 23236, 26862, 11720, 47410, 26911, 23261,\n",
       "         11691, 53282, 11661, 16344, 26941, 57313, 26964, 44294, 23223,\n",
       "         53281, 57093, 11851, 12000, 44482, 26606, 26622, 53412, 11965,\n",
       "         11963, 47374, 23317, 44419, 56957, 44416, 11871, 26750, 23279,\n",
       "         57073, 53407, 44512, 44258, 16367, 23160, 43936, 23127, 11318,\n",
       "         11308, 11300, 11297, 57788, 27280, 27316, 11203, 16471, 53120,\n",
       "         43752, 57884, 53101, 11215, 44256, 27168, 44025, 57435, 57439,\n",
       "         44192, 53214, 57461, 44072, 11540, 27159, 11536, 57562, 11508,\n",
       "         11497, 11494, 44060, 53203, 57664, 57522, 61127, 12025, 16097,\n",
       "         56166, 12725, 47207, 26030, 56239, 45009, 56245, 56158, 12682,\n",
       "         12666, 23570, 23568, 47215, 15920, 12556, 15936, 26072, 53696,\n",
       "         53752, 25996, 12953, 56018, 53779, 56040, 25786, 53774, 25803,\n",
       "         12810, 25808, 25923, 56124, 15861, 25981, 25985, 12823, 25987,\n",
       "         12866, 44538, 23563, 23522, 56510, 56554, 56557, 44689, 44668,\n",
       "         56641, 12131, 44794, 12121, 44606, 44581, 53452, 56700, 26511,\n",
       "         56721, 12057, 56665, 15971, 16065, 12305, 12489, 26253, 56416,\n",
       "         12469, 15996, 12443, 44902, 12285, 23494, 56463, 56469, 26296,\n",
       "         26312, 44848, 47254, 53538, 56456, 17767,  7598, 41163,  2816,\n",
       "         65422,  2805, 50910, 19381,  2769, 34176, 19403,  2750, 37844,\n",
       "         34199, 20987, 65538, 65570, 65571,  2828,  2831, 65412, 37909,\n",
       "         65177, 19309,  2977, 34032, 49458, 34051, 65245, 49644, 65255,\n",
       "         65284, 65305, 21003, 65317, 65336, 19363, 34151,  2907,  2635,\n",
       "         49647, 50840, 34424, 37491, 19599, 19619, 37415,  2329, 65863,\n",
       "          2432, 49682, 37376, 34527,  2231, 65954, 50701, 37361, 65987,\n",
       "         20873,  2991, 65768, 50739, 65592, 50802,  2595, 49662, 34295,\n",
       "          2572, 19529, 65752, 20908,  2530, 34352, 34377, 65700, 50740,\n",
       "         37548, 37527, 19557, 33985, 65110,  3076, 49279,  3689, 18962,\n",
       "         33369, 18971,  3669, 33382,  3742, 38640,  3601, 48476, 64373,\n",
       "         51154, 64399, 64433, 64472,  3606,  3554, 33317, 38700, 51224,\n",
       "         33118, 38798,  3991,  3972, 64142, 38791, 18900, 64172,  3906,\n",
       "         51204,  3863, 64198, 18876, 33183, 49198, 49192, 20857, 19009,\n",
       "         19018, 19138,  3259, 64929,  3256, 19142, 38121, 50960, 19137,\n",
       "         19232, 64959, 21041, 19239, 38064, 38038, 19254, 65038, 33865,\n",
       "         64561,  3290, 33655, 64579,  3492, 51142, 38567, 33517, 33538,\n",
       "         33546, 64916, 51028, 33582, 21076, 64696, 33607, 33611, 38420,\n",
       "         49304, 49303,  4059,  2121, 20804,   719, 66846, 66851, 50344,\n",
       "         20100, 20447, 36177,   531,   481, 20156, 66910, 50152,   442,\n",
       "         49950,   421,   720,   732, 36261, 66797, 35301, 36334, 66690,\n",
       "           890, 66709,   874, 66712, 49962, 35307, 35337,   793, 36322,\n",
       "         50348,   758, 35401, 66778, 66731, 20408, 66920, 35541, 49990,\n",
       "         67195, 67202, 36012, 50006, 20332, 67216, 67179,    80, 35798,\n",
       "         20273, 35923, 67281, 35825, 35921, 35905, 67240, 49912, 36016,\n",
       "         49984, 35553,   318,   317,   306, 66948,   292, 20210, 36019,\n",
       "         35614, 35617,   217, 35625, 66973, 66991, 66996, 67015,   235,\n",
       "           924, 66646,   961, 36995, 20735,  1732, 66176,  1709, 20716,\n",
       "         50531, 19846, 20706, 66229, 34900, 36923, 36865, 19895,  1532,\n",
       "         50524, 66226,  1520, 34840, 34808,  1984, 20801,  1945, 34700,\n",
       "         19764, 49751, 37296,  1801, 37071, 37044, 34792, 37009,  1853,\n",
       "         49784,  1849,  1825,  1906, 19678, 34998, 66304, 66429, 36483,\n",
       "         36474, 66451, 66457, 35249, 66533,  1120, 66544, 36381,  1026,\n",
       "         50374, 36358, 49877,   976, 66620, 66577,  1490, 49841,  1139,\n",
       "          1440, 20638,  1396,  1388, 50455, 36687,  1337, 20625, 66373,\n",
       "         66379,  1248, 49820, 36622, 35114, 36608,  1161,  1314,  4062,\n",
       "         54532, 62980,  6578, 62734, 61640, 31842, 40922,  5539, 40012,\n",
       "          5552,  5568, 48700, 51720, 48689,  5595, 31809, 31006, 31804,\n",
       "          5640, 17891, 38831, 40919, 61697, 18198, 61719,  5660,  6518,\n",
       "          6511, 18187, 51729, 51748, 31062, 61677, 62555,  6629, 62760,\n",
       "         51975,  6716, 17864, 62992,  5202,  5205, 40944, 32109, 51599,\n",
       "         61546], dtype=int64),\n",
       "  'feature_absent_idx': array([39377, 46402, 46406, 13606, 57656, 13608, 29424, 29423, 29422,\n",
       "         57650, 13615, 29414, 29413, 13620, 57643, 57642, 57641, 13626,\n",
       "         29410, 29408, 13631, 29406, 13637, 13638, 46417, 57629, 57628,\n",
       "         57626, 29430, 57662, 29432, 29433, 29462, 57699, 13551, 29461,\n",
       "         13557, 29453, 13564, 13565, 13566, 46389, 13568, 57688, 13571,\n",
       "         13647, 46390, 13577, 29444, 13579, 13582, 46393, 57676, 29436,\n",
       "         57670, 57667, 57666, 13595, 57665, 46399, 57683, 29393, 29392,\n",
       "         29389, 29353, 13701, 29352, 13705, 29350, 29349, 46442, 57579,\n",
       "         57578, 29346, 29345, 46446, 57571, 13698, 13718, 46447, 57570,\n",
       "         29335, 57568, 13725, 57567, 29334, 57566, 13729, 13731, 46449,\n",
       "         29329, 29326, 13719, 46383, 29357, 46439, 29388, 13654, 29387,\n",
       "         57611, 13659, 57609, 29383, 29382, 29380, 57605, 13671, 13672,\n",
       "         29377, 13696, 13675, 57601, 46427, 57599, 29372, 57596, 46428,\n",
       "         57594, 29368, 13688, 13689, 57591, 13692, 46434, 46426, 29465,\n",
       "         46382, 13541, 57825, 57821, 29572, 29569, 13399, 57811, 13405,\n",
       "         57807, 57801, 13410, 29558, 57796, 13415, 29574, 57795, 13422,\n",
       "         13423, 13425, 13426, 29552, 13429, 29549, 29548, 57782, 13435,\n",
       "         29547, 29544, 29543, 46334, 46341, 57835, 57840, 13338, 29615,\n",
       "         57876, 46299, 13344, 13345, 13347, 29608, 29605, 46304, 29602,\n",
       "         57867, 57864, 46317, 29601, 46305, 29597, 13362, 13364, 13365,\n",
       "         57857, 57856, 57850, 46312, 57846, 46314, 46316, 29580, 57860,\n",
       "         46458, 46342, 46343, 13495, 57736, 13498, 29495, 57735, 29490,\n",
       "         13507, 13511, 57731, 13513, 57730, 29483, 29482, 13494, 13519,\n",
       "         57725, 29481, 13524, 46372, 57723, 46374, 46377, 13532, 57718,\n",
       "         57717, 13536, 57715, 29470, 13520, 13441, 46361, 13485, 46344,\n",
       "         13446, 57772, 13448, 57770, 29532, 13454, 57768, 57766, 29529,\n",
       "         57762, 46349, 29526, 57741, 29525, 46350, 29522, 13466, 13467,\n",
       "         29521, 46353, 57753, 57750, 29516, 13476, 29508, 29504, 57745,\n",
       "         13463, 46294, 29320, 57550, 46572, 14028, 57336, 57334, 14033,\n",
       "         14034, 14035, 29115, 29114, 57329, 46573, 29111, 57325, 29110,\n",
       "         29107, 29105, 46575, 29098, 14054, 14056, 29097, 14059, 29094,\n",
       "         14062, 46582, 57306, 57305, 14026, 29119, 29123, 14021, 13974,\n",
       "         13975, 13976, 29152, 46558, 57367, 13986, 29149, 13988, 57366,\n",
       "         57365, 57362, 29147, 29086, 57359, 57352, 57350, 29140, 29139,\n",
       "         29135, 29133, 46563, 57344, 29131, 46564, 29127, 57341, 57339,\n",
       "         29146, 57303, 14073, 57301, 14135, 29042, 57247, 29041, 29040,\n",
       "         29039, 14143, 46617, 14146, 29035, 29033, 57237, 29032, 14134,\n",
       "         57232, 14157, 14158, 29029, 57227, 29028, 14162, 14163, 14164,\n",
       "         57224, 46632, 14169, 57221, 29020, 57230, 13973, 46609, 57251,\n",
       "         57299, 14078, 14079, 57297, 46588, 14085, 46589, 46591, 29071,\n",
       "         14091, 57283, 14099, 14102, 14131, 46602, 14110, 14111, 29058,\n",
       "         14113, 57266, 57265, 46603, 57261, 57257, 57256, 57254, 14127,\n",
       "         57252, 57271, 29161, 57381, 13964, 13804, 13808, 57502, 46480,\n",
       "         57501, 13815, 46482, 57493, 46486, 13823, 13825, 46487, 46488,\n",
       "         13801, 13829, 46490, 29254, 46493, 29252, 46494, 13840, 29249,\n",
       "         57480, 46495, 57468, 29239, 46510, 46511, 46489, 46513, 13799,\n",
       "         13796, 46462, 57544, 29308, 29306, 29305, 29304, 29303, 13767,\n",
       "         13772, 13773, 13774, 13776, 13778, 57511, 57526, 57524, 29287,\n",
       "         46472, 57518, 57516, 13788, 46473, 29284, 13791, 57513, 46475,\n",
       "         13794, 13795, 57525, 29317, 13864, 13868, 46536, 29191, 46538,\n",
       "         57420, 46542, 13933, 57415, 57413, 13936, 13937, 29184, 13941,\n",
       "         57405, 57422, 57403, 29177, 57399, 13950, 46546, 57395, 29175,\n",
       "         57392, 57391, 57389, 13958, 29170, 13961, 57386, 57401, 13867,\n",
       "         13921, 57423, 13869, 29229, 13872, 29226, 46518, 57450, 57447,\n",
       "         29219, 57442, 57441, 29214, 29213, 57437, 13920, 46530, 29205,\n",
       "         57430, 13900, 13901, 57429, 57428, 29200, 13908, 57427, 29199,\n",
       "         57425, 29196, 29194, 57433, 46638, 13333, 13329, 30023, 30020,\n",
       "         46013, 46016, 58318, 58316, 12762, 12763, 58311, 46018, 12768,\n",
       "         12769, 12770, 12771, 12773, 30007, 12777, 58310, 30005, 30004,\n",
       "         12782, 58305, 46023, 58301, 46024, 58297, 29997, 30024, 46008,\n",
       "         46007, 46006, 12696, 58358, 30064, 58357, 58354, 45990, 12707,\n",
       "         58349, 12710, 12711, 30054, 12714, 30052, 46028, 45993, 45994,\n",
       "         12721, 12723, 30044, 30040, 58340, 58337, 30036, 58333, 30035,\n",
       "         30033, 12739, 12742, 12717, 58294, 58292, 12799, 58242, 12858,\n",
       "         29950, 58240, 12862, 58239, 12865, 58237, 58236, 29943, 12877,\n",
       "         12878, 12880, 58243, 46063, 46066, 58215, 12892, 46067, 12894,\n",
       "         29929, 12898, 46071, 12901, 46075, 29920, 29915, 58208, 58221,\n",
       "         58360, 58246, 12852, 58286, 58285, 29988, 12805, 29987, 12807,\n",
       "         29986, 58283, 12811, 12812, 12813, 58277, 58274, 12854, 46036,\n",
       "         12824, 58267, 12826, 12829, 29971, 12835, 29969, 46047, 46049,\n",
       "         29957, 29956, 58254, 12851, 29979, 12693, 58361, 58363, 58488,\n",
       "         12527, 12530, 30191, 12534, 30188, 30185, 30184, 45923, 30180,\n",
       "         12544, 58476, 12546, 58489, 30178, 12550, 45927, 58465, 30170,\n",
       "         12557, 45929, 30168, 12562, 58460, 45935, 12568, 30157, 58450,\n",
       "         30177, 12574, 30200, 30203, 30232, 58526, 58519, 45899, 45900,\n",
       "         45903, 12484, 30224, 45904, 30222, 12490, 12491, 30221, 58491,\n",
       "         12494, 58513, 30217, 30216, 30213, 30212, 58506, 12506, 58502,\n",
       "         30209, 12510, 12512, 58496, 30208, 12495, 58207, 45939, 58444,\n",
       "         12633, 12634, 30103, 45968, 45969, 12644, 30097, 58389, 58388,\n",
       "         58385, 12653, 58380, 30087, 30116, 30086, 12663, 12664, 12667,\n",
       "         45976, 58373, 12675, 12676, 30071, 45984, 45986, 58367, 30067,\n",
       "         58364, 12661, 12581, 58411, 58413, 12583, 58443, 58442, 12586,\n",
       "         58439, 58438, 30147, 45945, 12592, 30145, 30144, 12595, 12596,\n",
       "         30117, 12597, 58434, 30143, 30141, 58429, 58428, 45948, 30133,\n",
       "         30130, 30126, 45953, 58416, 30121, 58415, 12598, 29622, 46088,\n",
       "         12915, 29717, 46228, 46237, 46239, 13183, 29709, 57978, 57977,\n",
       "         13190, 29708, 13193, 57975, 57974, 57973, 29705, 46241, 13201,\n",
       "         57972, 29703, 57971, 29701, 29700, 13209, 57968, 13214, 29696,\n",
       "         13217, 13176, 57988, 13173, 57990, 58034, 58032, 29745, 58030,\n",
       "         58029, 46198, 46199, 58021, 58017, 29735, 46209, 13146, 29731,\n",
       "         13219, 13148, 13151, 58006, 13154, 58000, 57998, 13160, 13161,\n",
       "         29727, 29726, 13167, 46214, 29720, 57991, 13149, 13221, 29693,\n",
       "         29692, 13280, 57919, 57911, 57908, 57907, 13288, 13290, 13292,\n",
       "         13293, 13295, 13301, 57901, 57900, 57922, 57899, 29640, 13307,\n",
       "         46284, 13311, 29635, 46287, 13317, 57887, 13322, 29628, 29624,\n",
       "         57885, 13328, 57898, 58036, 57924, 13274, 57960, 13233, 46258,\n",
       "         29683, 57955, 29675, 57953, 13243, 46268, 46271, 13247, 13249,\n",
       "         29666, 29654, 29661, 57940, 46274, 13259, 57938, 57937, 57933,\n",
       "         29658, 29656, 13269, 57929, 13271, 57927, 13273, 13255, 58037,\n",
       "         29750, 29751, 46124, 29870, 12969, 12970, 12971, 12973, 58152,\n",
       "         58151, 29867, 12983, 46128, 29857, 12987, 12964, 29856, 46129,\n",
       "         29851, 29849, 46130, 58132, 58130, 29845, 13002, 13003, 46135,\n",
       "         58122, 58118, 58112, 12989, 46138, 29875, 12960, 58203, 29907,\n",
       "         58200, 58197, 29903, 58195, 58191, 29899, 46100, 12930, 46110,\n",
       "         29891, 29887, 58158, 46117, 12943, 58178, 29883, 12947, 12948,\n",
       "         29882, 46120, 12951, 12952, 29880, 29879, 58163, 29876, 58179,\n",
       "         46089, 13014, 13016, 58060, 13079, 13081, 29776, 46180, 13084,\n",
       "         58057, 46182, 29771, 46183, 46184, 29765, 13095, 46172, 13096,\n",
       "         58052, 46187, 13101, 13103, 58049, 13106, 58046, 13108, 29758,\n",
       "         29757, 13112, 29754, 58039, 13098, 58110, 29782, 46168, 29834,\n",
       "         13020, 29831, 29830, 58106, 46146, 29825, 13028, 13029, 29822,\n",
       "         13037], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_destination': {'feature_present_idx': array([ 1048, 66468, 62455, 58639, 48836, 43916, 39551, 30107, 24467,\n",
       "         17819, 14642, 12331, 38940,  8265, 57652, 36096,  4712, 57732,\n",
       "         57783, 39546, 63231, 45916, 57588, 10333,  7481, 32984, 38222,\n",
       "         38621,  1301, 39387, 26475, 24718, 65625,  7639, 57390, 24456,\n",
       "         53749, 51857, 65140, 62228, 43411, 43137, 12716, 18289, 55798,\n",
       "         54294, 46677, 40799, 50670, 40882, 56129, 53400, 46313, 36147,\n",
       "         47884, 51147, 55532, 55216, 50303, 33463, 65501, 12138, 15695,\n",
       "         63626, 63344,  6717, 21477, 33466, 22024, 58720, 22866,  5788,\n",
       "         25122, 10956, 58010, 57668,  2999, 57631,  9247, 31292, 31475,\n",
       "         14836, 13573, 61865, 58344, 57203, 65178, 41423, 66843, 46059,\n",
       "         10935, 13584, 14987, 17232, 17314, 18157, 21836, 27122, 47610,\n",
       "         29906, 27330, 42747, 45003,  3213, 45221, 37952, 35918, 53451,\n",
       "         15667, 30330, 39744,  1550, 21240, 62004,  1927, 22282, 66708,\n",
       "         63313,  3082, 29687, 51514, 59671, 26963, 17301, 61596, 34294,\n",
       "         57538, 52572, 45964, 27689, 52232,  9117], dtype=int64),\n",
       "  'feature_absent_idx': array([10511, 43828, 12490, 12491, 62479, 12494, 12495, 43827, 26983,\n",
       "         26982, 43825, 62475, 56734, 26974, 12506, 12510, 12512, 43816,\n",
       "         26965, 56742, 56746, 56747, 56748, 12527, 62461, 12530, 26948,\n",
       "         12534, 26987, 56726, 56725, 12484, 38616, 12431, 49994, 62497,\n",
       "         56706, 56710, 27022, 27018, 49999, 12446, 12447, 12448, 27013,\n",
       "         38647, 12452, 43839, 12459, 12460, 62490, 62489, 12468, 27000,\n",
       "         52037, 43833, 43831, 50000, 62483, 56724, 12454, 26940, 62456,\n",
       "         12544, 12598, 62427, 62426, 38654, 26906, 26905, 38655, 62423,\n",
       "         26899, 43784, 26897, 56765, 50016, 12597, 62418, 38664, 26878,\n",
       "         12633, 12634, 38666, 26870, 52016, 56775, 12644, 26865, 62410,\n",
       "         26863, 26860, 43780, 12428, 12596, 12592, 56750, 12546, 62454,\n",
       "         43803, 26936, 12550, 62452, 26932, 12557, 12562, 38651, 43798,\n",
       "         62443, 12595, 12568, 62442, 12574, 43794, 26918, 26915, 12581,\n",
       "         62435, 12583, 43791, 12586, 62431, 52023, 26910, 26920, 62500,\n",
       "         56704, 43852, 12267, 49973, 27144, 62551], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 132\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 132\n",
       "  })},\n",
       " 'contains_direction': {'feature_present_idx': array([   88, 43141, 42103, 41911, 40335, 39588, 37691, 37053, 36313,\n",
       "         35870,  9001, 35583,  9448, 34273, 33464, 32850, 30225, 29603,\n",
       "         14453, 15879, 15989, 16447, 16680, 17352, 50540, 17631, 21167,\n",
       "         21260, 22279, 22954, 26038, 10756, 20031, 52015, 15422,  2492,\n",
       "         61068, 59918,  1656, 58232,  1596, 61324,  1302, 62828, 61664,\n",
       "         60448, 63882, 65436, 64029,   658, 31002, 32049, 16060, 66529,\n",
       "         61279, 28375, 16101, 28214, 27817, 26783, 66414, 26534, 18639,\n",
       "         25667, 24813, 24548, 24012, 33147, 22408, 21997, 21989, 61684,\n",
       "         20544, 63413, 19642, 64665, 25688, 51861, 35260, 53674, 53054,\n",
       "         42481, 42772, 43136, 52897, 43552, 41562, 44542, 45963, 47643,\n",
       "         48039, 48151, 49602, 50367, 52768, 45352, 52655, 41029, 40561,\n",
       "         59937, 35616, 59281, 36055, 57875, 36964, 56948, 40915, 37247,\n",
       "         38470, 38929, 39366, 54942, 15669, 39683, 54549, 55616, 39594,\n",
       "         32698, 11899,  6015,  7664, 10712, 12881,  5888, 12856, 10994,\n",
       "          2862,  2773,  2776, 11162, 10448,  2950,   189,  5730, 25836,\n",
       "         29889, 10676, 28991, 45344, 54088, 24512, 24525, 11852, 43802,\n",
       "         24633, 28315, 54198, 27151, 45784, 55554, 26763, 55609, 41289,\n",
       "         41431, 46767, 25370, 25627, 26103, 11504, 25933, 57472, 11021,\n",
       "         54168, 30271, 48758, 35611, 35743, 35775, 35891, 36146, 36400,\n",
       "         35441, 46533,  8436, 39712, 47737,  7798,  8309, 47579, 39266,\n",
       "         46766, 49056, 49068,  4903,  7375, 10222, 31213, 31512,  3734,\n",
       "         40285, 52660, 32647, 52104, 32736, 32910, 33179,  5557, 33950,\n",
       "         34039, 50691,  4837, 53756, 53721, 26152, 43526, 44864, 65515,\n",
       "         43693,   352,  6503, 20243, 65409, 65238, 20007, 61692, 16795,\n",
       "         60302,   475, 19484, 13515, 17378, 19073, 18836,  5978, 18318,\n",
       "         64513, 18289, 63854, 64334, 19561,   205, 64008, 15087, 59692,\n",
       "         45048, 23442, 59902, 66957, 23290, 23043, 12128, 59693, 12126,\n",
       "         37275,  8219, 43737, 16909,  5308, 39166, 39219, 33255, 15318,\n",
       "         51418,  7861, 17487, 10007,  4031,  7821, 10048, 46779, 51030,\n",
       "         49228, 16631, 66568, 14627, 66279, 44253, 36749, 36424, 65746,\n",
       "         48251, 13798, 37652, 39903, 13742,  8349, 16106, 38339, 35668,\n",
       "         35629, 48406, 16362,  9170, 48653, 43779, 38623, 38099,  8785,\n",
       "         23997, 32648, 26800, 61032, 60826, 26688, 60377, 26503, 60144,\n",
       "         44915,  3184, 12480, 12433,  6953, 25896, 22076, 25741, 11253,\n",
       "         22483, 25613, 25454, 22538, 22566, 24719, 59436, 24594, 24557,\n",
       "          6865, 58977, 21237, 52228,  7074, 21217,  3807, 32236, 31763,\n",
       "          3585, 59002, 62921, 40801,  3490, 30523, 44263, 29961, 61090,\n",
       "         19614, 44352, 29721, 53770, 29386, 28543, 13073, 61366, 44708,\n",
       "         28100, 40828, 40903, 54799, 29836, 39592, 46202, 45771, 45911,\n",
       "         15233, 47735, 58595, 59272, 59967,  1833,  1630,  1315,  1240,\n",
       "         58384, 61838, 63013, 63108, 63801,   751, 64963, 65960, 66843,\n",
       "         62046, 58327, 58093, 56960, 47919,  5017, 48167, 48274,  4931,\n",
       "         51324, 52754, 52908, 52925, 53242, 53477, 54523,  3468, 55160,\n",
       "         55190,  3213, 56687, 46957, 43999, 67320, 43739, 28352, 38935,\n",
       "         38648, 25956, 21283, 10812, 37375, 18175, 16207, 26754, 28479,\n",
       "         26962,  9158, 26984, 35499, 27034,  9513, 34920, 21225, 17223,\n",
       "         34745,  9669, 12731, 21192, 15142, 29659, 12300, 21536,  6543,\n",
       "         31280, 21344, 23580, 19432, 42357, 21332, 42069, 23998, 13202,\n",
       "         15860, 41785,  7180, 30971, 30733, 39905, 13481, 67213, 39766,\n",
       "         29930, 13985, 20737, 10892, 30244, 56491, 43958, 21492, 23863,\n",
       "         24021,  2076, 58356, 11844, 60568, 60767,  3107, 57830, 21299,\n",
       "         57205, 26359, 19344, 61057, 27771, 31522, 52093, 19008, 47964,\n",
       "         37651, 38388, 15992, 47523,  7834, 39756, 13843,  5305, 46217,\n",
       "         40377, 42004, 66665, 66818, 15626, 44653, 15507,  6260, 66142,\n",
       "         62978, 65415,  9860,  1155, 32484, 52285, 32728, 21547, 32990,\n",
       "          4623, 48479, 33476, 18190, 21751, 18069, 64603, 49098, 35472,\n",
       "           746, 13780, 20780, 66219, 13487, 15767, 19603, 63755, 16432,\n",
       "         18799, 65938, 13744, 55073, 52236, 44695, 42433, 44851,  6656,\n",
       "         40114, 39520,  8470, 34801, 49896, 34329, 50893, 52658, 10213,\n",
       "         31836, 27169, 39426, 59353, 23970, 24239, 55038,  3306, 25682,\n",
       "         20718, 22703, 15741, 25216,  8547,  8686, 17106, 18043, 34294,\n",
       "         64690, 59879, 31504, 22011, 52446, 55135, 30640, 45759, 45964,\n",
       "         46506, 55440, 47660,  3536, 41819, 63180, 49880, 33776, 53840,\n",
       "         42793, 26143,  8474, 25048, 47561, 31613,  1158, 22503,  1533,\n",
       "         26565], dtype=int64),\n",
       "  'feature_absent_idx': array([27955, 49383, 27707, 27703, 49378, 64756, 49377, 12707, 27701,\n",
       "         12710, 12711, 12714, 49374, 49373, 27708, 12717, 27693, 12723,\n",
       "         49369, 41649, 41650, 27688, 41653, 27686, 41655, 49362, 41658,\n",
       "         12739, 27676, 12721, 12742, 12696, 12693, 49411, 12653, 41631,\n",
       "         61650, 64766, 58796, 27735, 12661, 27733, 12663, 12664, 41634,\n",
       "         27731, 27710, 12667, 27726, 27725, 12675, 12676, 27723, 49398,\n",
       "         41638, 27715, 57208, 49391, 27713, 27712, 57209, 49400, 41628,\n",
       "         49360, 27658, 12807, 12811, 12812, 12813, 27616, 41695, 64737,\n",
       "         27612, 57224, 49315, 12824, 12826, 41697, 27620, 27607, 27606,\n",
       "         27605, 49309, 12835, 41703, 27593, 27591, 27590, 12851, 12852,\n",
       "         49294, 12854, 27586, 12829, 41664, 12805, 41694, 49350, 57218,\n",
       "         27656, 49345, 41671, 12762, 12763, 27653, 27650, 12768, 12769,\n",
       "         12770, 12771, 27621, 12773, 64749, 49340, 27641, 64748, 12782,\n",
       "         64747, 27638, 27637, 27631, 27625, 12799, 57221, 27624, 12777,\n",
       "         41706, 41626, 12644, 12495, 27864, 49486, 27863, 57188, 27861,\n",
       "         27860, 64806, 12506, 58814, 49474, 12510, 41558, 12494, 12512,\n",
       "         49468, 41565, 41566, 27845, 49466, 12527, 49463, 12530, 12534,\n",
       "         41572, 27831, 27828, 61627, 49471, 12544, 12491, 49489, 61607,\n",
       "         49516, 41530, 58821, 49511, 49509, 12446, 12447, 12448, 61608,\n",
       "         12452, 49508, 12454, 12490, 49507, 12459, 12460, 58820, 27891,\n",
       "         49503, 61611, 12468, 27883, 49500, 27877, 49493, 12484, 49490,\n",
       "         41533, 61648, 49456, 41580, 12595, 12596, 12597, 12598, 49434,\n",
       "         61637, 49431, 58799, 64779, 27776, 49425, 41614, 64778, 12592,\n",
       "         58797, 49424, 49421, 61641, 27763, 27758, 27757, 12633, 12634,\n",
       "         41624, 27754, 61646, 49418, 61647, 64776, 12546, 27791, 49437,\n",
       "         64797, 12550, 27820, 61629, 41582, 12557, 58809, 41584, 27811,\n",
       "         12562, 49450, 64792, 61632, 27792, 12568, 49446, 49445, 12574,\n",
       "         49444, 27801, 27799, 12581, 41591, 12583, 27796, 49439, 12586,\n",
       "         41593, 27805, 12858, 49291, 49290, 27386, 57261, 61733, 27381,\n",
       "         49133, 49131, 49130, 27376, 27374, 13146, 57265, 13148, 13149,\n",
       "         49140, 49125, 49124, 64668, 13154, 57266, 27371, 13160, 13161,\n",
       "         41798, 61734, 27365, 13167, 27364, 27363, 13151, 61735, 27388,\n",
       "         27389, 13079, 13081, 13084, 27417, 49164, 27413, 13095, 13096,\n",
       "         27409, 13098, 57256, 27408, 13101, 49143, 13103, 13106, 61729,\n",
       "         13108, 27402, 13112, 27401, 57257, 49153, 27399, 27398, 61730,\n",
       "         27395, 27394, 49160, 41777, 27361, 13173, 13221, 49088, 49087,\n",
       "         61742, 49084, 27319, 13233, 49082, 27317, 41828, 27314, 64650,\n",
       "         49078, 49089, 13243, 13247, 13249, 27306, 27304, 49067, 13255,\n",
       "         13259, 49062, 64646, 27298, 49060, 49059, 27294, 41832, 49111,\n",
       "         13219, 64654, 27360, 27359, 13176, 27356, 41802, 49108, 13183,\n",
       "         64663, 58754, 64662, 41807, 49102, 13190, 13217, 27349, 57271,\n",
       "         61737, 41817, 13201, 27337, 61739, 49094, 13209, 41818, 49091,\n",
       "         27331, 27329, 13214, 13193, 41776, 49168, 41775, 41719, 27561,\n",
       "         27557, 41722, 49263, 27548, 12915, 64721, 41729, 27535, 49255,\n",
       "         49254, 12930, 12901, 41731, 57237, 61695, 27527, 12943, 61698,\n",
       "         27516, 12947, 12948, 41738, 12951, 12952, 61700, 49241, 27531,\n",
       "         12960, 41718, 12898, 12862, 64730, 12865, 27582, 27581, 64728,\n",
       "         49284, 57227, 58781, 58780, 49281, 27576, 12877, 58776, 12878,\n",
       "         58779, 57230, 27573, 64725, 27571, 57232, 49272, 49271, 12892,\n",
       "         27568, 12894, 27567, 49269, 12880, 27506, 12964, 41741, 13028,\n",
       "         13029, 27458, 41762, 49196, 57251, 13037, 13040, 27451, 27449,\n",
       "         57252, 49186, 58769, 27459, 49185, 13052, 49182, 27439, 49181,\n",
       "         41772, 41773, 27431, 13065, 27430, 61727, 49174, 49173, 57254,\n",
       "         61724, 57247, 49202, 13020, 41742, 49235, 12969, 12970, 12971,\n",
       "         41744, 12973, 27500, 61704, 41747, 49226, 12983, 64704, 12987,\n",
       "         12989, 27486, 61709, 58770, 49219, 13002, 13003, 49216, 64699,\n",
       "         49215, 27471, 13014, 13016, 61717, 27464, 64814, 27908, 64816,\n",
       "         12431, 58865, 11832, 49825, 11834, 41270, 28361, 28350, 64948,\n",
       "         11848, 11850, 41279, 41282, 28341, 11830, 28337, 49809, 11861,\n",
       "         64943, 64941, 28333, 57112, 28331, 49803, 11874, 41296, 11876,\n",
       "         49800, 11882, 41290, 28316, 11828, 11826, 11785, 49851, 61507,\n",
       "         49847, 64956, 61508, 41257, 28388, 11802, 28383, 11804, 11805,\n",
       "         11806, 11827, 28382, 11811, 28378, 49837, 41262, 28374, 61510,\n",
       "         11817, 57107, 28371, 28370, 11821, 49831, 41266, 11809, 11784,\n",
       "         11885], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 577\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 577\n",
       "  })},\n",
       " 'contains_domain': {'feature_present_idx': array([38730, 62404, 62375,  7285, 47765,  7343,  7346,  7355, 62314,\n",
       "         26540, 47896, 26439, 47977, 48017, 26303,  7578, 26885,  7169,\n",
       "         26887, 26938, 62824, 46988, 27596, 27551, 27525, 27514, 47060,\n",
       "          7588, 47090, 62718, 27219, 47375, 27019, 27011, 47536, 47581,\n",
       "         27392,  7617,  7692, 62141, 24954,  8466, 24890, 49159,  8546,\n",
       "         61502,  8603, 61591, 24635, 49386,  8744,  8897, 49547, 49565,\n",
       "         24123, 49641, 61412, 46945, 49018,  8218, 26047, 26032, 62125,\n",
       "         62092, 48352, 62051, 48412,  8228, 25883, 48425, 61982, 25758,\n",
       "          8038, 61857, 61848, 48747, 25882, 46929,  6513,  6435, 44929,\n",
       "          4922,  4937, 30235, 63826,  5030, 45211, 63862, 29985, 45313,\n",
       "         63743, 29748, 29695, 29663, 45452, 45524, 45217, 45541, 63873,\n",
       "         44785, 43822, 43984, 64085, 31122, 31066, 30996, 64024, 44912,\n",
       "         44147, 30811, 30669,  4645,  4658, 30554, 30531,  4698, 44249,\n",
       "         24061, 29536, 29503, 28531, 28467, 28412,  5986, 63132, 28249,\n",
       "         28220, 46288, 28132, 46765, 27853,  6365, 62874, 27800,  6415,\n",
       "          6428, 27995, 63668, 46195, 28916, 63648, 45698, 45781, 29420,\n",
       "         29342,  5420, 29294, 46125,  5481, 29185, 29181, 29137, 63494,\n",
       "         29084, 45996, 46068,  5491, 61111, 49860, 23964, 12602, 17686,\n",
       "         17665, 54687, 16672, 58563, 16589, 54494, 13091, 58401, 16449,\n",
       "         16410, 55273, 16298, 16280, 16120, 55162, 58313, 58871, 12463,\n",
       "         18797, 18677, 53968, 18674, 59227, 12136, 18641, 12535, 12170,\n",
       "         12245, 54182, 18413, 12299, 12340, 12397, 18276, 18481, 18934,\n",
       "         55673, 55707, 14145, 57454, 56715, 14173, 14898, 14878, 14230,\n",
       "         56705, 57380, 14290, 56834, 14370, 56977, 57029, 57064, 57094,\n",
       "         14810, 15990, 56666, 15269, 15916, 15811, 15794, 15492, 13627,\n",
       "         56370, 15401, 56531, 56429, 13811, 56468, 57754, 13850, 13861,\n",
       "         13888, 57619, 57820,  4286, 59267, 59277,  9995, 22494, 22448,\n",
       "         22197, 10053, 10111, 51430,  9938, 51565, 51592, 51686, 21558,\n",
       "         21397, 21386, 21212, 21166, 21955, 21115, 51035, 50939, 61100,\n",
       "         23926, 23757, 61079,  9265,  9273, 61053, 22751,  9378,  9411,\n",
       "         50436,  9642, 23034,  9685, 50720, 50823, 50207, 53738, 60282,\n",
       "         20954, 19986, 59785, 19927, 19887, 59745, 19623, 11606, 11386,\n",
       "         53292, 53350, 11721, 19305, 38689, 59310, 11907, 53678, 19548,\n",
       "         10774, 59848, 11311, 20901, 20850, 20837, 52583, 52601, 20675,\n",
       "         20626, 52972, 52648, 11081, 52687, 11111, 20347, 20275, 20262,\n",
       "         59988, 20493, 43777, 62315, 64178, 41169, 34844, 32624,  3257,\n",
       "         40432, 37597, 36072, 41258, 40017, 32645, 36229, 66307,  2261,\n",
       "         66535, 34807, 40406, 41793, 65721, 35058, 39532, 37732, 32386,\n",
       "         40871, 43074,   468, 43039, 32422, 33614,  2647, 34984, 65423,\n",
       "         32535, 40157, 36345, 64762, 66148, 36456, 41454, 34471, 42486,\n",
       "         41613, 42485, 33125, 42432, 41542,  2994, 32975, 40175, 66282,\n",
       "          2953, 42449, 32855, 64858, 34492, 41749, 66770, 34597,  3123,\n",
       "         37515, 42719, 32778, 42334, 40126, 36541, 41652, 41392, 37450,\n",
       "         37374, 32807, 42142, 39127, 35872,  3474, 64305,  3721, 35327,\n",
       "         33712,   888, 31830, 43613, 65802, 64287, 35211, 31601, 33640,\n",
       "         35231, 38808, 39624, 38963, 38930,   992, 38875,  3877,  2381,\n",
       "         40784, 39713, 67110, 38501, 41854, 35744,  3718,  2320, 43186,\n",
       "         66413,   370,   832, 31402, 35520, 33870, 31377,  3579, 35356,\n",
       "         35647,    67, 36725, 31423, 38626, 33799, 43421,  2532, 66511,\n",
       "         32068, 39036, 31490, 34015, 36730, 43509, 31519, 53089, 36724,\n",
       "         36535, 19906, 18959, 19907, 18994, 53697, 40038, 53164, 53558,\n",
       "         19236, 53530, 19213, 19281, 19178, 19170, 39806, 39929, 19331,\n",
       "         53575, 19158, 53473, 39946, 39971, 53340, 53667, 53322, 39804,\n",
       "         19604, 19050, 36719, 19608, 19624, 53232, 53133, 40140, 20393,\n",
       "         20051, 21390, 21360, 52039, 21279, 52060, 52122, 21216, 40732,\n",
       "         40712, 52189, 52220, 21118, 40586, 52292, 21092, 35725, 21050,\n",
       "         51950, 51926, 40832, 21902, 21839, 51603, 21810, 51606, 21763,\n",
       "         51650, 21685, 51800, 21657, 21644, 21615, 40774, 51872, 51938,\n",
       "         40584, 21033, 21008, 20363, 36372, 20335, 52702, 52736, 40343,\n",
       "         40294, 20254, 36452, 52793, 20237, 52800, 20172, 52956, 36479,\n",
       "         36747, 20459, 36281, 20502, 52447, 35926, 52515, 40485, 20889,\n",
       "         35979, 35982, 19958, 20809, 20730, 52602, 36098, 36215, 52652,\n",
       "         20516, 20503, 20782, 53751, 54268, 39779, 55979, 56088, 56123,\n",
       "         15729, 56159, 56233, 15579, 56263, 39159, 56295, 56336, 56362,\n",
       "         39144, 37760, 15397, 15390, 56460, 39172, 39054, 55802, 15934,\n",
       "         55463, 55555, 16206, 16198, 16197, 16160, 16133, 16131, 37555,\n",
       "         16069, 39227, 55590, 16018, 37613, 15975, 55679, 39178, 37670,\n",
       "         55442, 37917, 37983, 38403, 38405, 14873, 14828, 38548, 38799,\n",
       "         56837, 56860, 14759, 56922, 38745, 56938, 14601, 38733, 38669,\n",
       "         14557, 57097, 38345, 37934, 38253, 15025, 39045, 15351, 56480,\n",
       "         15312, 15304, 15301, 56523, 56527, 38071, 38123, 15200, 38132,\n",
       "         15180, 15102, 15039, 15030, 15027, 38230, 18839, 39234, 55290,\n",
       "         18333, 54220, 18207, 18200, 18193, 54278, 54279, 18165, 18135,\n",
       "         54344, 39440, 18075, 54393, 54432, 17967, 17935, 17895, 18345,\n",
       "         17867, 39547, 39548, 18764, 53869, 36781, 36826, 36852, 36860,\n",
       "         18667, 39656, 54012, 18601, 18576, 18491, 54149, 18473, 18439,\n",
       "         39573, 37007, 54196, 39275, 17813, 37209, 54994, 54995, 39419,\n",
       "         37346, 16641, 16637, 16635, 16600, 55064, 55070, 16521, 16500,\n",
       "         37484, 37502, 39310, 16430, 55271, 16710, 37177, 16764, 54834,\n",
       "         17765, 37238, 54504, 37259, 37280, 17652, 17630, 17529, 17474,\n",
       "         54680, 17393, 17361, 37318, 17026, 54825, 54830, 16941, 16821,\n",
       "         51460, 23021, 51323, 46686, 27906, 32779, 46777, 27884, 27869,\n",
       "         42713, 46672, 42633, 32918, 42546, 27795, 27773, 46898, 27761,\n",
       "         27744, 46840, 28168, 28175, 28204, 42796, 28641, 28533, 32658,\n",
       "         46364, 28514, 46419, 42780, 46440, 32742, 46534, 46592, 28362,\n",
       "         28339, 42721, 28262, 32765, 27687, 27671, 46944, 27623, 33351,\n",
       "         42195, 26970, 33385, 47667, 26907, 42180, 33430, 42152, 33508,\n",
       "         47753, 26852, 42145, 47769, 26712, 26711, 33622, 47517, 46136,\n",
       "         33329, 27031, 42482, 27570, 33005, 33038, 33106, 27482, 27437,\n",
       "         27273, 47230, 33202, 47234, 27233, 47319, 42310, 47401, 27074,\n",
       "         47477, 42307, 26687, 42835, 28787, 31667, 31695, 31720, 30496,\n",
       "         43686, 44888, 44904, 30629, 30339, 43651, 30328, 31885, 31896,\n",
       "         30258, 45068, 45109, 43677, 31663, 44515, 30690, 43837, 31275,\n",
       "         43876, 43920, 31206, 43938, 43949, 31124, 43755, 31542, 44140,\n",
       "         31552, 30942, 44271, 31619, 44368, 44460, 45121, 43559, 31951,\n",
       "         43507, 29275, 29236, 29215, 45867, 32467, 32491, 42997, 29151,\n",
       "         42983, 45912, 32568, 29118, 32580, 28951, 42855, 46044, 46104,\n",
       "         45844, 28757, 45829, 29403, 29839, 29832, 43331, 29716, 43298,\n",
       "         29611, 29604, 32128, 43279, 43209, 32300, 29460, 43093, 32381,\n",
       "         29438, 45748, 32383, 45821, 40841, 26648, 33672, 41286, 41283,\n",
       "         23903, 23712, 23691, 49967, 49991, 23953, 49998, 50032, 50101,\n",
       "         41139, 50211, 41119, 23263, 50224, 23496, 34735, 41341, 23969,\n",
       "         24385, 24359, 24336, 34591, 24256, 49589, 24197, 24138, 49637,\n",
       "         34609, 24095, 34660, 24059, 49812, 23995, 34677, 23984, 23240,\n",
       "         23206, 50339, 50362, 51019, 22678, 22646, 22633, 51036, 35266,\n",
       "         22583, 22524, 51106, 35273, 22449, 22400, 22283, 40905, 51291,\n",
       "         22167, 51310, 50971, 24416, 40924, 35201, 23153, 23072, 50529,\n",
       "         35087, 50538, 40993, 40949, 50598, 22996, 22959, 22957, 50690,\n",
       "         22933, 50712, 35179, 22898, 22889, 50827, 57106, 49441, 24510,\n",
       "         26111, 26108, 41930, 33879, 26019, 41926, 25993, 26112, 33952,\n",
       "         48391, 25928, 48396, 41904, 41868, 34076, 25835, 33965, 41987,\n",
       "         26168], dtype=int64),\n",
       "  'feature_absent_idx': array([39735, 13564, 13565, 13566, 13568, 57924, 13571, 57922, 57919,\n",
       "         13577, 29640, 13579, 13582, 29635, 57927, 57911, 57907, 46802,\n",
       "         57901, 57900, 57899, 13595, 57898, 29628, 46804, 29624, 29622,\n",
       "         13606, 13608, 57908, 57887, 46787, 57929, 46759, 29683, 13507,\n",
       "         46769, 13511, 57960, 13513, 29675, 13519, 13520, 57955, 13524,\n",
       "         57953, 13557, 29666, 29661, 46783, 13536, 46784, 29658, 29656,\n",
       "         13541, 57940, 57938, 57937, 57933, 29654, 13551, 13532, 13498,\n",
       "         46812, 13615, 57850, 13675, 57846, 29558, 57840, 46851, 29552,\n",
       "         13688, 13689, 57835, 46852, 13692, 57825, 13672, 29549, 13696,\n",
       "         29548, 13698, 29547, 13701, 29544, 29543, 13705, 46860, 46862,\n",
       "         57811, 46863, 57807, 57821, 29615, 13671, 29569, 57885, 46815,\n",
       "         46816, 13620, 29608, 29605, 13626, 29602, 29601, 13631, 57876,\n",
       "         46818, 29597, 46844, 13637, 57867, 57864, 57860, 13647, 46832,\n",
       "         29580, 13654, 57857, 57856, 13659, 29574, 29572, 46835, 13638,\n",
       "         29692, 29693, 13495, 13328, 13329, 13333, 13338, 46703, 29788,\n",
       "         13344, 13345, 13347, 29782, 46712, 58072, 29776, 29799, 13362,\n",
       "         13365, 29771, 58060, 29765, 58057, 58052, 29758, 58049, 58046,\n",
       "         29757, 29754, 58039, 29751, 13364, 58037, 58090, 13322, 29834,\n",
       "         29831, 29830, 13280, 58122, 46671, 58118, 58112, 13288, 13290,\n",
       "         29825, 13292, 13293, 58092, 13295, 58110, 13301, 29817, 58106,\n",
       "         13307, 29815, 29814, 46679, 13311, 29811, 13317, 29808, 46688,\n",
       "         29822, 58036, 58034, 29750, 46747, 13454, 57991, 57990, 57988,\n",
       "         29709, 13463, 29708, 13466, 13467, 29705, 46749, 57978, 13448,\n",
       "         57977, 13476, 29701, 57975, 57974, 29700, 57973, 13485, 46755,\n",
       "         57972, 57971, 29696, 57968, 13494, 29703, 29717, 13446, 57998,\n",
       "         58032, 13399, 29745, 58030, 58029, 46729, 13405, 46730, 58021,\n",
       "         13410, 46731, 58017, 13415, 29735, 46735, 29731, 13422, 13423,\n",
       "         13425, 13426, 13429, 29727, 29726, 58006, 46737, 13435, 58000,\n",
       "         13441, 29720, 57801, 46670, 29532, 13718, 57596, 57594, 57591,\n",
       "         13986, 46986, 13988, 29335, 29334, 29329, 57579, 47002, 29326,\n",
       "         57578, 29345, 47004, 29317, 57571, 57570, 57568, 57567, 14021,\n",
       "         57566, 29308, 29306, 14026, 29305, 14028, 29304, 29320, 29303,\n",
       "         57599, 13976, 29372, 13936, 13937, 29368, 13941, 46962, 57629,\n",
       "         57628, 57626, 13950, 46964, 57611, 57609, 29346, 13958, 46976,\n",
       "         13961, 57605, 13964, 29353, 29352, 29350, 29349, 57601, 46977,\n",
       "         13973, 13974, 13975, 29357, 13933, 14033, 14035, 47049, 57511,\n",
       "         14110, 14111, 29239, 14113, 57502, 57501, 47056, 57493, 29229,\n",
       "         14127, 29226, 57513, 47061, 47064, 14134, 14135, 29219, 47066,\n",
       "         14143, 29214, 14146, 29213, 47070, 57480, 47072, 47073, 14131,\n",
       "         14034, 14102, 47044, 47013, 47016, 57550, 29287, 29284, 14054,\n",
       "         14056, 57544, 14059, 47025, 14062, 47028, 47030, 14099, 14073,\n",
       "         14079, 47036, 29254, 57526, 14085, 57525, 57524, 29252, 14091,\n",
       "         47039, 57518, 29249, 57516, 14078, 46953, 57641, 57642, 13774,\n",
       "         57750, 13776, 13778, 29483, 29482, 29481, 46896, 57745, 13788,\n",
       "         46899, 57741, 13791, 13773, 13794, 13796, 57736, 13799, 13801,\n",
       "         57735, 13804, 46905, 57731, 29470, 13808, 57730, 46906, 46908,\n",
       "         13795, 13815, 13772, 29490, 13719, 29529, 57795, 13725, 29526,\n",
       "         29525, 46871, 13729, 29522, 13731, 29521, 46872, 29516, 57753,\n",
       "         57782, 46882, 29504, 57772, 46883, 57770, 57768, 46884, 46886,\n",
       "         57766, 29495, 46890, 57762, 13767, 29508, 46909, 29465, 57725,\n",
       "         29410, 57676, 29408, 29406, 57670, 57667, 57666, 57665, 46938,\n",
       "         57662, 13900, 13901, 29393, 29413, 29392, 57656, 13908, 29389,\n",
       "         29388, 29387, 57650, 29383, 29382, 13920, 13921, 29380, 29377,\n",
       "         57643, 46943, 29414, 46932, 13872, 57723, 29462, 29461, 13823,\n",
       "         13825, 57718, 13829, 57717, 57715, 29453, 29444, 13840, 46919,\n",
       "         57699, 29436, 29433, 29432, 29430, 57688, 46924, 29424, 29423,\n",
       "         57683, 13864, 29422, 13867, 13868, 13869, 46930, 57796, 29205,\n",
       "         13274, 58130, 46389, 46390, 12675, 12676, 30257, 46393, 30255,\n",
       "         58573, 58572, 58571, 46399, 30248, 12693, 30269, 30247, 12696,\n",
       "         58559, 46402, 46406, 30241, 58553, 30236, 12707, 12710, 12711,\n",
       "         58548, 12714, 30232, 30246, 12717, 12667, 12664, 58631, 30325,\n",
       "         46349, 58628, 46350, 46353, 30312, 58621, 30311, 30306, 46361,\n",
       "         30300, 12633, 46383, 12634, 58615, 30292, 12644, 46372, 46374,\n",
       "         58601, 12653, 46377, 30276, 46382, 12661, 30272, 12663, 30297,\n",
       "         58632, 12721, 12723, 12777, 58506, 30184, 58502, 12782, 46434,\n",
       "         58496, 30180, 30178, 30177, 46439, 58491, 58489, 30185, 58488,\n",
       "         46442, 12799, 30168, 12805, 12807, 46446, 12811, 12812, 12813,\n",
       "         46447, 30157, 58476, 46449, 30170, 46417, 30188, 46428, 30224,\n",
       "         30222, 30221, 58538, 58537, 58536, 30217, 30216, 58526, 12739,\n",
       "         30213, 30212, 12742, 12773, 30209, 58519, 30203, 30200, 58513,\n",
       "         12762, 12763, 46426, 30191, 46427, 12768, 12769, 12770, 12771,\n",
       "         30208, 46344, 58635, 46343, 58741, 58740, 58739, 46274, 12446,\n",
       "         12447, 12448, 30446, 12452, 12454, 30442, 12459, 12460, 12431,\n",
       "         30438, 46284, 12468, 30429, 30428, 58718, 58714, 58713, 46287,\n",
       "         12484, 58712, 30420, 12490, 12491, 30436, 12494, 12428, 58746,\n",
       "         12363, 30506, 12365, 58776, 12367, 12368, 46241, 12372, 12374,\n",
       "         30499, 58770, 58769, 30489, 58744, 30488, 12391, 30483, 46258,\n",
       "         12404, 58754, 12411, 12412, 46268, 12418, 46271, 30460, 30459,\n",
       "         58747, 12390, 12495, 46294, 58708, 30371, 12557, 30367, 12562,\n",
       "         58666, 30366, 12568, 30358, 58657, 12574, 30352, 46334, 12581,\n",
       "         30373, 12583, 30346, 58643, 30345, 30344, 30343, 12592, 46341,\n",
       "         12595, 12596, 12597, 12598, 46342, 30334, 12586, 30375, 12550,\n",
       "         58671, 30414, 46299, 12506, 30404, 12510, 58697, 12512, 30403,\n",
       "         46304, 58694, 46305, 30398, 58687, 58684, 12527, 58680, 12530,\n",
       "         46312, 30389, 46314, 12534, 30387, 30385, 30383, 46316, 46317,\n",
       "         12544, 12546, 58672, 58465, 13273, 12824, 12829, 13103, 46573,\n",
       "         13106, 29957, 13108, 29956, 58246, 13112, 58243, 58242, 46575,\n",
       "         29950, 58240, 13101, 58239, 58236, 29943, 46582, 46588, 46589,\n",
       "         29929, 46591, 58221, 13146, 13148, 13149, 13151, 58215, 58237,\n",
       "         13154, 46572, 13098, 58292, 46546, 30007, 30005, 58286, 30004,\n",
       "         13052, 58285, 29997, 58283, 58277, 58274, 13065, 58254, 46558,\n",
       "         29987, 58267, 29986, 13079, 29979, 13081, 46563, 13084, 46564,\n",
       "         29971, 29969, 13095, 13096, 29988, 13040, 13160, 46602, 13214,\n",
       "         29875, 58179, 13217, 58178, 13219, 13221, 29870, 29867, 46647,\n",
       "         13233, 58163, 29857, 29876, 29856, 13243, 29851, 13247, 58152,\n",
       "         13249, 58151, 29849, 13255, 29845, 13259, 13269, 58132, 13271,\n",
       "         58158, 13161, 29879, 29880, 29920, 46603, 58208, 13167, 58207,\n",
       "         29915, 13173, 13176, 46609, 58203, 29907, 13183, 58200, 13209,\n",
       "         29903, 58197, 13190, 58195, 13193, 29899, 29891, 46632, 13201,\n",
       "         58191, 29887, 29883, 29882, 46638, 46617, 13037, 58294, 46542,\n",
       "         46475, 12880, 58416, 58415, 30117, 58413, 30116, 58411, 12892,\n",
       "         12894, 46480, 12898, 12901, 12878, 30103, 30097, 46486, 46487,\n",
       "         46488, 12915, 58389, 58388, 46489, 58385, 46490, 58380, 30087,\n",
       "         30086, 46482, 58373, 12877, 58428, 46458, 30147, 58460, 12835,\n",
       "         30145, 30144, 30143, 30141, 46462, 58450, 30133, 58444, 12851,\n",
       "         30121, 12852, 12854, 58442, 58439, 12858, 58438, 12862, 30130,\n",
       "         12865, 30126, 46472, 58434, 46473, 58429, 58443, 46493, 12930,\n",
       "         46494, 12987, 12989, 30044, 46530, 58333, 30040, 30036, 13002,\n",
       "         13003, 30035, 30033, 46536, 58318, 58337, 58316, 58311, 13016,\n",
       "         46538, 58310, 13020, 30024, 30023, 30020, 58305, 13028, 13029,\n",
       "         58301, 58297, 13014, 30052, 12983, 30054, 46495, 30071, 58367,\n",
       "         12943], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_duration': {'feature_present_idx': array([    3, 43271, 41957, 40883,  3326,  3337, 36115, 35631, 33896,\n",
       "          3927, 32237, 32233, 47429, 28101, 26733, 24640, 23031, 22040,\n",
       "         20432, 18132, 17823, 17129, 13559, 12935, 11903, 27237, 47652,\n",
       "         39863, 59244, 60400, 47716, 60867, 58003, 63371, 53681, 52834,\n",
       "         64121, 65754, 60190, 50916, 66603, 49568, 14893, 10016, 11263,\n",
       "         22814, 61625, 62477, 19267, 13198, 65991, 13114, 63867, 25590,\n",
       "         15762, 12376, 17690, 49161, 27221, 46631, 45491, 49208, 43037,\n",
       "         42706, 49709, 51104, 40730,  7716, 39317, 38381, 37568, 37119,\n",
       "         55774, 57797, 58748, 31163, 29835, 59046, 26768,  7541, 32537,\n",
       "          4673,   137,  2981,  4913,  1820, 50052, 49892, 49817, 13821,\n",
       "         20306, 14129, 46601, 49106, 48141, 14808, 47585, 47213, 19826,\n",
       "         34531, 13539, 49449, 51680, 33145, 56664, 12507, 31516, 31643,\n",
       "         39483, 55375, 32528, 53957, 53915, 13275, 13281, 13353, 13367,\n",
       "         52550, 33133, 19724, 45757, 15381, 30228, 41678, 41422, 36740,\n",
       "         41078, 40850, 38467, 40739, 40542, 40230, 40191, 38584, 40071,\n",
       "         39839, 39767, 18385,  3135, 35084, 17071, 42874, 15604, 45537,\n",
       "         15739, 45047, 44728, 44520, 44327, 44195, 35854, 35949, 42995,\n",
       "         16503, 16780, 42941, 16969,  3031, 12073, 32327, 57331,   619,\n",
       "         26105, 26620,  8151, 26779, 26901,  8754, 62762, 62636, 23252,\n",
       "         23192, 61530,  9023, 56962, 61462, 61453,  9074, 64132, 26021,\n",
       "          7796,  7783, 24833, 66799, 24985, 25466,  6394, 65933,  6569,\n",
       "         23971, 27163, 25759,  7165,  7243,  7316, 65376, 65097, 64961,\n",
       "         23799,  5317,  7006, 61124, 18208, 29366, 58406, 22452, 11284,\n",
       "         59533, 29160,  1265, 27949, 22367, 58461, 60433, 29513, 11174,\n",
       "          9181,  9843, 60832,  9387,  1022, 29704, 60629,  4348, 30793,\n",
       "         32368, 24848, 29355, 31972, 39443, 31116, 25664, 31709, 38480,\n",
       "         31364, 37965, 34317, 28609, 28750, 33884, 27315, 34414, 33866,\n",
       "         27645, 35391, 33474, 33341, 33275, 32874, 35566, 26892, 26828,\n",
       "         27954, 26338, 28486, 36604, 34156, 28720, 33011, 35629, 34489,\n",
       "          5692, 39631, 61038, 60943, 60268, 60127, 59919, 59375,  1298,\n",
       "         61134, 58730, 58044, 57910,  1616, 57787, 57759, 57702, 56880,\n",
       "         58238, 56840, 61840, 62943, 67142, 66902, 66687, 66579, 66320,\n",
       "           330, 65694, 62474, 65389, 64189, 64104, 64003,   716, 63425,\n",
       "         63387, 62954, 64855, 56256, 56143,  1626, 24750, 46232, 45715,\n",
       "         45591, 45419, 45242, 44134, 46707, 43891, 42866, 41359, 41264,\n",
       "         40753,  3384, 40072,  3490, 43202, 46958, 47037, 48422, 55773,\n",
       "         55740, 55568, 55404, 54498, 54066, 53802, 53188, 52383, 52304,\n",
       "         51194,  2005, 50544, 49808, 49749,  2103, 48451, 39464, 24707,\n",
       "          3797, 67331, 17871,  4742, 17806, 17797, 19821,  8854, 22414,\n",
       "         13376, 22447, 13379, 13504, 22538, 22665, 17044,  8036, 16990,\n",
       "         16262,  8914,  9028, 18044,  4675, 20082, 20220, 19317, 20790,\n",
       "         20866, 20872, 10946, 12349,  7894, 21087, 12691, 12844, 21378,\n",
       "          5303, 12918,  5008,  9656, 21673, 10793,  7800, 15187, 24322,\n",
       "         13805, 23530, 15616, 24476, 24143, 13922, 14030, 23999,  6019,\n",
       "         16225,  7437, 23269, 16256,  6170, 24127, 15249, 24268, 12466,\n",
       "          2503,  3578, 56217, 43096, 19006, 12801, 55677, 55662, 55647,\n",
       "          2848, 18999, 55597, 37957, 37041, 36602, 36841, 34717, 11747,\n",
       "         34920, 35025, 47009, 57543, 57495, 15241, 11944, 56379, 19448,\n",
       "         57154, 46015,  3671, 57003, 56990, 36434, 45423, 45942, 56519,\n",
       "         57183, 12863, 55123, 55452, 52199, 52053, 16007, 17223, 17192,\n",
       "         51517, 51490, 41688, 41767, 13550, 13576, 42661, 13594, 16992,\n",
       "         42873, 16920, 13790, 43657, 50003, 49375, 44516, 44608, 44709,\n",
       "         55416, 39413,  4824, 18460, 14874, 54391, 45165, 18024, 45081,\n",
       "         38676, 14747, 48607, 54320, 54317, 48846, 53889, 49054,  4758,\n",
       "         53616, 53540, 14451, 17316, 11665,  2810, 62299, 62206,  6543,\n",
       "          6348, 29679, 62191, 25905, 29884, 61864, 30295, 30347,  9053,\n",
       "         23808,  9620, 64514, 31160,  4126, 23920, 21567, 29469,  9977,\n",
       "          6696, 29390, 27518,  5369, 27928, 65151,   867,  4244, 65374,\n",
       "         28185, 26740, 63234, 65424, 28647, 28670,  8542,  8767,  8773,\n",
       "         26542,  6839, 28961, 23580, 31472, 64102, 60527, 10812,  5299,\n",
       "         34201, 59263, 24917, 32951,  6255, 20877, 33012,  4464,  1330,\n",
       "          5874, 20806, 11033, 24896, 24895,  1470, 58710, 24976, 58541,\n",
       "         58131, 31549,  1174, 66718, 21361, 31999, 10434, 10572, 67205,\n",
       "         60059, 59967,  6161, 58081, 21142, 59947, 10754, 32279, 46820,\n",
       "         64691, 14896,  7490, 64868, 14359, 67092,  2289, 49464, 65643,\n",
       "         49112, 47040,  4830, 66830, 47456, 66393, 48326, 66492, 48008,\n",
       "          6964, 47776, 11480, 63919, 54948,  9764, 60719, 55505, 10044,\n",
       "         55945, 56260, 59503, 59373, 56627,  5180, 12332, 58841, 57138,\n",
       "         57249, 11198, 57527, 58353, 11328,  9157, 61590,  8905, 13208,\n",
       "         63671, 50480, 63408,  8457,  4832, 51223, 63172, 51395, 62712,\n",
       "         50212, 51781, 52214, 52234, 13385, 11348,  1669, 53342,  1640,\n",
       "         53844, 62095, 62614,   871, 24543, 15309, 21464, 17354, 21563,\n",
       "         31273, 40835, 17295, 30395, 30242, 41131, 21974, 36877, 17251,\n",
       "         41442, 41535, 17164,  4789, 42308, 29932, 42479, 31729, 21240,\n",
       "         32517, 32715, 36960,  3594, 19099, 37753, 38181, 46612, 19465,\n",
       "         38599, 35166, 42732, 34775, 18189, 34438, 19850, 34042, 33539,\n",
       "         33422, 21007, 32740, 17663,  3497, 29583, 41155, 15905, 26736,\n",
       "         29337, 27024, 15831, 26095,  4273, 45563, 15343, 25559, 44682,\n",
       "         15786, 45670, 22935, 27916,  4294,  2912, 44487, 22772, 22743,\n",
       "         46583,  4580, 24817, 36158, 20045, 58171, 26409, 23684, 56572,\n",
       "           183, 24420, 56663, 19269,  5275, 57654, 56890, 66953, 19611,\n",
       "         57473,  6252, 35875, 24969, 11951,  1590, 22312, 59353,  4629,\n",
       "          4201, 28825, 28799,  8672, 61798, 28793, 62972, 62979, 61781,\n",
       "         63835, 64005,  9540, 30956, 27513, 21653, 31397, 31502, 27443,\n",
       "          4491, 64263, 64271,  3997, 23075, 23450, 65332, 59132, 33446,\n",
       "          3824, 36806,  5417, 56277, 54876, 54813, 13067,  4973, 49414,\n",
       "         17807, 14289, 13210, 40114, 14174, 40210, 49793, 44291, 40225,\n",
       "         16049, 16297, 50373, 50981, 17294, 56445, 53015, 17311,  3240,\n",
       "         39289, 48710, 39585, 40785, 48582, 45647, 55807, 19003, 55639,\n",
       "         38577, 46429, 47267, 55477, 12679, 15011, 46842, 39164, 48183,\n",
       "         24200,   908, 51716, 43853, 42322, 30163, 25446, 30783, 28960,\n",
       "         61783,  4252,  2487, 64174, 45015, 15845, 64859, 31100,  7940,\n",
       "         49175,  8034, 27630,  7318, 14762, 65475, 23554, 15929, 45254,\n",
       "         25899, 65672, 30250, 15118, 19436, 57311, 13261, 53887, 33119,\n",
       "         57414, 53472, 58686, 38993, 39230, 34716, 39947, 52403, 34619,\n",
       "         19708, 38151,  3501, 19775, 60201, 59818,  4112, 13314, 40664,\n",
       "         53171, 37717, 38046, 56845, 36706, 36262, 32473, 32139, 46093,\n",
       "         37540, 36766, 23788, 48312, 18515, 57382, 35855, 34564, 57041,\n",
       "         45263, 26922,  4278,  2429, 28821, 40611, 32822, 62554, 13678,\n",
       "         22049, 49830,  8282, 42773,  2391, 20288, 52209, 52572, 52454,\n",
       "         32656, 25068,  4613, 26291, 25542, 44970, 47894,  7968, 39992,\n",
       "         44498, 58255, 27941, 52232, 11019, 22847, 23423, 59622, 32378,\n",
       "         51811, 44386,  9117, 45013,  2437, 45074], dtype=int64),\n",
       "  'feature_absent_idx': array([24363, 60209, 60210, 51180, 18678, 42109, 42110, 18670, 18668,\n",
       "         42112, 51177, 18665, 18661, 18660, 18656, 60228, 18691, 18650,\n",
       "         51183, 42102, 60180, 60183, 18733, 18732, 18727, 60188, 60189,\n",
       "         60191, 18718, 18715, 18714, 18712, 18707, 18700, 60206, 18694,\n",
       "         60178, 18648, 18640, 18592, 60256, 18589, 18584, 60258, 18578,\n",
       "         60260, 60270, 60274, 18551, 18550, 60275, 42153, 60280, 18542,\n",
       "         51167, 60235, 42137, 60253, 60238, 42121, 60243, 18630, 42123,\n",
       "         18624, 18623, 18622, 42126, 18619, 18617, 18616, 60248, 18610,\n",
       "         60249, 18596, 18536, 18750, 18761, 18898, 60113, 18894, 42031,\n",
       "         18889, 18887, 42037, 42039, 18880, 60124, 18867, 18864, 60128,\n",
       "         60129, 18860, 42024, 60130, 18911, 60107, 18953, 18952, 18951,\n",
       "         42011, 18948, 18947, 18946, 18942, 18938, 60100, 42014, 42015,\n",
       "         42016, 18919, 60104, 18912, 42091, 18856, 42050, 18808, 51195,\n",
       "         18796, 18794, 60160, 18791, 42078, 60164, 18783, 18778, 42081,\n",
       "         60168, 51190, 18773, 18765, 60154, 18855, 42070, 42067, 18850,\n",
       "         18847, 42053, 18841, 42054, 60138, 60139, 60140, 18832, 60143,\n",
       "         18830, 18826, 42062, 51199, 42066, 42068, 18535, 18531, 18529,\n",
       "         42276, 18223, 18218, 60401, 18213, 51112, 18204, 18202, 42280,\n",
       "         18195, 60410, 18185, 18180, 18176, 51108, 18226, 42293, 42274,\n",
       "         60394, 42256, 42257, 18267, 60382, 42269, 18255, 18254, 18253,\n",
       "         60386, 60387, 18247, 60390, 18239, 18237, 18236, 18232, 60374,\n",
       "         60420, 60421, 18119, 18115, 18112, 18110, 18109, 18108, 18107,\n",
       "         18105, 42318, 18096, 51091, 18090, 42326, 18088, 18086, 60440,\n",
       "         42295, 42313, 18127, 18160, 18156, 18152, 18151, 18149, 51101,\n",
       "         60428, 60430, 18143, 42304, 60435, 18137, 60436, 51098, 60438,\n",
       "         18126, 18283, 60373, 18294, 18469, 42182, 42184, 18451, 42187,\n",
       "         42194, 51151, 18426, 51148, 18423, 18422, 18420, 18412, 42204,\n",
       "         60329, 60305, 60332, 42177, 60300, 42160, 18521, 18520, 18518,\n",
       "         51159, 18516, 60287, 18511, 18501, 42168, 18494, 60292, 42171,\n",
       "         18487, 42174, 42176, 18402, 18400, 42206, 18343, 51136, 51135,\n",
       "         18337, 18336, 18334, 18332, 18330, 51127, 18324, 18315, 18304,\n",
       "         60367, 42249, 42252, 18344, 42226, 42223, 18355, 18392, 18391,\n",
       "         42210, 18389, 18383, 60338, 42215, 18954, 18376, 18370, 18369,\n",
       "         60340, 18361, 60342, 60344, 60345, 18371, 42009, 42008, 18960,\n",
       "         19502, 51300, 51299, 41832, 59899, 59901, 59903, 59904, 51295,\n",
       "         19479, 41843, 19477, 41844, 19475, 19466, 41828, 41847, 19505,\n",
       "         19507, 19552, 19550, 19549, 41818, 51303, 19541, 19540, 19539,\n",
       "         19538, 19537, 19523, 19521, 59892, 19512, 19511, 19506, 41817,\n",
       "         59909, 41848, 19419, 19410, 19405, 19402, 19400, 19396, 59930,\n",
       "         59933, 59934, 19386, 19385, 59935, 19379, 59936, 41867, 19420,\n",
       "         19459, 19422, 59922, 59911, 19454, 41850, 59914, 59915, 41851,\n",
       "         19445, 41853, 19439, 59917, 59920, 59921, 19431, 19430, 41856,\n",
       "         19423, 19555, 19560, 19562, 19696, 19695, 19691, 19687, 59837,\n",
       "         19677, 41772, 41773, 59840, 59843, 19663, 19661, 19660, 59845,\n",
       "         59846, 19697, 41775, 41762, 19706, 59817, 19745, 41747, 19739,\n",
       "         59820, 59821, 19726, 19725, 59825, 19719, 19717, 59827, 19714,\n",
       "         59828, 19709, 19701, 19654, 19651, 41776, 41802, 19590, 19584,\n",
       "         59877, 41807, 19581, 19578, 19577, 19576, 19570, 59883, 19566,\n",
       "         19565, 19564, 59885, 51317, 59870, 19602, 41798, 59852, 41777,\n",
       "         19646, 59853, 51337, 51333, 19640, 19369, 19639, 19630, 19621,\n",
       "         59864, 59866, 19615, 59868, 19606, 19636, 18084, 51286, 59942,\n",
       "         19119, 51248, 60038, 60039, 60041, 19103, 41962, 19088, 19087,\n",
       "         19086, 19085, 19084, 19083, 19080, 19079, 19123, 60047, 19124,\n",
       "         41949, 60015, 41929, 19173, 60018, 41932, 60020, 51260, 41935,\n",
       "         60024, 19159, 60028, 19149, 60031, 19135, 19132, 19127, 51262,\n",
       "         19074, 60053, 60083, 41992, 18993, 18992, 18989, 41994, 41996,\n",
       "         18980, 18979, 18977, 18973, 42001, 60093, 42005, 42006, 18998,\n",
       "         41970, 60082, 41989, 41971, 60056, 41973, 19052, 19051, 41976,\n",
       "         19045, 60065, 19040, 19038, 19036, 19031, 51234, 19021, 60073,\n",
       "         19001, 19181, 19184, 60013, 59971, 41887, 19310, 19297, 19294,\n",
       "         19293, 19290, 19288, 19287, 51275, 51274, 41896, 41897, 41898,\n",
       "         19273, 59964, 19271, 59963, 19319, 19355, 59943, 19350, 59944,\n",
       "         59945, 59950, 19339, 59953, 51280, 19335, 59956, 41884, 59958,\n",
       "         59959, 59960, 19318, 59984, 19266, 59986, 41916, 60006, 19211,\n",
       "         19209, 41919, 19207, 19201, 19199, 41922, 19197, 19194, 19192,\n",
       "         51264, 19189, 19187, 19216, 41914, 19221, 41913, 41899, 59987,\n",
       "         19257, 19256, 59992, 19251, 59993, 19362, 19248, 59996, 51269,\n",
       "         41908, 19234, 51268, 19228, 51267, 59995, 19748, 60453, 51086,\n",
       "         16981, 50949, 42707, 16973, 60837, 16970, 50943, 42715, 60842,\n",
       "         16955, 42717, 16943, 42723, 50938, 42726, 42699, 16937, 16986,\n",
       "         16989, 17037, 42682, 42684, 17027, 60820, 42686, 17019, 42687,\n",
       "         60822, 42690, 17006, 17001, 16996, 50953, 16991, 42696, 60817,\n",
       "         16935, 50934, 42758, 16874, 16873, 42759, 16871, 60881, 16867,\n",
       "         42760, 42761, 50923, 42764, 16856, 16855, 42765, 16849, 16876,\n",
       "         60852, 60880, 60877, 60856, 42735, 16919, 60859, 60864, 16905,\n",
       "         16901, 42745, 16898, 16897, 50930, 16893, 60871, 60872, 16889,\n",
       "         60878, 42766, 60816, 17050, 17179, 17177, 50972, 17173, 17169,\n",
       "         17165, 17163, 17162, 17161, 17159, 17156, 17154, 60772, 17152,\n",
       "         17148, 17184, 17146, 42632, 50976, 60754, 17228, 17227, 50980,\n",
       "         60756, 42618, 17216, 17215, 17209, 17208, 50978, 42624, 17204,\n",
       "         60764, 17201, 42631, 42679, 42644, 42646, 42666, 17090, 60803,\n",
       "         50961, 17080, 17077, 60806, 60807, 17072, 17070, 42674, 60812,\n",
       "         17056, 17055, 17053, 50962, 50966, 17105, 17111, 60777, 17139,\n",
       "         60781, 17132, 60786, 60788, 42652, 17125, 42653, 42654, 17118,\n",
       "         42656, 17116, 17113, 42658, 42659, 16847, 42767, 16844, 16626,\n",
       "         42847, 60965, 42850, 50896, 60968, 42853, 16607, 42857, 42859,\n",
       "         42861, 50892, 42867, 16588, 16586, 16627, 16585, 60961, 60953,\n",
       "         60937, 60939, 16668, 42824, 16661, 42827, 42828, 42829, 42831,\n",
       "         16654, 50900, 16644, 42840, 16640, 50898, 42843, 16675, 42869,\n",
       "         16578, 16543, 42890, 16539, 42891, 16537, 50883, 16534, 16533,\n",
       "         16532, 50882, 42897, 50877, 16522, 16517, 50872, 16544, 16579,\n",
       "         60991, 42888, 42871, 16575, 42875, 42877, 60982, 42880, 16566,\n",
       "         42881, 16564, 42883, 16560, 50887, 42885, 60986, 50885, 16551,\n",
       "         16681, 16685, 42821, 16797, 60899, 16794, 16792, 16788, 16786,\n",
       "         16785, 16782, 16778, 16776, 16775, 50911, 60906, 16771, 16770,\n",
       "         42782, 16766, 16802, 16808, 60888, 16835, 42769, 16830, 42770,\n",
       "         16827, 60891, 16824, 60892, 42776, 60894, 42778, 60895, 16813,\n",
       "         16812, 16807, 16760, 60913, 16755, 60924, 16715, 16712, 16711,\n",
       "         42815, 16709, 50904, 42817, 16702, 16699, 16698, 16697, 42820,\n",
       "         16694, 16692, 50905, 16719, 50906, 16721, 16752, 16750, 42798,\n",
       "         16748, 16747, 42799, 60920, 60753, 16736, 60921, 16732, 42807,\n",
       "         42808, 16725, 50907, 42810, 42804, 60752, 17235, 42612, 42430,\n",
       "         17775, 17774, 17772, 17769, 42437, 42439], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 924\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 924\n",
       "  })},\n",
       " 'contains_example': {'feature_present_idx': array([15765, 46813, 48197, 32016, 49024, 29112, 29038,  7689, 12461,\n",
       "         42515,  5522,  8840, 30309, 54409, 60976, 33752,   400, 24065,\n",
       "         31098,  2792, 64148, 38832, 17219, 15933, 35548, 35669, 29428,\n",
       "         45162, 22327, 38803, 35891, 44800, 42756, 41999, 14175, 41791,\n",
       "         29792, 16814, 45104, 29243, 12126,  8830,   352,   677, 63069,\n",
       "         21468, 61692, 24927, 20691, 58317,  9249, 48842,  8435, 53989,\n",
       "         50219,  6083, 52931,  6375, 54137, 50663,  6809, 26611, 31166,\n",
       "         28420, 24594, 26039, 29759, 24290, 26165,     6, 34778, 65312,\n",
       "         63539, 62349, 61656, 60286, 59614, 57816, 56728, 56112, 34267,\n",
       "         52606, 49531, 47884, 45967, 45917, 41615, 41506, 41269, 40060,\n",
       "         37742, 50132, 23026, 30580, 12793, 14903,  3590,  3553, 13918,\n",
       "         15287,  4784, 16385, 13503, 13389, 13153, 16922, 14314,  4927,\n",
       "         17582,  1493, 14226, 10819, 10662, 12523, 21930,  7946, 21357,\n",
       "         11666, 38755, 52442, 52415,  6405,  4116, 39237, 13621, 56960,\n",
       "         40138, 58327,  5395, 48661,  8078, 52801, 47228, 56685, 56490,\n",
       "         56352, 12873, 45919, 10869, 43320, 43905, 44090, 44113, 40477,\n",
       "         67247, 37461, 50349, 17023, 17351, 17886, 60060, 63193, 27405,\n",
       "         16884,   771, 20565, 25568, 64411, 25058, 20949, 23630, 20379,\n",
       "         29846, 28522, 16762, 14993, 60295, 34057, 33326, 32326, 61447,\n",
       "         32752,  7493, 16284, 30688, 61769,  3422, 52316, 66741,  3823,\n",
       "           528, 65116, 62329,  6318, 54754,  4155,  5970,  1545, 63832,\n",
       "          3133,  5533,  1155, 63526, 62831, 53762, 22628, 49888, 39207,\n",
       "         37765, 37593, 14969, 34320, 32198, 31342, 30818, 66878, 29992,\n",
       "         28400, 27636, 19563, 26583, 25305, 21895, 23863, 40221, 13094,\n",
       "         44178, 48999, 42000, 48390, 13006,  9908, 44712, 11900, 56485,\n",
       "         49442, 52347,  8495, 15527,  6471, 50651, 54792,  7823, 58782,\n",
       "         14044, 66564, 28144, 49401,  7909, 65516, 23519, 61852, 46266,\n",
       "         15127, 22703, 39190, 40131, 59381, 18928, 29057, 43054],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([55813, 37571, 37569, 37567, 37565, 37562, 37559, 13767, 37551,\n",
       "         13772, 13773, 13774, 59519, 13776, 13778, 37545, 64505, 37539,\n",
       "         13788, 13791, 37532, 13794, 13795, 13796, 13799, 37524, 13801,\n",
       "         37523, 37521, 13804, 59515, 37575, 37578, 37584, 37657, 13701,\n",
       "         59499, 59500, 13705, 37646, 64525, 37642, 37640, 37635, 13718,\n",
       "         13719, 37634, 37633, 13808, 37632, 13729, 13731, 37617, 37616,\n",
       "         64521, 59508, 59509, 37610, 37609, 37606, 64518, 64517, 37587,\n",
       "         37585, 13725, 13698, 64497, 13815, 37440, 13872, 37439, 37438,\n",
       "         37432, 37430, 64478, 37427, 64477, 37426, 37425, 37411, 37410,\n",
       "         37409, 37408, 37402, 37398, 59544, 37396, 13900, 13901, 37387,\n",
       "         37386, 13908, 59547, 37363, 13920, 13921, 37360, 37441, 13869,\n",
       "         13868, 13867, 37508, 37504, 64494, 37500, 37499, 13823, 37497,\n",
       "         13825, 59529, 37495, 13829, 37490, 37485, 37482, 37509, 37481,\n",
       "         13840, 64486, 37466, 37464, 37460, 37459, 64482, 59537, 37453,\n",
       "         37452, 64480, 13864, 37447, 37446, 37479, 13696, 37666, 13692,\n",
       "         64566, 37868, 37867, 13541, 37865, 37863, 64562, 37856, 64560,\n",
       "         13551, 37854, 37853, 37850, 59456, 64557, 13557, 37841, 13564,\n",
       "         13565, 13566, 13568, 37837, 13571, 37834, 37829, 37825, 13577,\n",
       "         13579, 37820, 13536, 59454, 13532, 59452, 59444, 13485, 37924,\n",
       "         37921, 37919, 37918, 13494, 13495, 37914, 64576, 13498, 37904,\n",
       "         37901, 59449, 13582, 13507, 13511, 37895, 13513, 37894, 37892,\n",
       "         64570, 37890, 13519, 13520, 37889, 37887, 13524, 37883, 37882,\n",
       "         64572, 59460, 37816, 37810, 59479, 64540, 37729, 64537, 13647,\n",
       "         37726, 37725, 59484, 13654, 37714, 13659, 37707, 37704, 37703,\n",
       "         37736, 37701, 59486, 37696, 13671, 13672, 13675, 64534, 64531,\n",
       "         37684, 64530, 64528, 37677, 37676, 13688, 13689, 37700, 37351,\n",
       "         13638, 37740, 37806, 37804, 37803, 64550, 13595, 64549, 37795,\n",
       "         37794, 64548, 59467, 37789, 13606, 37784, 13608, 13637],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 251\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 251\n",
       "  })},\n",
       " 'contains_extent': {'feature_present_idx': array([33795, 20468, 37855, 18795, 17495, 46942, 52705, 12904, 53903,\n",
       "         10148, 25577,  7207, 65881,  5923, 62788,  3696, 62787, 55134,\n",
       "         30599, 30984, 39234, 40492, 42172, 42458, 43245, 45646, 46828,\n",
       "         62477, 47343, 29330, 61509, 59200, 55822, 47611,   137, 16731,\n",
       "         14730, 19890, 16757, 12747, 16102, 18608, 22898,  2752,  1540,\n",
       "          7019, 48268, 46076, 48336, 14493, 42623, 14850, 42347, 19713,\n",
       "         47681, 36024,  7798, 33366, 20223, 61568, 28457, 19030, 53343,\n",
       "         55764,  7557, 56878, 26516, 15187, 45591, 27214, 27465, 30329,\n",
       "         32236, 21286, 16739, 43367, 34063,  4721, 35918, 49098,  5305,\n",
       "          6964, 24299, 66580, 66665, 59530, 61781, 61302, 57538, 52010,\n",
       "         65447, 41687], dtype=int64),\n",
       "  'feature_absent_idx': array([59444, 57938, 57937, 12212, 57933, 12215, 36093, 57929, 12218,\n",
       "         36092, 57927, 47630, 25508, 57924, 12224, 47634, 57922, 47635,\n",
       "         12230, 25503, 57919, 12234, 12236, 12239, 12240, 12243, 36088,\n",
       "         47641, 25511, 57940, 12207, 25512, 57971, 25543, 57968, 47613,\n",
       "         39515, 39516, 47618, 25536, 57960, 47620, 12178, 47623, 57955,\n",
       "         39528, 12184, 12186, 57953, 39521, 36097, 47626, 25519, 12198,\n",
       "         25517, 25516, 12202, 25514, 47627, 12205, 25526, 57972, 12247,\n",
       "         12251, 34005, 41164, 57876, 47669, 12308, 47671, 25457, 25456,\n",
       "         12313, 12315, 57867, 12318, 57864, 25452, 57860, 57857, 34009,\n",
       "         57856, 47680, 47682, 57850, 12338, 25438, 57846, 47684, 12344,\n",
       "         47687, 47664], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 92\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 92\n",
       "  })},\n",
       " 'contains_frequency': {'feature_present_idx': array([52941, 25425, 46547, 25002, 60926, 47031,  8165, 23959, 23529,\n",
       "          8422, 47476,  8599, 48024, 60664, 22415, 48777, 25534, 14656,\n",
       "          6969, 46192, 43807, 44016, 44107, 44401, 44403, 62187, 27064,\n",
       "         48821, 61889, 26683, 26621,  6228,  6295, 26321, 26191, 45808,\n",
       "         61763, 49944, 59897, 59889, 13060, 17541, 53287, 13178, 53372,\n",
       "         56823, 53374, 17812, 13294, 13505, 56565, 16148, 16094, 16028,\n",
       "         54899, 15531, 13350, 28849, 12791, 57869, 10350, 21280, 20966,\n",
       "         50423, 50705, 19926, 11473, 18477, 19736, 19704, 50903, 51047,\n",
       "         59039, 11884, 12226, 18686, 59162, 28944, 25699, 40092, 35213,\n",
       "         31260, 41447, 35086, 41229, 31782, 38644,  1406, 64739, 32529,\n",
       "          1564, 65008, 40604, 32901, 40405, 33930, 65384, 29021, 33462,\n",
       "         33370, 33166,  2422, 65839, 31133,   863,  2032, 66802, 67022,\n",
       "         38370, 42463, 35805, 43082, 42446, 62794, 30078,   158, 35811,\n",
       "         43166, 30727, 30384, 15461, 50624, 39031, 40065, 15956, 19129,\n",
       "         15017, 33923, 15242, 39102, 39407, 33576, 33571, 15792, 20083,\n",
       "         19922, 20054, 36194, 19985, 19830, 51602, 51192, 38474, 16865,\n",
       "         38359, 53491, 35072, 17272, 35014, 53558, 34901, 17575, 53276,\n",
       "         38263, 50468, 17969, 18123, 37292, 16209, 52367, 34358, 52030,\n",
       "         18491, 51990, 38908, 19015, 38737, 43272, 21029, 25382, 46445,\n",
       "         41217, 41305, 31382, 41356, 46058, 45806, 45767, 26257, 31015,\n",
       "         45523, 30864, 25338, 26764, 45092, 29937, 27087, 44972, 27728,\n",
       "         27777, 27848, 29435, 43990, 43814, 28631, 43736, 28743, 42388,\n",
       "         33253, 25323, 25154, 21053, 50314, 40087, 50295, 50114, 49981,\n",
       "         22029, 48972, 33141, 33105, 22678, 48302, 23019, 25296, 23259,\n",
       "         47484, 23354, 23429, 47426, 32619, 23854, 40694, 24137, 32366,\n",
       "         24625, 46917, 46794, 41125, 32977, 14498, 67221,  7307,  9561,\n",
       "          9718, 60050, 62759, 63137,  4179,  3667, 63872, 63965, 63991,\n",
       "          7335,  3342, 64274, 59098, 11774, 64750, 58352, 12271, 57946,\n",
       "         12423, 65091, 65321,  2589, 62726,  2476, 62637,  5127, 61260,\n",
       "         61445,  7107, 60919,  7972,  8185,  6691, 61623,  8472,  8539,\n",
       "         60799,  6205, 61713, 60688,  6096, 60548,  5877, 62289, 60279,\n",
       "          5635, 62473,  5322,  9277, 60158,  2440, 11334, 66056, 57139,\n",
       "         66298, 13182,  1414, 56817, 13570, 13622, 13129, 65551,  1232,\n",
       "         66394,  1127, 56335, 67040, 56214, 14334, 56558,  1753,  7424,\n",
       "         57394, 66139,  1883, 39467, 65037, 35711, 38217, 35533, 26782,\n",
       "         45245,  5998, 45055, 66776,  5785, 44900, 44781, 44633, 44497,\n",
       "         38524, 66536,  1118, 62380, 66836, 26618, 37978, 37858, 55793,\n",
       "         37321, 36617,  6838, 46145, 37365, 37470, 46133,  6798,  6743,\n",
       "         37531, 36157, 61689, 26442, 45678, 61693, 45455, 45416, 26601,\n",
       "         62416, 32268, 35017,  1814,  3050,  3913, 41587,  3698,  1553,\n",
       "          1595, 40684,  3110, 63996, 30382, 31411, 41312, 66192, 32374,\n",
       "         31648, 64703, 31799,  1756,  3208, 40973,  1730, 40437, 41820,\n",
       "          4482, 27971, 28050,  5217, 39912,  2865,  5126,  5031, 40506,\n",
       "         39710, 40641, 38671,  4828, 28946,  1284, 38739,  2982,  4701,\n",
       "          4644,  4614, 62765, 28856, 34548, 56017,  7446, 57455, 57572,\n",
       "         52936, 52862, 57810, 51664, 12204, 18743, 18792, 11713, 50864,\n",
       "         11663, 19762, 11474, 11443, 20012, 59420, 59644, 59769, 59798,\n",
       "         10829, 20602, 50383, 50360, 50353, 10601, 21001, 12687, 53104,\n",
       "         17887, 17791, 14354, 15044, 15090, 15398, 15399, 55021, 14027,\n",
       "         13970, 15878, 54359, 13797, 56505, 54323, 10582, 13679, 54059,\n",
       "         53870, 13289, 16655, 56859, 16887, 53296, 17282, 17357, 17450,\n",
       "         57225, 17597, 17613, 54150, 21061, 59222, 37000, 22348, 60893,\n",
       "         24149, 48577, 22475, 22573,  8163,  8261, 48430, 22664,  9050,\n",
       "         22863, 60599, 23767, 59882, 23237, 60647, 47309, 47587, 23333,\n",
       "         60889, 22297, 24178, 23538, 49631, 46923,  9403, 10197, 49777,\n",
       "         21570, 21462,  7473, 60103,  7798, 61120, 49072, 37480, 53755,\n",
       "         66942, 61381, 38786, 38893, 47417, 39028, 55543, 45693, 46223,\n",
       "         67112, 54294, 38321, 38212, 54854, 54815, 56498, 66719, 66958,\n",
       "         61459, 60960, 38031, 55139, 61541, 38539, 55419, 47127, 47242,\n",
       "         66674, 59849, 60805, 64409, 50760, 61292, 62594, 48998, 49035,\n",
       "         59624, 49070, 50563, 41495, 49531, 63344, 62706, 63240, 63198,\n",
       "         63162, 43689, 60216, 48654, 51076, 51121, 39482, 39522, 57143,\n",
       "         39693, 39980, 57369, 48259, 62064, 66321, 40329, 57764, 44755,\n",
       "         58091, 48527, 51313, 64957, 58124, 58523, 48323, 45402,    32,\n",
       "         33341,  9936, 21294, 10456, 11200, 11667, 27859,  9774, 11684,\n",
       "         27502, 27466, 27333, 12529, 12638, 26880, 11858, 26859, 29300,\n",
       "         29530, 31579,  7861, 31357, 31323, 31064,  7870, 29431,  7946,\n",
       "         30093, 29591,  8543,  8963,  9235,  9584, 30304,  7690, 12912,\n",
       "         26563, 23434, 16540, 23274, 16751, 16938, 18404, 16158, 22385,\n",
       "         22292, 22281, 18565, 19161, 19528, 20757, 36967, 26570, 23606,\n",
       "         23845, 12922, 13139, 26406, 26068, 26054, 25979, 23806, 25799,\n",
       "         25388, 14039, 24874, 15219, 24687, 24287, 13918,  7435, 29189,\n",
       "         21331, 33526,  4874, 33684,  4257,  1965,  4240,  3750,  3553,\n",
       "          3383,  2332,  2395,  1094, 34217, 35606, 34336,  3266, 31927,\n",
       "         34515, 35537, 34521,  3167, 35433,  3081,  3020, 34305,   770,\n",
       "          1682,  6662, 32973, 33522,  6079,  5985, 32882,  6362,  6145,\n",
       "         32589,   441,  6264, 36562, 32439,  5008, 33463, 20201,  2575,\n",
       "         16063, 20297, 54823, 54364, 65667, 50449, 54327, 20379, 54786,\n",
       "         20617, 20816, 18485, 53750, 20133,   912,  1078,   570, 51804,\n",
       "         52295, 18480, 52458, 15661, 17024,  1686, 66232, 19279, 16623,\n",
       "          1778, 16558, 67118, 19818, 16405, 15569,  7125, 65325,  4571,\n",
       "         11189, 59626, 11099, 11001, 10526, 10074,  5505,  5828,  4506,\n",
       "         62045, 61743,  8644,  8415,  8413, 60901,  6526, 60987,  6833,\n",
       "         61451, 61990, 15441, 11820,  4342, 65021, 14324, 64784, 13549,\n",
       "         56986,  3183, 56992, 57006, 13121, 58800, 13010,  3320,  3376,\n",
       "         12655, 57841, 58069, 12330, 11891, 58473, 58501, 64701, 57129,\n",
       "         36823, 50099, 31732, 31568, 41596, 42327, 42889, 43052, 43290,\n",
       "         43524, 28660, 43749, 41050, 28522, 21449, 44379, 27740, 27727,\n",
       "         27362, 45474, 26551, 45926, 25494, 46907, 43873, 46952, 32811,\n",
       "         32915, 36396, 37599, 37611, 37747, 36094, 37996, 35866, 38557,\n",
       "         34670, 38983, 40469, 34023, 39355, 33683, 33625, 39603, 39819,\n",
       "         67165, 33235, 33163, 33159, 40390, 39208, 23543, 52278, 22104,\n",
       "         21746, 47610, 48449, 49266, 22105, 22654, 48237, 21546, 23297,\n",
       "         18740, 40570, 61753, 32633, 51417, 32224, 30818, 22352, 18684,\n",
       "         53986, 18988, 41947, 29583, 60273, 22594, 43398, 18328, 43958,\n",
       "         11480, 22772, 44436, 60907, 41781, 62230, 44691,   160, 66869,\n",
       "         21583, 66654, 37952, 20309, 49561, 38332, 35176, 65118,  2748,\n",
       "         38511, 64971, 34485, 63829, 63582, 63526, 50850, 19657, 33775,\n",
       "         49098,  4704,  5305,  5501,  5575,  5928, 58217, 22588, 54456,\n",
       "         54674, 53451, 25821, 13601, 13676, 45103, 15693, 24631, 26912,\n",
       "         14421, 23454, 14436, 16095, 54104, 48113, 12415, 16230, 12440,\n",
       "         14554, 12467, 26197, 57767, 54460, 22277, 46842, 33853, 41142,\n",
       "          7200,  2771, 26106, 40920, 51875, 35148, 53631, 54792,  3397,\n",
       "         63755, 34908, 63103, 27429, 63609, 46623, 64414,  3308, 21802,\n",
       "         59530, 63493, 58171, 36158, 28223, 17741,   693, 59671, 53015,\n",
       "           746, 18252, 21670, 53794, 60068,  9481, 15368, 47267, 35232,\n",
       "         47146, 57349,  8690, 16277, 54444, 36114,  8613, 46857, 67044,\n",
       "         36262, 63650, 46878,   745, 35695, 34206, 35769, 23343,  2621,\n",
       "         15929, 50656, 38606, 21734,   702, 54843, 12016, 47703, 13248,\n",
       "         22169, 31504,  7935, 26458,  8839, 57503, 52890, 57622, 11157,\n",
       "         17898, 28030, 44886, 44501, 44573, 13261, 56624, 51103, 18961,\n",
       "         13736], dtype=int64),\n",
       "  'feature_absent_idx': array([63587, 49468, 49466, 64779, 64778, 64776, 49463, 27820, 41772,\n",
       "         12799, 41773, 41775, 27811, 12805, 12782, 41776, 41777, 27805,\n",
       "         12811, 12812, 12813, 49456, 58842, 27801, 27799, 49450, 12824,\n",
       "         27796, 12826, 12807, 49446, 27828, 12777, 12723, 41744, 41747,\n",
       "         49503, 49500, 27864, 27863, 27861, 27860, 49493, 12739, 12742,\n",
       "         57271, 49471, 49490, 49486, 27845, 12762, 12763, 49474, 41762,\n",
       "         12768, 12769, 12770, 12771, 12773, 27831, 58851, 49489, 41742,\n",
       "         49445, 49444, 27757, 41818, 27754, 61704, 49411, 12892, 12894,\n",
       "         12898, 12901, 64756, 27735, 27733, 41828, 12880, 27731, 12915,\n",
       "         27725, 49400, 61709, 49398, 27723, 49391, 12930, 27715, 27713,\n",
       "         27712, 27710, 64749, 27726, 12829, 49418, 12877, 27792, 27791,\n",
       "         12835, 61695, 41798, 57283, 49439, 49437, 41802, 64766, 49434,\n",
       "         12851, 12852, 12878, 12854, 49431, 12858, 61698, 12862, 41807,\n",
       "         12865, 61700, 27763, 49425, 49424, 41817, 49421, 27758, 27776,\n",
       "         27708, 12721, 12717, 27992, 12562, 49579, 49578, 12568, 41671,\n",
       "         49574, 12574, 64822, 64821, 64820, 57261, 61641, 12557, 12581,\n",
       "         12583, 49572, 49570, 12586, 64816, 12592, 27967, 12595, 12596,\n",
       "         12597, 12598, 64814, 27963, 64819, 61646, 27994, 49586, 61629,\n",
       "         12510, 57251, 12512, 49606, 41655, 49605, 41658, 28018, 57252,\n",
       "         57254, 12527, 57256, 61637, 12530, 28013, 12534, 55978, 64833,\n",
       "         57257, 61632, 49590, 12544, 12546, 49588, 41664, 64831, 12550,\n",
       "         49594, 41741, 27958, 61647, 57266, 27908, 49532, 12675, 12676,\n",
       "         49529, 41729, 64797, 49526, 49524, 49523, 41731, 27891, 12667,\n",
       "         12693, 27883, 49516, 41738, 64792, 12707, 49511, 12710, 12711,\n",
       "         49509, 27877, 12714, 49508, 49507, 12696, 27957, 57265, 12663,\n",
       "         27955, 61648, 49560, 41694, 41695, 49558, 41697, 61650, 27946,\n",
       "         27937, 41703, 12633, 12634, 12664, 27931, 64806, 49549, 49548,\n",
       "         12644, 58865, 49546, 12653, 58859, 41718, 41719, 41722, 12661,\n",
       "         27910, 41706, 27707, 64748, 41832, 41929, 41932, 13201, 27516,\n",
       "         64699, 61751, 13209, 13214, 49241, 13217, 27506, 13219, 41935,\n",
       "         13193, 13221, 49235, 58814, 57325, 13233, 49226, 27486, 13243,\n",
       "         57329, 13247, 13249, 41949, 49219, 49216, 27500, 49215, 27527,\n",
       "         41922, 58820, 27557, 49272, 49271, 13146, 49269, 13148, 13149,\n",
       "         13151, 13154, 41908, 49263, 13160, 13190, 13161, 13167, 41913,\n",
       "         41914, 41916, 49255, 13173, 13176, 49254, 41919, 13183, 64704,\n",
       "         27535, 27531, 27548, 27561, 13255, 61762, 13311, 49181, 41971,\n",
       "         13317, 27439, 41973, 13322, 41976, 49174, 27431, 49173, 13328,\n",
       "         13329, 41970, 57339, 13333, 49168, 58809, 13338, 49164, 57341,\n",
       "         13344, 13345, 13347, 64668, 49160, 27417, 27413, 27430, 13259,\n",
       "         49182, 27449, 27471, 61765, 41962, 13269, 13271, 49202, 13273,\n",
       "         13274, 61766, 27464, 57334, 13280, 49196, 13307, 61767, 27459,\n",
       "         27458, 13288, 13290, 13292, 13293, 13295, 61771, 27451, 61772,\n",
       "         13301, 49186, 49185, 57336, 61742, 58821, 49281, 61717, 12987,\n",
       "         64737, 12989, 41850, 41851, 41853, 27676, 41856, 57301, 13002,\n",
       "         13003, 49350, 41848, 57303, 13014, 49340, 13016, 27658, 61724,\n",
       "         13020, 27656, 27653, 64730, 13028, 13029, 27650, 41867, 49345,\n",
       "         61727, 12983, 27686, 12943, 49383, 64747, 12947, 12948, 49378,\n",
       "         12951, 12952, 27703, 49377, 57297, 27701, 49374, 41847, 49373,\n",
       "         49369, 12964, 57299, 12969, 12970, 12971, 27693, 12973, 41843,\n",
       "         41844, 27688, 49362, 49360, 12960, 57305, 13037, 64728, 13096,\n",
       "         27593, 13098, 27591, 27590, 13101, 13103, 13106, 27586, 13108,\n",
       "         41896, 61737, 13112, 13095, 27582, 27581, 49291, 49290, 61739,\n",
       "         41897, 27576, 41898, 27573, 41899, 27571, 49284, 27568, 27567,\n",
       "         49294, 61735, 41887, 27605, 13040, 27641, 27638, 27637, 61729,\n",
       "         57306, 58827, 27631, 13052, 61730, 64725, 27625, 27624, 27621,\n",
       "         27620, 13065, 49315, 61733, 27616, 27612, 64721, 49309, 61734,\n",
       "         13079, 41884, 13081, 27607, 27606, 13084, 49609, 12506, 49610,\n",
       "         28026, 64964, 28473, 49931, 11922, 11923, 61545, 41416, 41419,\n",
       "         49923, 11931, 28452, 11939, 11940, 11914, 28450, 28447, 64956,\n",
       "         28445, 41429, 28441, 28439, 11952, 28436, 41432, 11959, 49901,\n",
       "         28429, 41436, 28448, 41440, 28476, 64967, 49973, 28521, 28520,\n",
       "         28519, 11861, 41389, 49960, 11874, 28504, 11876, 28501, 28500,\n",
       "         28498, 28478, 11882, 11885, 28494, 28493, 58919, 49948, 28487,\n",
       "         61537, 41406, 11902, 28482, 49941, 11906, 61538, 49954, 61528,\n",
       "         11968, 49897, 49865, 28388, 12029, 28383, 28382, 12033, 28378,\n",
       "         41455, 28374, 41457, 28371, 49856, 49855, 12022, 12045, 12047,\n",
       "         64928, 49854, 28370, 49851, 12056, 12059, 41465, 12062, 49847,\n",
       "         12064, 28361, 64920, 12046, 49898, 61559, 12015, 28421, 11975,\n",
       "         11976, 64948, 41441, 57188, 49891, 49890, 58915, 28416, 11984,\n",
       "         11985, 11987, 12017, 49885, 11994, 11995, 41444, 64943, 64941,\n",
       "         28408, 28407, 41448, 28398, 28397, 61557, 12013, 12014, 28410,\n",
       "         28525, 61527, 11850, 41337, 11699, 11700, 65001, 28624, 11704,\n",
       "         11706, 11707, 11708, 28622, 28621, 11711, 61507, 11696, 61508,\n",
       "         11722, 61510, 28605, 41346, 28602, 11731, 11733, 11734, 41347,\n",
       "         11736, 11737, 11738, 11739, 28612, 41349, 11695, 28634, 58933,\n",
       "         11647, 11649, 41321, 11651, 11653, 11656, 28649, 50062, 11659,\n",
       "         50060, 50058, 65012, 28630, 50055, 11669, 11672, 11673, 11676,\n",
       "         50049, 28642, 11679, 41331, 41333, 50046, 65005, 58928, 65004,\n",
       "         11668, 41351, 28595, 50024, 28552, 11809, 41375, 11811, 28548,\n",
       "         41376, 61522, 11817, 28544, 11821, 49988, 11826, 11827, 64984,\n",
       "         11828, 11830, 64981, 11832, 11834, 28537, 28536, 61525, 28534,\n",
       "         28530, 28529, 49978, 49976, 11848, 49985, 11806, 11805, 11804,\n",
       "         64997, 50021, 11749, 64996, 28592, 28589, 58925, 50016, 11758,\n",
       "         41360, 28583, 11765, 11766, 28580, 41361, 11777, 11779, 11781,\n",
       "         41365, 11784, 11785, 41369, 64988, 28562, 50000, 49999, 28558,\n",
       "         49994, 11802, 49837, 27409, 12075, 61563, 12356, 49691, 28128,\n",
       "         12362, 12363, 12365, 28126, 12367, 12368, 28124, 12372, 57237,\n",
       "         12374, 41593, 49686, 64866, 28117, 49679, 58884, 28114, 28113,\n",
       "         58882, 12390, 12391, 49678, 49677, 28109, 28108, 58885, 41614,\n",
       "         49696, 28136, 41580, 12313, 12315, 49713, 49712, 12318, 64874,\n",
       "         61601, 61602, 41582, 49708, 49707, 61603, 28135, 28150, 64872,\n",
       "         64871, 49703, 12338, 41584, 61607, 57232, 61608, 12344, 12346,\n",
       "         28140, 61611, 41591, 61604, 12308, 12404, 28097, 64845, 41628,\n",
       "         12459, 12460, 41631, 49642, 28064, 28063, 41634, 12468, 49639,\n",
       "         28056, 41638, 12454, 28051, 64840, 12484, 28042, 61627, 41649,\n",
       "         12490, 12491, 41650, 12494, 12495, 57247, 28034, 41653, 28047,\n",
       "         49668, 12452, 12448, 49667, 12411, 12412, 28093, 49666, 28091,\n",
       "         12418, 28088, 49661, 28085, 28084, 49654, 12428, 41626, 28082,\n",
       "         12431, 64850, 64849, 64847, 28080, 28079, 28078, 28076, 49649,\n",
       "         49648, 41624, 12446, 12447, 64851, 28167, 28173, 12297, 64908,\n",
       "         49796, 28299, 12142, 12143, 58907, 41509, 41515, 41516, 12158,\n",
       "         41520, 28274, 61578, 41503, 41523, 28265, 28264, 57218, 12178,\n",
       "         64900, 41530, 49771, 12184, 12186, 49768, 49767, 61579, 41533,\n",
       "         28267, 28248, 12134, 12132, 12079, 28350, 61565, 58914, 57208,\n",
       "         49825, 12087, 41474, 28341, 28337, 28333, 28331, 58912, 28304,\n",
       "         41485, 41486, 12106, 12108, 12109, 41487, 64914, 28316, 49809,\n",
       "         57209, 41494, 28310, 49803, 49800, 12104, 28247, 61582, 12198,\n",
       "         28208, 12251, 12252, 12253, 12254, 64888, 49742, 28207, 12258,\n",
       "         64887, 28205, 49739, 12267, 28209, 49732, 49729, 12279, 28188,\n",
       "         12283, 41565, 41566, 28182, 41572, 12292, 12293, 12294, 49725,\n",
       "         57230, 28191, 12247, 41558, 28213, 28241, 12202, 28240, 12205,\n",
       "         28238], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_instrument': {'feature_present_idx': array([35051, 18652, 19522, 19931, 46980, 20687, 63220,  6736, 45621,\n",
       "          5010,  4875,  4543,  7061, 27580, 29117, 24288, 39531, 43640,\n",
       "         16189, 17544, 54047, 37510, 52271, 19243, 30685, 51711, 30572,\n",
       "         20771, 21247, 46687, 22411, 22630, 56577, 28237, 41732, 23551,\n",
       "         24931, 41669, 56940, 19042, 57185, 13218, 64033,  1997,  9868,\n",
       "         64553, 11398,   971, 58656, 64911, 63338,   249, 12876, 67070,\n",
       "         36200, 63510, 24389, 24390, 38357, 43464, 39728, 41332, 27050,\n",
       "         64278,  5871,   287, 29016, 66067, 43105, 42370, 44370,  7674,\n",
       "         57462, 56264,  9671,  9148,  8866, 35318, 62793,  7962, 46533,\n",
       "         33648,  8375, 42227, 35607, 36844, 62868, 37801, 56192, 38366,\n",
       "         39340, 55654, 47232, 57593, 46965, 53755, 65926, 53709, 45360,\n",
       "         41708, 59374, 51921, 61381, 55550, 58338,   142, 33754, 26214,\n",
       "         25314, 23960, 23654, 23222, 21930, 21619, 19766, 19315, 12263,\n",
       "         11643,  8398,  7964,  4617,  4395,  1922,   262, 26322, 28824,\n",
       "         18637, 67238, 29637, 29893, 31699, 14993, 55684, 14263, 56440,\n",
       "         29174, 13400, 56682, 13396, 13025, 32114, 58050, 11770, 37461,\n",
       "         18290, 11068, 60580, 32125, 63130,  7493, 33634, 36057, 67201,\n",
       "          1859,  1315, 58561, 54664, 27961, 30034, 45919, 38291, 27095,\n",
       "         20737, 20142, 43320, 19896, 31181, 47735, 48718, 38906, 37719,\n",
       "         19057, 53185, 33915, 47801, 54069, 64268, 64407, 44345,  9860,\n",
       "          6318, 61221, 56501, 58896, 30713, 13006, 57083, 14969, 35604,\n",
       "         43092,   931,   557, 66223, 18299, 37401, 31836, 22763, 60615,\n",
       "         59816, 46692, 46857, 56919, 67044, 18961, 62911], dtype=int64),\n",
       "  'feature_absent_idx': array([52664, 57571, 57570, 12721, 12723, 57568, 45583, 57567, 57566,\n",
       "         28274, 45592, 45594, 28267, 12739, 12717, 28265, 12742, 45598,\n",
       "         45599, 57550, 45600, 45603, 57544, 28248, 28247, 45609, 12762,\n",
       "         12763, 28241, 28264, 28240, 12714, 12710, 12661, 12663, 12664,\n",
       "         57611, 45557, 12667, 57609, 28316, 57605, 12675, 12676, 28310,\n",
       "         57601, 12711, 45565, 57596, 28304, 57594, 57591, 45567, 12693,\n",
       "         12696, 28299, 45573, 57579, 57578, 12707, 45576, 57599, 45611,\n",
       "         28238, 12768, 57502, 57501, 28207, 57493, 28205, 12824, 12826,\n",
       "         12829, 45634, 45635, 12835, 28191, 28188, 12813, 45638, 57480,\n",
       "         28182, 45643, 57468, 12851, 12852, 45652, 12854, 28173, 12858,\n",
       "         12862, 28167, 12865, 45639, 12812, 12811, 28208, 12769, 12770,\n",
       "         12771, 12773, 28233, 12777, 28232, 45615, 45616, 12782, 57526,\n",
       "         57525, 57524, 45618, 45619, 28225, 57518, 28224, 57516, 57513,\n",
       "         57511, 12799, 28218, 45626, 28213, 12805, 45628, 12807, 28209,\n",
       "         45553, 57450, 45544, 57626, 57745, 28447, 57741, 12506, 28445,\n",
       "         45458, 57736, 12510, 57735, 12512, 28441, 57731, 57730, 28448,\n",
       "         45460, 57725, 28436, 57723, 45462, 12527, 57718, 12530, 57717,\n",
       "         57715, 12534, 28429, 45467, 45469, 28439, 28421, 45457, 57750,\n",
       "         28487, 45411, 12452, 57782, 12454, 45413, 45414, 28482, 12459,\n",
       "         12460, 45415, 28478, 28476, 28450, 57772, 28473, 57770, 57768,\n",
       "         57766, 57762, 45446, 12484, 12490, 12491, 28452, 12494, 12495,\n",
       "         57753, 12468, 12544, 45473, 12546, 12598, 57666, 57665, 28374,\n",
       "         45509, 28371, 28370, 57662, 45511, 57656, 28361], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 205\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 205\n",
       "  })},\n",
       " 'contains_location': {'feature_present_idx': array([   12, 36023, 15909, 56154, 35763, 16170, 56386, 35378, 36377,\n",
       "         56573, 35250,  5053, 35068, 57507, 34538, 17092, 17107, 16418,\n",
       "         34236, 15625, 37050, 54862, 39479, 14791, 54923, 54972, 38487,\n",
       "         15050, 15611,  5901, 15108, 55319, 55363, 55513,  5818, 38039,\n",
       "         15445, 55230, 39769, 17158,  4535,  3517, 60194, 60404, 31387,\n",
       "          3369, 30648, 30432, 31448, 30431, 61063, 19298, 19348, 19607,\n",
       "         29655,  2860, 19785, 19125, 33990, 60095, 18302, 58675, 33769,\n",
       "         33395, 33389, 17657,  4113, 32443, 18446, 59061, 17973, 32264,\n",
       "         18015,  3923, 18047, 32201, 18212,  4022, 19794, 39933, 40152,\n",
       "         45822, 49230, 49389, 45673, 49582, 45405, 10995,  9315, 45150,\n",
       "         49818, 11061, 45101, 45094,  8892, 50156,  8801, 45131, 11292,\n",
       "         45876, 49152, 47885,  9901,  9889, 10063, 47281, 48542, 48565,\n",
       "          9425, 48709, 46286, 46279, 46206, 46152, 10480, 49092, 45977,\n",
       "         46394, 54390, 44673, 44237, 41522, 41374,  7333, 13707, 13708,\n",
       "         13732, 13740, 52720, 53201,  7084, 13875, 53366, 13999, 53710,\n",
       "          6906, 53944, 53255,  8752, 41668, 52567, 44233,  8680, 44062,\n",
       "         50838, 51339, 12206, 43343, 41761, 51503, 51719, 12673, 52075,\n",
       "         52118, 42092, 52470, 52536, 51616, 61708,  9945, 26700, 62967,\n",
       "         62941,  2286,   479, 64284, 28096, 62889, 21300, 27826, 26122,\n",
       "         62783,   387, 64479, 66705,  1106, 66849, 26333, 21346, 20274,\n",
       "         65785, 24164, 21258, 28089, 66207,  2001, 27674, 20917, 25641,\n",
       "          2067, 27517, 63441, 63407, 27903, 66322, 63950, 20652, 27989,\n",
       "           563, 24830,  1795, 27428, 63096, 27375, 62694, 62796, 62583,\n",
       "         28988, 21566, 21568, 28975, 62413,  2613, 62422,  1400, 26599,\n",
       "         67302, 26412,  2596, 24133, 23585,   233, 66949, 26373, 66884,\n",
       "         62444, 62130, 43331, 13955, 13953, 42680, 26678, 40789, 25771,\n",
       "         13894, 42562, 12827, 42480, 40513, 25676, 12750, 43171, 42688,\n",
       "         42737, 12698, 40413, 12422, 42979, 25655, 43042, 43146, 43268,\n",
       "         43223, 25455, 40415, 40485, 22140, 42143, 42292, 41287, 13287,\n",
       "         26452, 41883, 41302, 26189, 26523, 26392, 13484, 41670, 41561,\n",
       "         26289, 41532, 13670, 41700, 42399, 41207, 26548, 13890, 12996,\n",
       "         13616, 40816, 42097, 13061, 41139, 25845, 22054, 42061, 41092,\n",
       "         13242, 26585, 26574, 42075, 25448, 19811, 43412, 24033, 46272,\n",
       "         24049, 24148, 10536, 10559, 10570, 45954, 10603, 24334, 10636,\n",
       "         24402, 24447, 45793, 24455, 45742, 45625, 45476, 10877, 23774,\n",
       "         24504, 10325, 23709,  9960, 23225, 47699, 23217, 47614, 23499,\n",
       "         47575, 10090, 47373, 47365, 46708, 10230, 10232, 46616, 23602,\n",
       "         23662, 46545, 46529, 46470, 23720, 43348, 45384, 24558, 44136,\n",
       "         11616, 44130, 40410, 25180, 44005, 43858, 43771, 43750, 11941,\n",
       "         43467, 25304, 43457, 43439, 43415, 12165, 12169, 12189, 25381,\n",
       "         22333, 45315, 44155, 11564, 22666, 11026, 24698, 22609, 22589,\n",
       "         24734, 44890, 44744, 11239, 44683, 24815, 11283, 24823, 22450,\n",
       "         44582, 44450, 22397, 11481, 11490, 25109, 44073, 39814, 26714,\n",
       "         33616, 17454, 33236, 20610, 33233, 17850, 32749, 32599, 32337,\n",
       "         32280, 20583, 20576, 32255, 28194, 32164, 32054, 18118, 20509,\n",
       "         31998, 33623, 31988, 33669, 17404, 34582, 34559, 27868, 34523,\n",
       "         34517, 34466, 27944, 17187, 34130, 34104, 17274, 34025, 33994,\n",
       "         17313, 33935, 33854, 33838, 33824, 20623, 20616, 16931, 18270,\n",
       "         18293, 30370, 20178, 30322, 20017, 19300, 29963, 19500, 29763,\n",
       "         29665, 19974, 19951, 29396, 19655, 29087, 29278, 29207, 29089,\n",
       "         19859, 19827, 19027, 18273, 30379, 30657, 31812, 28653, 18311,\n",
       "         18395, 31787, 31727, 31478, 20212, 28801, 31443, 28848, 18742,\n",
       "         18772, 31115, 31093, 31050, 18815, 30990, 30984, 18927, 34660,\n",
       "         16735, 34678, 39658, 39570, 21383, 39305, 21354, 38907, 38881,\n",
       "         27015, 14858, 14879, 38811, 38788, 14894, 38694, 38610, 27047,\n",
       "         38421, 21325, 38282, 39661, 27341, 26855, 14462, 40333, 40259,\n",
       "         26768, 40123, 14197, 40111, 14239, 14240, 40074, 14265, 40067,\n",
       "         14288, 21499, 14330, 26807, 39927, 39922, 19815, 26840, 14478,\n",
       "         21105, 27407, 37967, 35700, 35595, 35536, 27734, 35295, 35291,\n",
       "         27835, 20808, 16454, 35189, 27843, 16521, 16536, 47928, 34906,\n",
       "         16576, 34868, 34776, 34706, 16077, 35741, 27660, 15969, 37682,\n",
       "         15405, 37133, 37113, 36991, 15480, 15484, 36975, 36705, 14083,\n",
       "         27480, 27501, 36327, 15864, 15871, 27614, 15934, 15947, 27633,\n",
       "         35888, 36450, 34922, 45179, 56994,  2526, 62728,  6280,  6301,\n",
       "         54879,  6367, 54834,  6408, 54647, 54589, 54507,  6588,  6600,\n",
       "          6605, 62763, 54287, 54229, 54916,  6231, 54970, 55003,  5606,\n",
       "         55690, 55570, 61777,  2691,  5695, 55539, 55531,  6712,  2659,\n",
       "         62290, 55224,  5962,  2645,  6041,  6052,  6056, 62469, 55286,\n",
       "          5591,  2377, 54046,  1902,  1896, 63827, 52924,  1885, 63911,\n",
       "         64081, 64098,  7368,  1758, 52659, 52578, 64105,  7532, 64124,\n",
       "          1691,  7566,  7204, 63640, 63578, 53131, 53878, 53765,  6910,\n",
       "          6913, 63002, 53691, 53683, 59610,  6830, 53589, 63164, 63330,\n",
       "          2134, 53347, 63536,  2026,  1982, 63571, 53522,  5524, 55959,\n",
       "          5493, 58873,  4268, 60665,  3321, 58830, 58823, 58773,  4391,\n",
       "         58695, 58600, 58515,  4559, 58370,  4572,  4578, 58210,  3313,\n",
       "         58942, 58947, 58973, 60548, 59577, 59701, 59471, 59824, 59258,\n",
       "         59254, 59874,  3764,  4631, 60102,  4000,  4013,  4043, 59047,\n",
       "          4114,  4154, 60488,  4182, 59105,  4666, 57925, 57902, 61073,\n",
       "         56529, 56442, 56426,  5204, 61189, 56377, 56349, 60983,  5235,\n",
       "          3041,  5330,  2952, 56055, 56025,  5464, 61250,  5492, 56318,\n",
       "          1654, 56732,  3163, 57714, 57657,  4711, 57590, 60709, 60711,\n",
       "          4766, 57298, 56744,  4845,  4944, 57056, 57053, 60836, 60869,\n",
       "         56936,  3191, 56843, 57149,  7575, 63051,  1636,   362, 49557,\n",
       "         49672, 66615,   488,   534, 66513, 49716,  9033,  8987,   554,\n",
       "         50127,  8855,  8787, 50158,  8757, 50258, 65848, 50789, 65939,\n",
       "          8584, 50662, 66059,  9195,  8594, 50624, 50489, 66151, 50398,\n",
       "           696, 50324,  8595,  8527, 49402, 49313,  9923, 48063,    22,\n",
       "          9905, 48111, 48154, 48264, 48281, 48316, 48445, 48458, 67137,\n",
       "         48484, 48496, 48516, 67130, 67045, 66847,  9409,  9446, 49187,\n",
       "          9491, 49145, 66758, 49051,   229,   224,   207, 48855,  9684,\n",
       "          9723, 48986, 50994, 59652,  1123, 51401, 52182, 65671,  1506,\n",
       "         52319, 51462,  8088, 65566, 52235,  7791, 51496, 64740,  1510,\n",
       "         51497, 51663, 65534, 64595,  8193, 52042, 65680, 51386, 65361,\n",
       "         51217, 65060, 65709, 52531, 30613, 30445, 63552, 24155, 30998,\n",
       "         65195, 64898, 64854, 64812, 31046, 30441, 31041, 66877, 60682,\n",
       "         66845, 24337, 27813, 27825, 24333, 60691, 24234, 24407, 24210,\n",
       "         65045, 31047, 26607, 64961, 30866, 30522, 30895, 30466, 65018,\n",
       "         28234, 64014, 67034, 27372, 31439, 27008, 60380, 60133, 27230,\n",
       "         31501, 27151, 31544, 67232, 67282, 67294, 64286, 31746, 59712,\n",
       "         23400, 64372, 31795, 59689, 31424, 60455, 67204, 31348, 27505,\n",
       "         23911, 23870, 26814, 24482, 23868, 60679, 60561, 64681, 63883,\n",
       "         31130, 27377, 23665, 31221, 67173, 31261, 23618, 26978, 31285,\n",
       "         26985, 64619, 24492, 27982, 66655, 62811, 28952, 25513, 62341,\n",
       "         66126, 66131, 25414, 62906, 66267, 62283, 29000, 25268, 29023,\n",
       "         29078, 62254, 62214, 61904, 65595, 66315, 62378, 61642, 26259,\n",
       "         66008, 28315, 28332, 28434, 26069, 26057, 28459, 28532, 25938,\n",
       "         25925, 28607, 62749, 65889, 65928, 28669, 26194, 25755, 62515,\n",
       "         62784, 65980, 28164, 61624, 66328, 25101, 66385, 29999, 66387,\n",
       "         24799, 26453, 61110, 63294, 66510, 30091, 30113, 63325, 30135,\n",
       "         30181, 65515, 24731, 66590, 30336, 65358, 63331, 66363, 29978,\n",
       "         61194, 24850, 61619, 61581, 61500, 29362, 29363, 61367, 64582,\n",
       "         26383], dtype=int64),\n",
       "  'feature_absent_idx': array([39346, 25433, 54098, 10626, 31389, 18630, 10630, 31386, 10632,\n",
       "         10633, 10634, 49284, 45152, 25438, 49281, 10641, 10642, 31379,\n",
       "         10645, 10646, 45157, 10649, 18624, 18623, 59853, 10638, 18622,\n",
       "         59864, 10618, 59885, 31417, 10589, 31416, 59883, 31414, 18650,\n",
       "         18648, 59877, 54085, 54086, 45151, 54087, 54090, 25427, 18640,\n",
       "         59870, 25429, 10611, 31399, 45148, 59868, 54096, 59866, 10602,\n",
       "         10654, 18619, 59852, 49271, 31346, 59828, 10697, 59827, 10699,\n",
       "         25456, 59825, 25457, 45178, 49269, 49272, 59821, 10708, 10710,\n",
       "         10711, 59820, 45188, 10716, 10717, 59817, 18596, 10720, 10723,\n",
       "         10706, 25452, 45172, 31355, 10658, 10659, 18617, 18616, 59846,\n",
       "         10665, 10666, 45159, 59845, 31367, 45160, 59843, 10673, 54109,\n",
       "         10677, 59840, 10680, 31360, 18610, 54111, 45168, 59837, 10686,\n",
       "         10687, 54113, 31418, 31328, 45135, 49290, 59944, 59943, 31489,\n",
       "         59942, 54049, 25396, 10490, 31485, 59936, 49309, 45096, 54048,\n",
       "         59935, 59934, 59933, 18678, 31477, 10502, 10503, 59930, 54057,\n",
       "         10511, 31469, 59922, 10496, 10514, 31491, 31492, 31515, 45070,\n",
       "         54041, 18694, 10451, 59964, 59963, 45073, 59960, 59959, 59958,\n",
       "         59945, 59956, 45078, 59953, 25391, 18691, 59950, 10468, 54043,\n",
       "         54045, 10474, 45089, 10478, 31507, 59921, 25408, 31467, 59901,\n",
       "         31445, 59899, 25413, 18661, 10558, 31438, 18660, 31435, 45122,\n",
       "         10565, 45117, 49294, 54077, 18656, 31429, 45128, 31426, 10575,\n",
       "         10576, 49291, 10578, 10579, 25421, 59892, 59903, 10549, 45113,\n",
       "         10518, 18670, 59920, 54068, 10522, 18668, 59917, 54072, 59915,\n",
       "         10527, 59914, 18665, 59911, 45106, 45107, 59909, 45108, 31456,\n",
       "         10540, 31455, 31453, 10544, 45111, 59904, 10547, 10584, 54037,\n",
       "         54125, 49263, 45275, 45281, 10905, 59725, 45282, 31201, 18536,\n",
       "         10910, 10911, 18535, 10913, 25508, 31194, 45292, 59714, 10921,\n",
       "         10922, 18531, 25512, 59710, 18529, 45299, 10928, 25514, 25511,\n",
       "         54179, 10900, 31211, 54164, 45250, 59734, 31230, 31229, 31228,\n",
       "         10874, 45252, 45253, 31224, 10879, 31210, 45255, 10883, 45258,\n",
       "         18542, 49235, 31217, 54171, 10889, 45266, 10893, 10894, 45271,\n",
       "         10882, 10931, 10932, 45304, 10967, 31151, 59673, 54188, 31148,\n",
       "         59670, 18511, 59668, 10978, 31146, 59665, 45323, 10982, 45331,\n",
       "         10986, 10987, 25526, 45333, 31140, 10991, 45338, 49219, 54191,\n",
       "         45339, 31145, 59676, 10963, 18516, 31178, 31177, 45305, 59698,\n",
       "         10938, 25516, 59691, 10943, 25517, 31172, 10947, 25519, 45310,\n",
       "         18521, 18520, 49226, 18518, 54184, 59678, 31161, 45317, 10958,\n",
       "         45321, 10960, 31157, 10866, 18592, 59736, 59737, 49255, 10763,\n",
       "         59793, 10765, 31302, 10767, 31301, 25477, 59786, 10773, 45212,\n",
       "         59795, 54144, 59783, 31293, 31291, 10782, 31289, 45220, 10785,\n",
       "         45223, 10787, 59780, 10790, 49254, 59779, 59796, 10758, 59810,\n",
       "         10730, 18589, 54128, 59809, 10734, 10736, 10737, 59808, 45197,\n",
       "         10740, 59797, 25469, 54131, 45199, 18584, 10746, 31312, 54133,\n",
       "         54138, 59803, 18578, 25474, 59799, 10742, 59774, 31282, 54152,\n",
       "         45236, 31251, 10836, 31250, 10838, 10839, 18550, 45237, 45239,\n",
       "         10843, 59744, 59749, 54159, 31243, 31242, 10850, 10852, 31240,\n",
       "         59739, 59738, 45243, 45247, 25503, 45248, 10846, 18551, 31254,\n",
       "         59754, 31279, 59771, 10799, 25488, 10801, 31277, 10803, 59767,\n",
       "         31276, 10806, 31274, 59764, 45232, 31272, 54156, 45233, 25492,\n",
       "         59756, 59755, 10821, 10822, 49241, 54158, 31258, 31257, 45249,\n",
       "         31134, 45064, 10441, 10046, 18855, 60256, 31803, 31802, 25272,\n",
       "         44850, 53950, 10055, 60253, 18850, 60258, 60249, 10064, 31792,\n",
       "         25274, 53952, 18847, 60243, 53953, 10071, 10073, 60238, 31784,\n",
       "         60248, 44858, 60260, 10042, 10017, 44825, 10019, 53945, 53946,\n",
       "         60280, 44829, 10024, 60275, 18860, 60274, 10043, 44830, 44834,\n",
       "         25269, 49411, 10034, 31811, 18856, 31807, 10038, 31806, 10040,\n",
       "         10041, 60270, 44859, 10080, 60235, 53967, 10119, 49398, 31752,\n",
       "         31749, 10125, 10127, 60191, 53969, 10130, 10132, 44878, 60189,\n",
       "         53970, 10137, 49391, 10139, 31737, 60183, 31735, 60180, 60178,\n",
       "         44893, 18808, 60188, 60206, 60209, 60210, 10083, 44860, 10085,\n",
       "         18841, 10087, 53956, 44867, 53959, 60228, 25283, 49400, 10097,\n",
       "         18832, 10099, 31765, 53962, 10102, 18830, 10105, 10107, 10108,\n",
       "         53964, 18826, 53966, 31756, 18864, 10150, 10015, 31826, 31907,\n",
       "         25236, 31905, 31904, 53910, 31902, 31898, 31897,  9915, 53913,\n",
       "         53916, 31910,  9918, 49425, 60345, 60344, 60342, 44777, 60340,\n",
       "         31889, 31888, 60338, 18898, 31886, 44775, 49424,  9897, 18911,\n",
       "         31938, 31937, 44737, 60390, 60387, 31935,  9870, 31934, 60386,\n",
       "         44739, 53902, 49431, 60382, 44749, 25227, 25228, 60374, 60373,\n",
       "         25231, 31918,  9891, 60367, 44764, 18912, 18919, 31882, 18894,\n",
       "         49421,  9982, 53933, 31848,  9987,  9988, 31846, 31845, 44811,\n",
       "          9994, 44812, 60305, 18880, 53939, 53941, 10001, 60300, 10003,\n",
       "         10004, 53942, 18867, 60292, 53943, 31828, 60287, 31837,  9980,\n",
       "         25255,  9978, 60332,  9942, 25249, 60329, 18889, 31874, 31872,\n",
       "         31870, 44793,  9953, 18887, 31866, 44795, 53927, 25252, 44797,\n",
       "          9963,  9964, 31859, 53929, 44801, 49418, 31854,  9973,  9975,\n",
       "         44822, 10442, 31726, 53975, 10339, 31589, 60041, 10342, 10343,\n",
       "         60039, 31588, 10346, 60038, 10349, 18733, 60047, 18732, 25357,\n",
       "         10355, 60031, 10357, 45008, 60028, 25358, 31578, 10363, 18727,\n",
       "         10366, 45007, 60024, 54016, 31592, 54009, 44980, 10304, 44982,\n",
       "         44983, 18750, 10308, 10309, 54010, 60065, 44987, 10336, 31604,\n",
       "         10321, 44995, 44996, 60056, 10326, 54013, 10330, 25354, 54015,\n",
       "         60053, 49340, 44993, 31575, 10370, 31574, 31548, 18714, 59996,\n",
       "         31545, 59995, 25374, 59993, 59992, 18712, 54031, 31535, 10408,\n",
       "         45058, 54032, 31532, 18707, 59986, 25378, 59984, 31528, 18700,\n",
       "         45062, 49315, 59971, 59987, 18715, 31551, 18718, 25366, 60020,\n",
       "         10376, 10377, 25367, 60018, 60015, 10383, 60013, 45022, 31565,\n",
       "         10388, 31563, 10390, 10391, 10392, 45026, 10394, 10395, 60006,\n",
       "         45028, 31559, 54024, 45036, 10402, 31616, 10153, 10300, 44976,\n",
       "         10190, 10191, 60139, 60138, 18791, 49374, 31696, 31694, 53987,\n",
       "         10203, 53988, 10189, 10205, 60130, 44920, 44921, 60129, 44922,\n",
       "         10212, 60128, 53990, 60124, 31686, 25313, 49373, 10218, 60140,\n",
       "         60143, 31724, 44901, 25300, 44903, 60168, 31719, 25301, 31716,\n",
       "         60164, 60160, 49383, 10187, 31712, 60154, 49378, 25306, 10177,\n",
       "         31708, 44913, 18796, 31704, 49377, 18794, 31701, 31711, 10220,\n",
       "         44927, 18783, 31646, 18765, 44958, 10268, 18761, 10271, 44959,\n",
       "         60093, 49350, 31634, 44966, 60100, 44968, 10281, 10282, 31630,\n",
       "         60083, 60082, 31629, 31628, 10289, 31626, 49345, 60073, 10280,\n",
       "         49360, 60104, 31653, 25315, 10224, 49369, 31677, 10228, 18778,\n",
       "         10231, 31675, 31674, 60113, 44934, 31671, 10239, 53993, 53994,\n",
       "         10242, 18773, 31660, 31658, 10249, 10250, 31656, 49362, 60107,\n",
       "         10257, 10299, 45340, 59643, 31129, 30612, 49053, 30608, 25729,\n",
       "         45683, 18247, 11722, 30601, 30600, 25730, 59139, 30614, 49045,\n",
       "         59134, 11731, 11733, 11734, 11736, 11737, 11738, 11739, 18239,\n",
       "         59128, 18237, 49042, 30589, 45674, 45672, 30637, 30636, 30635,\n",
       "         59158, 30633, 59154, 25723, 30627, 45664, 11695, 11696, 11711,\n",
       "         18255, 11699, 11700, 30622, 18253, 25724, 11704, 45671, 11706,\n",
       "         11707, 11708, 59147, 18254, 18236, 54396, 59123, 18226, 11781,\n",
       "         59089, 11784, 11785, 59088, 59087, 49038, 18223, 45711, 30559,\n",
       "         11779, 30558, 25744, 25745, 25746, 30552, 45716, 59073, 45717,\n",
       "         11802, 11804, 11805, 11806, 45713, 54406, 11777, 59092, 45695,\n",
       "         11749, 30585, 54399, 45696, 30582, 30581, 54400, 45699, 11758,\n",
       "         30577], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_manner': {'feature_present_idx': array([36878, 64216,  8712, 24347, 24338, 45561, 58080, 45554, 24294,\n",
       "         40805,  8820, 24221,  8838, 24116, 24365, 24090, 40874,  8896,\n",
       "         49819, 64111,  8956, 45464,  8973, 64096, 23938, 23925,  9044,\n",
       "         23898, 40962, 40862, 23853, 24415, 57992, 64473, 25585,  8073,\n",
       "         57761, 64426, 25529, 25524, 64393, 25424, 45839, 25291, 40582,\n",
       "          8328, 24501, 25149,  8405, 25029, 40619, 49721,  8498, 49726,\n",
       "          8508,  8516,  8519, 24882, 64306, 24822, 40677,  8359,  9108,\n",
       "         23787, 49870, 22896, 58486,  9824,  9828, 45132, 22764, 41364,\n",
       "         63729, 58590,  9979, 63688,  9990, 58604, 22904, 63666, 63566,\n",
       "         45059, 63538, 22399, 22394, 63530, 51757, 22304, 22219, 51725,\n",
       "         10311, 63455, 45017, 10057, 22961, 63750, 23063, 23780, 64026,\n",
       "         41011,  9198, 23716, 23700, 41098,  9297,  9327,  9329,  9347,\n",
       "         23476, 23448, 45356, 23394, 58328, 23357, 23348, 23321, 23202,\n",
       "         45259, 45241, 63864, 41256,  9646,  9664, 23112, 23066, 49924,\n",
       "         25719, 58825, 45941, 49657, 28221, 56661, 28195,  6251, 28121,\n",
       "          6261, 65168, 49354, 56718, 46605, 46595, 65130, 46567,  6196,\n",
       "         56778,  6403, 65068, 56844, 27858, 65057, 39990, 56873,  6507,\n",
       "          6517, 46507, 52272, 56879, 56941, 65095, 56952, 56649,  6142,\n",
       "         39507,  5633, 29083,  5671, 29079, 65313, 29069, 29022, 39578,\n",
       "         52352, 56427, 28937, 28843,  6153, 46763, 39657, 28671,  5933,\n",
       "          5943, 28639, 28581, 28495,  6037,  6065, 56634, 28340, 52315,\n",
       "          6115, 56481, 27619, 27575, 27560, 26512, 49616, 26489, 57443,\n",
       "          7400,  7440, 40282, 40290, 57492, 26244, 26234, 26190, 26182,\n",
       "         40201, 57515, 26161,  7613,  7731, 46060, 25932, 40398, 25864,\n",
       "          7787,  7808,  7852,  7859, 57681, 45957,  7567, 26603, 26818,\n",
       "         26868, 27522,  6715, 27503, 64935, 27478, 64926, 27427,  6789,\n",
       "         27415, 57048,  6852, 27370,  6859, 27358, 64846, 27261,  6899,\n",
       "          6909, 57089, 57109, 40117, 52185, 27140, 57144, 27070, 46309,\n",
       "         26913,  7163,  7168, 40468, 58837, 10422, 10454, 44078, 17602,\n",
       "         13650, 17527, 13661, 51000, 13666, 42986, 50991, 13686, 50969,\n",
       "         17432, 13727, 17632, 50921, 17242, 17233, 62264, 17066, 43975,\n",
       "         13948, 61207, 43955, 16903, 14005, 14009, 14015, 50560, 43080,\n",
       "         62182, 50520, 13514, 51075, 62625, 12992, 18780, 13026, 18746,\n",
       "         13059, 18675, 62564, 13119, 62540, 50375, 42720, 13533, 60605,\n",
       "         18352, 44306, 42779, 60733, 42834, 13375, 13395, 13398, 60759,\n",
       "         44215, 13477, 60810, 60862, 60614, 61224, 16841, 50572, 16017,\n",
       "         14772, 14802, 15981, 15959, 61561, 50648, 14869, 15820, 15795,\n",
       "         61968, 15697, 14989, 61452, 43495, 15508, 15028, 15043, 15081,\n",
       "         15093, 43548, 15454, 15128, 61898, 15207, 43558, 43599, 15234,\n",
       "         61931, 14712, 16115, 43387, 43899, 16753, 43165, 16708, 61263,\n",
       "         16671, 14219, 16638, 62137, 61269, 14336, 14348, 14360, 43815,\n",
       "         61353, 61360, 43783, 14496, 61400, 16352, 61418, 14583, 16327,\n",
       "         43336, 50613, 43748, 16267, 14691, 16186, 60442, 60396, 60381,\n",
       "         18990, 21291, 42020, 11192, 11204, 51405, 59433, 11310, 59447,\n",
       "         20887, 59494, 59504, 59511, 20738, 21341, 20705, 20703, 50148,\n",
       "         11521, 59629, 59649, 51363, 11580, 20451, 20450, 42254, 59713,\n",
       "         11640, 20293, 11456, 11147, 59208, 21377, 58839, 51673, 22026,\n",
       "         10500, 21909, 21857, 41739, 50077, 58922, 21768, 63359, 10644,\n",
       "         41752, 44933, 63332, 10695, 10753, 21682, 51555, 10841, 10858,\n",
       "         44896, 21649, 21635, 10996, 21608, 41837, 59164, 59197, 59720,\n",
       "         29197, 20260, 11743, 12449, 19390, 42591, 12543, 60135, 50270,\n",
       "         19272, 50274, 60224, 12601, 19245, 12608, 19237, 12437, 62808,\n",
       "         50276, 62781, 62780, 60311, 60314, 42610, 42615, 19100, 19044,\n",
       "         19043, 19026, 12798, 60366, 12630, 62923, 12403, 62939, 11755,\n",
       "         44696, 63074, 59832, 20146, 11875, 20145, 59861, 20125, 11938,\n",
       "         59916, 20033, 20014, 19970, 63028, 44662, 19801, 59976, 19740,\n",
       "         19684, 60000, 42425, 12199, 12228, 19554, 19551, 60099, 50233,\n",
       "         19404, 20232, 29322, 15302, 33069, 66824, 47296, 38802, 35278,\n",
       "         54029, 55561, 54092,   762, 55565, 32949, 34268,  1772,   741,\n",
       "         35465, 31010,  3002, 32866, 37474,  4020, 34346, 31253,  4103,\n",
       "         66217,  4117, 32780,   889, 65910,  4125, 37718,  1708, 38772,\n",
       "         32809,  1717,  4293, 30931,  1782, 65730,   649, 30658, 30625,\n",
       "         39000, 37285, 35748,  1884, 35820,   597,  1890, 66434, 35852,\n",
       "         35861,  4577, 34081, 37293,  4012, 48960,  2847, 38867, 48367,\n",
       "         38885, 34266, 67101, 33009, 54844,  1823, 54449, 30743, 66396,\n",
       "         53965,  2850, 52582, 30675, 53948, 31265, 55499, 65971,  1433,\n",
       "          3629, 47420, 47404,  1189, 47395, 38620,  1464, 54176, 31555,\n",
       "         55394, 66927, 48230, 53202, 54141,  3622,  3276, 31697, 31740,\n",
       "         47481, 55204, 66118, 31958,  3469, 54254, 34614, 37619,  1234,\n",
       "         54215, 55299, 32248,  3535,  3319,  3540, 55355,  4588, 31529,\n",
       "         34925, 67066, 34432, 48903, 37518, 37708, 47313, 35136, 48300,\n",
       "          3178,  3151, 48161, 67067, 31297,  3119, 34407, 55035,  1527,\n",
       "         37663, 66901, 38685, 38422, 32436, 31462, 34954, 67009, 66058,\n",
       "         34505, 54123, 55426, 31436, 66006,  3917, 67053,  3234,  3920,\n",
       "         30481, 34656,  4601, 33371, 48520, 55973,  2042,  2354,  2536,\n",
       "         36277, 33510,  4999, 38167, 33839, 33294, 65458, 30065, 39226,\n",
       "         33837, 52398, 38172, 33997, 39427,  5349, 37148,  5363, 65494,\n",
       "         55921, 47078, 67156, 36368,  5083, 36635,  2416,  5240, 56105,\n",
       "         33851, 29747, 66592,   138, 38152, 37879, 52473, 36537, 53722,\n",
       "         65396, 47012, 47975, 53395,  5285,  2078, 47045, 65428, 29645,\n",
       "         29634, 37873, 37123,   200, 36387, 47052, 30197, 67153, 33441,\n",
       "          2631, 33155, 34067, 39118,   457,  4826,  5429, 67151, 47088,\n",
       "          2004, 56195, 56220, 38186,  4798,  4796, 56243, 36058, 30331,\n",
       "         46921, 30369, 48638,  5490, 36918,  2265, 39459, 30458, 55832,\n",
       "         37151, 36113, 66489, 53006,  4872, 36822,  4849, 49165, 67274,\n",
       "         47079, 34003, 34002, 29538, 54615, 33551, 34652, 59551, 21088,\n",
       "         19308, 19200, 42045, 60242, 51138, 53172, 52998, 33757, 33721,\n",
       "         34645, 20799, 20669, 60234, 54285, 33816, 19331, 53004, 19231,\n",
       "         37897, 54277, 34585, 20898, 53177, 37644, 20964, 19252, 42064,\n",
       "         37650, 42605, 33847, 20684, 20632, 59517, 20395, 20572, 20216,\n",
       "         42335, 20017, 20016, 34142, 53072, 42331, 19953, 19922, 59781,\n",
       "         53123, 20270, 19853, 34001, 19942, 19788, 19111, 20214, 20182,\n",
       "         42328, 20147, 34098, 20187, 53051, 34016, 51292, 37815, 54472,\n",
       "         34124, 20099, 20205, 37828, 42314, 54588, 19759, 19716, 33953,\n",
       "         34365, 42220, 34367, 42558, 33952, 20175, 20492, 37680, 20548,\n",
       "         19367, 37669, 60120, 59640, 19398, 20305, 19476, 19509, 59979,\n",
       "         20310, 34278, 34296, 34310, 42429, 37712, 42467, 19579, 19575,\n",
       "         42480, 20361, 37866, 60092, 51304, 29323, 18174, 19064, 36037,\n",
       "         16529, 16511, 37155, 16506, 43227, 16476, 16473, 16466, 37199,\n",
       "         36078, 36086, 16389, 61365, 36155, 37141, 16336, 36198, 53746,\n",
       "         36222, 43240, 16272, 16645, 43190, 43142, 16946, 16923, 53899,\n",
       "         16902, 61219, 35756, 35766, 53818, 16647, 16826, 16774, 37255,\n",
       "         16744, 37236, 35908, 53805, 37216, 16666, 16656, 16820, 53739,\n",
       "         53305, 43378, 53654, 61749, 36746, 43508, 36750, 43520, 15477,\n",
       "         36753, 36764, 43504, 36964, 53534, 61818, 36957, 61836, 15408,\n",
       "         15360, 15347, 36804, 53475, 61817, 36614, 43485, 15610, 36328,\n",
       "         16101, 16027, 37102, 50745, 36440, 50736, 53376, 36567, 43478,\n",
       "         15850, 61597, 36571, 36574, 15796, 36578, 37033, 15761, 61612,\n",
       "         61633, 15647, 43140, 19098, 61164, 35542, 34928, 60560, 18627,\n",
       "         34969, 18611, 34989, 18543, 60610, 34992, 60496, 60628, 54099,\n",
       "         18331, 51046, 35107, 18227, 18200, 42830, 42835, 18124, 51052,\n",
       "         18113], dtype=int64),\n",
       "  'feature_absent_idx': array([20091, 20701, 53312, 53316, 53317, 20694, 53320, 53323, 20685,\n",
       "         53326, 53328, 53331, 20664, 20663, 20659, 53341, 53310, 20650,\n",
       "         53309, 20712, 20768, 20767, 53265, 53266, 53279, 20746, 20744,\n",
       "         20743, 20739, 53285, 20731, 53288, 20729, 53290, 20720, 20707,\n",
       "         53261, 20646, 20639, 53401, 20577, 20575, 20559, 53411, 20552,\n",
       "         20551, 53414, 53415, 20540, 20538, 53417, 53418, 20533, 20530,\n",
       "         20584, 20641, 53393, 20597, 53356, 20635, 53358, 53359, 53360,\n",
       "         53365, 20622, 20620, 20608, 20606, 53382, 53383, 20601, 20599,\n",
       "         53389, 53391, 53260, 20773, 20776, 20939, 53137, 20933, 53142,\n",
       "         53143, 20929, 20927, 20926, 53145, 20922, 53147, 53148, 53149,\n",
       "         20916, 20914, 20945, 20911, 20947, 53132, 20990, 20988, 20985,\n",
       "         20984, 20983, 20981, 20979, 20977, 20972, 20965, 53119, 53121,\n",
       "         20959, 53124, 53128, 20948, 20909, 20907, 20891, 53224, 53227,\n",
       "         53229, 20812, 53230, 53231, 20803, 53234, 20795, 53244, 20792,\n",
       "         20787, 20785, 53249, 53258, 20819, 53218, 20829, 20831, 20888,\n",
       "         53175, 20879, 53176, 53178, 20874, 53181, 20525, 20871, 53190,\n",
       "         53198, 20851, 20845, 20840, 20839, 53212, 53182, 53426, 53429,\n",
       "         20520, 53595, 20219, 53597, 53600, 53601, 53602, 53606, 53613,\n",
       "         20197, 20196, 53617, 20191, 53619, 20181, 20179, 20221, 20176,\n",
       "         20222, 53592, 53566, 53568, 20261, 53570, 53571, 20252, 20249,\n",
       "         20248, 20246, 20244, 20242, 53582, 53584, 53590, 53591, 20224,\n",
       "         53626, 53627, 20167, 20108, 53662, 20103, 53664, 20090, 20084,\n",
       "         53679, 20079, 20077, 53684, 53687, 53688, 20066, 53694, 53700,\n",
       "         20109, 53660, 53657, 20116, 53636, 53638, 53639, 20152, 20150,\n",
       "         20149, 53641, 20267, 53643, 20135, 20134, 53652, 20128, 20122,\n",
       "         20121, 20118, 53645, 53106, 20268, 53562, 53462, 53464, 20456,\n",
       "         20454, 20452, 53469, 53480, 20439, 20430, 53484, 20426, 53489,\n",
       "         20423, 20420, 20419, 20465, 20418, 20469, 20472, 20519, 20518,\n",
       "         53438, 20508, 53443, 20501, 20488, 53453, 53455, 20482, 53456,\n",
       "         20478, 53457, 20475, 20474, 20471, 53492, 20412, 20411, 20316,\n",
       "         20315, 20313, 53547, 20302, 20301, 20300, 20299, 53552, 20294,\n",
       "         20290, 53556, 53560, 20281, 53561, 20317, 20321, 20327, 20331,\n",
       "         20409, 20403, 20396, 53502, 53508, 20374, 53511, 53565, 20372,\n",
       "         53515, 53516, 20352, 20350, 53523, 53526, 53529, 53513, 53103,\n",
       "         53100, 21011, 21623, 21610, 21607, 21603, 52695, 52698, 21593,\n",
       "         21584, 21579, 21578, 52714, 52718, 21571, 21564, 52721, 21626,\n",
       "         52725, 52680, 21632, 52661, 52662, 21663, 21660, 52664, 21656,\n",
       "         21654, 52669, 21648, 52671, 21641, 21640, 52676, 21636, 52679,\n",
       "         21631, 21561, 52728, 52733, 21496, 21491, 21490, 52780, 52785,\n",
       "         21479, 21478, 52786, 52790, 52791, 21473, 52795, 52798, 52810,\n",
       "         21459, 52774, 52767, 21503, 52766, 52734, 21543, 52738, 52740,\n",
       "         21528, 21526, 52751, 21668, 21524, 21522, 21518, 21514, 52761,\n",
       "         52764, 21507, 21505, 52753, 21458, 21684, 21691, 52543, 52544,\n",
       "         21848, 21846, 52547, 52548, 52556, 21834, 21832, 21829, 21826,\n",
       "         52562, 21821, 21816, 52580, 52541, 52581, 52539, 21863, 21922,\n",
       "         52493, 52501, 21906, 52503, 52508, 52518, 21897, 21894, 21880,\n",
       "         21879, 21878, 21874, 21866, 52535, 52537, 52585, 21808, 21807,\n",
       "         21741, 52619, 52620, 52623, 21726, 21724, 52627, 21720, 21718,\n",
       "         21710, 52635, 21702, 21700, 21697, 52637, 52616, 21747, 21757,\n",
       "         52604, 21804, 21801, 21798, 52591, 21796, 52595, 52596, 52640,\n",
       "         21787, 21783, 52599, 21781, 21780, 21773, 52603, 21767, 21784,\n",
       "         53703, 52813, 21455, 21175, 21171, 52996, 21165, 21164, 52997,\n",
       "         53008, 53012, 21149, 21148, 53013, 21146, 53019, 21137, 21135,\n",
       "         21178, 21134, 52991, 21188, 52961, 21221, 21220, 52963, 21218,\n",
       "         52965, 21215, 52966, 21209, 52975, 21202, 21200, 52977, 52979,\n",
       "         52982, 52990, 53020, 21129, 21128, 21071, 53055, 21068, 21066,\n",
       "         21064, 21060, 53074, 21036, 21030, 53087, 21026, 21020, 21019,\n",
       "         21016, 53092, 53049, 53047, 21083, 21084, 21125, 21124, 21123,\n",
       "         21122, 53027, 53028, 21116, 21227, 53030, 53036, 53039, 21100,\n",
       "         53040, 53042, 21086, 21085, 53033, 21456, 21228, 21234, 21392,\n",
       "         21389, 52859, 21381, 52864, 21372, 21370, 52868, 21367, 21365,\n",
       "         52869, 52871, 21353, 21349, 52884, 52855, 52885, 21400, 21405,\n",
       "         52814, 21451, 21448, 52821, 21441, 52831, 21430, 21424, 21421,\n",
       "         52840, 21418, 21415, 52842, 21411, 21410, 21403, 21345, 21343,\n",
       "         21342, 21275, 21271, 21269, 21266, 21264, 52938, 52939, 21251,\n",
       "         52942, 52946, 21244, 52947, 21242, 52958, 21235, 52933, 52919,\n",
       "         52914, 21305, 21340, 52888, 52892, 52893, 21333, 52895, 21330,\n",
       "         21231, 52898, 21323, 21322, 21321, 21319, 52905, 52906, 52909,\n",
       "         21324, 52492, 53705, 53708, 54519, 54520, 54525, 18867, 18864,\n",
       "         18860, 18856, 18855, 18850, 18847, 18841, 54542, 54546, 54547,\n",
       "         18832, 54518, 18830, 18880, 18887, 54483, 18919, 54485, 18912,\n",
       "         18911, 54490, 54491, 54493, 54495, 18898, 54497, 18894, 54499,\n",
       "         54503, 18889, 54509, 54480, 54550, 54558, 54614, 54616, 18733,\n",
       "         18732, 18727, 54623, 54625, 18718, 54629, 18715, 18714, 18712,\n",
       "         54632, 18707, 18700, 18750, 18826, 18761, 18765, 54559, 54560,\n",
       "         54562, 18808, 54564, 54566, 18796, 18794, 54568, 18791, 54571,\n",
       "         54573, 18783, 18778, 18773, 54587, 54477, 18938, 54476, 19088,\n",
       "         19087, 19086, 19085, 19084, 19083, 19080, 19079, 54379, 19074,\n",
       "         19052, 19051, 54396, 54399, 19045, 54372, 54400, 54369, 19103,\n",
       "         54318, 54319, 19159, 54337, 19149, 19135, 19132, 19127, 19124,\n",
       "         19123, 54350, 19119, 54351, 54354, 54361, 54365, 19040, 54402,\n",
       "         19038, 54445, 18973, 54452, 54457, 54465, 18960, 54470, 18954,\n",
       "         18953, 18952, 18951, 18948, 18947, 18946, 18942, 18977, 18979,\n",
       "         18980, 54438, 54404, 19036, 19031, 54406, 19021, 54412, 54413,\n",
       "         54639, 54418, 54430, 19001, 18998, 54433, 18993, 18992, 18989,\n",
       "         54419, 54641, 18694, 54646, 18392, 18391, 18389, 54849, 18383,\n",
       "         18376, 18371, 18370, 18369, 18361, 54868, 18355, 54870, 54871,\n",
       "         18344, 54842, 18343, 54840, 18400, 18451, 54809, 54811, 54814,\n",
       "         54816, 54820, 54822, 18426, 18423, 18422, 18420, 18412, 54831,\n",
       "         54837, 18402, 54838, 54878, 18337, 18336, 54943, 18255, 18254,\n",
       "         18253, 54952, 18247, 54962, 18239, 18237, 18236, 54966, 18232,\n",
       "         18226, 18223, 54975, 18267, 54940, 54935, 18283, 18334, 54880,\n",
       "         18332, 18330, 54882, 18324, 54890, 18469, 18315, 18304, 54907,\n",
       "         54909, 54912, 18294, 54915, 54922, 54892, 19173, 54795, 54781,\n",
       "         18640, 54688, 54694, 18630, 18624, 18623, 18622, 18619, 18617,\n",
       "         18616, 54700, 18610, 54702, 54705, 54712, 54678, 18596, 54675,\n",
       "         18650, 18691, 54650, 54651, 54653, 54655, 18678, 18670, 18668,\n",
       "         54665, 18665, 54666, 18661, 18660, 18656, 54670, 18648, 54715,\n",
       "         18592, 54718, 18531, 54755, 18529, 18521, 18520, 18518, 18516,\n",
       "         18511, 54767, 18501, 18494, 54775, 54776, 18487, 54780, 18535,\n",
       "         18536, 54753, 54752, 18589, 54719, 54723, 18584, 18578, 54730,\n",
       "         54734, 54789, 54735, 54738, 54741, 18551, 18550, 54746, 54748,\n",
       "         18542, 54736, 54306, 19181, 19184, 53939, 53941, 53942, 19750,\n",
       "         19748, 19745, 53943, 53945, 53946, 19739, 53950, 53952, 53953,\n",
       "         19726, 19725, 19758, 53956, 19763, 53933, 19825, 53892, 53893,\n",
       "         53896, 53900, 53902, 53910, 19802, 53913, 53916, 19791, 53927,\n",
       "         19779, 53929, 19770, 19765, 53959, 19719, 19717, 53993, 53994,\n",
       "         19663, 19661, 19660, 19654, 19651, 19646, 54009, 54010, 19640,\n",
       "         19639, 54013, 19636, 54015, 53990, 53988, 53987, 19677, 19714,\n",
       "         53962, 53964, 19709, 53966, 53967, 19706, 53891, 19701, 53970,\n",
       "         19697, 19696, 19695, 19691, 53975, 19687, 53969, 54016, 53890,\n",
       "         53885], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_medium': {'feature_present_idx': array([50340, 65807, 66354, 21024, 16925, 36408, 23463, 18349, 34965,\n",
       "         23487, 28616, 12674, 27125, 40128, 27669, 48808, 18188, 45350,\n",
       "         50226, 17380, 12055, 36228, 46260, 46303, 12954, 62389, 17207,\n",
       "         18450, 33863, 19482, 27769, 39511, 26833, 26515, 37662, 41476,\n",
       "         25253, 45156, 22619, 42570, 42868, 44142, 44164, 11908, 44951,\n",
       "         19498, 22600, 20208, 15240,  6275,  8608,  8325,  8213,  8053,\n",
       "         53347, 53594, 53021, 54078,  6449, 50869, 66587,  6216, 56281,\n",
       "          5295,  3343, 57238, 56184,  1206, 10173, 52994, 32733, 10520,\n",
       "         65071, 58219, 57653, 57477,  4597, 23046,  3361, 39964,  1039,\n",
       "          1736, 42477, 40642,  1920, 27068, 25113, 56969,  2864, 41223,\n",
       "         63328, 61015, 26975, 60463, 57002, 33661, 42279, 26014, 11216,\n",
       "         46771, 35962, 52100, 12119, 12486, 49972, 59650, 49351, 52197,\n",
       "         13530, 14570, 49086, 14872, 66738, 31318, 37288, 62303, 16399,\n",
       "         66390, 35920,  5958, 19627, 54598, 16076, 18725, 33050, 17434,\n",
       "         17051, 59329, 37001, 45661, 18683, 38031, 37075, 28252, 38994,\n",
       "         57416, 56908, 55300, 58977, 52033, 51388, 49212, 38483, 47226,\n",
       "         59961, 34697, 44013, 43479, 42762, 40801, 39451, 47127, 45510,\n",
       "         58456, 33828, 25046, 23849, 21211, 19711, 17919, 34494, 16045,\n",
       "         15616, 15375, 15339, 12521, 64799, 10728,  8746,  8223,  7891,\n",
       "          6865, 66279,  5370,  2420,  2018, 25545, 62574, 16643, 28845,\n",
       "         30355, 29626, 29122, 30890, 31286, 13684, 47141, 14761, 27397,\n",
       "         12628, 12626, 49893, 61970, 10694, 10648, 52329, 29796, 31732,\n",
       "         31946, 35960, 54325, 33326, 35407, 55493, 56027,  2551, 57862,\n",
       "         64863, 63508, 31472, 29794, 40145, 40453, 40491, 26592, 26225,\n",
       "         25373, 41490, 38990, 38821, 37641, 21369, 60157, 22533, 16492,\n",
       "         38256, 45548, 11049,  1054,  1076, 35298, 26843,  2980,  2983,\n",
       "          4230,  5187, 47062, 55253, 60644, 43383, 14805, 19465, 10929,\n",
       "         36877, 43120, 29340,  6708, 21046, 21236,  8954, 21013, 21010,\n",
       "         59234, 65525, 52849, 62460, 61781, 64414, 66981, 54014,  3620,\n",
       "          5275,  6656,  7658,  9224, 15424, 25728, 58314, 27255, 29586,\n",
       "         27137, 37667, 30410, 46429, 49773, 53189, 28960, 53444, 15497,\n",
       "         12016,  6935,  5518, 40418, 37289, 10495, 43054, 33339,   106],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([20533, 17163, 17162, 59749, 39306, 17161, 54144, 36549, 26987,\n",
       "         17159, 59744, 46588, 59754, 46589, 26982, 49978, 59739,  9942,\n",
       "         46591, 59738, 17156, 59737, 59736, 59734, 36548, 26983, 49976,\n",
       "         59755, 59756, 27013, 59774, 22612, 17177,  9897, 59771, 54131,\n",
       "         46572, 59767, 46573, 17173, 46582, 46575, 54133, 22616, 27000,\n",
       "         17169, 54138, 22617,  9915, 33892, 34554,  9918, 17165, 59764,\n",
       "         17179, 17154,  9953, 54156, 46617,  9987,  9988, 54158, 17139,\n",
       "         54159, 26948,  9994, 33904, 34552, 33903, 59698, 10001, 46632,\n",
       "         10003, 10004, 35371, 36538, 54164, 26940, 17132, 22634, 40884,\n",
       "         59691, 26974, 35369, 59710, 39311, 22624, 17152, 34553, 59725,\n",
       "         46602, 46603,  9963,  9964, 41376, 26965,  9982, 17148, 41375,\n",
       "         17146, 54152, 46609,  9973, 36544,  9975, 59714,  9978, 33902,\n",
       "          9980, 49973, 26936,  9891, 54128,  9795, 59852, 49999, 22590,\n",
       "         27066, 33878, 22591, 46530, 17209,  9804, 59846, 59853, 27061,\n",
       "          9808, 17208,  9811,  9812, 59843, 54109, 33880,  9816, 17204,\n",
       "         46536,  9820, 59845, 46538, 50000, 22586,  9766, 54098, 46518,\n",
       "         59870,  9770,  9771, 59868, 35358, 27076, 59866, 27075,  9792,\n",
       "          9777, 59864,  9780, 39298,  9782,  9784, 17216,  9786,  9787,\n",
       "         17215, 39299, 36565,  9778, 36556, 59840, 54111, 59808, 49985,\n",
       "         46558, 54125, 17184, 59803, 33887, 46563,  9870, 46564, 59799,\n",
       "         59809, 59797, 59795, 27022, 59793, 33888, 33889, 59786, 27018,\n",
       "         59783, 39303, 59780, 59779, 59796,  9823, 59810, 22604, 17201,\n",
       "          9826, 46542, 49994, 34556, 59837, 27046, 46546, 54113,  9835,\n",
       "         33883,  9856, 59828, 36561, 59825,  9845,  9846, 27037,  9848,\n",
       "         59821, 59820, 59817, 33885, 49988, 59827, 27080, 59678, 49960,\n",
       "         49923, 22681, 59529, 36505, 46712, 22682, 22683, 10187, 22684,\n",
       "         10189, 10190, 10177, 10191, 26831, 26829, 59519, 36502, 26826,\n",
       "         26825, 26824, 10203, 17056, 10205, 59515, 54223, 26822, 59537,\n",
       "         17070, 26863, 17080, 59565, 22671, 26860, 10150, 59564, 10153,\n",
       "         26858, 36510, 17077, 46703, 22673, 54213, 26854, 35380, 59555,\n",
       "         49931, 17072, 26850, 26848, 59547, 59544, 26847, 59560, 54209,\n",
       "         17055, 17053, 22699, 10249, 10250, 46729, 46730, 26794, 59479],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 288\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 288\n",
       "  })},\n",
       " 'contains_mod': {'feature_present_idx': array([30320, 13969, 56810, 45496, 45495, 56812, 28545, 28549, 13954,\n",
       "         45490, 28553, 28556, 13946, 56821, 13942, 13940, 28560, 56826,\n",
       "         28585, 56839, 28582, 28574, 28573, 13911, 13971, 13917, 56832,\n",
       "         13925, 13926, 13927, 28564, 45466, 28572, 56807, 13977, 56806,\n",
       "         45525, 14032, 28499, 14045, 56763, 28497, 14025, 14049, 14052,\n",
       "         45528, 56756, 56755, 56754, 14065, 56758, 13903, 14023, 14019,\n",
       "         13984, 56804, 13987, 56800, 45508, 56793, 45518, 45513, 14004,\n",
       "         56785, 14008, 45516, 14011, 28510, 14001, 14066, 13899, 13889,\n",
       "         56920, 13784, 56926, 45368, 56946, 45365, 56949, 13757, 13752,\n",
       "         13751, 28691, 28693, 28695, 28696, 28709, 28710, 13739, 57013,\n",
       "         57010, 45326, 57009, 45332, 28722, 28665, 13723, 56995, 45345,\n",
       "         13734, 45346, 28711, 13738, 28721, 13803, 56916, 13807, 45389,\n",
       "         28636, 56871, 28629, 45395, 13860, 13846, 56864, 56858, 45404,\n",
       "         45417, 28610, 13886, 45436, 28620, 56849, 45385, 56883, 56910,\n",
       "         45372, 13817, 56904, 56903, 56902, 28646, 28659, 13824, 28656,\n",
       "         56892, 45377, 45378, 13839, 13822, 56751, 56749, 56740, 28314,\n",
       "         14373, 56543, 45688, 14358, 56546, 56547, 45686, 14347, 45681,\n",
       "         28335, 45677, 14337, 45676, 14329, 45663, 45657, 14281, 56582,\n",
       "         56581, 28367, 14298, 14301, 14379, 56578, 45649, 28359, 28358,\n",
       "         14316, 45651, 56568, 28364, 14381, 28311, 56541, 28268, 14442,\n",
       "         14446, 45734, 14452, 28255, 56500, 14465, 56449, 28243, 14479,\n",
       "         56444, 56433, 14489, 14468, 56583, 14432, 56504, 14392, 14394,\n",
       "         28309, 56538, 56536, 28305, 56503, 56532, 45709, 45714, 28289,\n",
       "         14416, 28283, 28281, 14405, 28379, 14271, 14270, 14107, 28442,\n",
       "         45579, 56690, 14123, 56689, 28455, 28438, 14138, 56684, 14144,\n",
       "         14148, 56683, 56677, 28437, 45586, 45572, 28458, 14075, 28481,\n",
       "         45536, 56739, 56738, 28474, 56716, 28470, 45564, 14095, 56729,\n",
       "         14097, 14100, 28460, 14090, 13697, 14161, 28430, 28396, 14236,\n",
       "         28394, 14238, 45636, 28392, 56611, 56597, 45641, 28385, 14258,\n",
       "         28384, 28380, 14269, 14252, 56669, 56625, 45632, 14180, 56655,\n",
       "         28424, 28422, 14194, 14198, 14228, 56646, 45604, 14211, 14212,\n",
       "         28414, 56629, 45610, 14203, 28733, 57023, 13687, 57529, 13170,\n",
       "         13165, 57531, 29099, 29106, 45012, 57540, 29116, 29120, 13141,\n",
       "         45010, 29124, 44998, 57560, 13130, 44986, 29168, 57583, 44960,\n",
       "         29162, 29159, 13110, 13180, 57577, 13118, 44965, 29155, 29143,\n",
       "         13127, 44975, 57576, 45042, 29080, 13186, 13238, 57452, 45079,\n",
       "         29049, 13250, 45090, 29052, 45098, 45102, 57424, 13266, 57419,\n",
       "         57418, 57410, 13258, 57585, 13236, 29056, 57509, 45052, 13195,\n",
       "         45053, 13199, 13206, 29055, 29066, 13213, 57481, 57465, 13223,\n",
       "         29063, 29059, 57482, 29173, 13089, 44956, 29274, 44894, 29272,\n",
       "         57721, 29263, 12965, 29276, 29260, 44905, 12990, 44907, 12994,\n",
       "         57703, 57698, 12972, 57696, 57738, 44887, 57763, 12899, 29301,\n",
       "         12903, 12906, 12911, 12940, 57760, 29293, 44881, 57748, 12924,\n",
       "         29288, 12931, 29295, 45105, 13001, 57687, 29202, 57630, 57627,\n",
       "         57620, 13068, 13069, 44943, 57612, 44947, 57603, 29180, 13083,\n",
       "         44953, 13087, 29190, 29238, 57644, 13043, 29233, 57678, 57677,\n",
       "         57660, 29232, 44910, 29209, 44911, 29225, 29220, 13032, 57649,\n",
       "         29217, 13039, 13022, 56431, 45115, 29014, 57147, 28828, 28829,\n",
       "         13563, 28832, 13553, 13552, 57159, 45235, 57161, 57164, 57165,\n",
       "         28842, 45231, 57172, 28854, 13525, 57202, 45195, 13482, 45198,\n",
       "         45205, 13499, 45256, 13501, 57182, 28866, 28857, 13518, 57174,\n",
       "         13523, 28871, 57136, 13586, 13588, 13644, 13649, 28764, 13660,\n",
       "         28753, 57049, 28780, 45293, 45295, 28745, 13677, 57036, 13682,\n",
       "         28737, 13668, 13475, 28782, 13635, 13592, 13598, 28809, 13600,\n",
       "         57119, 13605, 57087, 57110, 45272, 57105, 57102, 28796, 28794,\n",
       "         13633, 13609, 28885, 57207, 13465, 28985, 45137, 13340, 13342,\n",
       "         13348, 57342, 13332, 28978, 57335, 57333, 13361, 57330, 45141,\n",
       "         28970, 57337, 45145, 45134, 57347, 57398, 57393, 29010, 29009,\n",
       "         13291, 13296, 45133, 13300, 13309, 45126, 13319, 57357, 28995,\n",
       "         13324, 45125, 13279, 28963, 45153, 57250, 57248, 28911, 13438,\n",
       "         57244, 28908, 13430, 57240, 13453, 28904, 57229, 28889, 45189,\n",
       "         28886, 57235, 45149, 13428, 28921, 45158, 45166, 57312, 57304,\n",
       "         45169, 57294, 28912, 57288, 28945, 28943, 57278, 28938, 13409,\n",
       "         13412, 45174, 28236, 28235, 14507, 15650, 15648, 46337, 27496,\n",
       "         15644, 15643, 55541, 15639, 27497, 55544, 46330, 15627, 27507,\n",
       "         15622, 15618, 27509, 27510, 46308, 46311, 55566, 15589, 15591,\n",
       "         15593, 27492, 15595, 15599, 46321, 46323, 15609, 15612, 55559,\n",
       "         15597, 15653, 55535, 15655, 27446, 46401, 55458, 55456, 27438,\n",
       "         55446, 55469, 15740, 46409, 27425, 27422, 55418, 15757, 27419,\n",
       "         46408, 55574, 46388, 15707, 46338, 15665, 27490, 27487, 55516,\n",
       "         55509, 27461, 55504, 55492, 46358, 27472, 55485, 46380, 15702,\n",
       "         55502, 46301, 46298, 15555, 46251, 55683, 27617, 27610, 46253,\n",
       "         46255, 46249, 27603, 27600, 15464, 55671, 55668, 55665, 15475,\n",
       "         27601, 27587, 55688, 55691, 46211, 15396, 27661, 15400, 55716,\n",
       "         55710, 15438, 55703, 15418, 46245, 15421, 55700, 15425, 46248,\n",
       "         27646, 55410, 55661, 15482, 27553, 46285, 27550, 27547, 27545,\n",
       "         55614, 15525, 46293, 15545, 55598, 27542, 46297, 55584, 27539,\n",
       "         55602, 15481, 27554, 15518, 15487, 46273, 55658, 27569, 46276,\n",
       "         55637, 27556, 46278, 55633, 15505, 55632, 55631, 55626, 15513,\n",
       "         15501, 15393, 27418, 15764, 55187, 46569, 55207, 27222, 46560,\n",
       "         16020, 16019, 27224, 46556, 55210, 27226, 46555, 55217, 16006,\n",
       "         46540, 55226, 27243, 15941, 15944, 46521, 55265, 55259, 15962,\n",
       "         46574, 46522, 46531, 15980, 15983, 55242, 27246, 55231, 55254,\n",
       "         46576, 16039, 27207, 16085, 16086, 16087, 16090, 27175, 55137,\n",
       "         27179, 55133, 46608, 46610, 55127, 16116, 55126, 16121, 55131,\n",
       "         15940, 16080, 27182, 27206, 27205, 16048, 27195, 55161, 16058,\n",
       "         55141, 55157, 55152, 55149, 46593, 55145, 16074, 27184, 27192,\n",
       "         27278, 27282, 46516, 15814, 15817, 15819, 46422, 46424, 15828,\n",
       "         55388, 27369, 55359, 55357, 55356, 55352, 27354, 55346, 15832,\n",
       "         46448, 46415, 27390, 27412, 15769, 15771, 15772, 15778, 15781,\n",
       "         27387, 15782, 15785, 15788, 55402, 46411, 27404, 46413, 55406,\n",
       "         27416, 15856, 27336, 15900, 46478, 55302, 15910, 55298, 27300,\n",
       "         46476, 15915, 46498, 46501, 27292, 46508, 46515, 55281, 27297,\n",
       "         55339, 55314, 55316, 27335, 46451, 46452, 15869, 15870, 27328,\n",
       "         15895, 27326, 15877, 15883, 46455, 46460, 27320, 15892, 55320,\n",
       "         12896, 15386, 55727, 28019, 56180, 28021, 56193, 14823, 28033,\n",
       "         14821, 56200, 56201, 28035, 14809, 28040, 45873, 56223, 56226,\n",
       "         28055, 45857, 45834, 14745, 14746, 28107, 45841, 45842, 45882,\n",
       "         28075, 56259, 45855, 56254, 14773, 28062, 14778, 56265, 28014,\n",
       "         14849, 56171, 56094, 45970, 56077, 56075, 56073, 56071, 45965,\n",
       "         45987, 14944, 14948, 27943, 56057, 56056, 56052, 27948, 14737,\n",
       "         27960, 56100, 14856, 14870, 27991, 45918, 56139, 14882, 56097,\n",
       "         27986, 27978, 45956, 56110, 45962, 14907, 56104, 45949, 45833,\n",
       "         56282, 45832, 28192, 56363, 28189, 56359, 45776, 14592, 28197,\n",
       "         45777, 14604, 14609, 28169, 56342, 14622, 14623, 45780, 14624,\n",
       "         56375, 56382, 14508, 45749, 56421, 45760, 56417, 56414, 28200,\n",
       "         14537, 28203, 56390, 56384, 28201, 14558, 14559, 45766, 56050,\n",
       "         28165, 14630, 14696, 14697, 14701, 56311, 14703, 56310, 45816,\n",
       "         45827, 14721, 14722, 14726, 56284, 14729, 56283, 14714, 45791,\n",
       "         14687, 14680, 28160, 45795, 14647, 28156, 56325, 28152, 56314,\n",
       "         56319, 14663, 28147, 14670, 14673, 56317, 45814, 45805, 55726,\n",
       "         56047], dtype=int64),\n",
       "  'feature_absent_idx': array([35509, 50885, 30543, 50883, 18176, 50882, 50877, 18180, 50872,\n",
       "         18185, 30542, 50862, 50861, 18195, 39969, 50853, 39972, 39973,\n",
       "         50849, 18202, 18204, 50848, 30535, 30534, 50887, 18213, 50892,\n",
       "         18156, 18112, 39942, 18115, 39952, 18119, 30552, 18126, 18127,\n",
       "         50911, 39954, 50907, 50906, 50905, 18137, 50904, 18143, 50900,\n",
       "         50898, 30546, 18149, 18151, 18152, 50896, 18160, 18218, 50843,\n",
       "         39974, 50799, 50797, 50796, 18294, 50795, 18304, 50792, 50790,\n",
       "         50788, 18315, 39995, 50781, 18324, 18330, 50773, 18332, 18334,\n",
       "         50771, 18336, 18337, 50769, 18343, 18344, 39984, 18283, 50806,\n",
       "         50807, 18223, 18226, 39975, 18232, 50835, 18236, 18237, 39977,\n",
       "         18239, 50829, 50828, 50923, 50824, 18247, 18253, 18254, 18255,\n",
       "         50821, 50819, 50816, 50815, 18267, 30524, 39979, 30527, 50768,\n",
       "         18110, 18108, 51098, 17932, 51091, 17934, 39890, 17936, 17940,\n",
       "         51086, 17947, 17948, 51079, 51068, 17958, 51066, 30589, 17971,\n",
       "         51059, 51055, 17977, 17978, 17984, 39902, 30585, 51101, 39907,\n",
       "         30600, 17924, 30622, 39879, 51159, 30614, 51151, 51148, 30612,\n",
       "         39882, 17888, 30608, 51136, 51135, 17899, 17905, 51127, 39886,\n",
       "         17911, 17912, 39888, 30601, 51112, 17921, 51108, 17928, 30582,\n",
       "         17996, 30581, 50966, 18067, 18073, 50962, 18077, 50961, 39938,\n",
       "         50953, 18084, 50949, 18086, 18088, 30559, 18090, 50943, 30558,\n",
       "         18096, 39940, 50938, 50934, 50930, 18105, 18107, 18061, 50972,\n",
       "         18056, 18054, 51033, 30577, 51021, 18006, 51018, 18010, 18011,\n",
       "         18012, 18013, 51017, 51004, 18109, 30576, 18023, 50999, 18031,\n",
       "         39919, 50988, 18037, 50986, 18042, 50980, 50978, 50976, 51001,\n",
       "         51167, 30513, 30511, 18660, 18661, 18665, 18668, 18670, 50515,\n",
       "         50512, 18678, 50507, 50506, 50498, 50496, 18691, 18694, 30414,\n",
       "         18700, 50493, 40093, 40095, 30404, 18707, 30403, 50479, 40088,\n",
       "         40109, 50523, 18656, 50558, 50555, 18616, 18617, 50554, 18619,\n",
       "         18622, 18623, 18624, 50553, 50552, 18630, 40083, 50541, 30429,\n",
       "         50535, 18640, 30428, 40086, 18648, 18650, 50527, 50526, 30420,\n",
       "         18712, 50476, 18714, 50432, 50430, 18783, 30387, 50427, 18791,\n",
       "         50424, 30385, 18794, 50422, 18796, 40129, 30383, 50406, 50405,\n",
       "         50403, 18808, 50400, 40139, 50393, 18826, 50392, 18830, 18778,\n",
       "         50434, 30389, 18773, 18715, 18718, 50475, 18727, 30398, 18732,\n",
       "         18733, 40119, 50465, 50463, 50462, 18610, 50460, 50458, 50457,\n",
       "         18750, 40127, 50452, 50450, 18761, 50448, 18765, 50446, 50442,\n",
       "         50459, 50764, 50561, 50566, 50722, 50719, 30489, 18420, 50711,\n",
       "         18422, 18423, 18426, 50709, 50706, 30488, 50704, 40011, 30483,\n",
       "         18451, 50696, 50689, 50688, 50677, 40023, 50672, 18469, 40028,\n",
       "         50723, 40033, 18412, 18402, 30510, 39998, 30508, 30506, 18355,\n",
       "         50750, 18361, 18369, 18370, 18371, 40001, 18376, 50747, 40002,\n",
       "         50742, 18383, 30499, 50738, 18389, 18391, 18392, 50737, 18400,\n",
       "         50728, 50652, 50650, 50649, 18550, 18551, 30446, 50596, 50594,\n",
       "         50593, 50592, 50591, 50588, 50585, 50581, 18578, 30442, 50578,\n",
       "         18584, 40077, 50575, 18589, 18592, 30438, 50571, 18596, 30436,\n",
       "         50600, 50601, 50603, 18542, 18487, 40044, 40047, 18494, 50644,\n",
       "         50642, 50640, 18501, 50635, 50629, 18511, 50564, 30460, 18518,\n",
       "         18520, 18521, 30459, 50616, 40058, 18529, 18531, 18535, 18536,\n",
       "         50606, 18516, 18832, 51177, 51183, 51791, 17293, 51788, 17296,\n",
       "         51785, 51784, 30816, 39711, 51770, 30810, 17318, 17319, 51767,\n",
       "         17321, 17322, 30804, 17324, 30803, 17330, 30801, 51753, 30797,\n",
       "         17338, 51793, 30796, 17288, 17286, 17241, 30837, 17244, 17247,\n",
       "         17248, 30834, 30826, 17252, 39703, 17254, 51820, 51819, 30823,\n",
       "         51810, 51809, 17265, 17266, 39706, 17278, 51807, 51806, 39708,\n",
       "         51799, 17287, 17343, 17344, 51747, 17402, 30778, 51685, 17408,\n",
       "         39757, 30776, 17415, 17417, 17420, 17421, 17423, 17424, 51675,\n",
       "         39768, 17428, 17429, 51671, 51669, 17435, 51665, 17437, 17438,\n",
       "         17439, 17401, 17399, 30780, 17396, 51743, 51742, 30795, 17353,\n",
       "         17355, 51731, 39735, 51727, 30792, 51721, 39736, 17240, 17367,\n",
       "         17369, 51718, 51712, 51709, 39748, 51705, 30786, 17384, 17389,\n",
       "         30784, 17392, 39739, 51661, 17235, 51853, 39666, 17072, 51987,\n",
       "         17077, 51978, 17080, 51977, 30865, 51972, 51968, 17090, 30861,\n",
       "         51958, 51957, 39674, 51954, 39685, 51945, 17105, 39690, 51943,\n",
       "         51941, 17111, 17070, 51937, 51992, 30872, 52050, 17006, 52048,\n",
       "         52047, 52046, 17019, 52043, 17027, 52037, 30881, 17037, 52023,\n",
       "         52016, 39663, 30875, 17050, 52011, 30874, 17053, 39665, 17055,\n",
       "         17056, 51998, 30871, 17113, 51935, 17116, 17179, 51895, 17184,\n",
       "         51886, 30844, 30843, 51878, 51877, 39696, 51868, 17201, 17204,\n",
       "         17208, 17209, 51867, 39700, 17215, 17216, 51859, 51856, 17227,\n",
       "         17228, 30840, 17177, 17173, 17169, 51900, 17118, 51933, 51928,\n",
       "         51924, 51922, 17125, 39692, 17132, 17139, 30851, 17146, 51848,\n",
       "         17148, 51914, 17152, 17154, 30849, 17156, 51909, 17159, 17161,\n",
       "         17162, 17163, 17165, 51915, 51180, 51660, 30768, 30668, 17708,\n",
       "         17710, 51358, 51356, 30664, 51352, 17721, 51351, 51348, 51344,\n",
       "         30663, 17731, 30661, 17735, 17737, 51337, 17740, 17742, 17743,\n",
       "         51333, 30660, 39843, 35513, 51317, 51370, 17698, 51428, 51427,\n",
       "         17659, 51425, 39835, 51419, 51415, 17667, 51411, 17671, 30670,\n",
       "         17679, 17680, 51403, 17683, 51402, 51392, 51391, 51389, 51384,\n",
       "         51382, 51377, 51376, 51375, 17758, 17759, 51303, 39856, 51264,\n",
       "         51262, 51260, 30643, 30642, 51248, 17828, 39865, 30637, 51234,\n",
       "         17838, 30636, 30635, 30633, 51199, 39875, 51195, 17856, 51190,\n",
       "         30627, 39877, 17862, 51267, 51268, 51269, 17800, 39849, 51300,\n",
       "         17769, 17772, 51299, 17774, 17775, 51295, 17779, 51286, 51280,\n",
       "         30678, 17782, 17784, 17785, 39850, 17788, 17790, 17792, 30651,\n",
       "         51275, 51274, 39851, 17799, 17783, 39771, 30679, 17648, 39787,\n",
       "         51585, 17512, 17513, 30742, 30737, 51578, 51572, 17519, 30735,\n",
       "         17521, 17522, 17523, 30734, 17525, 17526, 30732, 51558, 17530,\n",
       "         17532, 17533, 51557, 17540, 51593, 39791, 17502, 39783, 17449,\n",
       "         51646, 51638, 39775, 30762, 17458, 17462, 51632, 30760, 17465,\n",
       "         17466, 30759, 17469, 51620, 17471, 17475, 30756, 17478, 30755,\n",
       "         17491, 17492, 39781, 39782, 17497, 39799, 17545, 51552, 17608,\n",
       "         51489, 17614, 17615, 17616, 51485, 51484, 51482, 39816, 51474,\n",
       "         51473, 17627, 51469, 39817, 51463, 51459, 39818, 51453, 51452,\n",
       "         39823, 51446, 51440, 51439, 17606, 39813, 17603, 30698, 17549,\n",
       "         30719, 51540, 30716, 17558, 30706, 17563, 17564, 51526, 17570,\n",
       "         51523, 51436, 30705, 51513, 17581, 17583, 17584, 17587, 51508,\n",
       "         51506, 17592, 30700, 17596, 17600, 30701, 17001, 50391, 50389,\n",
       "         49235, 40475, 20066, 30007, 20077, 20079, 20084, 30005, 30004,\n",
       "         49226, 40481, 20090, 20091, 49219, 49216, 49215, 20103, 40484,\n",
       "         29997, 20108, 20109, 49202, 49196, 49241, 20116, 20052, 20038,\n",
       "         19994, 19996, 19999, 49294, 49291, 49290, 49284, 20011, 49281,\n",
       "         30024, 49272, 49271, 20019, 49269, 20022, 30023, 20026, 49263,\n",
       "         20028, 20029, 30020, 49255, 49254, 40470, 20118, 29988, 20121,\n",
       "         49131, 49130, 49125, 20191, 49124, 29971, 20196, 20197, 49111,\n",
       "         40519, 49108, 29969, 49102, 49094, 49091, 49089, 49088, 49087,\n",
       "         20219, 49084, 20221, 20222, 49082, 49133, 20181, 20179, 49140,\n",
       "         20122, 49186, 49185, 20128, 20134, 20135, 49182, 49181, 29987,\n",
       "         29986, 49174, 19989, 49173, 20150, 20152, 49168, 40498, 49164,\n",
       "         49160, 20167, 49153, 29979, 49143, 20176, 20149, 20224, 40463,\n",
       "         19983, 49466, 49463, 40402, 19802, 40404, 49456, 30087, 49450,\n",
       "         49446, 19825, 49445, 49444, 49439, 19831, 19832, 19833, 49437,\n",
       "         30086], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_mode': {'feature_present_idx': array([    0, 16218, 46190, 46178, 46167, 45950, 16323, 16375, 45947,\n",
       "         16535, 45931, 16577, 45893, 16831, 45571, 45361, 45303, 45093,\n",
       "         45091, 17121, 45000, 44988, 16202, 44935, 16169, 46471, 47906,\n",
       "         47893, 47855, 47818, 47787, 47727, 47700, 47439, 15526, 47318,\n",
       "         47212, 15752, 47105, 15793, 47021, 15874, 46937, 15924, 15938,\n",
       "         46590, 16105, 46346, 47908, 44842, 44788, 43512, 18713, 43189,\n",
       "         18813, 18863, 18874, 43108, 18949, 18975, 42832, 42673, 19122,\n",
       "         42507, 42303, 19311, 42285, 42250, 42148, 19357, 42056, 19392,\n",
       "         43540, 44818, 18528, 43609, 17548, 17561, 44619, 44545, 44504,\n",
       "         44289, 44223, 17840, 17893, 44110, 44044, 43964, 18181, 43932,\n",
       "         18197, 43906, 43870, 43809, 43808, 18259, 43643, 18523, 41821,\n",
       "         48051, 48054, 12002, 51645, 12066, 51561, 12096, 12124, 51501,\n",
       "         12150, 12219, 12220, 51476, 12304, 12312, 12336, 51410, 51399,\n",
       "         51342, 12590, 51328, 51100, 51015, 11942, 13297, 11918, 51849,\n",
       "         52425, 10805, 10950, 11007, 11031, 11034, 11060, 52196, 11090,\n",
       "         52179, 11316, 11345, 52135, 11552, 11577, 11604, 11631, 52061,\n",
       "         11690, 51892, 11728, 11859, 15208, 13303, 50868, 49788, 49763,\n",
       "         49697, 49612, 49599, 14460, 14538, 14595, 14639, 14725, 49285,\n",
       "         49064, 14758, 48941, 48827, 48773, 48724, 48593, 48209, 48107,\n",
       "         15169, 14196, 50870, 14155, 49914, 50772, 50697, 50549, 13439,\n",
       "         13447, 50510, 50472, 13528, 50332, 50321, 13691, 13700, 50272,\n",
       "         13714, 13733, 50063, 13847, 13928, 49945, 13979, 13994, 14153,\n",
       "         10794, 19471, 19605, 33213, 33210, 33113, 33033, 25911, 33008,\n",
       "         25926, 32873, 26012, 32837, 26055, 32646, 32441, 32418, 26196,\n",
       "         26255, 32207, 32155, 26336, 32102, 32073, 33245, 31769, 33272,\n",
       "         33319, 24606, 24706, 34961, 34934, 34876, 24958, 25077, 34419,\n",
       "         34257, 34211, 34167, 34010, 25278, 33719, 25365, 33651, 33477,\n",
       "         33410, 25505, 33357, 25594, 25661, 34993, 31717, 26587, 29812,\n",
       "         27964, 27976, 28001, 29714, 28028, 28130, 28143, 28186, 29546,\n",
       "         29415, 29409, 29267, 28511, 29172, 28611, 28662, 29081, 29070,\n",
       "         28755, 28802, 29973, 31625, 30056, 30260, 31600, 26834, 26944,\n",
       "         31154, 31080, 30970, 30933, 27139, 30587, 27193, 30548, 30422,\n",
       "         30351, 30310, 30302, 27302, 30301, 30294, 27481, 30261, 27485,\n",
       "         27566, 41579, 24493, 24296, 38974, 38894, 21162, 38545, 38430,\n",
       "         21318, 21336, 38416, 21555, 38179, 38109, 38007, 21799, 21822,\n",
       "         37737, 21856, 37688, 37658, 37589, 37564, 37512, 20956, 22063,\n",
       "         20955, 20868, 19703, 19718, 19772, 41316, 41152, 40927, 40880,\n",
       "         20137, 40668, 20235, 20241, 40555, 20329, 40412, 40234, 20511,\n",
       "         40037, 39812, 20678, 39468, 39316, 20892, 24396, 22086, 37205,\n",
       "         23180, 35907, 35890, 35823, 23435, 35761, 35721, 23682, 35621,\n",
       "         23739, 35609, 35570, 23844, 23947, 35516, 23987, 35389, 24182,\n",
       "         24240, 24269, 35287, 36036, 37250, 23059, 36246, 22220, 37169,\n",
       "         37166, 37052, 22276, 22332, 36969, 36871, 36776, 36727, 22575,\n",
       "         22613, 22618, 22659, 36514, 36480, 36426, 22770, 22911, 36271,\n",
       "         22978, 23017, 10741, 28958, 59983, 58326,  6544,  6561, 64563,\n",
       "          2200, 58077, 58025, 57987, 64685,  2062, 57886,  6725,  6748,\n",
       "         64876, 57877, 58362,  6780, 58368, 58453, 59136,  2669, 64067,\n",
       "         59049, 64190, 58927,  5867,  5869, 64234, 58732,  5982, 58640,\n",
       "          6095,  6248, 64424,  6475,  5619, 57608,  6970,  1374,  7686,\n",
       "         56730,  7724, 56662, 56642, 56609, 56475, 56412, 65417,  1286,\n",
       "         65442,  8024, 56389, 56339,  1380, 65006, 65259, 57104,  6977,\n",
       "         65010, 65080,  7124, 57372, 57326, 57324, 57307, 57273,  1605,\n",
       "          7363,  1579,  7387,  1507,  1482, 57033,  1235, 59148,  5479,\n",
       "          3732,  4374,  3644,  3605, 62157,  3584, 60620, 60593, 62324,\n",
       "         62340, 60583,  3521, 60519, 60483,  3479, 61951, 60471,  3760,\n",
       "          4357,  4092, 61148,  4007,  3959,  4163,  3957,  4189,  3930,\n",
       "          4214,  4228, 60948, 61383,  4285, 60925,  3794, 61831,  2709,\n",
       "         60416, 62573, 59461, 59438,  5055,  2841,  2840,  5121, 63623,\n",
       "         63680,  5255,  5286,  2803, 59341,  2754, 63725, 63782,  4968,\n",
       "          3437, 63440,  4941, 62688,  3248, 62785, 62887, 63050, 59905,\n",
       "          3140, 59835, 63196,  4860, 59715, 63208, 59653,  4938, 63428,\n",
       "          4947,  8061, 65135, 56330, 54407, 54534, 55361, 53505, 53467,\n",
       "         66260,  9644,  9643,  8971, 66275,  8538,   856,  8492,  8489,\n",
       "           865, 66051,   124, 66039, 53416,   520, 54103,  8655, 10175,\n",
       "          8676, 66939, 54979, 55045,  9748, 66838, 66842, 53789, 66181,\n",
       "         53546,   767, 53976, 54662, 66775, 53533,  8719, 66105, 66923,\n",
       "          9708, 55173,   801, 55285, 66094,  9933, 54110,  8456, 54328,\n",
       "         52865, 56031, 54142,  8222, 65764, 66433, 56161, 52737,    34,\n",
       "         56175, 52719,  9196, 65523, 67243,  1083,  8119,   396, 52555,\n",
       "         65449, 65925, 53043,  1020,   727, 67102, 55863, 55525,   925,\n",
       "         55875,   345, 53052, 54411, 53327,  9279, 55494, 10324,  9167,\n",
       "         10356, 55902, 67038, 36007, 63483, 36087, 62872, 36008, 66760,\n",
       "         35746, 66652, 35661, 35709, 29768, 35665, 29684, 35696, 35767,\n",
       "         29685, 29374, 36104, 29259, 67072, 29156, 37203, 61778, 61685,\n",
       "         61605, 37373, 36972, 29125, 67220, 29030, 37558, 61380, 37627,\n",
       "         29003, 37722, 61273, 67161, 62863, 61988, 36907, 62827, 66834,\n",
       "         29631, 29579, 29537, 36289, 36419, 36425, 36944, 29468, 62563,\n",
       "         36531, 62163, 36576, 29283, 66986, 36633, 62144, 36460, 35632,\n",
       "         35091, 66437, 65140, 65962, 31437, 31378, 33220, 66038, 37741,\n",
       "         65125, 65098, 31315, 31216, 31179, 67249, 64972, 33452, 64689,\n",
       "         66079, 33534, 33588, 33610, 30927, 33115, 64587, 65201, 31505,\n",
       "         32119, 65446, 32107, 32103, 65760, 32461, 32489, 32591, 65409,\n",
       "         31939, 31779, 32659, 65272, 32736, 65900, 32906, 32940, 65241,\n",
       "         31560, 31514, 33027, 31464, 30603, 33929, 33940, 35045, 35054,\n",
       "         64038, 35069, 32160, 63870, 30253, 63834, 30128, 30102, 30058,\n",
       "         35343, 66395, 30008, 30006, 66432, 29960, 35522, 35551, 63620,\n",
       "         35586, 66258, 66239, 64201, 34971, 66087, 64544, 34203, 30388,\n",
       "         64533, 64516, 34277, 34361, 64471, 30321, 63589, 66122, 64398,\n",
       "         66126, 34469, 34698, 34767, 64286, 34932, 64255, 64245, 66133,\n",
       "         34458, 37830, 52554, 37874, 48337, 48505, 48570, 48598, 48631,\n",
       "         48671, 56285, 48913, 56074, 56034, 49119, 56011, 55927, 48196,\n",
       "         29002, 49300, 49514, 49556, 55579, 55560, 55554, 55486, 49811,\n",
       "         49861, 49894, 49900, 49913, 55417, 55894, 48069, 56367, 48042,\n",
       "         45981, 46017, 46085, 57458, 57390, 46300, 57258, 46539, 46596,\n",
       "         46837, 57246, 57215, 57211, 46948, 46989, 56838, 47119, 56780,\n",
       "         56772, 47237, 47383, 47399, 47412, 56551, 56539, 47900, 56424,\n",
       "         47942, 48014, 55411, 57462, 50034, 50111, 51465, 54091, 51525,\n",
       "         53734, 51596, 53727, 53693, 51682, 51728, 51764, 51780, 53525,\n",
       "         51884, 51444, 53450, 53449, 52067, 53315, 52083, 53298, 52156,\n",
       "         52988, 52812, 52758, 52204, 52293, 52326, 52656, 51967, 54333,\n",
       "         51347, 54362, 50172, 50240, 55279, 50317, 55132, 50440, 55120,\n",
       "         50444, 55076, 55041, 54919, 50551, 54798, 50782, 54531, 54516,\n",
       "         50876, 50891, 50913, 50932, 50948, 51054, 51063, 51116, 51172,\n",
       "         51196, 51203, 51251, 51281, 55365, 57497, 57555, 45624, 39993,\n",
       "         60592, 40172, 40207, 60570, 40313, 40434, 40503, 40542, 60437,\n",
       "         40632, 40652, 60310, 39686, 40821, 60175, 60052, 40912, 40916,\n",
       "         52504, 40930, 40941, 59940, 41273, 41393, 41396, 41439, 41459,\n",
       "         40873, 39653, 39647, 39616, 37908, 61152, 37988, 38098, 61002,\n",
       "         60952, 38281, 38319, 38340, 38425, 38452, 38622, 38744, 38874,\n",
       "         38884, 60782, 38961, 39011, 39089, 39119, 39266, 60779, 39272,\n",
       "         60775, 39283, 60669, 60656, 39364, 60630, 41792, 41810, 41881,\n",
       "         41885], dtype=int64),\n",
       "  'feature_absent_idx': array([49087, 39601, 62592, 27845, 12892, 12894, 62589, 12898, 57015,\n",
       "         12901, 57017, 62588, 57019, 52599, 27831, 57020, 27828, 12915,\n",
       "         27820, 39611, 50696, 57027, 62582, 44687, 44686, 12930, 52596,\n",
       "         27811, 62593, 12880, 44705, 12878, 12835, 27883, 52603, 27877,\n",
       "         57004, 62612, 62611, 57005, 44725, 44724, 12851, 12852, 39597,\n",
       "         62579, 12854, 44719, 27864, 27863, 12862, 27861, 12865, 27860,\n",
       "         57008, 44714, 50688, 62600, 50689, 12877, 12858, 62578, 52595,\n",
       "         57031, 50706, 12983, 27776, 57043, 12987, 62551, 12989, 50709,\n",
       "         39628, 57044, 57046, 44663, 52591, 57042, 13002, 27763, 62544,\n",
       "         27758, 44659, 27757, 57052, 62539, 13014, 27754, 13016, 50711,\n",
       "         13020, 57054, 13003, 50677, 39625, 44671, 27805, 62576, 12943,\n",
       "         27801, 27799, 12947, 12948, 62568, 12951, 12952, 27796, 44679,\n",
       "         39620, 62560, 62566, 27791, 12960, 50704, 62562, 12964, 39621,\n",
       "         57038, 62561, 12969, 12970, 12971, 12973, 57040, 27792, 44730,\n",
       "         62615, 56991, 62671, 52619, 12667, 44793, 62669, 50644, 56942,\n",
       "         12675, 12676, 56943, 62668, 56944, 56945, 12664, 27994, 62664,\n",
       "         56947, 12693, 12696, 56951, 62662, 50649, 62657, 62656, 12707,\n",
       "         44777, 56953, 12710, 27992, 12711, 12663, 39543, 39528, 39529,\n",
       "         44812, 56931, 28042, 44811, 56934, 62693, 28034, 50640, 12633,\n",
       "         12634, 28026, 12661, 56937, 62684, 44801, 50642, 12644, 28018,\n",
       "         62680, 56939, 62678, 12653, 44797, 28013, 52620, 44795, 39538,\n",
       "         62536, 62655, 56955, 12773, 56971, 12777, 56972, 12782, 44749,\n",
       "         62629, 27910, 27908, 12799, 62624, 12805, 12807, 12771, 50672,\n",
       "         12812, 12813, 44739, 62621, 44737, 39586, 27891, 52604, 12824,\n",
       "         44734, 12826, 56989, 12829, 12811, 12714, 12770, 12768, 62654,\n",
       "         12717, 44775, 27967, 12721, 12723, 27963, 56956, 50650, 27958,\n",
       "         62650, 62649, 27957, 12769, 50652, 27955, 12739, 52616, 12742,\n",
       "         39564, 44764, 27946, 56968, 27937, 12762, 12763, 27931, 56970,\n",
       "         56958, 13028, 13029, 62535, 27567, 57107, 13280, 44565, 27561,\n",
       "         62435, 27557, 13288, 62431, 13290, 13292, 13293, 13295, 44567,\n",
       "         13301, 62427, 27548, 13307, 62426, 13311, 50737, 62423, 57112,\n",
       "         13317, 39703, 13322, 57117, 62418, 39700, 13328, 27568, 13274,\n",
       "         44587, 13233, 44586, 44585, 44583, 27586, 13243, 44580, 57101,\n",
       "         27582, 13247, 62456, 13249, 62442, 27581, 44577, 13255, 13259,\n",
       "         27576, 62452, 27573, 44571, 27571, 39696, 13269, 13271, 62443,\n",
       "         13273, 62454, 44588, 13329, 44553, 62395, 50747, 44531, 27500,\n",
       "         62393, 52562, 44525, 13399, 50750, 44521, 13405, 62387, 13410,\n",
       "         57133, 27486, 44514, 52556, 13422, 13423, 13425, 13426, 27471,\n",
       "         13429, 57156, 44510, 13435, 52548, 27464, 13415, 50738, 62398,\n",
       "         44537, 27535, 13333, 39706, 39708, 27531, 13338, 57120, 27527,\n",
       "         13344, 13345, 13347, 57121, 39711, 62399, 57124, 50742, 44543,\n",
       "         62410, 27516, 57126, 13362, 13364, 13365, 62406, 57130, 27506,\n",
       "         62400, 57131, 57125, 62696, 62461, 27591, 13084, 57071, 27693,\n",
       "         57072, 13095, 13096, 27688, 13098, 44635, 52581, 13101, 27686,\n",
       "         13103, 27701, 62510, 13108, 44634, 57076, 13112, 44632, 44630,\n",
       "         39663, 52580, 39665, 27676, 44628, 39666, 50719, 13106, 62500,\n",
       "         13081, 27703, 39638, 62534, 62532, 13037, 13040, 62530, 27735,\n",
       "         27733, 52585, 27731, 39646, 27726, 27725, 13079, 13052, 57062,\n",
       "         39651, 27715, 44645, 27713, 27712, 13065, 44642, 27710, 27708,\n",
       "         27707, 62517, 39652, 27723, 27590, 44621, 44616, 13183, 27624,\n",
       "         39685, 62479, 27621, 27620, 13190, 44600, 13193, 27616, 27612,\n",
       "         13201, 62475, 27625, 39690, 27607, 27606, 13209, 27605, 13214,\n",
       "         13217, 57095, 13219, 39692, 13221, 27593, 50728, 57098, 44597,\n",
       "         57080, 57091, 27631, 62497, 27658, 27656, 39674, 57082, 27653,\n",
       "         13146, 57084, 13148, 13149, 27650, 13151, 13154, 57090, 62490,\n",
       "         44610, 13160, 13161, 27641, 50722, 13167, 44607, 27638, 27637,\n",
       "         50723, 13173, 62483, 13176, 62489, 13441, 28047, 28056, 28452,\n",
       "         62903, 28450, 62902, 62901, 45008, 45007, 12045, 12046, 12047,\n",
       "         39382, 28448, 28447, 50571, 28445, 12056, 62896, 12059, 28441,\n",
       "         12062, 12064, 28439, 62894, 28436, 56801, 12075, 62888, 56797,\n",
       "         12033, 56795, 12029, 11987, 56786, 28478, 45026, 39375, 28476,\n",
       "         11994, 11995, 45022, 28473, 39377, 62917, 56790, 44996, 62916,\n",
       "         50561, 12013, 12014, 12015, 62914, 12017, 52680, 52679, 50564,\n",
       "         12022, 50566, 62909, 62908, 62915, 12079, 44995, 28429, 62865,\n",
       "         44976, 56813, 12142, 12143, 28388, 39399, 28383, 28382, 62859,\n",
       "         12158, 28378, 39401, 12134, 50585, 44968, 44966, 28374, 28371,\n",
       "         28370, 62856, 52669, 62855, 62854, 12178, 28361, 50588, 62848,\n",
       "         52671, 11985, 12132, 62866, 52676, 50575, 12087, 44993, 28421,\n",
       "         28416, 39394, 50578, 44987, 12104, 12106, 28410, 12108, 28397,\n",
       "         12109, 62879, 28408, 62878, 62877, 28407, 62875, 56808, 56811,\n",
       "         44983, 44982, 44980, 28398, 50581, 56805, 11984, 62927, 28482,\n",
       "         28595, 11830, 62994, 11832, 45073, 11834, 39346, 56746, 28592,\n",
       "         28589, 56747, 56748, 28583, 11828, 45070, 11850, 28580, 62988,\n",
       "         62986, 62985, 62984, 56750, 11861, 50535, 45064, 62976, 39351,\n",
       "         45062, 11848, 11874, 11827, 56742, 11779, 11781, 52695, 28624,\n",
       "         11784, 11785, 50526, 28622, 28621, 63008, 50527, 63005, 28612,\n",
       "         11826, 11802, 11805, 11806, 56734, 11809, 28605, 11811, 28602,\n",
       "         45078, 11817, 62999, 62998, 11821, 39344, 11804, 12184, 11876,\n",
       "         11882, 11940, 45036, 50553, 39367, 62944, 50554, 39368, 50555,\n",
       "         11952, 28504, 39370, 28501, 28500, 11939, 28498, 28494, 28493,\n",
       "         56775, 11968, 62937, 56782, 45028, 62934, 28487, 11975, 11976,\n",
       "         50558, 39374, 11959, 28562, 39363, 28519, 28558, 11885, 45058,\n",
       "         28552, 62965, 28548, 28544, 62961, 11902, 11906, 50541, 28537,\n",
       "         28536, 39362, 56765, 28534, 11914, 39358, 28530, 28529, 11922,\n",
       "         11923, 28525, 39360, 28521, 11931, 50552, 28520, 62957, 12186,\n",
       "         50591, 44959, 44867, 56895, 12468, 56897, 62754, 52637, 62752,\n",
       "         39497, 52635, 28140, 62750, 39499, 28136, 28150, 28135, 12490,\n",
       "         12491, 28128, 62747, 12494, 12495, 62745, 44860, 44859, 44858,\n",
       "         28126, 28124, 50616, 12484, 12506, 56893, 12459, 39478, 12411,\n",
       "         12412, 28191, 28188, 12418, 56877, 62768, 28182, 39481, 52640,\n",
       "         12428, 12431, 12460, 28173, 44878, 62761, 28167, 62758, 56884,\n",
       "         39489, 12446, 12447, 12448, 39493, 12452, 56891, 12454, 39485,\n",
       "         62776, 56905, 28117, 44834, 50629, 12568, 44830, 39516, 44829,\n",
       "         56917, 12574, 56918, 62709, 44825, 56921, 12581, 28076, 12583,\n",
       "         12586, 44822, 50635, 28063, 12592, 52627, 12595, 12596, 12597,\n",
       "         12598, 39521, 62699, 52623, 28064, 12510, 12562, 28078, 12512,\n",
       "         39504, 28114, 44850, 28113, 28109, 28108, 62730, 12527, 12530,\n",
       "         56912, 12534, 28097, 39515, 56913, 28091, 28088, 12544, 12546,\n",
       "         62723, 62722, 12550, 28085, 28084, 28082, 12557, 28080, 28079,\n",
       "         28093, 28051, 56872, 44893, 52661, 12247, 28316, 12251, 12252,\n",
       "         12253, 12254, 28310, 12258, 39429, 28304, 50596, 12267, 12243,\n",
       "         28299, 39431, 56847, 62810, 62809, 39433, 12279, 12283, 39437,\n",
       "         56851, 50600, 39439, 12292, 12293, 44934, 12294, 52662, 12239,\n",
       "         56822, 44958, 12198, 28350, 52664, 12202, 39411, 62840, 12205,\n",
       "         12207, 50592, 12212, 50593, 12240, 62837, 28341, 12218, 39416,\n",
       "         28337, 12224, 50594, 39417, 28333, 12230, 56833, 28331, 12234,\n",
       "         12236, 12215, 12404, 12297, 39442, 28238, 39460, 50606, 12362,\n",
       "         12363, 12365, 28233, 12367, 12368, 28232, 62790, 12372, 12374,\n",
       "         12356, 28225, 28224, 39470, 44901, 28218, 39474, 28213, 56870,\n",
       "         12390, 12391, 28209, 28208, 28207, 28205, 44903, 44927, 28240,\n",
       "         39458, 50601, 62805, 62804, 28274, 12308, 12313, 12315, 44922,\n",
       "         44921], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_name': {'feature_present_idx': array([35751, 40989, 31088, 17483, 17470, 17448,  6750, 64489, 17427,\n",
       "         31150,  6766, 17397,  6790, 64448,  6804, 64444, 31173, 50160,\n",
       "          6981, 31483, 54153, 50189, 31474, 31442, 40995, 40720, 31376,\n",
       "         31361, 40751, 54210, 54226, 17335,  6924, 17509, 17518, 41025,\n",
       "         64620, 17752, 41307,  6272, 17814, 17821,  6340, 17832, 30789,\n",
       "         30787,  6178, 30721, 59741,  6076, 30790, 31487,  6345, 17701,\n",
       "         17520, 50045, 54291, 64526, 17547, 41087, 30857,  6465, 50038,\n",
       "         41126, 17617, 64604,  6384, 17668, 50043, 31527,  7055, 60132,\n",
       "         32267, 60468, 16325, 60466, 63993, 60459, 40009, 53767,  7904,\n",
       "         16387, 16402,  7877, 64025, 60425, 64010,  7838, 32275,  8009,\n",
       "         39811, 60588, 15970, 53512, 60575,  8145, 16292, 39848, 16139,\n",
       "         39915, 63951, 39957, 50466,  8014, 16023, 17933, 32187, 60351,\n",
       "          7281, 60174, 50252, 31623, 31596,  7244, 40452, 60156,  7221,\n",
       "         17029, 64324, 64332,  7145, 40533,  7228, 16463, 60187, 60213,\n",
       "         60327, 16555, 16590, 40241, 53919, 40256, 60204,  7555,  7471,\n",
       "         60254, 16783, 31797, 40366, 60230, 16734, 30674, 17974, 41548,\n",
       "         19421, 29163, 65248, 19517, 29077, 29068, 42879, 58997, 58970,\n",
       "         43063, 29037, 19644, 49071, 49065, 54971,  4397, 42841, 49176,\n",
       "         54928, 29280, 19295,  4778,  4765,  4759, 65225, 59062, 19366,\n",
       "         59057, 42801,  4649, 54947, 42813, 42757, 29351, 19702, 65323,\n",
       "         28748, 20042, 58715, 58701, 58700, 48991,  4121, 65453, 20120,\n",
       "         20141, 48925, 58679, 20198, 20231, 43384, 54991,  4132, 43264,\n",
       "          4334, 19753, 28930, 43156,  4274, 43163, 43266, 58844,  4245,\n",
       "         58832, 43224, 58808, 43231,  4170, 49049, 39805,  4869,  4897,\n",
       "          5719, 30407,  5702, 18266, 41764, 30289, 41692, 18374, 30252,\n",
       "          5535,  5527, 18435, 41890, 30234, 18394, 41906, 54535, 59599,\n",
       "         41606,  5950, 30573, 18095,  5895, 30536, 30430, 30521, 41646,\n",
       "          5845,  5819, 54496, 18178, 49889,  5875, 19053, 30215, 41937,\n",
       "         29734, 49518, 18853, 54796, 18923, 29562, 18809, 49410, 49379,\n",
       "         49366, 65067, 29510, 29488,  4921, 49390, 30156, 18807, 29816,\n",
       "         18548, 41950, 41963, 59459, 18612, 64951, 54764, 42086, 29911,\n",
       "          5236, 49566, 29850, 49541, 29820, 29970, 28590,  8266, 32623,\n",
       "         34818, 10689, 10692, 34851, 52502, 61678, 13263, 13228, 61706,\n",
       "         10768, 13164, 10780, 36992, 34936, 52488, 36956, 13135, 62549,\n",
       "         62550, 12966, 11023, 35118, 51539, 34798, 13046, 13051, 13093,\n",
       "         36920, 10863, 52455, 13125, 35050, 51368, 34769, 52520, 13703,\n",
       "         10237, 34404, 61471, 37546, 37581, 10298, 61465, 34344, 62918,\n",
       "         34300, 51273, 34256, 13916, 13816, 12913, 10316, 61533, 13421,\n",
       "         10508, 13492, 10494, 13529, 10473, 62832, 34622, 34511, 61567,\n",
       "         13614, 10381, 34487, 13657, 34532, 35254, 62542, 12902, 62280,\n",
       "         12262, 11712, 12284, 52186, 12307, 35832, 12309, 36392, 24679,\n",
       "         11635, 51880, 36404, 35701, 36367, 11595, 62262, 36202, 52069,\n",
       "         36081, 62192, 12040, 35976, 62209, 36227, 52120, 11887, 62114,\n",
       "         11843, 11841, 11839, 11814, 11893, 51244, 11590, 36417, 51654,\n",
       "         62450, 11269, 35346, 11241, 12720, 51655, 11221, 61860, 35312,\n",
       "         52372, 36742, 52382, 12867, 36673, 11566, 35412, 35449, 36453,\n",
       "         61966, 35628, 12419, 61948, 61937, 52301, 36501, 36555, 11468,\n",
       "         11457, 11451, 12594, 11441, 12540, 37778, 61370, 62982, 50785,\n",
       "          8874, 50776, 39131, 60798, 33062, 39084,  8799, 39199, 39203,\n",
       "         39229, 53344, 15537, 33003, 60705, 63672, 53243, 60827, 15211,\n",
       "          9043, 15213, 60843, 39021,  9015, 63533, 63463,  9004, 50851,\n",
       "         39055, 39067, 39075, 53238, 39024, 63433, 32988, 63703, 32813,\n",
       "         39577,  8458, 15763, 15779, 39607, 32827, 50580, 50577, 15888,\n",
       "          8336, 50550, 15906, 53476, 32741, 63683, 50632, 50647, 60680,\n",
       "          8677, 63716, 63724, 53379,  8606, 39517, 32917,  8573, 39383,\n",
       "         32869, 53399,  8545, 39400, 15658, 63905, 63426, 53192, 14283,\n",
       "         14294,  9750,  9742,  9738, 33956, 14241, 33921,  9697,  9692,\n",
       "         38197, 14395, 61182, 61166, 33881, 38389, 38050, 14191, 62990,\n",
       "         52744, 51211,  9943, 37859, 14041, 61256, 52748, 51187, 51185,\n",
       "          9906, 52778, 38014, 38017, 37898, 63419, 38390, 38400, 38809,\n",
       "         15059,  9208, 53159, 15133,  9165, 15020, 38910,  9155, 33368,\n",
       "          9146, 63357, 38934,  9111, 53165, 38395, 50884, 53118, 61108,\n",
       "          9509, 38466, 33764, 14667, 33711, 33482, 50983, 14803, 53045,\n",
       "         53069, 33602, 33561,  9281, 38609,  3804, 41625, 52084,  2614,\n",
       "         25691, 66934, 48420, 23428, 21552, 25689, 27393, 27400, 27406,\n",
       "         25651, 66971, 55733,   942,  2673, 56470, 21391,   915, 55638,\n",
       "         21560,  2584, 66907, 55768,  2398, 21824, 25797, 27134,  2442,\n",
       "         66168, 23377,  1046, 27177, 25602, 46332, 27198, 44722, 21652,\n",
       "         44704, 55803, 21634, 55783, 66129, 46368, 66154, 23521,   886,\n",
       "         46551, 48551, 27798,  3015, 23737,   690, 44165, 55500,  3057,\n",
       "         67076,   730,   662, 44141, 46853,   637, 20998, 46892, 27898,\n",
       "         27909, 46895, 20975, 23835, 27109,  2988, 44188, 21263, 67007,\n",
       "          2788, 21253,  2799,  2802, 21222, 48532,  2838, 65842, 58235,\n",
       "         44287, 46680, 44274, 57169, 25478, 58281, 25462, 44228, 21121,\n",
       "         57177, 44099, 23303, 25868, 22563, 26538, 57704, 45442, 57724,\n",
       "         56048, 48075, 22873, 45752, 22874, 48164, 26136, 66479,  1956,\n",
       "         45820, 22381, 22360, 22349, 57826, 22857,  1847, 48082, 22825,\n",
       "         66562,  1699, 45602, 22709, 45640,  1725,  1750, 22644, 45577,\n",
       "         56016, 22760, 66575, 56117, 22599,  1791, 26506,  1603,  1601,\n",
       "         57701, 45667, 22777, 26731, 57554, 57843, 26972,  1178, 23155,\n",
       "         46056,  2245, 66334, 66890,  2258,  2260, 46038,  1156, 23185,\n",
       "          1151,  2291, 46086, 48297, 44879, 23244, 46099, 57431, 46065,\n",
       "         66269, 25995, 26930, 45207, 45921, 45940, 57863,  1363, 45966,\n",
       "         66740, 45971, 23048, 46031, 26916, 26923, 26924,  1261, 46004,\n",
       "         45067, 46005,  2161, 26005, 45039,  1276, 27927, 45613, 55415,\n",
       "         47323, 47094, 24139, 25062, 24066, 43877, 67254,  3287, 47239,\n",
       "           503, 28031,   508, 47336,  3690,   177, 43710, 47515, 24790,\n",
       "         24216, 48688, 43857, 24870, 28515, 28360, 58339, 47086,   478,\n",
       "         20453, 47272,  3312, 44015, 25111, 20479, 20766, 24111,  3633,\n",
       "         43995, 24112, 24825, 28125, 43649, 24801, 28355, 25176, 56929,\n",
       "         20696, 20807,  3660,  3402, 43620,  3407, 20353, 24805, 55447,\n",
       "         46935, 43796, 55434, 24297,   309, 25256, 58642, 28571, 20320,\n",
       "         28542, 44080, 67162, 47547, 58613, 43823, 28287, 24254, 55312,\n",
       "         28527, 20546, 24648, 57039, 25320, 65774, 28263, 53122, 60994,\n",
       "         15031, 33440, 56273, 33698, 52959, 33386, 57519, 26059, 15124,\n",
       "         15107, 60976, 14495, 60983, 53144, 14523, 15069, 56315, 33811,\n",
       "         56255, 24398, 52948, 15038, 35679, 33793, 56267, 33475, 33784,\n",
       "         12402, 14904, 56965, 14875, 61089, 61071, 61069, 33604, 33565,\n",
       "         14730, 14822, 56964, 25984, 57491, 33650, 61062, 14748, 12396,\n",
       "         61112, 23130, 14940, 24855, 56950, 12314, 24404, 60999, 12341,\n",
       "         52983, 25974, 24860, 33542, 14943, 56288, 14637, 56769, 33721,\n",
       "         52223, 61098, 61020, 23880, 35803, 57600, 60699, 26227, 24773,\n",
       "         35933, 15515, 26211, 15502, 35929, 15484, 26240, 24575, 15473,\n",
       "         52142, 60707, 26150, 15432, 24573, 60760, 60766, 15405, 33147,\n",
       "         15483, 24586, 33002, 56900, 24697, 36044, 32872, 26396, 62146,\n",
       "         36009, 32923, 15617, 56107, 12023, 22755, 15600, 24637, 32957,\n",
       "         53345, 12037, 56837, 24603, 62138, 32979, 56119, 15558, 56835,\n",
       "         52158, 23068, 12166, 60811, 15248, 22996, 24541, 56205, 26096,\n",
       "         23009, 60861, 24391, 15192, 57535, 62043, 23021, 26085, 60876,\n",
       "         33348, 35824, 53172, 15156, 26084, 57528, 12265, 53166, 35829,\n",
       "         57558, 56187, 33242, 35898, 33167, 33184, 33185, 22883, 22885,\n",
       "         22910], dtype=int64),\n",
       "  'feature_absent_idx': array([20922, 31355, 48180, 14511, 31346, 48191, 48195, 48200, 14530,\n",
       "         14531, 14533, 14534, 14535, 58389, 58388, 14541, 14542, 58385,\n",
       "         31328, 14545, 58380, 14549, 14550, 48208, 14552, 14553, 58373,\n",
       "         14561, 58411, 14504, 14503, 14501, 14449, 58443, 14457, 14458,\n",
       "         58442, 58439, 58438, 14463, 31379, 58434, 14474, 14477, 58429,\n",
       "         14562, 58428, 14484, 48174, 31367, 14488, 14490, 48175, 48176,\n",
       "         58416, 31360, 58415, 58413, 14499, 14500, 14482, 48213, 31312,\n",
       "         14573, 14626, 31274, 58340, 31272, 58337, 14634, 14635, 14636,\n",
       "         58333, 14645, 31258, 14651, 31257, 48240, 48247, 31251, 31250,\n",
       "         14659, 48249, 31243, 31242, 31240, 48253, 14675, 14677, 58318,\n",
       "         31230, 14681, 31254, 14448, 31276, 31279, 58367, 48220, 14577,\n",
       "         31302, 31301, 58364, 58363, 14584, 58361, 31293, 14593, 58360,\n",
       "         58358, 31277, 58357, 31291, 14600, 58354, 48229, 14603, 31289,\n",
       "         14605, 14610, 58349, 14615, 31282, 48236, 14619, 14598, 14447,\n",
       "         58444, 48165, 48096, 58553, 31515, 58548, 31507, 14285, 14286,\n",
       "         14287, 48103, 14291, 48106, 14293, 14295, 14268, 14296, 31492,\n",
       "         14304, 14305, 31491, 31489, 14310, 58538, 14312, 58537, 58536,\n",
       "         14317, 31485, 14319, 48109, 48115, 58559, 14262, 31574, 48055,\n",
       "         14215, 14216, 31565, 31563, 14220, 31559, 14225, 48065, 31551,\n",
       "         14232, 48070, 31528, 31548, 48079, 48080, 58573, 58572, 14249,\n",
       "         14251, 48083, 58571, 31535, 31532, 48087, 14260, 14261, 31545,\n",
       "         31229, 58526, 48117, 14387, 14388, 14390, 14393, 48150, 31418,\n",
       "         31417, 31416, 31414, 14402, 48157, 58476, 14414, 58488, 14417,\n",
       "         58465, 14422, 14424, 58460, 14426, 14427, 48162, 58450, 31389,\n",
       "         14439, 14441, 31386, 14443, 31399, 31477, 58489, 14383, 48118,\n",
       "         58519, 31469, 31467, 14340, 58513, 31456, 31455, 48123, 31453,\n",
       "         31445, 58506, 14362, 14384, 14363, 58502, 31438, 14369, 14371,\n",
       "         58496, 31435, 48143, 31429, 14378, 31426, 14380, 48146, 58491,\n",
       "         14365, 31228, 14684, 58316, 31039, 14953, 48401, 58132, 14958,\n",
       "         58130, 14960, 48403, 31034, 58122, 58118, 14966, 14967, 31040,\n",
       "         31028, 14973, 58112, 31021, 31020, 14983, 58110, 14986, 48413,\n",
       "         31013, 48415, 58106, 31007, 14999, 14971, 31005, 14947, 48388,\n",
       "         14888, 14889, 14890, 31078, 14892, 31076, 14897, 48370, 31069,\n",
       "         48374, 58163, 48375, 58158, 48400, 14914, 31060, 31059, 14921,\n",
       "         14922, 14925, 58152, 14927, 58151, 14929, 14930, 31055, 31051,\n",
       "         14937, 14917, 58178, 58092, 15008, 48461, 58060, 30949, 15066,\n",
       "         58057, 15071, 15075, 58052, 48471, 30941, 30939, 58049, 58046,\n",
       "         48459, 48475, 48477, 30930, 48478, 30926, 58039, 58037, 15106,\n",
       "         15109, 30917, 15112, 48494, 58036, 30907, 15092, 58090, 30953,\n",
       "         15057, 48424, 15010, 15013, 30997, 15015, 48431, 15018, 48433,\n",
       "         48438, 15026, 48441, 15029, 30983, 30955, 30979, 48444, 30976,\n",
       "         58072, 15040, 15042, 15046, 30968, 30967, 30966, 48455, 48456,\n",
       "         48457, 30957, 15034, 14207, 58179, 48364, 48295, 14740, 58286,\n",
       "         14744, 48299, 58285, 58283, 58277, 14753, 58274, 31178, 31177,\n",
       "         14760, 48292, 58267, 31172, 48303, 48304, 48310, 48315, 58254,\n",
       "         31161, 48319, 48320, 31157, 14780, 48321, 58246, 14764, 58243,\n",
       "         48291, 14733, 48262, 31224, 48265, 58311, 14694, 14695, 58310,\n",
       "         31217, 48271, 31211, 58305, 31210, 58301, 58292, 14707, 14710,\n",
       "         14711, 48280, 14716, 14717, 14718, 31201, 48282, 14723, 48286,\n",
       "         58294, 14727, 31194, 58297, 14883, 31151, 58242, 58207, 31117,\n",
       "         48340, 14842, 48342, 31112, 14845, 58203, 14847, 14848, 48345,\n",
       "         31109, 58200, 58208, 48346, 31106, 14857, 58195, 14859, 31103,\n",
       "         31101, 31092, 14871, 58191, 31090, 48359, 14877, 48361, 58197,\n",
       "         14788, 31120, 48339, 31148, 31146, 58240, 14794, 31145, 58239,\n",
       "         14797, 58237, 14799, 14800, 58236, 31140, 48329, 14833, 14811,\n",
       "         31134, 48333, 31129, 58221, 14820, 31128, 31127, 14824, 14825,\n",
       "         14826, 48338, 14829, 58215, 48332, 14206, 31575, 14204, 59037,\n",
       "         13541, 32077, 59032, 47748, 13551, 13557, 32063, 32061, 13564,\n",
       "         13565, 13566, 32057, 59038, 13568, 13571, 47759, 32051, 32050,\n",
       "         47760, 59006, 13577, 32047, 13579, 59003, 13582, 47762, 32040,\n",
       "         59016, 47767, 47744, 59040, 47721, 13494, 13495, 13498, 32106,\n",
       "         32105, 47728, 59058, 47730, 47732, 47733, 13507, 32098, 13536,\n",
       "         32096, 13513, 32093, 32091, 13519, 13520, 47738, 47740, 32086,\n",
       "         13524, 59045, 32082, 59043, 13532, 13511, 32113, 58992, 32032,\n",
       "         58951, 31973, 58950, 13671, 13672, 13675, 47810, 58941, 13688,\n",
       "         13689, 58937, 13692, 58935, 47797, 31954, 47814, 13698, 58933,\n",
       "         13701, 47816, 13705, 31948, 31944, 31943, 58928, 31938, 58925,\n",
       "         13718, 13696, 13595, 13659, 13654, 32030, 58987, 47770, 32024,\n",
       "         13606, 13608, 58982, 58981, 47772, 13615, 47773, 13620, 47774,\n",
       "         31982, 58974, 32010, 32008, 13631, 32005, 47785, 13637, 13638,\n",
       "         58966, 32000, 47786, 31994, 13647, 47794, 13626, 13719, 47719,\n",
       "         13485, 32232, 13317, 47645, 32230, 59179, 59178, 13322, 32228,\n",
       "         32227, 32226, 13328, 13329, 13333, 59183, 47646, 13338, 59168,\n",
       "         32215, 13344, 13345, 13347, 32209, 47659, 59163, 47664, 59158,\n",
       "         32203, 13362, 59170, 13364, 32235, 13307, 32270, 13259, 47634,\n",
       "         47635, 59212, 59211, 13269, 13271, 59210, 13273, 13274, 32262,\n",
       "         13280, 13311, 59206, 59199, 13288, 59198, 13290, 13292, 13293,\n",
       "         13295, 32251, 32245, 13301, 59195, 47641, 59191, 32254, 32115,\n",
       "         13365, 59154, 13429, 59106, 47694, 13435, 59104, 32146, 13441,\n",
       "         47695, 32142, 13446, 59093, 13448, 59092, 32154, 32141, 13454,\n",
       "         59088, 59087, 13463, 13466, 13467, 32130, 32126, 47710, 13476,\n",
       "         47715, 59073, 47717, 59089, 32199, 13426, 13423, 32195, 32194,\n",
       "         47669, 32186, 47671, 59147, 59139, 32179, 32177, 59134, 59128,\n",
       "         47680, 32170, 13425, 32169, 13399, 59123, 47682, 13405, 47684,\n",
       "         47687, 13410, 32158, 13415, 59112, 59110, 47691, 13422, 32167,\n",
       "         58034, 31937, 31934, 14028, 58708, 31694, 14033, 14034, 14035,\n",
       "         31686, 47988, 58697, 31677, 31675, 14054, 14056, 31696, 31674,\n",
       "         14059, 47993, 14062, 31671, 47995, 47996, 48000, 14073, 31660,\n",
       "         58687, 58684, 14078, 14079, 58694, 58680, 14026, 58712, 13974,\n",
       "         13975, 13976, 58747, 58746, 58744, 31737, 58741, 58740, 13986,\n",
       "         31735, 13988, 58739, 47976, 31726, 47965, 31719, 31716, 31712,\n",
       "         31711, 47970, 31708, 31704, 58718, 31701, 58714, 58713, 14021,\n",
       "         31724, 13973, 31658, 31656, 58635, 58632, 58631, 14157, 14158,\n",
       "         58628, 48037, 14162, 14163, 14164, 31604, 14169, 58621, 48034,\n",
       "         14176, 58615, 14181, 31589, 31588, 14187, 14189, 14190, 48049,\n",
       "         58601, 31578, 48053, 14200, 14201, 31592, 14085, 31616, 48030,\n",
       "         14091, 31653, 58672, 48009, 58671, 48011, 14099, 14102, 31646,\n",
       "         58666, 14110, 14111, 14113, 14146, 58657, 31634, 31630, 14127,\n",
       "         31629, 31628, 14131, 31626, 14134, 14135, 48027, 58643, 48029,\n",
       "         14143, 48022, 31935, 47956, 13964, 13788, 13791, 13794, 13795,\n",
       "         13796, 58885, 58884, 13799, 31889, 13801, 58882, 31888, 13804,\n",
       "         47852, 31886, 31882, 47860, 13815, 31874, 58865, 31872, 31870,\n",
       "         13823, 31866, 13825, 13829, 58859, 47870, 13808, 58851, 47850,\n",
       "         31898, 47823, 13725, 58919, 13729, 13731, 58915, 47830, 58914,\n",
       "         58912, 47831, 58907, 31918, 47841, 31897, 31910, 31907, 31905,\n",
       "         58897, 31904, 13767, 58894, 31902, 13772, 13773, 13774, 13776,\n",
       "         13778, 47848, 47845, 31749, 31859, 13840, 47918, 47922, 31792,\n",
       "         13920, 13921, 31784, 58781, 58780, 58779, 58776, 47931, 13933,\n",
       "         47933, 13908, 13936, 47937, 13941, 47939, 58770, 58769, 31765,\n",
       "         13950, 47947, 31756, 13958, 31752, 13961, 58754, 13937, 58842,\n",
       "         58796, 58797, 31854, 47876, 31848, 31846, 31845, 31837, 13864,\n",
       "         47883], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_ord': {'feature_present_idx': array([20211, 40808, 59138, 43308, 66276, 16247, 55605, 16870, 38847,\n",
       "         66969, 10466, 61050, 14115, 43976, 14313, 13938, 44063, 45155,\n",
       "         46587, 47725, 14551, 48815, 49447, 49873,  9299, 55063, 55188,\n",
       "          6922, 57198, 57340, 45729, 15002, 40660, 41091, 25277, 27420,\n",
       "         30607, 23414, 30902, 31004, 31431, 21606, 21457, 21243, 15274,\n",
       "         34537, 36940, 19642, 37702, 38478, 39252, 17989, 39312, 39548,\n",
       "         40115, 57747, 35491, 58087, 25403,  5054, 60717,  5748,  2691,\n",
       "         63014, 63199, 63303, 63358, 64591, 64829,  1528,   754, 66132,\n",
       "          5441, 60728,   250, 66966,  1785, 27844,  2148, 40097, 40099,\n",
       "          2185, 16906, 24900, 40174, 16684, 16630, 40322, 16307, 16276,\n",
       "         27493, 15974, 66335, 41348, 27150, 41473, 41713, 42862, 43083,\n",
       "         61474, 61427, 61295, 61237,  1738, 24791, 18443, 38785, 23156,\n",
       "         30522,   926, 66128, 31659, 31776, 22685, 21924, 65985, 21677,\n",
       "         65948, 34171,  1154, 34360,  1210, 65596, 65096, 23857, 36429,\n",
       "         29418, 19686, 64694, 37404, 14177, 27900, 38460, 64044, 18859,\n",
       "         18753, 30611,  5776, 15196,  9251, 10786, 59630, 10195, 59469,\n",
       "          5038, 50059,  9794, 50732, 50935, 51155, 52368, 53213,  8540,\n",
       "         53273, 10853, 53275, 54425, 54964, 59431,  7375,  5222, 55409,\n",
       "         55849,  6613,  6609, 56203, 56240, 58359, 57373,  5580, 53999,\n",
       "         11032, 67166, 11346, 48254, 46084, 45754, 60638, 60667, 46724,\n",
       "         12473, 47076, 13759, 60554, 14018, 47808, 47925, 44721, 55196,\n",
       "         61811, 42243, 42163, 58303, 42811, 32654, 32657, 58189, 32718,\n",
       "         32058, 30829, 55764, 27836, 30799, 30723, 45433, 33316, 30424,\n",
       "         55966, 44393, 43907, 56525, 27572, 59142, 59328, 54691, 54185,\n",
       "         45946, 48354, 60223, 39356, 48506, 39255, 48916, 40500, 47276,\n",
       "         62849, 38476, 62184, 37549, 51249, 37202, 44081, 51605, 40959,\n",
       "         54405, 54130, 34332, 53637, 62032, 46107, 33660, 35021, 41318,\n",
       "         35597, 35867, 36423, 26803, 52854, 35328, 61165, 33842, 15712,\n",
       "          9284, 15675,  2925,  3094, 23550, 23498,  9062, 23047,  3818,\n",
       "         13352,  3979, 15717,  4185, 22811, 15179, 16236,  8257, 22629,\n",
       "         22625,  4705,  5214, 21792,  7557, 18405, 21489, 21099,  5974,\n",
       "         19134,  7003, 20202,  8683,  9328,  6430,  1107, 11256, 11998,\n",
       "         24947, 13072,  1664, 25222, 25510, 10160, 39019,  7458, 39235,\n",
       "         13845,  7406,  7253, 44292, 18017,  7681, 17720, 44523, 15155,\n",
       "         13786, 38187, 55322, 37875, 19427, 37414, 55692, 13612, 56020,\n",
       "         19840, 36884, 36841,  6440, 13202,  7171, 55272, 39472, 12986,\n",
       "         41597, 41571, 41942, 50658, 15085, 10117, 42553, 49871, 42734,\n",
       "         41249, 51971, 48867, 51985, 48377, 14899, 11407, 15822, 47485,\n",
       "         12335, 53548, 40186, 12778, 16947, 16971, 17079,  7711, 14159,\n",
       "         14037, 41785, 39462, 25589, 36523, 20529, 28730, 28961, 62120,\n",
       "          2808, 24610, 29480, 29509, 61959, 30449, 36602, 22964,  4090,\n",
       "          4116, 60343, 31990, 28678, 28608, 28594, 28352, 66908, 66822,\n",
       "         26101, 66365, 26117, 26661, 25001, 32059,  1413, 27518,  1554,\n",
       "         24929, 24889, 27873,  1627, 63844, 24961, 32184, 23134, 32295,\n",
       "         56378, 36053, 20986, 21056, 60078, 58183, 58187,  5739, 34265,\n",
       "          5497, 58704, 34031, 45942, 22635, 59831, 59334, 59386, 55572,\n",
       "         64953, 12415, 46877,  6260, 46618,  7131,  1282,  6263,  5375,\n",
       "         57364, 46483, 60084,   617,  6591, 57115, 56911, 46074,  6387,\n",
       "          1066,  7160, 48007,  3181, 61106, 61973,  5469, 61077, 55057,\n",
       "          9364,  9374, 58322,  4623, 52093, 55269,  1898,  8040, 49573,\n",
       "          8170, 64402, 10318, 53162, 57396, 57388, 57589, 45056, 36077,\n",
       "         41740, 41267, 41155, 16318, 17556, 39149, 18657, 38704, 18922,\n",
       "         38069, 19344, 37494, 37082, 36173, 35749, 34704, 21782, 25639,\n",
       "         27170, 27747, 28115, 23673, 23562, 42000, 31226, 31434, 31536,\n",
       "         31919, 32261, 32622, 33032, 31329, 42630,    43, 43256, 14445,\n",
       "         14963, 43958, 14437, 13878, 43173, 43900, 43006,  4201, 59703,\n",
       "         59671, 33533, 34060, 21590,  4181, 49619, 34329, 21358, 34386,\n",
       "         57613, 35361, 20895, 20754, 57284,  5482, 46623, 49793, 60829,\n",
       "         45431,   936, 65920, 65812, 64777, 24639, 64329,  1663, 28162,\n",
       "         63755, 28318, 63339, 28523, 62484,  2654, 30129, 23784, 61592,\n",
       "         23483,  3565,  3711, 61140, 44166, 20547, 14423, 58624, 16733,\n",
       "         40188,  7820, 17725, 54812, 39164, 52944, 10379,  8699, 41097,\n",
       "         38551, 36403, 43077, 19592, 51129, 10192, 50762, 49592, 49487,\n",
       "         15084, 50530, 39618, 19598, 27488,    85, 46614, 41559,  8469,\n",
       "         25731, 23150, 16392, 26102,  3519,   136, 42452, 52527,  1622,\n",
       "         13163, 28967, 40664, 63722, 15497,  2415,  2371, 46457, 25351,\n",
       "         36195, 60603,  5806, 60615, 56919, 34189, 19000, 10811, 14935,\n",
       "         33949, 43658, 34781, 33573, 36625,  5983, 56701, 13248, 48690,\n",
       "         59695, 59816,  6869,  6241, 36942, 46692, 60358, 56090, 56618,\n",
       "         34716, 27483, 41819, 36744, 46093,  2391,   748, 29050, 52835,\n",
       "         18217, 22790, 22900, 39868, 47288, 37289, 10185, 42649, 42793,\n",
       "          8682,  8474, 11500, 26143, 55501, 45013, 59622, 31613, 27515,\n",
       "         45461, 22503], dtype=int64),\n",
       "  'feature_absent_idx': array([38261, 28450, 12807, 45711, 28448, 28447, 12811, 12812, 12813,\n",
       "         28445, 45713, 28441, 57611, 57609, 12805, 28439, 57605, 12826,\n",
       "         28436, 12829, 45716, 45717, 57601, 12835, 57599, 45722, 28429,\n",
       "         45725, 45726, 12824, 57596, 57626, 57628, 45683, 57662, 28482,\n",
       "         28478, 12762, 12763, 57656, 28476, 12768, 12769, 12770, 12771,\n",
       "         28473, 28452, 12773, 12777, 45696, 57650, 12782, 45699, 45701,\n",
       "         57643, 57642, 57641, 45704, 45705, 12799, 57629, 45695, 57594,\n",
       "         57591, 28421, 57550, 12898, 12901, 28378, 45758, 45761, 28374,\n",
       "         28371, 57544, 28370, 12915, 45769, 28361, 28382, 28350, 57525,\n",
       "         12930, 45779, 57524, 45786, 28341, 57518, 57516, 28337, 12943,\n",
       "         57513, 57511, 12947, 57526, 28383, 12894, 12892, 45731, 45732,\n",
       "         12851, 12852, 12854, 28416, 12858, 57579, 57578, 12862, 28410,\n",
       "         12865, 45736, 28408, 28407, 45740, 57571, 57570, 57568, 45743,\n",
       "         57567, 57566, 12877, 12878, 12880, 28398, 28397, 45747, 28388,\n",
       "         28487, 12948, 57665, 57667, 45611, 12595, 12596, 12597, 12598,\n",
       "         28605, 45615, 28602, 45616, 45618, 57782, 45619, 28595, 12592,\n",
       "         28592, 45626, 28583, 57772, 57770, 28580, 57768, 45628, 12633,\n",
       "         12634, 57766, 57762, 12644, 45634, 28589, 28562, 28612, 57795,\n",
       "         45594, 12546, 57840, 28642, 12550, 45598, 57835, 45599, 12557,\n",
       "         28634, 45600, 12562, 57825, 45609, 57821, 12568, 45603, 28624,\n",
       "         57811, 12574, 28622, 28621, 57807, 57801, 12581, 12583, 57796,\n",
       "         12586, 28630, 45635, 57753, 57750, 28525, 28521, 12707, 28520,\n",
       "         28519, 12710, 12711, 57699, 12714, 12717, 45664, 12721, 12723,\n",
       "         28529, 57688, 28504, 57683, 45672, 28501, 28500, 28498, 12739,\n",
       "         12742, 28494, 28493, 57676, 45674, 57670, 45671, 28530, 45652,\n",
       "         12696, 12653, 28558, 45638, 57745, 45639, 12661, 57741, 12663,\n",
       "         12664, 28552, 12667, 57736, 57735, 28548, 12675, 12676, 57731,\n",
       "         57730, 28544, 45643, 57725, 57723, 28537, 28536, 57718, 57717,\n",
       "         12693, 28534, 57715, 57666, 12544, 28333, 12952, 13217, 28136,\n",
       "         13219, 28135, 13221, 45953, 28128, 28126, 28124, 57283, 13233,\n",
       "         28117, 28114, 57297, 28113, 57271, 28109, 28108, 13247, 13249,\n",
       "         57266, 57265, 45968, 13255, 57261, 13259, 45969, 57257, 13243,\n",
       "         57256, 13214, 57299, 13160, 13161, 28182, 45904, 13167, 57329,\n",
       "         28173, 57325, 13173, 13176, 28167, 45923, 13183, 45948, 45927,\n",
       "         13190, 13193, 28150, 45935, 57306, 57305, 45939, 13201, 45945,\n",
       "         57303, 57301, 13209, 28140, 45929, 57254, 57252, 57251, 57218,\n",
       "         45986, 45990, 13317, 57209, 13322, 57208, 45993, 28064, 28063,\n",
       "         13328, 13329, 45994, 13311, 13333, 28051, 13338, 57188, 28047,\n",
       "         13344, 13345, 46006, 13347, 46007, 46008, 28042, 46013, 28034,\n",
       "         28056, 45984, 28076, 13307, 13269, 13271, 28097, 13273, 13274,\n",
       "         57247, 45976, 28093, 13280, 28091, 57237, 28088, 57232, 13288,\n",
       "         57230, 13290, 13292, 13293, 28085, 13295, 28084, 28082, 57227,\n",
       "         13301, 28080, 57224, 28079, 57221, 28078, 57334, 12951, 45903,\n",
       "         45900, 57447, 13020, 28274, 57442, 13028, 13029, 57441, 28267,\n",
       "         28265, 57437, 13037, 28264, 13040, 13016, 45843, 45846, 45847,\n",
       "         45849, 57430, 57429, 57428, 13052, 45856, 57427, 57425, 28248,\n",
       "         28247, 45863, 57433, 57423, 57450, 45828, 28331, 57502, 57501,\n",
       "         12960, 57493, 45800, 12964, 45803, 45807, 12969, 12970, 12971,\n",
       "         12973, 13014, 28316, 28310, 12983, 28304, 12987, 57480, 12989,\n",
       "         28299, 45823, 57468, 13002, 13003, 45824, 45826, 45809, 57422,\n",
       "         13065, 57420, 13112, 57386, 28213, 28209, 57381, 28208, 28207,\n",
       "         28205, 57367, 57366, 57365, 57362, 45892, 57389, 57359, 57352,\n",
       "         45895, 57350, 57344, 28188, 13146, 13148, 13149, 57341, 13151,\n",
       "         57339, 45899, 13154, 28191, 13108, 57391, 13106, 45864, 28241,\n",
       "         28240, 57415, 57413, 45865, 28238, 57405, 57403, 13079, 13081,\n",
       "         28233, 28232, 13084, 45872, 45874, 57401, 57399, 28225, 28224,\n",
       "         45879, 13095, 13096, 13098, 57395, 13101, 28218, 13103, 57392,\n",
       "         57336, 45592, 28649, 45583, 11984, 11985, 58274, 11987, 45255,\n",
       "         45258, 11994, 11995, 58267, 29071, 45266, 45271, 29058, 58277,\n",
       "         45275, 12014, 12015, 58254, 12017, 45281, 12022, 58246, 45282,\n",
       "         58243, 58242, 12029, 29042, 58240, 12013, 58239, 45253, 58285,\n",
       "         29107, 58311, 58310, 29105, 58305, 45236, 45237, 58301, 11952,\n",
       "         29098, 29097, 45239, 58297, 58283, 29094, 58294, 45243, 45247,\n",
       "         45248, 58292, 11968, 29086, 45249, 45250, 45252, 11975, 11976,\n",
       "         58286, 11959, 12033, 58237, 29041, 29004, 58195, 45317, 45321,\n",
       "         12087, 45323, 58191, 28994, 28993, 45331, 45333, 58179, 28986,\n",
       "         58197, 12104, 28983, 12108, 12109, 28982, 58178, 28981, 45338,\n",
       "         28976, 45339, 58163, 45340, 45342, 45343, 12106, 29007, 12079,\n",
       "         29008, 58236, 29040, 29039, 45292, 29035, 29033, 12045, 12046,\n",
       "         12047, 29032, 29029, 29028, 45299, 58221, 45304, 12056, 29020,\n",
       "         58215, 12059, 45305, 12062, 12064, 45310, 58208, 58207, 29012,\n",
       "         58203, 12075, 58200, 11940, 58158, 11939, 58316, 58439, 58438,\n",
       "         58434, 29214], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 650\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 650\n",
       "  })},\n",
       " 'contains_part': {'feature_present_idx': array([22578, 24581, 37486,  8252, 48880, 63551, 63386, 24632, 37048,\n",
       "         24664, 49234, 36568, 37590, 49317, 56494,  9451,  9472,  9479,\n",
       "          9536,  9582, 20123,  9783, 24953, 35699, 19982, 62491, 63607,\n",
       "         63634, 63661, 40649,  5711, 40567, 47878, 23374, 39961, 55699,\n",
       "         48004, 39842,  6133,  6207, 39702,  6535,  6550, 38882,  6892,\n",
       "          7040,  7212, 38361, 55995,  7499, 37911, 48719,  7837,  7885,\n",
       "         49794, 10479, 10613, 10643, 14640, 14860, 30205, 15214, 29514,\n",
       "         52636, 29006, 15821, 58677, 16054, 18238, 16232, 53992, 57561,\n",
       "         16377, 18161, 28166, 53056, 57614, 53897, 17326, 58258, 58213,\n",
       "         17524, 53849, 14620, 47689, 30418, 59540, 10745, 35228, 10974,\n",
       "         34919, 34853, 19457, 61307, 11185, 11243, 11301, 50153, 61229,\n",
       "         61006, 50396, 19453, 25356, 12080, 50702, 25392, 33095, 33024,\n",
       "         31767, 18970, 31235, 51521, 30729, 41255, 20227,  4746,  1585,\n",
       "         44559, 45595, 22880,  1535, 41902, 44637, 66551, 41991, 65919,\n",
       "         46746, 67223, 42119, 67109,   669,  3202, 42129, 55083, 45691,\n",
       "         44997,  3630, 66224, 22357, 46961, 55414,  4264, 42852,  4426,\n",
       "         43954,  4353,  1912, 45562, 45512, 66683, 45522, 54828, 21596,\n",
       "         51500, 51468, 11180,  2319, 22846, 13018, 51462, 31980, 57114,\n",
       "         51379, 32122, 19147, 51270, 34652, 61035, 11144, 14239, 14213,\n",
       "         14210, 52089, 46022, 18802, 51711,  2349, 34847, 22691, 51607,\n",
       "         13866, 51577,  1319, 32218, 59931, 30887, 25445, 12856, 22486,\n",
       "         56846, 50162, 11384, 34301, 66898, 25298, 34234, 60974, 11991,\n",
       "         56760, 66815, 61001, 50288, 44542, 34130, 33131, 34604, 12565,\n",
       "         44647, 60488, 34213, 51188, 50120, 32492, 56854, 12727, 32779,\n",
       "         32856, 12689, 12683, 11325, 32872, 14338, 22842, 60828, 12651,\n",
       "         41555, 14404, 27854, 53217, 27915,   273, 53034, 16888, 53011,\n",
       "         45397, 27850, 28194, 16403, 67176, 45234, 16238,   455, 45606,\n",
       "         45114, 22688, 16476, 28418, 53329, 27456,    22, 27006, 27021,\n",
       "         17611, 58038, 53824, 67265, 53818, 17075, 17881, 57873, 22450,\n",
       "           110, 67264, 26707, 17231, 26670, 17141, 53634, 28570, 28789,\n",
       "         58703, 26309, 52443, 52400, 57281, 30238, 54146, 14807, 30409,\n",
       "         29790, 18742, 46111, 45975, 52128, 52098, 59322, 18760, 30607,\n",
       "         25887, 59281, 52487, 15086, 15089, 52815,   554, 28884, 28919,\n",
       "           578, 58719, 26411, 52688, 22387, 52618, 15486, 52559, 57464,\n",
       "         18331, 26353, 29563, 54083, 29619, 52531, 30659,   753, 50029,\n",
       "         43968, 48722, 55450, 47069,  7678, 42156, 56007, 37964, 55495,\n",
       "         47067, 24292, 24217,  7308, 63809, 63853, 38368, 48504, 23832,\n",
       "         38600, 38128, 37787, 48864,  7977, 56292,  8504, 63347, 48945,\n",
       "         20708, 10975, 20713, 37320, 48885, 37338, 42800, 37369, 37391,\n",
       "         37419, 42663, 21772, 24392, 37653, 66221, 23709, 63298, 23499,\n",
       "         21306,  5825, 40355, 65331, 47301, 23305, 47872,  5486, 64973,\n",
       "         47989, 21474, 21485, 41202, 23344,  5080,  5007, 47355, 47577,\n",
       "         41544, 65070, 64524, 65370,  5896, 39128, 39195, 41944, 21339,\n",
       "         39547, 39553, 39643, 39670, 64133, 39682, 41811, 39802, 55604,\n",
       "         64204, 64261, 39814, 39923, 21667,  5909, 48217,  8583, 42814,\n",
       "         43181, 61974,  2777, 10030,  2782, 49603, 43359, 49602, 24931,\n",
       "         62287, 62386, 54395, 22069, 49395, 23071,  2939,  8650, 21941,\n",
       "         56577, 36226, 10124, 10133, 54387, 61878, 61550, 49844, 19647,\n",
       "          2549, 19788, 10727, 10701, 22193, 43598, 62429, 10557, 22137,\n",
       "         61649, 35394, 61807, 25052, 43467, 35511, 10180, 25019, 35366,\n",
       "          9352, 17853, 49246, 24698, 62864, 24796, 23158, 62825,  3219,\n",
       "         23141, 46736, 20324, 24663,  9033,  8912, 62763, 49313, 63275,\n",
       "          8660, 20322, 24682, 57995, 37034, 36281,  8768, 36530, 63224,\n",
       "         25072, 24627, 25753, 26691, 24025, 54208, 25812, 54585, 54371,\n",
       "         26784, 25080, 26814, 22863, 25759, 54198, 54168, 25736, 55011,\n",
       "         23974, 23290, 54533, 54644, 54686, 23525, 54284, 23491, 25496,\n",
       "         25550, 54263, 23296, 55029, 23237, 25694, 55114, 22692, 23212,\n",
       "         54819, 25840, 67325, 27020, 47631, 40770, 40684, 47882, 40252,\n",
       "         39949, 39220, 48211, 39109, 48328, 39048, 38883, 48473, 38556,\n",
       "         48505, 38217, 38135, 37025, 37056, 37070, 37073, 37180, 37276,\n",
       "         41678, 37281, 37572, 48871, 37916, 38005, 48717, 38048, 37309,\n",
       "         36973, 41693, 41794, 45435, 45658, 45048, 44967, 44762, 44742,\n",
       "         46055, 44655, 44551, 46095, 46096, 44084, 44076, 43865, 46630,\n",
       "         43329, 43307, 47119, 41892, 42019, 47115, 42120, 42346, 47124,\n",
       "         47005, 42693, 46931, 42949, 46838, 43137, 46660, 46985, 53825,\n",
       "         49210, 49287, 31216, 31089, 31041, 30951, 30895, 30866, 51855,\n",
       "         30628, 30569, 52104, 30417, 30271, 52211, 30122, 52460, 29595,\n",
       "         29559, 53761, 53603, 53525, 27249, 27327, 53425, 51519, 27440,\n",
       "         28234, 28332, 52875, 29023, 29491, 29545, 52981, 49224, 31330,\n",
       "         31816, 49381, 36337, 36309, 49393, 36224, 36213, 49461, 49498,\n",
       "         35732, 49613, 35608, 49646, 49801, 49805, 49811, 35313, 34997,\n",
       "         32001, 51308, 32210, 32260, 51107, 50834, 31501, 33165, 33761,\n",
       "         33872, 33912, 50410, 34674, 34733, 33366, 50056, 22209, 64577,\n",
       "         15443, 58836,  6525,  6615, 15160,  6633,  6673,  6695,  6743,\n",
       "         14942,  6835, 14819, 59204, 63922,  7030,  7048,  7271,  7345,\n",
       "         14607, 14514, 59332, 59351, 59437, 59451, 59476,  6454, 64076,\n",
       "         15444, 15556, 58008, 17697, 17649, 58101, 65733, 58276, 17310,\n",
       "         58398, 17145, 17091,  4504,  4771, 14122,  5143, 16489, 16330,\n",
       "         65003, 16005,  5833, 64513,  5885, 15747, 64496, 64452,  6011,\n",
       "          6173, 58531, 17746, 59485, 13968, 60879,  9091,  9098,  9166,\n",
       "         12384,  9244, 62388,  9595,  9603,  9614,  9843, 11504, 10169,\n",
       "         61210, 11349, 61275, 11284, 11172, 10306, 11074, 61310, 61320,\n",
       "         10972, 61761, 61613, 62640, 62695, 60755,  9002,  7520, 59692,\n",
       "          7551,  7736,  7887, 59912, 13724,  8016, 63576, 60133,  8174,\n",
       "         13320, 59531,  8187,  8199,  8303, 13225, 13063, 12976, 63363,\n",
       "          8473, 63294,  8708,  8732, 12786, 12665, 13302,  4086, 61562,\n",
       "         20455, 21287, 56792,   979, 19198,   899,  2872,  2884, 57037,\n",
       "          2832,  2962, 18902, 18871, 66474, 21525, 21534,   700, 66397,\n",
       "         66328, 56035, 21744,  2827, 19561, 55986, 20755, 55965,  2327,\n",
       "         57926, 66655, 21067, 20406,  2636, 20226, 66957, 20107,  1405,\n",
       "         21069, 19807, 21101, 19638,  1355,  2439, 18769,  2964, 67135,\n",
       "         22027, 21875,  3510,   103, 57332, 22194, 66004, 57331, 67166,\n",
       "         55178, 18706,  3627, 55212, 21835, 57320, 22346, 44688,   697,\n",
       "          1369, 35478, 49783, 63491, 63481,  8390,  8419, 37366,  8274,\n",
       "           173, 35406, 37721, 10744,  7964,    94, 10499, 37673, 35436,\n",
       "         44480,  8136,  8159, 37566, 37533, 66804,  1555, 63626, 37252,\n",
       "         44710, 48933, 49228,  8977, 44843, 62199, 35843, 44898, 44940,\n",
       "         62673,  9068, 49472, 45075,   735, 45778, 45043, 45703, 62088,\n",
       "         67128,  9974,  8963,  9322, 44713, 67008,  8529, 10275, 44757,\n",
       "         45637,   476,   518, 10141, 35668,  8802, 35678, 49126, 62849,\n",
       "         44831, 46078,  4010, 37864, 47628,  4980,  5122,  5123, 41110,\n",
       "         41108,  3460, 65088, 40754, 40726, 66313, 47859,  5618, 40658,\n",
       "         40628, 64731,  5788, 10820,  3266, 47582, 65094, 41469, 47432,\n",
       "         42028, 65926, 42036,  3925,  3896, 42192, 47117,  4098, 66178,\n",
       "         40180, 65840,  3652, 65501,  4292,  4325, 47257,  3589, 65278,\n",
       "          4735, 47361,  3670, 47930,  5848, 66493, 46313, 43863, 66568,\n",
       "          2462, 46236,  7360, 48555, 66677, 38053, 43797, 48569,  7425,\n",
       "          7435, 44134, 63723, 44145, 37968,  2158,  2127, 63708, 44118,\n",
       "          7864, 63947, 38668,  3037,  2999, 39759, 64184, 43188, 64182,\n",
       "         48139, 39482, 48171,  6844, 39219, 66554,  6667, 46391, 39079,\n",
       "         46360, 63958,  6843, 48363, 48436, 39215, 22579, 11716, 28731,\n",
       "         15810], dtype=int64),\n",
       "  'feature_absent_idx': array([59198, 57715, 45968, 28775, 45969, 28772, 13014, 28768, 13016,\n",
       "         28767, 13020, 28765, 45976, 57699, 13003, 13028, 28759, 45984,\n",
       "         45986, 28754, 57688, 13037, 45990, 13040, 57683, 45993, 45994,\n",
       "         28738, 13052, 13029, 57676, 13002, 57717, 45953, 28805, 28803,\n",
       "         12960, 57745, 57741, 12964, 12969, 12970, 12971, 12973, 57736,\n",
       "         57735, 28777, 57731, 28792, 28791, 12983, 28788, 57725, 12987,\n",
       "         12989, 57723, 28784, 28783, 28779, 28778, 57718, 57730, 28727,\n",
       "         57670, 57667, 28697, 13112, 46023, 57629, 46024, 57628, 28688,\n",
       "         57626, 46028, 28684, 46036, 57611, 57609, 28699, 28677, 28676,\n",
       "         57601, 57599, 57596, 13146, 46047, 13148, 13149, 57594, 13151,\n",
       "         57591, 13154, 28664, 57605, 13108, 57641, 13106, 57666, 13065,\n",
       "         57665, 46006, 28724, 46007, 57662, 46008, 57656, 46013, 13079,\n",
       "         28715, 13081, 28714, 28713, 13084, 57650, 46016, 46018, 13095,\n",
       "         13096, 28703, 13098, 28702, 13101, 28700, 13103, 57643, 57642,\n",
       "         57750, 46049, 12952, 57753, 28924, 45872, 12805, 12807, 57876,\n",
       "         45874, 12811, 12812, 12813, 45879, 57867, 57864, 12824, 28927,\n",
       "         57860, 28909, 12829, 28907, 57857, 57856, 28905, 12835, 28902,\n",
       "         28901, 28900, 28897, 28896, 28895, 12826, 28893, 28928, 28929,\n",
       "         45846, 28957, 45847, 57901, 12762, 12763, 57900, 57899, 45849,\n",
       "         28954, 12768, 12769, 12770, 12799, 12771, 45856, 12777, 57898,\n",
       "         12782, 28942, 28940, 45863, 57887, 45864, 57885, 45865, 28933,\n",
       "         28932, 12773, 57850, 57846, 28890, 12901, 28853, 28850, 45923,\n",
       "         45927, 28840, 12915, 57782, 28839, 45929, 45935, 57772, 57770,\n",
       "         12898, 28827, 45939, 28823, 57768, 57766, 45945, 28818, 28817,\n",
       "         57762, 45948, 12943, 28815, 12947, 12948, 12930, 28860, 12894,\n",
       "         12892, 12851, 12852, 12854, 28887, 57840, 12858, 45892, 12862,\n",
       "         57835, 12865, 28881, 28880, 57825, 57821, 45895, 45899, 45900,\n",
       "         45903, 12877, 12878, 57811, 12880, 45904, 57807, 57801, 28868,\n",
       "         28865, 57796, 57795, 12951, 57907, 13160, 57579, 13422, 13423,\n",
       "         13425, 13426, 28473, 46187, 13429, 57367, 13435, 57366, 57365,\n",
       "         57362, 13441, 28476, 57359, 13446, 13448, 46199, 57352, 13454,\n",
       "         57350, 28452, 57344, 28450, 57341, 28448, 28447, 13463, 46198,\n",
       "         57339, 46184, 46183, 57422, 28501, 57420, 28500, 57415, 57413,\n",
       "         28498, 57405, 57403, 57401, 57399, 28494, 57395, 28478, 28493,\n",
       "         46172, 57392, 13405, 57391, 57389, 28487, 46180, 13410, 57386,\n",
       "         28482, 13415, 46182, 57381, 13399, 13466, 13467, 28445, 57299,\n",
       "         13524, 57297, 13532, 28398, 28397, 13536, 57283, 46258, 13541,\n",
       "         28388, 57271, 28383, 13520, 28382, 57265, 13551, 28378, 13557,\n",
       "         46268, 28374, 46271, 57261, 28371, 28370, 13564, 13565, 13566,\n",
       "         57266, 13519, 28407, 57301, 46209, 57336, 57334, 28441, 13476,\n",
       "         28439, 57329, 28436, 46214, 13485, 57325, 28429, 46228, 13494,\n",
       "         13495, 46237, 13498, 28421, 46239, 28416, 46241, 13507, 57306,\n",
       "         13511, 57305, 13513, 28410, 28408, 57303, 57423, 13161, 46168,\n",
       "         28504, 13221, 28612, 46100, 57544, 28605, 13233, 28602, 46110,\n",
       "         28595, 46117, 28592, 13243, 28589, 13219, 13247, 46120, 57526,\n",
       "         57525, 57524, 13255, 28583, 13259, 57518, 57516, 57513, 28580,\n",
       "         46124, 57511, 13249, 13269, 57550, 13214, 13167, 57578, 46063,\n",
       "         13173, 28649, 46066, 13176, 46067, 28642, 46071, 57571, 13183,\n",
       "         57570, 13217, 46075, 57567, 57566, 13190, 13193, 28634, 28630,\n",
       "         46088, 13201, 46089, 28624, 28622, 28621, 13209, 57568, 13271,\n",
       "         13273, 13274, 13338, 28530, 28529, 57450, 13344, 13345, 13347,\n",
       "         28525, 57447, 28521, 28520, 57442, 28519, 28534, 57441, 46158,\n",
       "         46159, 13362, 13364, 13365, 46162, 57433, 46163, 57430, 57429,\n",
       "         46164, 57428, 57427, 57437, 13333, 46146, 28536, 57502, 13280,\n",
       "         57501, 57493, 46128, 46129, 13288, 46130, 13290, 13292, 13293,\n",
       "         13295, 28562, 28558, 46135, 13301, 28552, 13307, 13311, 57480,\n",
       "         28548, 46138, 13317, 28544, 13322, 57468, 13328, 13329, 28537,\n",
       "         57425, 57257, 57908, 57911, 29389, 12178, 58340, 29388, 58337,\n",
       "         29387, 12184, 12186, 58333, 29383, 29382, 29380, 29377, 45583,\n",
       "         45592, 29372, 12202, 45594, 29368, 12205, 12207, 45598, 45599,\n",
       "         58318, 12212, 58316, 45600, 12215, 12198, 58311, 29392, 45576,\n",
       "         29432, 29430, 58373, 45565, 12132, 45567, 12134, 29424, 29423,\n",
       "         29422, 58367, 12142, 12143, 29393, 29414, 29413, 58363, 58361,\n",
       "         45573, 29410, 58360, 58358, 29408, 12158, 58357, 29406, 58354,\n",
       "         58349, 58364, 58310, 12218, 58305, 58283, 12267, 45618, 58277,\n",
       "         58274, 45619, 29329, 29326, 58267, 12279, 12283, 29320, 29317,\n",
       "         45616, 45626, 12293, 12294, 12297, 45628, 29308, 58254, 29306,\n",
       "         29305, 29304, 29303, 58246, 12308, 12313, 12292, 29334, 58285,\n",
       "         29335, 29357, 12224, 58301, 45603, 29353, 12230, 29352, 58297,\n",
       "         12234, 58294, 12236, 29350, 29349, 12239, 12240, 29346, 29345,\n",
       "         12243, 45609, 58292, 12247, 12251, 12252, 12253, 12254, 45611,\n",
       "         12258, 45615, 58286, 58380, 58243, 29433, 29436, 29552, 11968,\n",
       "         45477, 58513, 29549, 29548, 29547, 29544, 11975, 11976, 29543,\n",
       "         58506, 45488, 45473, 11984, 58502, 11987, 45489, 58496, 29532,\n",
       "         11994, 11995, 29529, 58491, 29526, 58489, 58488, 29525, 11985,\n",
       "         29522, 29558, 58519, 29602, 29601, 29597, 11914, 45446, 58559,\n",
       "         58553, 11922, 11923, 58548, 45457, 45458, 11931, 11959, 29580,\n",
       "         45462, 58538, 11939, 11940, 58537, 58536, 29574, 29572, 58526,\n",
       "         29569, 45467, 11952, 45469, 45460, 29521, 45500, 29516, 45520,\n",
       "         58434, 58429, 58428, 12075, 29470, 12079, 29465, 58416, 58415,\n",
       "         12087, 58413, 58411, 58438, 29462, 45535, 29453, 45542, 12104,\n",
       "         45544, 12106, 29444, 12108, 12109, 58389, 58388, 45553, 58385,\n",
       "         29461, 12064, 58439, 12062, 12013, 12014, 12015, 12017, 29508,\n",
       "         58476, 12022, 29504, 12029, 45504, 58465, 12033, 29495, 45509,\n",
       "         58460, 29490, 45511, 12045, 12046, 12047, 58450, 29483, 58444,\n",
       "         12056, 29482, 58443, 12059, 29481, 58442, 45557, 45843, 12315,\n",
       "         12318, 12586, 58030, 58029, 29086, 12592, 12595, 12596, 12597,\n",
       "         12598, 58021, 45769, 29071, 58017, 58032, 45779, 58006, 58000,\n",
       "         57998, 45786, 12633, 12634, 29042, 29041, 29040, 29039, 57991,\n",
       "         57990, 57988, 29058, 12644, 12583, 45761, 58060, 29119, 29115,\n",
       "         29114, 12544, 58057, 12546, 29111, 12550, 58052, 29110, 29107,\n",
       "         58049, 12581, 12557, 45747, 12562, 58046, 29098, 29097, 12568,\n",
       "         45758, 29094, 12574, 58039, 58037, 58036, 58034, 29105, 29035,\n",
       "         29033, 29032, 45823, 12707, 45824, 45826, 12710, 12711, 12714,\n",
       "         28986, 57940, 12717, 57938, 12721, 28983, 28993, 12723, 28982,\n",
       "         28981, 45828, 57933, 57929, 28976, 57927, 57924, 12739, 12742,\n",
       "         57922, 57919, 28964, 57937, 28994, 57953, 12696, 57978, 12653,\n",
       "         29029, 57977, 57975, 57974, 57973, 57972, 29028, 12661, 57971,\n",
       "         12663, 12664, 45800, 12667, 45803, 57968, 29020, 45807, 12675,\n",
       "         12676, 45809, 29012, 29008, 29007, 57960, 29004, 12693, 57955,\n",
       "         45743, 58242, 12534, 45740, 58197, 58195, 45664, 45671, 12390,\n",
       "         12391, 29239, 58191, 45672, 45674, 29229, 12404, 58179, 29249,\n",
       "         58178, 12411, 12412, 45683, 29219, 12418, 58163, 29214, 29213,\n",
       "         58158, 12428, 45695, 58152, 12431, 29226, 58151, 29252, 58200,\n",
       "         58240, 58239, 58237, 58236, 45634, 45635, 29287, 45638, 29284,\n",
       "         45639, 12338, 58221, 12344, 12374, 45643, 58215, 58208, 12356,\n",
       "         58207, 45652, 12362, 12363, 12365, 58203, 12367, 12368, 29254,\n",
       "         12372, 12346, 45696, 29205, 29200, 12491, 45717, 12494, 12495,\n",
       "         45722, 58092, 58090, 45725, 29152, 45726, 12506, 29149, 29147,\n",
       "         12490, 29146, 12512, 45731, 29140, 29139, 45732, 58072, 29135,\n",
       "         29133, 29131, 45736, 12527, 29127, 12530, 12510, 29161, 45716,\n",
       "         12484], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_path': {'feature_present_idx': array([37800, 50562, 33176,  3269, 29994, 56376, 17503, 19240, 28068,\n",
       "         42607, 42185, 21975, 40725, 11169, 11937, 66963, 36941, 13099,\n",
       "         13188, 43003, 23334, 31413, 30238, 27380, 15244, 46565, 21542,\n",
       "         58943, 59772, 54230,  2868, 50196, 53141,  7152,  7559,  7729,\n",
       "           499, 59251, 66508, 23419, 24677, 22738, 25507, 64684, 26083,\n",
       "         26762, 64425, 60046, 29928, 47192, 47057, 57175, 53706, 34464,\n",
       "         36739, 53682, 37059, 52891, 40191, 49777, 41021, 47534, 31215,\n",
       "         41585, 67146,  4379, 10461, 10172,  4774,  8742, 13913, 17851,\n",
       "         21442, 53905, 53608, 49382, 48646, 47252, 53926, 45792, 43188,\n",
       "          9546, 12041, 36312, 48245,  4617, 54381, 56148, 66935, 66348,\n",
       "         65606, 65599, 63895, 63205, 61501, 36171, 61103,  1439, 59513,\n",
       "          2021, 58913, 57888, 57636, 56192, 60426, 13042, 47235,   330,\n",
       "         32171, 14836, 27785, 19141, 19568, 33089, 22192, 17382, 21551,\n",
       "         20381, 21432, 31099,  7420, 14170,  6754, 49995,  6303, 52246,\n",
       "         52491, 66558,  5060,  1082,  4681, 62501, 54325, 54649,  4511,\n",
       "         26284,  7752, 58602, 58710, 59631, 60123, 66232, 23012, 65717,\n",
       "         61526,  1198,  8620, 34499, 52295, 42379, 10094, 43070, 43078,\n",
       "         41310, 32748, 32836, 40489, 43131, 13960, 12794, 35561, 38723,\n",
       "         39498, 66891, 54055, 42040, 27004, 54450, 66850, 41557, 56647,\n",
       "         21926, 57847, 57982, 53954, 22393, 37637,  3377, 59361, 24329,\n",
       "         40221, 57834, 15447, 16497, 48611,  6666, 49915, 44150, 50770,\n",
       "         51219, 51230, 14297,  9955, 31773,  5863, 46219, 15009, 52566,\n",
       "         17889, 59775, 11413, 12732, 49225,  1288, 12679,  1393, 46893,\n",
       "         58392, 26484, 45439, 21177, 32494, 27063, 25572, 50373, 36963,\n",
       "         44827, 65944, 33119, 13314, 30250, 18171, 62919, 39937, 51932,\n",
       "         34049, 53472, 62974, 44718, 49273, 51745, 36485, 26922, 46506,\n",
       "         53876,  8682, 42649, 35310], dtype=int64),\n",
       "  'feature_absent_idx': array([61527, 18850, 46016, 18847, 46018, 18841, 63427, 46023, 46024,\n",
       "         46028, 18832, 18830, 18826, 63432, 46036, 18808, 46013, 63436,\n",
       "         18855, 18860, 45986, 18898, 45990, 18894, 45993, 45994, 18889,\n",
       "         18887, 57762, 18880, 46006, 46007, 46008, 18867, 18864, 18856,\n",
       "         18796, 18794, 18791, 18727, 63450, 63452, 18718, 18715, 18714,\n",
       "         18712, 18707, 46088, 46089, 18700, 57745, 18694, 18691, 46100,\n",
       "         63449, 46075, 18732, 18733, 46047, 46049, 63438, 18783, 18778,\n",
       "         18773, 18765, 45984, 57753, 46063, 46066, 46067, 18750, 63445,\n",
       "         46071, 57750, 18761, 63460, 18911, 18919, 19074, 45903, 45904,\n",
       "         63383, 57782, 63385, 19052, 19051, 19045, 19040, 19038, 19036,\n",
       "         19031, 45923, 19021, 45900, 45927, 63381, 19079, 19124, 19123,\n",
       "         19119, 63375, 45892, 19103, 63378, 45895, 19088, 19087, 19086,\n",
       "         19085, 19084, 19083, 19080, 45899, 45929, 45935, 63393, 18954,\n",
       "         18953, 18952, 18951, 18948, 18947, 18946, 63405, 18942, 45968,\n",
       "         18938, 45969, 63409, 63410, 45976, 57766, 18960, 57768, 45953,\n",
       "         57772, 19001, 45939, 63397, 18998, 63398, 18993, 18912, 18992,\n",
       "         45945, 57770, 45948, 18980, 18979, 18977, 18973, 18989, 19127,\n",
       "         18678, 46110, 18392, 18391, 18389, 46268, 18383, 46271, 63523,\n",
       "         18376, 46274, 18371, 18370, 18369, 18361, 46284, 18355, 46258,\n",
       "         63528, 18400, 18412, 18469, 57718, 57717, 46228, 57715, 18451,\n",
       "         46237, 46239, 63513, 63514, 46241, 18426, 18423, 18422, 18420,\n",
       "         18402, 46287, 18344, 18343, 46334, 18267, 46341, 46342, 46343,\n",
       "         46344, 63545, 18255, 18254, 18253, 18247, 46349, 18239, 18237,\n",
       "         18236, 18283, 63540, 18294, 46317, 18337, 18336, 18334, 46294,\n",
       "         18332, 18330, 46299, 46214, 18324, 46304, 46305, 18304, 46312,\n",
       "         57699, 46314, 46316, 18315, 57741, 63506, 46209, 46135, 18624,\n",
       "         18623, 18622, 46138, 18619], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 238\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 238\n",
       "  })},\n",
       " 'contains_polarity': {'feature_present_idx': array([46026, 38879, 36414, 17654, 23330, 37429, 57545, 48121, 19694,\n",
       "         57541,  2293, 14632, 66406, 36679, 35610, 53580, 24654,  2459,\n",
       "         48275, 46626, 19377, 34987, 49591, 51795, 53289, 53470, 54056,\n",
       "         16513, 49328, 17555, 25197, 45456, 36655, 36161, 35649, 34937,\n",
       "         34514, 33619, 36970, 37552, 23278, 31827, 38631, 39392, 39630,\n",
       "         39955, 40116, 40179, 26559, 54417, 38459, 16437, 36648, 64338,\n",
       "          8428,  2933,  7380,  2600,  6069,  2685,  1004, 10297, 60865,\n",
       "          8777,   922, 11872, 58691, 55445,  3360, 13634, 56069, 57672,\n",
       "         64994, 66745, 14544, 30186, 43941, 32231,  1979, 41783, 37699,\n",
       "          3165,  5555,  2855, 66371, 31518, 38023, 33442, 36929,  3791,\n",
       "         24869, 44326, 16314, 15689, 17281,   916, 17844, 52727, 57823,\n",
       "         18819, 12393, 48783, 24694, 61041, 20980,  1027, 22008, 22089,\n",
       "         22388, 23081, 36890, 45848,  9037, 45297, 61174, 32881, 55988,\n",
       "         64386, 39724, 40075, 64345, 40898, 41905, 64058, 45905, 62732,\n",
       "         60061, 57729, 56378, 65652, 52049,   157, 27244, 29154, 16326,\n",
       "         28490, 19411,  6030, 17773, 18476, 29187, 24666, 23474, 36508,\n",
       "         21348, 20969, 19328, 20515, 20039, 24382, 29772,  9262,  9426,\n",
       "         10918, 33603, 33481, 32055, 11246, 57155, 49394, 62689, 61786,\n",
       "          9368, 50080,  3788, 51864, 60783, 18657, 52459, 59549, 64589,\n",
       "         16972, 53844,  5554, 59404, 16348, 12352, 13094, 13905, 57456,\n",
       "         57364, 15696, 19152,  9175, 32788, 65185, 39446, 28734, 38371,\n",
       "         37986, 42101, 43557, 43652, 43824, 30237, 37028, 44824, 34073,\n",
       "         45723, 66863, 35521, 36296, 36459,  3657, 14631, 61085, 58402,\n",
       "         57872, 57720, 66564, 48561, 29990, 17110, 47421, 49850, 46668,\n",
       "         20779, 44779, 30146, 25473, 49298, 64358, 26320,  2917, 56445,\n",
       "          9141, 52031, 23425, 12864,   169, 15448, 31245, 14222, 36644,\n",
       "         54238, 16541, 53349, 51146, 19330, 38408, 60695, 30862, 67055,\n",
       "         16502, 25048, 26565,  1533], dtype=int64),\n",
       "  'feature_absent_idx': array([29788, 12717, 12721, 28310, 12723, 28304, 45609, 57579, 57578,\n",
       "         28299, 45611, 12739, 45615, 45616, 57591, 12742, 57570, 57568,\n",
       "         57567, 57566, 45618, 45619, 45626, 12762, 12763, 45628, 28274,\n",
       "         12768, 12769, 57571, 12770, 57594, 45603, 45576, 12675, 12676,\n",
       "         57629, 57628, 28341, 45583, 57626, 28337, 28333, 28331, 57611,\n",
       "         57609, 12714, 45592, 45594, 12696, 57605, 45598, 45599, 45600,\n",
       "         57601, 57599, 12707, 57596, 12710, 12711, 28316, 12693, 12771,\n",
       "         12773, 28267, 12826, 12829, 45664, 57502, 57501, 12835, 28225,\n",
       "         28224, 57493, 28218, 45671, 45672, 28213, 28232, 12851, 45674,\n",
       "         12854, 28209, 28208, 28207, 12858, 57480, 28205, 12862, 12865,\n",
       "         57468, 45683, 12877, 12852, 12824, 28233, 57511, 12777, 57550,\n",
       "         28265, 28264, 12782, 57544, 45634, 45635, 45638, 45639, 45643,\n",
       "         28248, 12799, 57526, 57525, 57524, 28247, 12805, 12807, 28241,\n",
       "         12811, 12812, 12813, 57518, 57516, 28240, 45652, 57513, 28238,\n",
       "         45573, 12878, 28350, 12664, 12506, 28473, 45488, 45489, 12510,\n",
       "         12512, 57753, 57750, 57745, 45500, 57741, 12527, 28452, 57762,\n",
       "         12530, 57735, 12534, 28450, 45504, 57731, 28448, 28447, 28445,\n",
       "         57730, 12544, 12546, 28441, 57725, 57736, 45509, 28476, 57768,\n",
       "         12460, 45458, 57796, 57795, 45460, 45462, 12468, 28504, 45467,\n",
       "         28501, 28500, 28498, 57782, 57766, 28494, 12484, 45469, 28487,\n",
       "         45473, 12490, 12491, 45477, 28482, 12494, 12495, 57772, 57770,\n",
       "         28478, 28493, 12550, 57723, 28439, 57676, 28383, 28382, 57670,\n",
       "         57667, 57666, 57665, 28378, 45553, 45557, 12633, 12634, 28374,\n",
       "         28388, 28371, 28370, 57656, 12644, 45565, 57650, 45567, 28361,\n",
       "         12653, 57643, 57642, 57641, 12661, 12663, 57662, 45544, 45542,\n",
       "         28397, 28436, 45511, 12557, 12562, 57718, 57717, 57715, 28429,\n",
       "         12568, 12574, 45520, 28421, 28416, 12581, 57699, 12583, 12586,\n",
       "         57688, 28410, 12592, 28408], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 247\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 247\n",
       "  })},\n",
       " 'contains_polite': {'feature_present_idx': array([62414,  2806, 44269, 59069, 35535, 49762, 52887, 57711, 66405,\n",
       "         66599], dtype=int64),\n",
       "  'feature_absent_idx': array([18992, 57567, 57566, 28225, 28224, 45542, 28218, 12693, 45544,\n",
       "         12696], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 10\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 10\n",
       "  })},\n",
       " 'contains_poss': {'feature_present_idx': array([67343, 10631, 10675, 10714, 10840, 10888, 49179, 49144, 49109,\n",
       "         10961, 48988, 50102, 11091, 48805, 11280, 48670, 11449, 48556,\n",
       "         48553, 48409, 48347, 11654, 48228, 48839, 11692, 50210, 50305,\n",
       "          9134, 52112, 52045,  9269,  9334,  9373,  9477, 51825, 51699,\n",
       "          9581, 50302,  9645, 51105, 51037,  9871, 50945, 50886, 10013,\n",
       "         50716, 10066, 50569, 10186, 51309,  9130, 48149, 11878, 13354,\n",
       "         45630, 45550, 45208, 45087, 45066, 13667, 45034, 13746, 13766,\n",
       "         13343, 44783, 13895, 44638, 13980, 44555, 13998, 14003, 44444,\n",
       "         44190, 14119, 14184, 44776, 48101, 45773, 45898, 11880, 11890,\n",
       "         47946, 12012, 47822, 47722, 12177, 47591, 12231, 47379, 45878,\n",
       "         47339, 12514, 12613, 46719, 46579, 46543, 46491, 46479, 13005,\n",
       "         13030, 46010, 47280, 44089,  9060, 52286, 58493, 58218,  5234,\n",
       "          5259, 58128,  5333,  5394,  5454, 57993, 57894, 58574, 57879,\n",
       "         57616, 57582, 57470,  5723, 57075, 56818, 56796, 56794,  6212,\n",
       "         56638, 57695,  6315, 58591, 58879, 60938, 60757,  3905, 60609,\n",
       "         60467, 60406, 60375, 60233, 60193, 60114,  4900, 59886, 59758,\n",
       "         59740,  4536, 59445, 59252, 59166,  4702,  4725,  4762, 59076,\n",
       "         59765, 52217,  6352,  6406,  7971,  8065, 53531,  8153,  8179,\n",
       "         53521, 53259, 53222, 53191, 53107, 53906, 53075,  8548,  8618,\n",
       "          8657, 52828, 52706, 52642,  8805, 52397, 52393, 52379, 53010,\n",
       "         56303, 53909, 53971, 56209, 56116, 56051, 55791,  6862, 55558,\n",
       "         55515, 55246, 55048, 54949,  7882, 54917, 54872,  7313,  7614,\n",
       "          7671, 54300,  7727,  7734, 54040,  7830,  7869, 54904, 44087,\n",
       "         14309, 43642, 32258, 32246, 32157, 32147, 32085, 21313, 32045,\n",
       "         31953, 31850, 21444, 32289, 31818, 21494, 31597, 21612, 31249,\n",
       "         21888, 31196, 21999, 30911, 30882, 30854, 31791, 30638, 20992,\n",
       "         32595, 19858, 34017, 19971, 33992, 33894, 33812, 33750, 20230,\n",
       "         20238, 20289, 32479, 33586, 33406, 20398, 33349, 33175, 20648,\n",
       "         20697, 33110, 20769, 33015, 32817, 33564, 19828, 30631, 22280,\n",
       "         27760, 24242, 24276, 27378, 27338, 27267, 27167, 24629, 27003,\n",
       "         26921, 27874, 24732, 24819, 24999, 26352, 25198, 25211, 26071,\n",
       "         25266, 25999, 25878, 25844, 26866, 30588, 23846, 23531, 30544,\n",
       "         30476, 30357, 22498, 22581, 30198, 30150, 22762, 29819, 22891,\n",
       "         28211, 22915, 22944, 29623, 23055, 29292, 29271, 29201, 23375,\n",
       "         29144, 29088, 28882, 29718, 34351, 34403, 19712, 15607, 41539,\n",
       "         41502, 15855, 41470, 41404, 41386, 15961, 41280, 16150, 41863,\n",
       "         16171, 16235, 40901, 40625, 16491, 40479, 40243, 40010, 39989,\n",
       "         39867, 39784, 41103, 39751, 42266, 15388, 14471, 43553, 43490,\n",
       "         14576, 14641, 14671, 14840, 43091, 14886, 42981, 15394, 14976,\n",
       "         15111, 42648, 42589, 15199, 42436, 15317, 15319, 15321, 15322,\n",
       "         42402, 15033, 16980, 39561, 39404, 18421, 18659, 18702, 36378,\n",
       "         36375, 18722, 36203, 18907, 18924, 18925, 36869, 35707, 35554,\n",
       "         35410, 35397, 35360, 35270, 19360, 34814, 34787, 34736, 34734,\n",
       "         35578, 18316, 37032, 37037, 39386, 39314, 39217, 39165, 38950,\n",
       "         38909, 17366, 17398, 38328, 38313, 38200, 17660, 37966, 17744,\n",
       "         17761, 37876, 17878, 37623, 37594, 37492, 18057, 18205, 37094,\n",
       "          3727,  3726, 25484, 65822,  2543, 64627, 61845, 65092, 63283,\n",
       "          2087,  2684, 62203, 66349, 63938, 64987, 64413,  3274,   434,\n",
       "         62374, 65627, 66345,  2330,  1798, 66482,  3126, 66657, 64109,\n",
       "          2513, 67267, 62724,  2250,   315, 61186, 65688, 62210,  3428,\n",
       "          3549, 62956, 65347, 62207, 63308, 64875, 62741, 67051, 67219,\n",
       "         66189, 64873,  2110,  3572, 66794, 66872, 66470, 63966, 62060,\n",
       "           567,  1740, 63847,   261, 65573,  1608, 64817, 63229, 63910,\n",
       "         62635,  2921, 65642,  3251, 66643,  2815, 65435,  1091,  1983,\n",
       "         66713,  2914, 64273, 61589, 63925, 13632,  1948, 13669,  1940,\n",
       "         32044, 44944, 45057, 45040, 13706, 45038, 13715, 44979, 45029,\n",
       "         63942, 13764, 44873,  1929, 66567, 45119, 31813, 45728, 45742,\n",
       "         45746, 13356, 45753, 63893, 21488, 45724, 13299, 45813, 45854,\n",
       "         13276, 63855, 21504, 13218, 31715, 45920, 31781, 13624, 31814,\n",
       "         45574, 31924, 13590, 31900, 13567, 31871, 45284, 31861, 66550,\n",
       "         45622, 13534,   609, 45441, 45447, 45491, 21454, 45543,  1963,\n",
       "         45570, 31833, 44862, 46407, 32122, 43480, 64257, 14568, 20921,\n",
       "         32651, 14526, 32625, 32605, 43460, 66215, 43637, 64222, 43680,\n",
       "         43717, 43760, 32414, 43817, 43832, 32488, 43943, 43403, 32678,\n",
       "         14867, 64312, 33055,  1770, 43178, 32999, 43199, 43209, 14594,\n",
       "         43219, 43250, 32948, 32897, 43303, 32858, 32828,  3663, 43346,\n",
       "         14749, 32064, 43969, 14328,  1873, 66416, 64103, 64047, 44592,\n",
       "         13967, 21169, 13197, 44522, 13935, 21176, 44678, 32191, 44738,\n",
       "         13866, 32159, 64011, 13834, 21170, 14332, 44506, 44471, 21038,\n",
       "         32298, 44019, 14213, 14195, 32272, 32266, 44121, 44485, 44126,\n",
       "         21118,  1863, 21119, 44218, 44264, 44265, 44413, 44423, 44146,\n",
       "          1905, 12958, 13166, 63349, 30773, 30741, 48250, 48272, 11622,\n",
       "         22241, 48335, 48343, 48355, 30610, 30605, 11528, 11527, 11516,\n",
       "         30568, 35941, 11490, 63276, 22122, 63275, 48122, 48089, 12049,\n",
       "         21975, 63456,   544, 47837, 47838, 47853, 47857, 47877, 47880,\n",
       "         11935, 22001, 30950,   538,  2190, 63376, 30848, 30842, 48088,\n",
       "         63353, 47779, 48568, 48571, 48889, 11097,  2339, 48902, 48909,\n",
       "         30433, 48993, 11056, 22405, 30393, 30374, 63248, 49101,  2367,\n",
       "         10920, 22478, 49155, 30333,  2375, 22389, 11389, 22387,  2338,\n",
       "         30555,  2313, 48683, 48705, 30530, 30529, 48721, 48742, 30507,\n",
       "         11278, 30500, 30495, 48791,  2337, 11238, 11187, 30468, 22366,\n",
       "         22370, 30448, 45928, 47747, 31014, 63744, 12847, 46519, 12820,\n",
       "         21664, 46570, 46690, 31508, 46736, 46782, 12760, 12753, 12733,\n",
       "         46836, 46845, 46847, 12678, 31482, 21701,  2071, 46870, 46444,\n",
       "         31543, 45995, 63805, 31666, 31633, 46116, 46121, 46169, 46193,\n",
       "           577, 63791, 46261, 46289, 46320, 43075, 46348, 46351, 31570,\n",
       "         46385, 12909, 21628, 21963, 46880, 21723, 63640, 47301, 63578,\n",
       "         47365, 47371, 47382, 12278, 47478, 31193, 31171, 47588,  2137,\n",
       "         12191, 47601, 12164, 12151, 47647, 47668, 47713, 47270, 46914,\n",
       "         31231,   568, 46933, 31457, 31440, 21772, 47003, 47022, 47041,\n",
       "         63645, 21813, 31420, 31368, 47123, 12464, 12444, 31256, 47224,\n",
       "         12424, 47236, 12399, 47247,  1753, 14994, 43003, 17612, 38062,\n",
       "         38087, 38128, 19409, 38143, 34944, 65009, 38262, 38276, 17553,\n",
       "         38299, 19444, 64998, 38320, 17517, 38360, 38387, 17480, 35007,\n",
       "         17630, 35012, 38009, 35134, 37733, 19323, 35089, 37771, 35037,\n",
       "         17845, 35035, 37852, 38407, 37872, 17755, 19365, 65033, 17713,\n",
       "         19373, 17687, 65027, 65020, 37985, 35030, 37605, 38426, 38477,\n",
       "         17135, 39214, 64945, 39279, 17096, 39357, 34676,  1367, 34616,\n",
       "         39558, 17009, 16988,  1386, 19673, 16968, 34615, 39610, 39617,\n",
       "         39643, 19643, 39210, 34708,  1344, 34910, 34897,  1326, 19542,\n",
       "         17359, 38778,   946, 19594, 38907, 38461, 34771, 38941, 17259,\n",
       "          1342, 38970, 38971, 65680, 17205, 39045, 17170, 17283, 34559,\n",
       "         37603, 18001, 35760, 65479, 35736, 65620, 18968, 18996, 18663,\n",
       "         18997, 36519, 35652, 36530, 35596,   988, 18595, 36577, 36578,\n",
       "         18562, 35543, 35529, 35764, 18748, 36329, 36323, 18908, 65537,\n",
       "         36009, 18901, 36015, 18873, 35857, 36045, 36106, 19022, 36117,\n",
       "         36194, 35834, 36207, 18828, 36226, 35780, 36264, 36300, 36320,\n",
       "         65577, 37595, 36646, 36700, 35323, 18221, 37219, 37233, 37277,\n",
       "         37300, 19191, 35248, 37412, 37419, 18100, 18097, 18089, 35194,\n",
       "         65154, 18052, 65152, 37519, 65120, 19148, 35332, 35334, 18234,\n",
       "         36719, 19042, 36786, 36831, 65363, 18414, 18387, 36897, 36908,\n",
       "         65628], dtype=int64),\n",
       "  'feature_absent_idx': array([33693, 53657, 53660, 21100, 53662, 53664, 21086, 21085, 21084,\n",
       "         21083, 21071, 53679, 21068, 53684, 21066, 21064, 53652, 53687,\n",
       "         21116, 21123, 21149, 21148, 53638, 21146, 53639, 53641, 21137,\n",
       "         21135, 21134, 53643, 53645, 21129, 21128, 21125, 21124, 21122,\n",
       "         21060, 53688, 53694, 20985, 20984, 20983, 20981, 53743, 20979,\n",
       "         20977, 20972, 53754, 20965, 20959, 53771, 53772, 20948, 20947,\n",
       "         53741, 20988, 20990, 53735, 53700, 53703, 53705, 21036, 53708,\n",
       "         21030, 53712, 53636, 21026, 21019, 21016, 53718, 53719, 21011,\n",
       "         53726, 53730, 21020, 20945, 53627, 21164, 21322, 21321, 21319,\n",
       "         21305, 53547, 53552, 53556, 53560, 53561, 21275, 53562, 21271,\n",
       "         53565, 21269, 53566, 21323, 21266, 21324, 21330, 53502, 53508,\n",
       "         53511, 21353, 21349, 53513, 53515, 21345, 53516, 21343, 21342,\n",
       "         21340, 53523, 53526, 21333, 53529, 21264, 53568, 53570, 53600,\n",
       "         53601, 21209, 53602, 53606, 21202, 21200, 53613, 21188, 53617,\n",
       "         53619, 21178, 21175, 21171, 21165, 21215, 53597, 53595, 21218,\n",
       "         53571, 21251, 21244, 53582, 21242, 53584, 21235, 53626, 21234,\n",
       "         21231, 21228, 21227, 53591, 53592, 21221, 21220, 53590, 21365,\n",
       "         20939, 53780, 53956, 20650, 53959, 20646, 53962, 20641, 20639,\n",
       "         53964, 20635, 53966, 53967, 53969, 53970, 20622, 20620, 53953,\n",
       "         53975, 53952, 20663, 53927, 20707, 53929, 20701, 53933, 20694,\n",
       "         20685, 53939, 53941, 53942, 53943, 53945, 53946, 53950, 20664,\n",
       "         20659, 53987, 53988, 53990, 54024, 20533, 20530, 20525, 54031,\n",
       "         54032, 20520, 20519, 20518, 54037, 54041, 20508, 54043, 54045,\n",
       "         20501, 20538, 20540, 20551, 20552, 20608, 20606, 53993, 20601,\n",
       "         53994, 20599, 20597, 20712, 20584, 20577, 54010, 20575, 54013,\n",
       "         54015, 20559, 54016, 54009, 53777, 20720, 20729, 53811, 20891,\n",
       "         20888, 53814, 53816, 20879, 53820, 20874, 20871, 53829, 53831,\n",
       "         53832, 53837, 53839, 20851, 53810, 20845, 53809, 53800, 20933,\n",
       "         53783, 53786, 20929, 20927, 20926, 20922, 53788, 53792, 20916,\n",
       "         20914, 53795, 20911, 20909, 20907, 53808, 20840, 20839, 53850,\n",
       "         53893, 20776, 53896, 20773, 20768, 20767, 53900, 53902, 53910,\n",
       "         20746, 20744, 20743, 20739, 20731, 53913, 53892, 53891, 53890,\n",
       "         53886, 53851, 53853, 53854, 20831, 20829, 53857, 20819, 53916,\n",
       "         53868, 20803, 20795, 20792, 53880, 20787, 20785, 53885, 20812,\n",
       "         54048, 21367, 21372, 22031, 22025, 53055, 22022, 22018, 22006,\n",
       "         21998, 53074, 21992, 53087, 21988, 21987, 21976, 53092, 21967,\n",
       "         22035, 21964, 53049, 53047, 53019, 53020, 22074, 53027, 53028,\n",
       "         53030, 53033, 22061, 22060, 53036, 53039, 53040, 22051, 53042,\n",
       "         22043, 22037, 21960, 21959, 53100, 53148, 21880, 21879, 21878,\n",
       "         53149, 21874, 21866, 21863, 53175, 21848, 53176, 21846, 53178,\n",
       "         53181, 53182, 53147, 53145, 53143, 21894, 21954, 53103, 53106,\n",
       "         21944, 53119, 21929, 21928, 22082, 53121, 53124, 53128, 53132,\n",
       "         21906, 53137, 53142, 21897, 21922, 53190, 22084, 22088, 22228,\n",
       "         52933, 22217, 22215, 52938, 52939, 22210, 22207, 52942, 52946,\n",
       "         52947, 22201, 22195, 52958, 52961, 22231, 22188, 22232, 22234,\n",
       "         22289, 52898, 52905, 22272, 52906, 52909, 22264, 22259, 52914,\n",
       "         22255, 22250, 52919, 22245, 22243, 22237, 22233, 52963, 22184,\n",
       "         52965, 22132, 52997, 22125, 22124, 22123, 22121, 22118, 22117,\n",
       "         22116, 22113, 53008, 22101, 53012, 22097, 53013, 52996, 22139,\n",
       "         52991, 22143, 22178, 52966, 22174, 22171, 22168, 52975, 52977,\n",
       "         22087, 22160, 22156, 52979, 52982, 22153, 22150, 52990, 22145,\n",
       "         22158, 21370, 21834, 21829, 21526, 53411, 21524, 21522, 21518,\n",
       "         53414, 53415, 21514, 53417, 53418, 21507, 21505, 21503, 21496,\n",
       "         21491, 21528, 21490, 53401, 53393, 53356, 53358, 53359, 53360,\n",
       "         21584, 53365, 21579, 21578, 21571, 21564, 21561, 53382, 53383,\n",
       "         53389, 53391, 21543, 53426, 21479, 21478, 21418, 21415, 53469,\n",
       "         21411, 21410, 21405, 21403, 53480, 21400, 53484, 21392, 21389,\n",
       "         53489, 21381, 53492, 21421, 21424, 53464, 53462, 53429, 21473,\n",
       "         53438, 53443, 21459, 21458, 21456, 21593, 21455, 53453, 21448,\n",
       "         21441, 53455, 53456, 53457, 21430, 21451, 21832, 21603, 21610,\n",
       "         53229, 53230, 53231, 21773, 21767, 53234, 21757, 53244, 53249,\n",
       "         21747, 21741, 53258, 53260, 53261, 21726, 21780, 21724, 21781,\n",
       "         21784, 53198, 21826, 21821, 21816, 21808, 21807, 53212, 21804,\n",
       "         21801, 21798, 53218, 21796, 53224, 21787, 53227, 21783, 53265,\n",
       "         53266, 21720, 53320, 21654, 53323, 21648, 53326, 53328, 21641,\n",
       "         21640, 53331, 21636, 21632, 21631, 21626, 21623, 53341, 21656,\n",
       "         53317, 53316, 53312, 21718, 21710, 53279, 21702, 21700, 21697,\n",
       "         53285, 21607, 21691, 53290, 21684, 21668, 53309, 53310, 21663,\n",
       "         21660, 53288, 52895, 54049, 54057, 19234, 19228, 54890, 54892,\n",
       "         19221, 19216, 19211, 54907, 19209, 19207, 54909, 19201, 54912,\n",
       "         19199, 19197, 54882, 54915, 54880, 54878, 19294, 19293, 19290,\n",
       "         54849, 19288, 19287, 19273, 19271, 19266, 54868, 54870, 19257,\n",
       "         19256, 54871, 19251, 19248, 19194, 19192, 54922, 54975, 54988,\n",
       "         19088, 19087, 19086, 19085, 19084, 19083, 19080, 19079, 19074,\n",
       "         54999, 19052, 19051, 19045, 19103, 54966, 54962, 19119, 19189,\n",
       "         19187, 19184, 19181, 19173, 54935, 54940, 19297, 19159, 19149,\n",
       "         54952, 19135, 19132, 19127, 19124, 19123, 54943, 19040, 54842,\n",
       "         54840, 54734, 19475, 54735, 54736, 19466, 54738, 54741, 19459,\n",
       "         54746, 19454, 54748, 54752, 54753, 54755, 19445, 19477, 19439,\n",
       "         19479, 54723, 54700, 19523, 19521, 54702, 54705, 19512, 19511,\n",
       "         19507, 19506, 19505, 19502, 54712, 54715, 54718, 54719, 54730,\n",
       "         19431, 19430, 54767, 19355, 19350, 54809, 54811, 54814, 19339,\n",
       "         54816, 19335, 54820, 54822, 54831, 19319, 19318, 54837, 54838,\n",
       "         54795, 19362, 19369, 19379, 19423, 19422, 19420, 19419, 54775,\n",
       "         54776, 19410, 19310, 54780, 19402, 54781, 19400, 19396, 19386,\n",
       "         19385, 54789, 19405, 19537, 19038, 19031, 18712, 18707, 18700,\n",
       "         55214, 18694, 55222, 18691, 55235, 18678, 55237, 55239, 55241,\n",
       "         18670, 18668, 18665, 18714, 18661, 18715, 18718, 55180, 18761,\n",
       "         55185, 18750, 55192, 55194, 55195, 18733, 18732, 55197, 55199,\n",
       "         18727, 55200, 55201, 55202, 55206, 18660, 55249, 18656, 55305,\n",
       "         55306, 18592, 18589, 55311, 18584, 18578, 55317, 55324, 55326,\n",
       "         55332, 55333, 18551, 18550, 55334, 18596, 55295, 55294, 18610,\n",
       "         55250, 55251, 18650, 18648, 55261, 18640, 55266, 18765, 55268,\n",
       "         18630, 18624, 18623, 18622, 18619, 18617, 18616, 55278, 19036,\n",
       "         55179, 18773, 18973, 55060, 18960, 18954, 18953, 18952, 18951,\n",
       "         55066, 55068, 18948, 18947, 18946, 18942, 18938, 55075, 55054,\n",
       "         55077, 55052, 18977, 55016, 19021, 55020, 55032, 55033, 19001,\n",
       "         18998, 55036, 55037, 18993, 18992, 18989, 55043, 18980, 18979,\n",
       "         55050, 55078, 55079, 55081, 18832, 18830, 18826, 55148, 55154,\n",
       "         18808, 18796, 18794, 18791, 55167, 55168, 55169, 18783, 18778,\n",
       "         55175, 55138, 18841, 18847, 18850, 18919, 55082, 18912, 18911,\n",
       "         55091, 18898, 18894, 55176, 18889, 18880, 55124, 18867, 18864,\n",
       "         18860, 18856, 18855, 18887, 20488, 19538, 19540, 54260, 20179,\n",
       "         54261, 20176, 54266, 20167, 54270, 54273, 54276, 20152, 20150,\n",
       "         20149, 54280, 54282, 20135, 20181, 20134, 54256, 54251, 20244,\n",
       "         20242, 54213, 20224, 20222, 20221, 54223, 20219, 54235, 54239,\n",
       "         54241, 54244, 54245, 20197, 20196, 20191, 20128, 54290, 20122,\n",
       "         54350, 54351, 54354, 20038, 20029, 20028, 20026, 54361, 20022,\n",
       "         20019, 54365, 54369, 54372, 20011, 54379, 20052, 54337, 20066,\n",
       "         54319, 20121, 20118, 20116, 54297, 20109, 20108, 54299, 54209,\n",
       "         20103, 20091, 20090, 54306, 20084, 20079, 54318, 20077, 54302,\n",
       "         19999], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_purpose': {'feature_present_idx': array([20875, 28735, 62518, 28635, 28554, 47214, 53656, 62590,  5432,\n",
       "          5949,  5997,  6137, 48060,  6520,  6539,  6548, 26040, 27936,\n",
       "         25038,  5418, 56270, 33977,  4450, 61884, 32468, 32193, 45934,\n",
       "         32023, 29183, 31654, 45988,  4924, 31184, 59292,  4952, 46585,\n",
       "         46973, 31647, 48962, 24207,  7117, 15682, 15430, 15194, 14586,\n",
       "         54237, 14502, 13403, 54645, 10713, 13191, 10808, 11137, 12524,\n",
       "         53544, 53659, 58269, 10769, 51134, 18417, 18734, 24171, 49162,\n",
       "          7349, 22510,  7597, 58068,  7726, 58676, 21698, 20828, 20727,\n",
       "         66040,  8316, 64727, 50231, 50323, 19113, 56717, 34058, 53653,\n",
       "         57277,   778,   349, 43605, 40587, 34765, 41787,   482,  2945,\n",
       "         40511, 61022, 41769, 36014, 42051, 35653, 36123,  3695, 66695,\n",
       "         42512,  1465, 44205,  2558,  2115, 39622, 60250, 34222, 17642,\n",
       "         51160, 18089, 41224, 51472, 41060, 18601, 17845, 58557, 19742,\n",
       "         40796, 64202, 22176, 21918, 50110, 42667, 64501, 39840, 58655,\n",
       "         40056, 19848, 19824, 19760, 51475, 40774, 50543, 18789, 16574,\n",
       "         45374, 58509, 52489, 13277, 41836, 52494, 41893, 42098, 13189,\n",
       "         13041, 12975, 42786, 12802, 12729, 42447, 42504, 42728, 13502,\n",
       "         58284, 13722, 13802, 16246, 16110, 51946, 15701, 43249, 38769,\n",
       "         52032, 51500, 14891, 58404, 41510, 14512, 14244, 65211, 14080,\n",
       "         13983, 14732, 41434, 23109, 22411, 46173, 46552, 35072, 59127,\n",
       "         30377, 30249, 57693, 31071, 45177, 35304, 28931, 35452, 35540,\n",
       "         35641, 28347, 36488, 35289, 34885, 34865, 34756, 61503, 61512,\n",
       "         33415, 33087, 61614, 32945, 32703, 61219, 45366, 45884, 61150,\n",
       "         32143, 45296, 45273, 34686, 31610, 59318, 36631, 47604, 60834,\n",
       "         44746, 37815, 44506, 24504, 24362, 37960, 37964, 24175, 24046,\n",
       "         59620, 24003, 38247, 49286, 34090, 49651, 49765, 44308, 38442,\n",
       "         48540, 59707, 25435, 63439, 36939, 47799, 27534, 63067, 27265,\n",
       "         47927, 26951, 37066, 44617, 37553, 26695, 37577, 48241, 26249,\n",
       "         26144, 37697, 25957, 25603, 28266,    28,  5045,  1982, 53912,\n",
       "         65861, 67122, 56225, 10593,  5608,  2080, 10561,  9017,  6724,\n",
       "          6709, 57536,  4507,   995,  2315, 57961, 55343,  8381, 10155,\n",
       "         56940,  2911, 56881,  3103,   791, 56719,  3241, 56856, 54149,\n",
       "          4524, 56820,  7062,  4829, 57281,  9398,  7979,  7195,  4915,\n",
       "         58064,   354,  1469, 58143,  6911,  7631,  7482,  9277,  9485,\n",
       "         56552,  1435,  7958, 55399, 10835,  4775,  1976,  5310, 66988,\n",
       "         60278, 40724, 40956, 27770, 46403,  5288, 40684,  5762,  5945,\n",
       "         28229, 30206, 43656, 47176, 28513, 46718,  5661, 46791,   990,\n",
       "         29011, 29251, 29328, 62480, 62640, 28858, 11483, 27695, 58868,\n",
       "         55854, 58766, 63625, 55801, 48666, 48769, 48869,  7249, 41421,\n",
       "         55625,  7299, 23855, 23545, 49233, 23453, 23296, 23186, 60221,\n",
       "         63515, 43525,  6798, 25687,  6336, 58998, 47907, 58020, 55967,\n",
       "         27092, 46290, 48032, 55965, 26903, 48064,  6540, 48072, 26530,\n",
       "          1033, 48243, 25840, 66184, 25734, 25645, 27053, 60414, 31000,\n",
       "         37257, 37096, 60692, 44649,  2020, 44974,  2060, 36681, 44999,\n",
       "         36664, 36634, 36528, 60586, 59496, 36025,  2172, 35994, 35977,\n",
       "         59489,  1831, 37324, 37529, 57370,  1058, 39512, 59948, 39225,\n",
       "         59888, 38580, 57231, 59692,  1278, 35854, 38107, 37922,  1634,\n",
       "         37870, 57175, 60607, 44527,  1650, 44551, 37602, 38024, 35686,\n",
       "         66977, 35507, 40147,  4295, 32989, 59382, 32913, 44034, 45790,\n",
       "         32849, 32616, 33179, 57814,  4590, 32103, 31983,  4814, 31611,\n",
       "         40408, 31188, 56344, 31058, 45883, 30994, 59465, 33409, 60932,\n",
       "         57068, 35272,  2668,  2753,  2883, 59477, 34374, 34373, 45443,\n",
       "         66832,  3508, 34180,  3776, 34038,  3961,  4186, 33872, 33627,\n",
       "          4279, 34290, 49718, 25933,   266, 65056, 54315, 14572, 55090,\n",
       "         64907, 10314, 58288,  8860, 52244,  8858, 41975, 19160, 50293,\n",
       "         64795, 65193, 19455, 19501, 14137, 19561, 14000, 65541,  8511,\n",
       "         64622, 65889,  8414, 19776, 10515, 20218, 57740, 14813, 51024,\n",
       "         18307, 18297, 16275,  9508, 42320, 51869, 58499, 15945, 57659,\n",
       "         16951, 15824, 17043, 17086, 17202, 58470, 17450, 13457, 51242,\n",
       "         15549, 17629, 17633, 65716, 17714,  9992, 17803, 17887, 52132,\n",
       "         18026,  9131, 51093, 18211, 54397, 51996, 65472, 54554, 53078,\n",
       "         12328, 12567, 12493, 12887,  7733, 12882, 52953, 50096, 53729,\n",
       "         49965, 53723, 52980, 11262, 41691, 58275,  8012, 64377, 21756,\n",
       "         21830, 50025, 53135, 11115, 22395,    79, 11271,  8118, 49817,\n",
       "         11920,  8188, 20904, 64496, 52804, 42557, 12221,   165, 34251,\n",
       "          4292, 33084,  1452, 38828, 60590, 45337, 10068, 16225, 15072,\n",
       "         38119, 15067,  9610, 51756,  4312, 15414, 52052, 52020, 33122,\n",
       "         12276, 15805, 61541, 38649, 39196,  4249, 45409, 45400, 54521,\n",
       "         54405, 33361, 61575, 12433,  1368, 15499, 34146, 39482, 44338,\n",
       "          9934, 45269, 13389,  3046, 35786, 37496, 13035, 10919, 65310,\n",
       "         52832, 10467, 10793, 13216, 39917, 52383, 37045, 45045, 36206,\n",
       "         36357, 42545, 13690, 13683, 45035, 53852,  2072, 57669, 13535,\n",
       "         13349, 52476, 42836, 34489, 35759, 35719, 53095, 66987, 34657,\n",
       "         36827, 52203, 37912, 34835, 54252, 45201, 12703, 37812,  2556,\n",
       "         35238, 10397,  2410,  2395, 35485, 60657, 35510, 42487,  1698,\n",
       "         14327, 57145, 54206, 12934, 35740, 22674, 51372, 61714, 63367,\n",
       "          6679,  8245,  6717,  8159, 20971, 26358, 50119, 48251, 21199,\n",
       "         25437,  6877, 21292, 63541, 21127, 48421,  6624, 57532, 62943,\n",
       "         11807, 64788, 27484, 27477, 66321,   338, 27385, 20021,   681,\n",
       "         20081, 43147, 26724, 20264, 50216,   536, 21416, 25059,  7392,\n",
       "         22383, 23385, 23313, 43200, 23277, 49274, 49791,  7398,  7510,\n",
       "          7502, 49749, 22779, 22766, 49502, 58126, 49209, 57559, 21445,\n",
       "         21453, 50061, 63694, 21580, 24683, 63865, 21616, 64456, 48977,\n",
       "          7003, 64412, 24146, 49070, 49993, 16435, 19383, 62884, 57404,\n",
       "         30693, 30775, 30788, 17797, 30863, 54619, 40486,  4961, 17485,\n",
       "         56525, 46080, 51249, 17257, 22598,  4779, 45946, 56644, 64957,\n",
       "         45848, 43941, 32665, 43914,  9507, 50242, 16639, 32243, 51487,\n",
       "         16713, 59343, 16910, 61939, 32450, 66532,  5046, 46615, 18582,\n",
       "         66459, 67099, 40605, 18688, 55101,  5733, 64902, 19105, 47315,\n",
       "         28138, 28007, 47522, 57996,  5985,  5174, 28878, 47143,   209,\n",
       "         30340, 30264, 30151, 46677, 42192,  5319, 56261, 39639,   981,\n",
       "          5338,  5399, 29031, 18415, 44186, 43025, 57615, 43854, 42712,\n",
       "         42964, 59015, 45037, 49440, 49483, 49979, 50129, 50138, 50171,\n",
       "         55398, 50285, 55160, 55104, 58650, 51082, 55042, 54605, 51490,\n",
       "         51624, 54442, 58448, 52258, 52404, 58214, 53845, 53153, 53278,\n",
       "         53446, 58735, 55596, 49043, 58789, 57160, 56774, 45527, 45645,\n",
       "         45771, 56695, 59359, 56657, 46042, 46082, 46114, 46805, 57162,\n",
       "         46993, 47170, 47246, 47436, 47506, 47556, 59017, 47720, 47743,\n",
       "         56070, 55877, 58954, 48194, 47046, 42639, 29187, 21536, 64581,\n",
       "         19432, 19343, 19328, 64823, 18314, 17456, 17130, 16603, 16571,\n",
       "         21449, 16334, 65000, 15564, 15468, 15280, 15003, 14817, 14481,\n",
       "         14425, 13593, 65408, 16032, 13267, 60059, 22532, 27764, 27528,\n",
       "         63022, 63134, 26917, 26637, 26519, 26483, 25850, 25286, 64199,\n",
       "         63605, 24798, 24486, 24154, 24004, 23791, 63995, 23179, 23110,\n",
       "         22925, 64114, 63653, 27918, 13140, 12792,  7334,  6926,  6443,\n",
       "          6423, 66418, 66439,  5889,  5494,  5425,  4934,  7652,  4931,\n",
       "          4693,  4464,  4418, 66737,  2179,  1713,   996,   611,   348,\n",
       "         67118,  4723, 12873,  7836,  8701, 12701, 12652, 12585, 12564,\n",
       "         12320, 12094, 12068, 11853, 11376, 10760,  8277, 10685, 10433,\n",
       "         10259, 65623, 10094, 10072, 65717, 65747,  9263,  9237,  9171,\n",
       "         10629, 28176, 57694, 60700, 33806, 36150, 41969, 33225, 41877,\n",
       "         31539], dtype=int64),\n",
       "  'feature_absent_idx': array([19257, 12930, 28642, 45879, 28634, 28630, 12943, 57676, 12947,\n",
       "         12948, 57670, 57667, 12951, 12952, 57683, 57666, 28624, 57662,\n",
       "         28622, 12960, 28621, 57656, 12964, 45892, 12969, 12970, 12971,\n",
       "         12973, 57650, 57665, 28612, 45874, 28649, 28688, 57725, 12877,\n",
       "         12878, 12880, 57723, 28684, 57718, 57717, 57715, 12892, 12894,\n",
       "         28677, 45872, 12898, 45843, 12901, 45846, 45847, 45849, 28664,\n",
       "         45856, 12915, 57699, 45863, 45864, 45865, 57688, 28676, 45895,\n",
       "         57643, 57642, 13037, 45935, 13040, 57596, 57594, 28562, 57591,\n",
       "         45939, 28558, 13052, 28552, 28548, 45945, 57599, 57579, 13065,\n",
       "         28544, 45948, 57571, 57570, 57568, 57567, 28537, 57566, 13079,\n",
       "         28536, 13081, 28534, 57578, 57601, 45929, 13029, 12983, 45899,\n",
       "         45900, 57641, 12987, 12989, 28605, 45903, 28602, 45904, 28595,\n",
       "         28592, 57629, 13002, 13003, 57628, 28589, 57626, 45923, 28583,\n",
       "         57611, 13014, 57609, 13016, 28580, 13020, 45927, 57605, 13028,\n",
       "         57730, 45953, 57731, 45828, 57857, 57856, 12721, 28805, 12723,\n",
       "         28803, 45758, 45761, 57850, 57846, 28792, 28791, 28788, 12717,\n",
       "         12739, 12742, 28784, 28783, 57840, 28779, 28778, 57835, 28777,\n",
       "         28775, 57825, 57821, 28772, 12762, 45769, 12763, 12714, 12711,\n",
       "         45722, 28850, 45725, 45726, 12675, 12676, 57887, 28840, 57885,\n",
       "         28839, 45731, 45732, 45736, 57860, 28827, 12693, 45740, 28823,\n",
       "         12696, 45743, 28818, 28817, 28815, 57867, 45747, 57864, 12707,\n",
       "         12710, 57876, 28768, 28767, 45779, 12826, 57768, 57766, 12829,\n",
       "         28715, 57762, 12835, 28714, 28713, 45823, 45824, 28703, 57753,\n",
       "         12824, 57750, 45826, 12851, 12852, 28700, 12854, 28699, 57745,\n",
       "         12858, 57741, 28697, 12862, 57736, 12865, 28702, 57770, 57772,\n",
       "         28724, 28765, 12768, 12769, 12770, 12771, 12773, 12777, 57811,\n",
       "         28759, 45786, 12782, 57807, 57801, 28754, 57796, 57795, 45800,\n",
       "         45803, 12799, 45807, 57782, 28738, 12805, 12807, 45809, 12811,\n",
       "         12812, 12813, 28727, 57735, 12667, 13084, 28529, 13345, 57362,\n",
       "         13347, 28341, 57359, 46088, 28337, 46089, 57352, 57350, 13362,\n",
       "         28333, 13364, 13344, 13365, 57344, 57341, 57339, 46100, 57336,\n",
       "         46110, 57334, 28316, 57329, 57325, 28310, 46117, 28304, 28331,\n",
       "         57306, 46075, 57365, 28378, 57401, 13301, 57399, 28374, 57395,\n",
       "         28371, 13307, 28370, 13311, 57392, 57391, 57389, 46071, 57386,\n",
       "         46063, 13322, 46066, 28361, 57381, 13328, 13329, 46067, 13333,\n",
       "         57367, 13338, 57366, 28350, 13317, 13399, 57305, 57303, 57257,\n",
       "         57256, 46146, 13463, 57254, 13466, 13467, 57252, 57251, 57247,\n",
       "         13476, 46158, 46159, 28264, 28248, 46162, 13485, 57237, 46163,\n",
       "         28241, 57232, 28240, 57230, 13494, 13495, 46164, 28238, 13498,\n",
       "         28247, 57261, 28265, 13454, 57301, 13405, 57299, 28299, 46120,\n",
       "         13410, 57297, 46124, 13415, 13422, 13423, 46128, 13425, 13426,\n",
       "         46129, 13429, 46130, 57283, 13435, 46135, 46138, 57271, 13441,\n",
       "         28274, 13446, 57266, 13448, 57265, 28267, 13295, 28530, 13293,\n",
       "         46049, 57513, 13146, 13148, 13149, 57511, 13151, 28478, 45990,\n",
       "         13154, 28476, 28473, 13160, 13161, 57516, 57502, 45993, 45994,\n",
       "         13167, 57493, 13173, 13176, 46006, 28452, 13183, 28450, 46007,\n",
       "         28448, 28447, 57501, 13190, 57518, 45986, 28525, 28521, 28520,\n",
       "         13095, 13096, 28519, 13098, 13101, 13103, 13106, 13108, 57550,\n",
       "         13112, 28482, 45968, 57544, 28504, 28501, 28500, 28498, 28494,\n",
       "         28493, 45976, 57526, 28487, 57525, 57524, 45984, 45969, 13193,\n",
       "         28445, 46008, 28398, 57433, 28397, 13255, 57430, 13259, 57429,\n",
       "         57428, 57427, 57425, 46047, 28388, 13269, 13249, 13271, 13273,\n",
       "         13274, 57422, 57420, 13280, 57415, 57413, 28383, 28382, 57405,\n",
       "         13288, 57403, 13290, 57423, 57437, 13247, 46036, 57480, 28441,\n",
       "         28439, 13201, 28436, 46013, 46016, 13209, 57468, 28429, 46018,\n",
       "         13214, 13217, 13219, 13221, 46023, 28421, 46024, 46028, 28416,\n",
       "         57450, 13233, 57447, 28410, 28408, 28407, 57442, 57441, 13243,\n",
       "         13292, 57227, 28853, 12663, 58333, 45446, 45457, 12104, 45458,\n",
       "         12106, 12108, 12109, 45460, 45462, 58318, 58316, 29254, 12087,\n",
       "         58311, 58310, 29249, 45467, 58305, 58301, 45469, 12132, 58297,\n",
       "         12134, 45473, 45477, 58294, 58292, 29252, 29239, 58337, 29287,\n",
       "         45411, 45413, 45414, 58367, 29308, 12045, 12046, 12047, 58364,\n",
       "         58363, 29306, 58361, 29305, 29284, 58360, 12056, 29304, 58357,\n",
       "         12059, 29303, 45415, 12062, 58354, 12064, 58349, 12075, 58340,\n",
       "         12079, 58358, 12142, 12143, 29229, 12202, 58239, 12205, 12207,\n",
       "         58237, 58236, 12212, 29177, 12215, 29175, 12218, 12224, 29170,\n",
       "         29184, 45520, 12230, 12234, 58215, 12236, 29161, 12239, 12240,\n",
       "         12243, 12247, 58208, 29152, 12251, 12252, 58221, 12198, 45511,\n",
       "         58240, 58286, 58285, 29226, 58283, 45488, 45489, 12158, 58277,\n",
       "         58274, 29219, 58267, 29214, 29213, 45500, 29205, 12178, 29200,\n",
       "         29199, 58254, 12184, 29196, 12186, 45504, 29194, 58246, 58243,\n",
       "         29191, 58242, 45509, 58373, 12253, 12033, 12029, 45348, 45349,\n",
       "         29424, 29423, 29422, 58506, 45351, 58502, 58496, 45354, 11902,\n",
       "         29414, 29413, 29430, 11906, 58491, 58489, 29408, 58488, 11914,\n",
       "         29406, 45357, 11922, 11923, 45364, 58476, 29393, 11931, 29410,\n",
       "         29392, 11885, 58513, 45317, 29465, 29462, 29461, 45321, 45323,\n",
       "         11848, 11850, 29453, 58538, 58537, 58536, 45331, 29432, 11861,\n",
       "         45333, 45338, 29444, 58519, 45339, 11874, 45340, 11876, 29436,\n",
       "         45342, 45343, 29433, 11882, 58526, 29389, 58465, 29388, 29350,\n",
       "         29349, 45390, 45391, 58416, 58415, 11994, 11995, 58413, 58411,\n",
       "         29346, 29345, 45393, 11987, 29335, 29329, 12013, 12014, 12015,\n",
       "         29326, 12017, 58389, 58388, 12022, 58385, 45410, 58380, 29320,\n",
       "         29334, 11985, 11984, 29352, 29387, 11939, 11940, 29383, 58460,\n",
       "         29382, 29380, 58450, 29377, 11952, 29372, 29368, 11959, 58444,\n",
       "         45382, 45383, 58443, 58442, 11968, 58439, 58438, 29357, 45388,\n",
       "         11975, 11976, 58434, 58429, 58428, 29353, 29317, 12664, 12254,\n",
       "         29149, 57991, 57990, 57988, 12527, 45664, 12530, 12534, 28942,\n",
       "         57978, 57977, 28940, 57975, 12544, 28954, 57974, 57973, 57972,\n",
       "         57971, 12550, 45671, 28933, 57968, 28932, 12557, 28929, 28928,\n",
       "         28927, 12562, 12546, 45672, 28957, 45652, 58039, 28982, 28981,\n",
       "         58037, 58036, 58034, 45634, 58032, 45635, 12484, 28976, 58030,\n",
       "         58029, 57998, 12490, 45638, 12494, 12495, 45639, 58021, 58017,\n",
       "         45643, 12506, 28964, 58006, 12510, 12512, 58000, 12491, 28924,\n",
       "         12568, 45674, 57927, 28881, 57924, 28880, 45701, 57922, 45704,\n",
       "         45705, 12633, 12634, 45711, 28868, 57919, 45699, 45713, 12644,\n",
       "         57911, 57908, 57907, 28860, 45716, 12653, 45717, 57901, 57900,\n",
       "         57899, 57898, 12661, 28865, 57929, 28887, 28890, 57960, 12574,\n",
       "         57955, 45683, 12581, 57953, 12583, 12586, 28909, 28907, 28905,\n",
       "         12592, 12595, 12596, 12597, 12598, 28902, 28901, 28900, 28897,\n",
       "         28896, 28895, 57940, 45695, 28893, 57938, 45696, 57937, 57933,\n",
       "         28983, 58207, 28986, 28993, 12308, 29111, 29110, 12313, 29107,\n",
       "         12315, 58163, 12318, 29105, 45565, 45567, 58158, 29098, 29114,\n",
       "         29097, 58151, 29094, 12338, 45573, 29086, 12344, 45576, 12346,\n",
       "         58132, 58130, 12356, 45583, 29071, 58152, 12362, 29115, 58178,\n",
       "         12258, 29147, 29146, 58203, 45535, 58200, 12267, 29140, 29139,\n",
       "         58197, 58195, 29135, 12279, 45557, 29133, 45542, 12283, 29131,\n",
       "         45544, 29127, 29123, 45553, 12292, 12293, 12294, 12297, 58179,\n",
       "         29119, 58191, 12363, 58122, 12365, 12418, 29020, 45615, 45616,\n",
       "         58072, 12428, 45618, 45619, 12431, 29012, 29008, 58060, 29007,\n",
       "         45611, 58057, 12446, 12447, 12448, 45626, 12452, 58052, 12454,\n",
       "         58049, 45628, 12459, 12460, 28994, 58046, 29004, 45609, 29028,\n",
       "         29029], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_quant': {'feature_present_idx': array([25404, 59847, 23689,  8991, 23860, 23876, 60012, 46762,  8911,\n",
       "         60284, 60285, 24086,  8850, 60458,  8706, 46559, 24249, 46387,\n",
       "         24393, 46318, 24495, 46291, 60825, 24585, 60839,  8338, 46165,\n",
       "         24692, 59706, 59581, 23478, 23475, 22196, 10164, 22244, 10123,\n",
       "         47686, 58706, 47673, 58785, 22560, 47663, 47619, 22601, 22650,\n",
       "          8235, 58876, 47444, 23024, 59129, 59133, 59186,  9765, 23171,\n",
       "         23281,  9462, 23285,  9400, 59522, 47194, 22794, 22149, 24852,\n",
       "          8005, 26669, 44636, 44613, 61531, 44575, 61615, 61667, 26931,\n",
       "         26945, 27048, 27149, 61787,  6596,  6541, 27209, 44149, 27357,\n",
       "         27467, 27555, 27635, 43756, 27666, 27768, 43653, 28540, 28661,\n",
       "          5566,  6937, 26638,  6992, 26424, 45811, 25348, 25395, 14792,\n",
       "         25411,  7816, 25443,  7757, 61074, 45532,  7738, 61169, 45486,\n",
       "         60929, 61177,  7589, 45449,  7508, 45309, 45285, 26193, 45193,\n",
       "         61316,  7287, 26324, 26345, 61426,  7069,  7623, 62639, 10209,\n",
       "         10240, 16011, 53221, 53210, 16119, 55384, 53111, 53090, 55585,\n",
       "         52935, 52686, 16557, 52421, 13452, 16842, 51637, 56054, 56142,\n",
       "         12910, 51422, 17411, 17447, 17842, 17965, 18022, 51125, 18262,\n",
       "         56632, 55331, 13768, 53304, 13841, 14742, 54434, 14692, 54334,\n",
       "         54473, 54331, 14515, 54189, 15032, 54631, 54115, 53907, 14418,\n",
       "         51083, 54807, 14320, 14231, 55000, 15588, 55096, 15596, 14136,\n",
       "         53672, 15681, 14024, 15713, 53578, 15744, 14343, 22021, 51053,\n",
       "         18464, 11435, 11395, 11197, 48982, 21079, 21107, 48828, 11109,\n",
       "         11047, 57845, 57966, 58109, 10926, 21371, 48591, 21521, 58271,\n",
       "         48358, 21790, 48205, 48202, 58400, 21883, 21912, 58427, 58505,\n",
       "         10243, 49357, 57633, 49430, 49436, 50894, 18587, 18597, 50831,\n",
       "         18849, 50628, 12167, 57099, 12102, 19029, 19046, 12083, 19060,\n",
       "         18459, 19062, 50416, 19264, 19463, 50033, 49930, 49867, 19777,\n",
       "         49689, 57478, 49635, 11678, 57510, 49454, 50433, 42614, 54382,\n",
       "          2996,  1570,  3904, 31930, 41134,  1602, 40938, 34880, 38638,\n",
       "         64155, 40891, 32247,  1746, 38674,  1846,  3591, 34723,  3561,\n",
       "         38497, 40700, 41292,  1437, 35577, 41750, 63420,  4531, 35395,\n",
       "         63482, 38110,  4481,  4382, 66140, 38286, 31400,  4199, 63851,\n",
       "         31554, 63869, 31571,  4124, 66380, 40670, 40595,  2918,  2888,\n",
       "          2882, 34088, 39801, 39764,  2360, 65169, 33758,  2376,  2774,\n",
       "         33768, 65161, 39445, 65155, 65102,  2640, 33461,  1899, 40063,\n",
       "         40220,  3459, 34578, 65673, 32684, 64522,  2135, 34447, 40473,\n",
       "         40467, 32908,  3294, 40465,  3272, 39222, 40314, 33094,  3158,\n",
       "         33342, 63131, 65111,   415, 66702,  5052, 66717, 36085, 42084,\n",
       "           654, 36462, 29977, 35961, 35915, 36240, 42270, 62841, 30047,\n",
       "          5138, 30254, 67048, 35782, 29648,   547, 29858,  5264, 36189,\n",
       "         42501, 42018, 37325, 37514, 36091, 29528, 36761,   783, 36798,\n",
       "         30592, 20093, 39187, 20209, 39060, 19374, 50149, 50258, 15533,\n",
       "         36191, 37119, 53835, 39183, 37220, 15465, 20008, 15442, 15456,\n",
       "         49651, 39145, 15521, 19862, 20212, 19848, 15472, 19780, 39087,\n",
       "         34506, 15483, 19440, 53044, 20405, 53898, 20973, 36911, 14998,\n",
       "         54264, 36902, 36818, 14905, 36557, 36587, 48868, 21239, 14862,\n",
       "         54380, 21265, 34068, 48714, 34061, 34052, 48707, 15006, 36466,\n",
       "         49048, 36464, 34242, 39282, 36998, 15200, 20417, 34202, 54046,\n",
       "         49363, 34175, 20234, 36913, 34142, 39347, 20628, 20656, 49256,\n",
       "         20865, 49057, 20961, 49051, 20615, 34580, 15645, 19236, 35367,\n",
       "         51589, 17168, 17213, 35275, 51451, 38282, 51243, 35768, 17590,\n",
       "         35806, 17770, 51236, 38287, 15946, 17869, 51217, 35179, 53299,\n",
       "         17999, 17112, 17060, 53022, 16351, 35662, 37962, 16431, 35641,\n",
       "         35582, 16272, 37849, 16612, 52322, 38087, 16885, 52028, 52013,\n",
       "         51768, 35682, 16994, 37953, 50388, 15880, 35056, 50786, 50661,\n",
       "         50657, 15666, 18956, 34868, 18958, 18964, 15698, 50604, 38719,\n",
       "         34708, 38960, 34586, 37381, 19183, 19215, 37335, 38662, 51184,\n",
       "         53594, 34906, 15871, 51123, 15864, 48683, 51119, 53481, 18292,\n",
       "         51094, 38581, 37802, 18350, 51058, 34991, 34916, 18484, 34914,\n",
       "         18493, 18505, 38522, 18128, 42581, 39396, 41900, 30708, 30655,\n",
       "         45177, 41997, 45171, 26380, 45072, 26560, 30579, 41893, 30574,\n",
       "         30551, 42029, 30493, 42061, 26729, 26767, 30379, 30333, 26939,\n",
       "         42211, 44754, 30813, 41804, 30867, 41537, 45788, 25221, 45654,\n",
       "         41621, 25415, 45644, 31256, 25540, 31126, 31110, 31087, 31032,\n",
       "         45530, 30991, 25701, 25704, 41728, 25710, 25973, 45440, 26049,\n",
       "         41774, 44452, 42225, 27098, 44314, 28116, 43385, 43348, 28172,\n",
       "         43324, 28231, 28245, 28251, 28324, 28391, 43250, 43178, 43101,\n",
       "         29636, 43026, 28771, 42837, 42358, 42825, 42754, 42706, 29186,\n",
       "         29356, 43412, 45853, 43429, 28065, 27186, 30112, 44175, 30041,\n",
       "         44130, 27342, 43923, 29963, 27475, 43778, 27501, 43775, 29779,\n",
       "         27639, 42333, 27672, 27737, 27803, 27894, 29715, 27970, 43637,\n",
       "         43585, 28072, 24948, 24945, 45868, 22428, 33211, 33185, 40262,\n",
       "         22639, 47575, 40387, 47519, 22791, 22817, 22867, 22869, 47311,\n",
       "         32852, 23057, 47263, 47260, 32795, 23190, 23225, 23255, 40508,\n",
       "         40518, 33338, 32704, 22365, 22301, 33980, 33948, 21499, 48516,\n",
       "         48507, 21513, 21533, 21621, 48324, 39589, 21828, 48145, 21868,\n",
       "         39828, 48125, 22020, 33448, 48086, 40089, 42563, 33377, 33346,\n",
       "         22246, 22308, 21337, 40520, 47106, 46651, 46642, 32043, 46625,\n",
       "         24202, 46604, 32041, 41117, 24283, 46431, 46355, 41209, 31893,\n",
       "         24541, 41277, 46259, 31819, 31768, 46243, 41302, 31714, 45955,\n",
       "         24815, 24144, 47164, 24110, 32205, 23380, 23402, 47053, 46926,\n",
       "         40637, 46864, 23567, 23608, 23655, 23713, 23781, 23834, 40769,\n",
       "         32420, 32337, 46821, 40823, 23896, 23917, 23951, 46706, 24043,\n",
       "         40890, 24099,    14, 50973, 14828, 11452, 62987, 62993, 57580,\n",
       "         11562,  4910, 11585, 63078, 63235,  4775, 63330, 11655, 63415,\n",
       "          4523,  7949, 63598, 11857, 11339, 62975, 57746,  5099, 62648,\n",
       "          5437,  5378, 10937, 62770,  5208, 57818, 57800, 57387, 62867,\n",
       "         11173,  5161, 57775, 11298, 11323, 57758, 62899,  5113, 57783,\n",
       "         63890,  4099, 11960, 64509, 56987, 56979, 12316,  3456,  3427,\n",
       "         12327,  3401, 12211, 12373, 56760,  3313, 64625, 12456, 64656,\n",
       "         56626, 56533, 64714, 56798, 58287, 12185, 57079,  3878,  3857,\n",
       "          3849, 64152,  3809, 12050,  3808, 57267, 57056, 64183, 64228,\n",
       "         64301,  3599, 57168, 64462,  3557,  3506, 12127, 64195, 64738,\n",
       "         62627, 10570, 60171, 60121,  6967, 61503,  6936,  8987, 59989,\n",
       "         61505,  9038,  6895, 59931, 59867, 59776,  9151, 59562, 61688,\n",
       "          6644,  8922,  7041,  7082, 61482, 60957, 60904,  7817,  8160,\n",
       "         60868, 60845,  8301,  7662,  6600, 60831, 60818,  7648,  7642,\n",
       "         60706,  8648,  7181, 61438, 60439,  7655, 59478, 59396,  6515,\n",
       "          6092, 62211, 58725,  5984, 58692, 62330,  5924,  5904,  9950,\n",
       "         58630, 62356, 10183,  5683, 10235, 62469, 58404, 62523, 10525,\n",
       "         10136, 62577,  6156,  6198,  6495, 59251,  9613,  6451,  9704,\n",
       "         61894, 61961,  9810, 58870, 59072,  9840,  6383,  9851, 59047,\n",
       "         58946,  6276, 62030,  6239,  9836, 12605, 11833, 13377,  2547,\n",
       "           167, 65121,  1700,  1197,  1695, 67073, 65744,  2630, 65951,\n",
       "         65732, 55955, 54977, 65974, 55209, 65134, 55929, 12876,   175,\n",
       "         14315, 66856, 66893, 56185,   930, 66921, 12939, 55771, 66469,\n",
       "         55182,  1827, 54742, 65845, 66819, 66384, 55816, 66174, 55368,\n",
       "         65624,  1900, 14223,  2128, 13623, 66582, 13996, 54437, 56388,\n",
       "          3039, 13312, 54422,  2252,   598, 65547, 14076, 55147, 65593,\n",
       "         54484,   332, 12606,  2920, 13761,    52, 55382, 56337, 54565,\n",
       "            59, 55397,  1974, 67106, 65629,  2830, 61981,  6400, 66610,\n",
       "         37941], dtype=int64),\n",
       "  'feature_absent_idx': array([49500, 19288, 19287, 42831, 60410, 19273, 19271, 19266, 42840,\n",
       "         19257, 19256, 42843, 19251, 19248, 42847, 19234, 19290, 60420,\n",
       "         19293, 19297, 42821, 60386, 19339, 60387, 60390, 19335, 42824,\n",
       "         60394, 19319, 19318, 42827, 60401, 42828, 19310, 42829, 19294,\n",
       "         42820, 42850, 19228, 19184, 19181, 51819, 42867, 42869, 42871,\n",
       "         19173, 60435, 60436, 42875, 60438, 19159, 42877, 60440, 19149,\n",
       "         19187, 60421, 19189, 19192, 19221, 42853, 19216, 19211, 19209,\n",
       "         42857, 19207, 60428, 19201, 42859, 19199, 19197, 42861, 19194,\n",
       "         60430, 51820, 42880, 60382, 19350, 19502, 60329, 51848, 42764,\n",
       "         60332, 42765, 42766, 42767, 42769, 42770, 19479, 19477, 19475,\n",
       "         42776, 60338, 19505, 42778, 19506, 42761, 19552, 19550, 19549,\n",
       "         19541, 19540, 19539, 19538, 19537, 19523, 19521, 42758, 42759,\n",
       "         42760, 19512, 19511, 19507, 42817, 19466, 60342, 42804, 19396,\n",
       "         60367, 42807, 42808, 19386, 19385, 19379, 60373, 19369, 42810,\n",
       "         60374, 19362, 19355, 42815, 19400, 60340, 19402, 19410, 19459,\n",
       "         60344, 60345, 19454, 42782, 19445, 19439, 19431, 19430, 19423,\n",
       "         19422, 19420, 19419, 42798, 42799, 19405, 51853, 42881, 19135,\n",
       "         18867, 60523, 18864, 60524, 60526, 18860, 60529, 18856, 18855,\n",
       "         18850, 18847, 60531, 60533, 18841, 60535, 42973, 18832, 42972,\n",
       "         18880, 51785, 42953, 18919, 18912, 18911, 51784, 42958, 42960,\n",
       "         18898, 60515, 18894, 18889, 18887, 60517, 42968, 42971, 18938,\n",
       "         18830, 60547, 18761, 60571, 18750, 60572, 60574, 60577, 18733,\n",
       "         18732, 60579, 18727, 43024, 60587, 18718, 18715, 18714, 18765,\n",
       "         18826, 43012, 18773, 42987, 42990, 42991, 60551, 60552, 18808,\n",
       "         18796, 18794, 60558, 18791, 60559, 51770, 18783, 18778, 43009,\n",
       "         51767, 42883, 18942, 18947, 19085, 19084, 19083, 19080, 19079,\n",
       "         19074, 60464, 60469, 19052, 19051, 42911, 60472, 19045, 51799,\n",
       "         19040, 19086, 60475, 19087, 51806, 19132, 42885, 19127, 19124,\n",
       "         19123, 51810, 19119, 42888, 51809, 42890, 42891, 60453, 19103,\n",
       "         51807, 42897, 19088, 18946, 19038, 19036, 18980, 18979, 60495,\n",
       "         18977, 42933, 18973, 51791, 60498, 18960, 51788, 18954, 18953,\n",
       "         18952, 18951, 18948, 42932, 51793, 42931, 18989, 19031, 42919,\n",
       "         60477, 60478, 42920, 19021, 42924, 42925, 60489, 19001, 18998,\n",
       "         42928, 60492, 18993, 18992, 60494, 19555, 19560, 42745, 42536,\n",
       "         20135, 20134, 42537, 60104, 20128, 42541, 20122, 20121, 20118,\n",
       "         20116, 51924, 20109, 20108, 60107, 60100, 20103, 20149, 20152,\n",
       "         20197, 20196, 42511, 20191, 51933, 20181, 20179, 42521, 60093,\n",
       "         20176, 42522, 42524, 42525, 20167, 51928, 20150, 60083, 51922,\n",
       "         20090, 60139, 60140, 20038, 20029, 20028, 20026, 42576, 60143,\n",
       "         20022, 20019, 51909, 42582, 42584, 42585, 20011, 60138, 20091,\n",
       "         42573, 20052, 42554, 20084, 60113, 20079, 20077, 42559, 42560,\n",
       "         60124, 20066, 60128, 60129, 42564, 42565, 60130, 51915, 51914,\n",
       "         42586, 60082, 51935, 60031, 42459, 42460, 42462, 20331, 20327,\n",
       "         60038, 51941, 60039, 20321, 60041, 20317, 20316, 20315, 20313,\n",
       "         20350, 42470, 20352, 42454, 20409, 42439, 20403, 60013, 20396,\n",
       "         42440, 60015, 51945, 60018, 60020, 20374, 20372, 42450, 60024,\n",
       "         51943, 60028, 42509, 42472, 20302, 20246, 42492, 20244, 20242,\n",
       "         42493, 42495, 42496, 42497, 60073, 20224, 20222, 20221, 20219,\n",
       "         42500, 51937, 20248, 60047, 20249, 42490, 20301, 20300, 20299,\n",
       "         42475, 20294, 20290, 60053, 20281, 60056, 42483, 20268, 20267,\n",
       "         20261, 60065, 42489, 20252, 60154, 19999, 19996, 60258, 19697,\n",
       "         19696, 19695, 19691, 42696, 60260, 19687, 42699, 19677, 60270,\n",
       "         19663, 19661, 19660, 60274, 19701, 60275, 51877, 60256, 19739,\n",
       "         42682, 42684, 60248, 60249, 19726, 19725, 42686, 60253, 19719,\n",
       "         42687, 19717, 19714, 42690, 19709, 19706, 51878, 42707, 51868,\n",
       "         51859, 60305, 42735, 19590, 19584, 19581, 19578, 19577, 19576,\n",
       "         19570, 51856, 19566, 19565, 19564, 19562, 19602, 19654, 19606,\n",
       "         42726, 19651, 60280, 51867, 19646, 42715, 19640, 19639, 42717,\n",
       "         60287, 19636, 19630, 60292, 19621, 42723, 19615, 60300, 42679,\n",
       "         19745, 60243, 42618, 60180, 60183, 19915, 51895, 42624, 19902,\n",
       "         19899, 60188, 19893, 60189, 42631, 42632, 19889, 19886, 19928,\n",
       "         19885, 19930, 42612, 19994, 19989, 60160, 42592, 19983, 60164,\n",
       "         42597, 19972, 42600, 19956, 51900, 60168, 42604, 19943, 60178,\n",
       "         19933, 19882, 19880, 60191, 42659, 19802, 42666, 19791, 60228,\n",
       "         19779, 42674, 19770, 60235, 19765, 19763, 19758, 60238, 19750,\n",
       "         19748, 42658, 42656, 42654, 42653, 19875, 19868, 19866, 60206,\n",
       "         42644, 51886, 19841, 43029, 60209, 60210, 42646, 19833, 19832,\n",
       "         19831, 19825, 42652, 19839, 20411, 18712, 43034, 17533, 17532,\n",
       "         43475, 17530, 43476, 17526, 17525, 17523, 17522, 17521, 17519,\n",
       "         17513, 17512, 61026, 61027, 17540, 61028, 43472, 43470, 43454,\n",
       "         17592, 17587, 43456, 17584, 17583, 17581, 17570, 61011, 17564,\n",
       "         17563, 51620, 17558, 61016, 17549, 17545, 17596, 43481, 17497,\n",
       "         17438, 17437, 17435, 17429, 17428, 61060, 17424, 17423, 61061,\n",
       "         17421, 17420, 17417, 17415, 17408, 61064, 17439, 17502, 61056,\n",
       "         17449, 17492, 17491, 43486, 17478, 17475, 17471, 17469, 17466,\n",
       "         17465, 61046, 17462, 17458, 43497, 43498, 43499, 61055, 17402,\n",
       "         17600, 17606, 17783, 17782, 17779, 17775, 17774, 17772, 17769,\n",
       "         43380, 17759, 17758, 43386, 60937, 60939, 17743, 17742, 17784,\n",
       "         17740, 17785, 17790, 43360, 43362, 17828, 43364, 51661, 60920,\n",
       "         60921, 43368, 60924, 43370, 17800, 17799, 51660, 43372, 17792,\n",
       "         17788, 17603, 17737, 17731, 17659, 51638, 17648, 51632, 43433,\n",
       "         43435, 43437, 17627, 60982, 17616, 17615, 17614, 60986, 60991,\n",
       "         17608, 60968, 17735, 43418, 17671, 43393, 43395, 43397, 17721,\n",
       "         51646, 60953, 17710, 17708, 17698, 60961, 17683, 17680, 17679,\n",
       "         60965, 43416, 17667, 17838, 17401, 17396, 17118, 17116, 17113,\n",
       "         17111, 17105, 43611, 61171, 17090, 61176, 61178, 43617, 17080,\n",
       "         17077, 17072, 61180, 61161, 17070, 17125, 17132, 17165, 17163,\n",
       "         17162, 17161, 17159, 17156, 51572, 17154, 61151, 17152, 17148,\n",
       "         17146, 61154, 17139, 61157, 43601, 17169, 43621, 17056, 61200,\n",
       "         16996, 16991, 16989, 16986, 43647, 16981, 61208, 16973, 61211,\n",
       "         61213, 16970, 61215, 61216, 51558, 43644, 43623, 17001, 17019,\n",
       "         17055, 17053, 17050, 43627, 61190, 61191, 61192, 43629, 17037,\n",
       "         43630, 43631, 43632, 17027, 43634, 61195, 17006, 17399, 17173,\n",
       "         17179, 17324, 17322, 17321, 17319, 17318, 43542, 61101, 17296,\n",
       "         51593, 17293, 43551, 17288, 17287, 17286, 17278, 17330, 61115,\n",
       "         61087, 17338, 43515, 17392, 17389, 17384, 43521, 43522, 17369,\n",
       "         17367, 61078, 17355, 17353, 17344, 17343, 43531, 43533, 61084,\n",
       "         17177, 43556, 17266, 43569, 61138, 61139, 17216, 17215, 17209,\n",
       "         17208, 17204, 43575, 61144, 17201, 43576, 43578, 51578, 17184,\n",
       "         43567, 61116, 17227, 43566, 17265, 43560, 43561, 61123, 17254,\n",
       "         51585, 17252, 17248, 17247, 17244, 17241, 17240, 61128, 17235,\n",
       "         61129, 17228, 43357, 43355, 60913, 60697, 43139, 60698, 18426,\n",
       "         18423, 18422, 18420, 18412, 43144, 51727, 18402, 18400, 43149,\n",
       "         18392, 18391, 43138, 18389, 60694, 18451, 18511, 43112, 43114,\n",
       "         18501, 43115, 18494, 60672, 43116, 60673, 43117, 18487, 43118,\n",
       "         18469, 51731, 43132, 43133, 18516, 43157, 51721, 18332, 51712,\n",
       "         18330, 43177, 18324, 60731, 18315, 18304, 51709, 60739, 43192,\n",
       "         18294, 60743, 18283, 60747, 18334, 18383, 18336, 18343, 43159,\n",
       "         43161, 18376, 18371, 18370, 18369, 60716, 43164, 18361, 51718,\n",
       "         60718, 18355, 60723, 60725, 18344, 18337, 43197, 43107, 18520,\n",
       "         60613, 18656, 18650, 60619, 18648, 43051, 43053, 60625, 43055,\n",
       "         18640], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_range': {'feature_present_idx': array([ 1413, 15155,  9374, 43256, 20547, 50530,  8469], dtype=int64),\n",
       "  'feature_absent_idx': array([37992, 53975, 17252, 17248, 17247, 35242, 17244], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 7\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 7\n",
       "  })},\n",
       " 'contains_scale': {'feature_present_idx': array([41196], dtype=int64),\n",
       "  'feature_absent_idx': array([18993], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1\n",
       "  })},\n",
       " 'contains_source': {'feature_present_idx': array([56465, 57962, 50414, 60713, 20941, 33645, 63027, 43335, 33509,\n",
       "         47475, 22270, 64558, 50239, 10399, 17768, 51109, 51318, 33205,\n",
       "         52262,  9361, 52708, 32921, 18166, 53661, 32384, 55511, 51589,\n",
       "         50095, 19180, 31430, 14616, 36529, 14505, 14466, 38443, 38552,\n",
       "         39290, 13685, 13674, 47552, 36332, 41727, 12795, 12520, 34988,\n",
       "         12355, 11883, 34626, 34533, 46553, 35612, 34293, 37065, 19525,\n",
       "          2550, 26510,  2479, 21854, 62617, 25888,  1835, 25280, 64241,\n",
       "         27985, 65328, 65965, 24278, 66481, 23962, 66541, 66854, 66989,\n",
       "           419,   206, 65511, 28763, 26609, 58863, 58667,  5981,  3682,\n",
       "          5779, 30617,  5389,  6912,  6300, 28969, 59664, 20509, 20605,\n",
       "         20946, 29027, 32849, 31261, 23807, 31341, 32370, 34275, 30946,\n",
       "         35507, 29725, 29429, 34911, 36739, 24210,   103, 48468, 38303,\n",
       "         59018, 59101, 59169, 59410, 59607, 59819, 59926, 60637, 61500,\n",
       "         61513, 61562, 61785, 62586, 62613, 63287, 64214, 64893, 66085,\n",
       "         66462, 66510, 66829, 58801, 37431, 57055, 56590, 38386, 39824,\n",
       "         41112, 41372, 43013, 45454, 46053, 46175, 46654, 23706, 50431,\n",
       "         50439, 51855, 52245, 52717, 53071, 53972, 54310, 55859, 56035,\n",
       "         56329, 56671, 23186, 32291, 16184,  4668,  9885, 11856, 18246,\n",
       "          7136,  7238, 11393, 21394, 11349, 11087, 21288, 20132,  8856,\n",
       "          9649, 19681, 21544, 11983, 10455, 22835,  3180, 22664, 17327,\n",
       "          2548, 22531, 13472, 15409,  2936, 16465, 49201, 15884, 49745,\n",
       "         48613, 50303, 35910, 48541, 48124, 50309, 36444, 41493, 38526,\n",
       "         14017, 46223, 11612, 22912, 45116, 44941, 40978, 43366, 41196,\n",
       "         43176, 42917, 41583, 14774, 44421, 23098, 51478,  4193, 60882,\n",
       "         61137,  3638, 61877, 62520, 62552, 60597,  2217,  1452, 65611,\n",
       "         65691,   873,   809,   779,   564, 63152,  4604,  4961, 59468,\n",
       "         51600, 51688,  9772, 51974, 35859, 54007,  8349, 55620,  8117,\n",
       "          8090, 56401, 57564, 57752,  6333,  5887, 59201,  5068, 10291,\n",
       "          9260, 45932, 27345, 25820, 22052, 26476, 32470, 21470, 26681,\n",
       "         26800, 33435, 33869, 19731, 17711, 28157, 28110, 33526, 17897,\n",
       "         27786, 28363, 18379, 22254, 29360, 16237, 22866, 34986, 23239,\n",
       "         30904, 31844, 35104, 22567, 34318, 30894, 20277, 55644, 10196,\n",
       "         19932, 20087,  9064, 53431, 53798, 54924,  8748, 54129, 50865,\n",
       "          7836, 52512, 57624, 23471,   815,  1220, 66060,  1279, 65834,\n",
       "          1317,  1859, 63264, 24666, 27753,  1897,  2364, 24765, 61865,\n",
       "         25401, 25615,  4251,  5134, 58344, 57979, 27474, 62743, 10813,\n",
       "         67306, 32288, 45003, 10935, 12405, 42551, 13000, 34150, 17386,\n",
       "         45756, 17314, 16962, 46059, 48816, 14817, 48194, 31651, 14900,\n",
       "         27779, 45221, 34629, 44116,  6404, 58075, 33557,  5594,  1243,\n",
       "         27245, 64163, 60202, 60451, 65859, 34188, 24128, 22421, 62239,\n",
       "         25151, 14346, 14464,  1351, 19014, 33775, 35139,  9228, 52405,\n",
       "         30330, 30615, 51334, 10147, 32438, 51335, 10970, 51041, 52426,\n",
       "         10488, 24428, 26320, 34019, 28762, 34801,  3738, 13357, 34746,\n",
       "         29753, 19162, 24994, 24668, 50378, 19808, 14563, 33983,  1719,\n",
       "          1707,  1565, 32153, 39426, 61302, 47729, 17994, 17925, 46179,\n",
       "         45584, 54487, 18844, 26481, 27247,  5244, 43381, 41589, 47705,\n",
       "         26988,  4419, 55135, 14935,  8034, 37407, 11973, 55752, 13642,\n",
       "         46457, 57661, 27116, 36427, 41559, 34982, 30640, 16012,  9014,\n",
       "          6219, 38653, 52403, 67044,  9586, 46857,   969, 27689, 52787,\n",
       "         53840, 11134, 30862,  6608, 47561], dtype=int64),\n",
       "  'feature_absent_idx': array([19083, 52503, 52508, 19369, 52518, 19362, 19355, 19350, 52535,\n",
       "         52537, 52539, 19339, 52541, 19335, 52543, 52544, 19379, 52547,\n",
       "         19385, 52501, 19430, 19423, 19422, 19420, 19419, 52480, 52481,\n",
       "         19410, 52486, 19405, 19402, 19400, 52492, 19396, 52493, 19386,\n",
       "         52548, 52556, 19319, 52604, 19257, 19256, 19251, 19248, 52616,\n",
       "         52619, 52620, 19234, 52623, 52627, 19228, 52635, 52637, 19221,\n",
       "         52603, 19266, 52599, 52596, 19318, 52562, 19310, 52580, 52581,\n",
       "         19297, 19294, 19431, 19293, 52585, 19288, 19287, 52591, 52595,\n",
       "         19273, 19271, 19290, 19439, 52468, 52465, 52349, 19590, 19584,\n",
       "         19581, 52364, 19578, 19577, 19576, 52369, 19570, 52376, 19566,\n",
       "         19565, 19564, 19562, 52346, 52345, 19602, 52342, 52305, 19646,\n",
       "         52310, 52312, 19640, 19639, 52318, 19560, 19636, 19630, 52331,\n",
       "         19621, 19615, 52335, 52341, 19606, 52323, 52640, 19555, 19550,\n",
       "         52418, 52429, 19479, 19477, 19475, 19466, 52444, 52445, 52450,\n",
       "         19459, 52452, 19454, 52461, 52462, 19445, 52414, 52409, 52408,\n",
       "         19502, 19549, 52385, 19541, 19540, 19539, 19538, 19537, 19552,\n",
       "         52396, 19521, 19512, 19511, 19507, 19506, 19505, 52406, 19523,\n",
       "         19651, 19216, 19209, 18919, 52864, 18912, 18911, 52868, 52869,\n",
       "         52871, 18898, 18894, 18889, 52884, 18887, 52885, 52888, 52892,\n",
       "         52859, 52893, 52855, 18942, 18979, 18977, 18973, 52821, 52831,\n",
       "         18960, 18954, 18953, 18952, 18951, 52840, 52842, 18948, 18947,\n",
       "         18946, 18938, 18880, 52895, 52898, 52946, 52947, 18808, 52958,\n",
       "         18796, 18794, 52961, 18791, 52963, 52965, 52966, 18783, 18778,\n",
       "         52975, 18773, 52942, 52939, 52938, 18826, 18867, 52905, 18864,\n",
       "         52906, 52909, 18860, 18856, 18980, 18855, 18850, 18847, 52919,\n",
       "         18841, 18832, 18830, 52933, 52914, 52814, 52813, 52810, 19149,\n",
       "         52695, 52698, 19135, 19132, 19127, 19124, 19123, 19119, 52714,\n",
       "         52718, 52721, 19103, 52725, 52728, 19159, 52680, 52679, 52676,\n",
       "         19207, 19201, 19199, 19197, 19194, 19192, 19189, 52733, 19187,\n",
       "         52661, 52662, 19181, 52664, 52669, 19173, 52671, 19184, 19211,\n",
       "         52734, 19087, 52767, 52774, 19021, 52780, 52785, 52786, 52790,\n",
       "         52791, 19001, 52795, 18998, 52798, 18993, 18992, 18989, 52766,\n",
       "         19031, 19036, 19038, 19086, 19085, 19084, 19080, 19079, 52738,\n",
       "         19074, 19088, 52740, 52753, 19052, 19051, 52761, 19045, 19040,\n",
       "         52764, 52751, 52303, 19654, 19660, 51807, 20294, 20290, 51809,\n",
       "         51810, 20281, 51819, 51820, 20268, 20267, 20261, 20252, 20249,\n",
       "         20248, 20246, 51806, 20244, 20299, 20301, 51770, 20331, 20327,\n",
       "         51784, 51785, 20321, 51788, 20317, 20316, 20315, 20313, 51791,\n",
       "         51793, 51799, 20302, 20300, 20242, 51848, 51853, 51909, 51914,\n",
       "         51915, 20152, 51922, 20150, 20149, 51924, 51928, 51933, 20135,\n",
       "         20134, 51935, 51937, 20128, 20167, 51900, 20176, 20179, 51856,\n",
       "         20224, 51859, 20222, 20221, 20219, 51867, 51767, 51868, 51878,\n",
       "         51886, 20197, 20196, 20191, 20181, 51895, 51877, 20350, 20352,\n",
       "         51753, 20538, 51638, 20533, 20530, 51646, 20525, 20520, 20519,\n",
       "         20518, 51660, 51661, 20508, 51665, 20501, 51669, 20540, 51632,\n",
       "         20551, 20552, 20622, 51572, 20620, 51578, 51585, 20608, 20606,\n",
       "         51671, 20601, 20599, 20597, 20584, 20577, 20575, 51620, 20559,\n",
       "         51593, 20122, 20488, 20482, 20418, 51718, 20412, 20411, 20409,\n",
       "         51721, 20403, 20396, 51727, 51731, 51742, 20374, 51743, 20372,\n",
       "         51747, 20419, 20420, 20423, 51712], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 446\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 446\n",
       "  })},\n",
       " 'contains_subevent': {'feature_present_idx': array([ 2363, 61201, 38576, 17453, 14264, 34681, 60247, 57530, 19481,\n",
       "         60711, 62337, 14125, 33171, 33343, 34148, 11888, 19981,  1165,\n",
       "         50354, 47224,  7121,  6701, 65479,  5775, 47189, 57472, 41022,\n",
       "         59422, 31035, 53436, 50199, 66462, 40173, 29909, 33566, 19681,\n",
       "          3217,  4562, 16479, 62341, 12567, 12497, 12233, 65791,  7767,\n",
       "         65054,  7777,  4019, 47914, 33869, 19937, 11933, 56291, 29487,\n",
       "         42464, 34882,  2316, 62397, 44152,   580,  2537, 42336, 42324,\n",
       "          9862, 11120, 35023, 17461, 19301, 19442, 29674, 44255, 14086,\n",
       "         43383, 66648, 55072, 53954, 51533, 26547, 17741, 37388, 66456,\n",
       "         20878, 20101, 32497, 51380, 35769, 46663, 57503, 11500],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([50294, 22562, 59734, 39218, 26920, 26918, 54111, 26915, 54113,\n",
       "          9915, 49931, 59725, 59736,  9918, 41321, 22570, 22571, 26906,\n",
       "         39223, 59714, 26905, 59710, 34468, 17090, 36473, 26910, 26899,\n",
       "         59737, 54109, 26940, 36484, 46538, 22555, 49941, 59756, 59755,\n",
       "         26936, 59754, 17113, 17111, 17105, 59749, 36482, 36481, 22559,\n",
       "         59744,  9891, 46542, 33808, 46546,  9897, 59739, 59738, 26932,\n",
       "         17116, 26897, 46558, 59668,  9975, 54133, 59665,  9978, 17072,\n",
       "          9980, 26870,  9982, 46575, 22586,  9973, 17070,  9987,  9988,\n",
       "         26865, 26863, 39232,  9994, 41309, 26860, 22590, 26858, 22591,\n",
       "         54138, 59698, 40829, 54131,  9942, 59691, 41315, 46563],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 89\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 89\n",
       "  })},\n",
       " 'contains_time': {'feature_present_idx': array([43315, 61010, 61017, 19816, 34444, 11881,  8279, 61118,  4009,\n",
       "         32360,  3976, 29833, 61305, 54561, 54537, 22377, 61327, 41644,\n",
       "         15139, 29848, 61384, 27344, 41600,  3822, 23990,  3782,  3743,\n",
       "         61484, 23916, 48181, 27396,  4236, 42530,  4560, 60315,  4512,\n",
       "         29588, 42361, 27751, 47442,  8035, 21103, 42201, 42131,  4387,\n",
       "         47572, 23804, 60508,  4324, 60581, 60606, 14855, 23809, 47683,\n",
       "         14909,  4265, 47749,  8196, 34401,  4197, 42556, 41480, 61588,\n",
       "          3104,  3096, 62439,  3087, 11289, 62482, 62512, 32035,  2966,\n",
       "         15950, 27032, 19559, 26902, 48639, 19547, 32011, 53555, 53483,\n",
       "         16109, 62813, 30240,  2694, 40090, 40062, 48824, 21295,  2625,\n",
       "         40710, 41477,  3114, 40781, 15382, 41362, 22343, 61683, 48223,\n",
       "         48252,  3575, 34558,  3522, 11620, 48270, 61903, 22315, 15575,\n",
       "         61935, 61947, 15636,  3365, 48416, 27097, 24113, 62083, 40870,\n",
       "          3268, 62127, 62279, 48515, 19667, 60211, 60205, 42634, 56098,\n",
       "         20634, 58058, 44928,  6033, 23182,  6025, 44872,  6004, 20859,\n",
       "         58295, 44806, 22753, 58320, 46425,  5820, 28508, 46441, 33423,\n",
       "         44579,  5734, 12560, 58544, 12541,  5687, 44430, 55708, 12748,\n",
       "         33490, 45147,  7147, 12985,  6758, 45642, 45620, 56594,  6900,\n",
       "         45515,  6971, 45381, 57222, 12840, 23029,  7007, 29090, 56466,\n",
       "         12839, 20786, 28728, 12806, 57466, 57475, 57489, 45229, 57539,\n",
       "         46029, 45190, 45184, 29141, 32772, 55676, 58788, 12171, 21733,\n",
       "         14218, 47104, 23605, 32612, 59576, 14335, 43258, 55158, 27919,\n",
       "         43229, 55112, 55110, 33725, 55103,  4793, 59887, 23657, 23676,\n",
       "         59913, 42938, 14467, 54987, 54974, 33843, 14510, 55318, 20970,\n",
       "         32634, 12183, 58795, 46689, 44128, 58815, 22700, 33496, 28300,\n",
       "         58833, 46702, 13856, 46711, 43965, 29443, 39996, 55611, 43655,\n",
       "          5350, 28206, 28174, 28154,  5256, 28133, 28092, 28066, 33597,\n",
       "         33657, 59300, 47065, 12354, 21320, 53881, 31941, 30746, 17413,\n",
       "         37869, 35305, 37840, 18965, 65584,  9637, 51622, 49781, 25785,\n",
       "         25747, 65653, 17379,   941, 65674, 37743,   902, 49799, 49857,\n",
       "         51466, 37622, 65786, 31526, 65793, 17656, 37542, 37516, 65663,\n",
       "         51450, 37937,  1146,  1501, 52166, 64889, 19145, 10709, 52058,\n",
       "         49530, 52009, 26073, 35255, 17087, 51993,  1312, 51774,  1283,\n",
       "         22005, 38325, 10681, 51964, 30652, 49643,  9471, 49665, 51841,\n",
       "         38074, 37987, 25860, 53096, 19121, 35230,   733, 35837, 36752,\n",
       "         36275, 51085, 50248, 36715, 50267, 66816, 36290, 31317, 25389,\n",
       "         31137, 50940, 18448, 25073, 18704, 25170, 36591, 36511,    95,\n",
       "         36491, 50615, 67253, 50753, 31208,    42,    41, 50668, 67315,\n",
       "           164, 25632, 66645, 51197, 35847, 37390, 18803, 37357, 37353,\n",
       "         37347, 50051, 66123,  9806,  9821, 37217, 37118, 18756, 18737,\n",
       "           550, 50066, 18749, 37008, 24979, 18068, 18083, 51259, 24993,\n",
       "           443, 30982, 36888, 50206, 66454, 51332,  9306, 49733, 49513,\n",
       "         63999, 39302,  2038, 30464, 49310, 64093, 64143, 21417, 52524,\n",
       "         39037, 49403, 64258, 22055, 16707, 26500, 52478, 38978,  1777,\n",
       "          9185,  1749, 38902, 22080, 63799, 63769, 24346, 16265, 39873,\n",
       "         39826,  2414, 63150, 63192, 34930, 49013, 34933, 26612, 52343,\n",
       "         39723, 39524, 63446, 10976, 63511, 26576, 30412, 63585, 49170,\n",
       "         63624,  2170, 16361, 16809, 45730, 64632, 16852, 38853, 52227,\n",
       "         38652, 22047, 64476, 64423, 10830, 52282, 26280,  1523, 64718,\n",
       "         38752,  9276, 64483, 10188, 46153, 11228, 12734, 32886, 46169,\n",
       "         12729, 47994, 11904, 12715, 31610, 12733, 48559, 21513, 46303,\n",
       "         46481, 21151, 50075, 31373, 12572, 11921, 10279, 32818, 11013,\n",
       "         50157, 49141, 10693, 32852, 46351, 21354, 10235, 46348, 50217,\n",
       "         32066, 32961, 50271, 49096, 32966, 48808, 12850, 48956, 32977,\n",
       "         31863, 32980, 12871, 50607, 45888, 12891, 45765, 32372, 45753,\n",
       "         48927, 45744, 10030, 11078, 31969, 10725, 32394, 50587, 46040,\n",
       "         25233, 49057, 10761, 11151, 21675, 48694, 48723, 47764, 50367,\n",
       "         12797, 50417, 48729, 47866, 48749, 45975, 45954, 31847, 50567,\n",
       "         46102, 31564, 47640, 49178, 48076, 47435, 31561, 47177, 11658,\n",
       "         11639, 49789, 47155, 11730, 47465, 49614, 11572, 49807, 49848,\n",
       "         21401, 47540, 32217, 12208, 12168, 49341, 48217, 47359, 49722,\n",
       "         21158, 11813, 47297, 10617, 21180, 47342, 11762, 12011, 10557,\n",
       "         47287, 21058, 49420, 47348, 32556, 49737, 47202, 47178, 31557,\n",
       "         32683, 46910, 11560, 31473, 49306, 32100, 31466, 49301, 21155,\n",
       "         49491, 11452, 46706, 11418, 48507, 46683, 47611, 21267, 46642,\n",
       "         12501, 12051, 46570, 49259, 11960, 49926, 45735, 48059, 46822,\n",
       "         11553, 21214, 11526, 32704, 32724, 32753, 12269, 10775, 49905,\n",
       "         10414, 12296, 47792, 12317, 12345, 32144, 46728, 32132, 11375,\n",
       "         12302,    11, 12978, 16568, 16552, 35154, 16524, 39373, 35117,\n",
       "         16499, 19222, 35064, 39391, 39395, 39511, 39730, 16342, 39743,\n",
       "         39770, 16484, 16291, 19217, 39134, 16926, 38694, 38715, 16880,\n",
       "         38765, 19167, 38807, 16624, 38827, 38895, 35222, 16740, 16722,\n",
       "         19175, 35178, 39039, 16811, 19155, 34872, 39945, 40663, 34758,\n",
       "         15880, 15842, 40782, 40820, 40843, 40601, 15799, 40909, 15783,\n",
       "         40911, 15742, 41006, 41019, 41031, 40885, 39936, 40443, 40301,\n",
       "         16220, 39970, 16199, 40034, 19416, 34839, 40064, 34776, 16132,\n",
       "         19458, 34836, 40142, 16021, 40161, 19480, 15987, 19451, 41038,\n",
       "         16952, 17000, 36263, 36222, 36843, 18169, 36891, 36913, 36924,\n",
       "         36756, 36054, 37049, 17993, 37221, 37282, 18788, 37339, 35863,\n",
       "         36993, 17880, 18264, 18711, 18614, 18609, 18588, 18580, 36371,\n",
       "         18666, 18564, 18303, 36327, 18450, 18442, 18438, 36612, 36632,\n",
       "         18341, 18335, 18455, 38544, 37443, 17754, 35281, 38178, 17258,\n",
       "         35268, 19118, 17218, 38311, 38090, 17191, 17100, 17097, 38421,\n",
       "         17048, 35234, 38473, 17008, 38333, 17798, 38065, 37976, 37579,\n",
       "         37659, 18890, 37693, 37702, 35662, 18930, 37980, 37766, 35531,\n",
       "         35417, 37899, 17400, 37925, 17371, 35300, 35587, 34695, 34644,\n",
       "         41072, 44375, 20521, 20524, 33484, 44536, 20541, 13711, 13779,\n",
       "         44651, 33323, 33318, 13617, 13611, 44798, 44838, 44840, 44690,\n",
       "         20596, 44343, 44175, 14076, 20282, 43597, 43635, 43664, 33548,\n",
       "         13978, 44179, 43769, 43790, 13929, 13892, 13877, 33511, 20449,\n",
       "         44163, 43787, 43572, 13521, 33243, 13171, 45375, 13157, 45438,\n",
       "         20698, 45503, 13117, 45322, 13111, 45587, 13078, 45593, 45607,\n",
       "         13009, 45680, 12979, 33141, 33251, 45296, 13234, 45002, 33224,\n",
       "         45080, 13414, 13411, 45119, 13339, 45284, 13334, 13287, 45183,\n",
       "         45210, 45238, 20676, 45265, 13237, 20670, 20272, 20215, 43455,\n",
       "         41789, 15027, 15025, 19773, 41804, 41816, 34449, 15047, 14992,\n",
       "         41836, 34436, 34409, 14941, 41965, 14912, 42032, 14965, 34296,\n",
       "         41753, 41627, 15543, 41114, 41167, 41235, 41261, 41263, 15428,\n",
       "         41681, 34540, 15347, 41489, 19760, 41524, 41544, 15210, 41616,\n",
       "         19743, 19849, 14839, 34252, 43000, 43030, 43049, 43246, 43249,\n",
       "         33717, 14322, 14419, 14307, 14209, 43321, 14193, 43356, 43392,\n",
       "         33687, 14142, 33701, 33735, 42975, 42942, 42117, 34213, 14769,\n",
       "         42321, 34061, 42353, 42358, 42448, 42469, 42498, 14616, 42510,\n",
       "         14606, 33920, 42893, 33818, 14455, 45697, 10029, 30657, 10014,\n",
       "         61278,  3974,  3971, 61319,  3892, 23929, 23936,  3861,  3852,\n",
       "         61343, 27350, 61413,  3803, 61477,  3713, 23994, 61511, 61119,\n",
       "         61547,  4021,  4048,  4391, 27639,  4380, 60567, 27634, 60589,\n",
       "         60621,  4271, 23822, 27562, 27546, 27410, 61003,  4097,  4071,\n",
       "          4064, 61071, 61107, 61606, 24033, 61634, 62147, 62301, 62330,\n",
       "         62379,  3127, 62389, 62445, 62453, 62516,  2923, 62531, 24184,\n",
       "         62628, 62641,  2836, 62715, 62717,  3285,  3300,  3330, 24095,\n",
       "          3621], dtype=int64),\n",
       "  'feature_absent_idx': array([40416, 10982, 19294, 19293, 10986, 10987, 49856, 60006, 19290,\n",
       "         10991, 32215, 19288, 32226, 19287, 32209, 26186, 59996, 59995,\n",
       "         45895, 54433, 45899, 59993, 11006, 59992, 32203, 45892, 45900,\n",
       "         60013, 60015, 10943, 45874, 10947, 32245, 60031, 60028, 26173,\n",
       "         45879, 60024, 10958, 26178, 10978, 10960, 10963, 32235, 26180,\n",
       "         10967, 19297, 32232, 60020, 60018, 32230, 32228, 32227, 54430,\n",
       "         60038, 11010, 49854, 59963, 11052, 11053, 11055, 32169, 45929,\n",
       "         32167, 11059, 59960, 59959, 59958, 59964, 11065, 11069, 11071,\n",
       "         26203, 59953, 54445, 59950, 45935, 32158, 11080, 19266, 59945,\n",
       "         59956, 49855, 32170, 45927, 32199, 45903, 45904, 11018, 59987,\n",
       "         59986, 32195, 32194, 59984, 49851, 49847, 19271, 32186, 32179,\n",
       "         19273, 11036, 11037, 32177, 45923, 59971, 11042, 26200, 11044,\n",
       "         11045, 54438, 59944, 60039, 60041, 49885, 10838, 10839, 45824,\n",
       "         45826, 60083, 10843, 60082, 26148, 10846, 32316, 10836, 10850,\n",
       "         10852, 32312, 32311, 32309, 32306, 19339, 54396, 54399, 60073,\n",
       "         19335, 54400, 45828, 10866, 45823, 60093, 49901, 10803, 45809,\n",
       "         60107, 10806, 32351, 49898, 60104, 32348, 54379, 60100, 32328,\n",
       "         26135, 19355, 32340, 26138, 32338, 10821, 10822, 26139, 49891,\n",
       "         19350, 26141, 49890, 49897, 32251, 32297, 32293, 10911, 19318,\n",
       "         10913, 45863, 49865, 60056, 54412, 45864, 60053, 32262, 10921,\n",
       "         10910, 10922, 54413, 45872, 54418, 10928, 10931, 10932, 32254,\n",
       "         60047, 54419, 19310, 10938, 45865, 45843, 19319, 10905, 10874,\n",
       "         45846, 26159, 54402, 45847, 10879, 32287, 32286, 10882, 10883,\n",
       "         45849, 32270, 32284, 54406, 10889, 32278, 10893, 10894, 32276,\n",
       "         60065, 26162, 10900, 26163, 45856, 54404, 32154, 59943, 45939,\n",
       "         59837, 54490, 19197, 46016, 32024, 54491, 46018, 19194, 19192,\n",
       "         11274, 26254, 19199, 11276, 59828, 59827, 19189, 11281, 46023,\n",
       "         59825, 46024, 11285, 32010, 11287, 59821, 54493, 32008, 32030,\n",
       "         59840, 11230, 32057, 26246, 11233, 32051, 59853, 59852, 32050,\n",
       "         32047, 49800, 59846, 11259, 11244, 46007, 11248, 59845, 32040,\n",
       "         46008, 19201, 59843, 11254, 49796, 32032, 46013, 46006, 19207,\n",
       "         46028, 59817, 59797, 59796, 59795, 11331, 46049, 26268, 59793,\n",
       "         31973, 59786, 11340, 54509, 26266, 26273, 19159, 59783, 59780,\n",
       "         11350, 59779, 11352, 11353, 11354, 11355, 54518, 46066, 46063,\n",
       "         59820, 26265, 19173, 32005, 19187, 32000, 19184, 59810, 11303,\n",
       "         46036, 54495, 11306, 11307, 59809, 59799, 19181, 54497, 59808,\n",
       "         11314, 54499, 54503, 26262, 26263, 46047, 11321, 59803, 31982,\n",
       "         31994, 54485, 11226, 32061, 11124, 59922, 45948, 59921, 59920,\n",
       "         26216, 59917, 32126, 19248, 59915, 45953, 11123, 26218, 11139,\n",
       "         59911, 11142, 59909, 54470, 32115, 11150, 32113, 59904, 59903,\n",
       "         59901, 59914, 11159, 32130, 11119, 59942, 11094, 26208, 49837,\n",
       "         54452, 26210, 32146, 54457, 19257, 59936, 32142, 54465, 32141,\n",
       "         59935, 59934, 45945, 11110, 49831, 59933, 49825, 59930, 11116,\n",
       "         26215, 19251, 19256, 59899, 26233, 11164, 32077, 49803, 45986,\n",
       "         11202, 26242, 19216, 54483, 59870, 45990, 59868, 59866, 45984,\n",
       "         11211, 11214, 19211, 59864, 11217, 19209, 11219, 11220, 45993,\n",
       "         32063, 11223, 45994, 26245, 11196, 11194, 19221, 32106, 32105,\n",
       "         45968, 45969, 19234, 59892, 32098, 32096, 54476, 11176, 11177,\n",
       "         32093, 59885, 54477, 32091, 45976, 19228, 26237, 59883, 49809,\n",
       "         32086, 59877, 54480, 11191, 32082, 10801, 19362, 10799, 60113,\n",
       "         10402, 45611, 19502, 54276, 32653, 10408, 32652, 45615, 45616,\n",
       "         26013, 45618, 49994, 45619, 32640, 54280, 45628, 60345, 32632,\n",
       "         60344, 60342, 32630, 60340, 32629, 60338, 45626, 54282, 54273,\n",
       "         45609, 32676, 32675, 10370, 60382, 19511, 10376, 10377, 26009,\n",
       "         60374, 26010, 10383, 19505, 60373, 32669, 45603, 10388, 10390,\n",
       "         10391, 10392, 19507, 10394, 10395, 19506, 60367, 32670, 19512,\n",
       "         49988, 10442, 10478, 19466, 60305, 32585, 60300, 32578, 32577,\n",
       "         10490, 45664, 32575, 10496, 54302, 32572, 19459, 10502, 10503,\n",
       "         26042, 54306, 32567, 60287, 45671, 45672, 26043, 10511, 60292,\n",
       "         10441, 32590, 26033, 54290, 45634, 45635, 60332, 49985, 45638,\n",
       "         10451, 45639, 60329, 26027, 32614, 10474, 32611, 19477, 45643,\n",
       "         54297, 19475, 26029, 32601, 32600, 10468, 54299, 32597, 45652,\n",
       "         19479, 10366, 10363, 60386, 60453, 32757, 19552, 45553, 45557,\n",
       "         19550, 19549, 10268, 45565, 10271, 45567, 32760, 32744, 60440,\n",
       "         54256, 10280, 10281, 10282, 32739, 60438, 60436, 60435, 19541,\n",
       "         10289, 32743, 19540, 10257, 19555, 25971, 19566, 10228, 19565,\n",
       "         60464, 10231, 19564, 32782, 54244, 19562, 54245, 54251, 45535,\n",
       "         32775, 19560, 10242, 25972, 25976, 32770, 45542, 32767, 10249,\n",
       "         10250, 45544, 10239, 60430, 32734, 45573, 45594, 19521, 10336,\n",
       "         60401, 32697, 10339, 32696, 50000, 10342, 10343, 45598, 45592,\n",
       "         10346, 45599, 10349, 32686, 60394, 45600, 10355, 49999, 10357,\n",
       "         60390, 54270, 60387, 32689, 10330, 19523, 25998, 60428, 32731,\n",
       "         19539, 19538, 10299, 10300, 19537, 32726, 45576, 10304, 25988,\n",
       "         60421, 32722, 10308, 10309, 60420, 54260, 54261, 32716, 10321,\n",
       "         45583, 60410, 54266, 10326, 32707, 19454, 46067, 10514, 26044,\n",
       "         26097, 32427, 45761, 32424, 10697, 10699, 32423, 54351, 26098,\n",
       "         60168, 10706, 19396, 54354, 10710, 10711, 32417, 32415, 45769,\n",
       "         10716, 10717, 60164, 32412, 10720, 32411, 10708, 60160, 32430,\n",
       "         10687, 10659, 45743, 60191, 26087, 60189, 60188, 10665, 10666,\n",
       "         45747, 19405, 19402, 32431, 32440, 19400, 45758, 60183, 10677,\n",
       "         49941, 54350, 10680, 60180, 60178, 32435, 10686, 10673, 10658,\n",
       "         10723, 49931, 54361, 10767, 54365, 26125, 10773, 60130, 60129,\n",
       "         60128, 19369, 32371, 10782, 10765, 54369, 10785, 10787, 60124,\n",
       "         32365, 10790, 32364, 32362, 45800, 45803, 54372, 45807, 26129,\n",
       "         26104, 45786, 10758, 32404, 10730, 19386, 32401, 60154, 10734,\n",
       "         32400, 10736, 10737, 32399, 10740, 10763, 19385, 10746, 45779,\n",
       "         32392, 49923, 26115, 19379, 60143, 32388, 60140, 60139, 60138,\n",
       "         10742, 49948, 10654, 19410, 26060, 32532, 19439, 60253, 26061,\n",
       "         10558, 60249, 60248, 32525, 32524, 26063, 10549, 10565, 32518,\n",
       "         60243, 45695, 45696, 32515, 32514, 10575, 10576, 54337, 10578,\n",
       "         10579, 49960, 45699, 10547, 49973, 10518, 45674, 49978, 10522,\n",
       "         60280, 54318, 60275, 10527, 60274, 54319, 45683, 60256, 60270,\n",
       "         32547, 32546, 49976, 19445, 32543, 60260, 10540, 32539, 60258,\n",
       "         32538, 10544, 32548, 60238, 32511, 10584, 45726, 26076, 10626,\n",
       "         32472, 45731, 60210, 10630, 45732, 10632, 10633, 10634, 45725,\n",
       "         26077, 60206, 10638, 10641, 10642, 32464, 10645, 10646, 45736,\n",
       "         10649, 45740, 32459, 60209, 19419, 10618, 19420, 45701, 32509,\n",
       "         60235, 19431, 10589, 19430, 32506, 45704, 45705, 60228, 49954,\n",
       "         45711, 32495, 10602, 32493, 45713, 19423, 45716, 45717, 19422,\n",
       "         32486, 10611, 26075, 32483, 45722, 32562, 32790, 59774, 11363,\n",
       "         18887, 31418, 31417, 31416, 31414, 59274, 59273, 26473, 59270,\n",
       "         59268, 46417, 18889, 12132, 12134, 54700, 18880, 59265, 59264,\n",
       "         59262, 12142, 12143, 26478, 49639, 59261, 26474, 54702, 59283,\n",
       "         59286, 31445, 46390, 26464, 49648, 12087, 59301, 18898, 46393,\n",
       "         59299, 31438, 59293, 26470, 31435, 18894, 49642, 46402, 12104,\n",
       "         31429, 12106, 46406, 12108, 12109, 31426, 54694, 46399, 46389,\n",
       "         26482, 31399, 18855, 54723, 12198, 26492, 26493, 31367, 12202,\n",
       "         12205, 46439, 12207, 18850, 18856, 26496, 31360, 46442, 12215,\n",
       "         12218, 59212, 59211, 59210, 12224, 18847, 31355, 26502, 12212,\n",
       "         54705, 26491, 46434, 54712, 46426, 12158, 46427, 26487, 18867,\n",
       "         59249, 31389, 18864, 54715, 31386, 54719, 46428, 54718, 18860,\n",
       "         12178], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_topic': {'feature_present_idx': array([25854, 15416, 65202, 15488, 54259, 17955, 26017, 25980, 25917,\n",
       "         46122, 46396, 63781,  3983, 46981, 65142, 65108, 59663, 37537,\n",
       "         25697, 59646, 59523, 54539,  8262, 42094, 43127, 17929, 56540,\n",
       "         37544, 54160, 46423, 49736, 20928, 45837, 10054, 37384, 48961,\n",
       "         50002, 49975, 46972, 35135, 53454,  3035, 27494, 53557, 14865,\n",
       "         35265, 56836, 27088, 27001,  6634, 53847, 21189,  9900, 53923,\n",
       "         41874, 21191,  3503, 15355,  6266, 24892, 17900,  4368, 17588,\n",
       "         55392, 39500,  8811, 61291, 49203, 23392, 16930, 23216, 55600,\n",
       "         23188, 56099,  5412, 43536, 55660, 42258, 17047, 64160, 46319,\n",
       "         17093, 63978, 22828, 22120, 43436, 48500, 55901,  5757, 17702,\n",
       "         34945, 55349, 36792,  4381, 21694, 36503, 36536,  4497, 36553,\n",
       "         24609, 24551,  9223,  8331, 48521,  9168, 16270, 42125,  6123,\n",
       "         42170,  9021,  9019, 24031, 23944, 39244, 43633,  8904, 39335,\n",
       "         16651,  5064, 23590, 55341, 44477, 14589, 53093, 31852, 19618,\n",
       "         51491, 19665, 50492, 34000, 61558, 31465, 12375, 38127, 44948,\n",
       "         50483, 31239, 10871, 66700, 10824,  7746, 38678,  1225, 42833,\n",
       "         61756, 34115, 38081, 58372, 20113,  1358, 30571, 31891,  1381,\n",
       "         61469, 46673, 32985, 50854, 11657,  7483, 19296, 50922, 32667,\n",
       "         61233, 51002, 11763, 11825, 32454, 32336, 32331, 51044, 57842,\n",
       "         38295, 47621, 12060, 61440, 32140, 51164, 38183, 51263, 12157,\n",
       "         31993, 50626, 11098, 60821, 57488, 61800, 40306, 30494,  2002,\n",
       "         29498,  2091, 14147,  6976,  2116, 20283, 44697, 63032, 29234,\n",
       "         29198, 50130, 52805, 52872, 50126, 28833, 52940, 60359, 48033,\n",
       "         28411, 65770, 50048, 41702, 40389, 34397, 29560, 58618, 52499,\n",
       "         52525, 66465, 44752, 18502, 29948, 30182, 66408, 13326, 30211,\n",
       "         47871, 29710,  7929,  7956, 52673, 40596, 13092, 29821, 19131,\n",
       "         18186, 58520, 18263, 58446, 48578, 19049, 38945, 18102, 18378,\n",
       "         58564, 17781, 39343, 18921, 18004, 48525, 18386, 18790, 48534,\n",
       "         17793, 17728, 57905, 39210, 18381, 38957, 18926, 23203, 39357,\n",
       "         12978, 40529, 13334, 13390, 60686, 47903, 13610, 14166, 60408,\n",
       "         14352, 60384, 14386, 60319, 14498, 14546, 14582, 48120, 60834,\n",
       "         14757, 47839, 12795, 11562, 11674, 61238, 47533, 61227, 40993,\n",
       "         40905, 61184, 40877, 12160, 12166, 12271, 12347, 61036, 12623,\n",
       "         12683, 47811, 12870, 14807, 14862, 48122, 16192, 39633, 39619,\n",
       "         59325, 59229, 39576, 16524, 39525, 16604, 16652, 48445, 16872,\n",
       "         59063, 17034, 17112, 58976, 17433, 59419, 16083, 59450, 39675,\n",
       "         14959, 60182, 15295, 40042, 15362, 40036, 15377, 15452, 17517,\n",
       "         39968, 15544, 59875, 39840, 59655, 15966, 16004, 48343, 16024,\n",
       "         19208, 19213, 56225, 19247, 27914, 35019, 53215, 50004, 28009,\n",
       "         53086, 28431, 28463, 28641, 52995, 50091, 29266, 50181, 29411,\n",
       "         50183, 34412, 29593, 50196, 29715, 53267, 53406, 27675, 53445,\n",
       "         36107, 54368, 36040, 25830, 54262, 35950, 35928, 26158, 49700,\n",
       "         34370, 26290, 26465, 54005, 26507, 26693, 26714, 26876, 35542,\n",
       "         35273, 27305, 54099, 25675, 34330, 30014, 31945, 51366, 32014,\n",
       "         33811, 32163, 50645, 33728, 32205, 33716, 33686, 33681, 51014,\n",
       "         32512, 50657, 33620, 50899, 32958, 33604, 33408, 31933, 31772,\n",
       "         31695, 51608, 52456, 30169, 52431, 30316, 30491, 34187, 30609,\n",
       "         52321, 50268, 29946, 52193, 52032, 31045, 31108, 51832, 31227,\n",
       "         31362, 31383, 31447, 31466, 52146, 54385, 36148, 54565, 37628,\n",
       "         21000, 56699, 37579, 21279, 21301, 21360, 48993, 56591, 21574,\n",
       "         56522, 37422, 56462, 56458, 56437, 21920, 49030, 49050, 56381,\n",
       "         56927, 20920, 37756, 57157, 48848, 19282, 57707, 48899, 19487,\n",
       "         38289, 19671, 19798, 19924, 21996, 20037, 20115, 20127, 20143,\n",
       "         38071, 20171, 48927, 48929, 57233, 20363, 57486, 56290, 37385,\n",
       "         56165, 24078, 24082, 55244, 24246, 55146, 55142, 24327, 24328,\n",
       "         24331, 24043, 24398, 36554, 24528, 54927, 49416, 36272, 36269,\n",
       "         25090, 25121, 54582, 24418, 48833, 23905, 36781, 49113, 49147,\n",
       "         55997, 55944, 49157, 22720, 22878, 49190, 22963, 49205, 37021,\n",
       "         23364, 23408, 23424, 36917, 36908, 23542, 55386, 23615, 55291,\n",
       "         36988, 61303, 59121, 33313,  8429, 44505, 65739,  8506,  8539,\n",
       "          8565,  8399,  2512,  8776,  8782, 65853, 42181, 62412,  2375,\n",
       "          2407,  8869,  2830, 62622, 63037,  7922, 63034, 63010, 44213,\n",
       "          3173,  8368, 65416, 62727,  2970,  8155, 42366, 44264, 44301,\n",
       "          8091,  2341,  8939,  2333,  1741, 47255, 62236,  1705,  1607,\n",
       "         44782,  1783,  1517, 66496, 41964, 44819,  9800,  9857,  1415,\n",
       "         42003,  1830,  1887,  9520, 45770, 62362, 44678,  2210,  9128,\n",
       "          9145, 62307, 66155, 62277, 66166,  9314, 62274, 45751,  9409,\n",
       "         66174, 44183, 63043,  7739,  3454, 64474, 43743, 46359, 64608,\n",
       "         43755,  6320, 46289,  6323,  6491, 43037,  4726,  4716,  4660,\n",
       "         43875, 43790,  6163, 64427,  6104,  5465, 46325, 64079, 43583,\n",
       "          5707, 43403, 64312,  5220,  5218,  5203, 46326, 63912,  5994,\n",
       "          5147,  6085, 46532,  1398,  4619, 43887,  3777, 63190,  7436,\n",
       "          3752,  7466,  3717,  3848,  7480,  3707,  7540, 42613,  3602,\n",
       "          3455, 63116, 65266,  3974,  3995,  7305,  4550, 42910, 43893,\n",
       "          4402, 64880,  6911, 46562,  6949, 46222,  4178, 65020, 63503,\n",
       "          7179, 65030, 65033, 63590, 41926,  5546,  1237, 62030, 10802,\n",
       "           344,   590, 11255, 10776, 67137, 10232, 10362, 45109,   281,\n",
       "         61388,  1127,   999, 67272, 10039, 67168, 61998, 41633, 44945,\n",
       "            38, 41287, 45287, 41636, 11113, 45521, 61890, 41641, 10166,\n",
       "         44964, 45444, 61773, 44977, 10401, 47368, 45425,  1281,   868,\n",
       "           276, 10624, 10652, 10529, 67079, 10440, 11403, 61570, 47528,\n",
       "         41186,  1297, 61377, 10411,   203, 36212, 54863, 54553, 51006,\n",
       "         49539, 54839, 32447, 32374, 46242, 36340, 36330, 64950, 64958,\n",
       "         64965, 25230, 25295, 54590, 25268, 54801, 44820, 45422, 54533,\n",
       "         54274,  3799, 26094,   388,   394, 51128, 26020, 32172, 26220,\n",
       "         35879, 26241, 35869,  3672, 33786, 67061, 25379,  3846, 46176,\n",
       "         32367,   289, 54526, 33646, 25466, 49545, 54286, 25646,  4077,\n",
       "          4056, 25736, 36049, 25796, 45222, 45225, 24708, 32745,  4476,\n",
       "         33190, 55567, 33180, 55556,  5194, 33165, 33543, 64328, 64372,\n",
       "         33085, 43612, 36817, 23577, 33072, 33558, 64291, 64396, 64280,\n",
       "         23252, 33257, 43530, 64191, 23046, 55655, 23099, 23107, 55651,\n",
       "          5392, 33321,     4, 43606, 45327,  5301, 33206, 36970, 33050,\n",
       "         33045,  5050, 32857,  4706, 32785, 67034,  4622, 50942, 36655,\n",
       "         55039, 32650, 32620, 67197,  4529, 24567, 43892,  4501, 49337,\n",
       "         24250, 32904,  4727, 55337, 23703, 33040, 23800,  5012, 23980,\n",
       "         45416, 54954, 50875, 49233, 67276, 43799, 24103, 55276,  4733,\n",
       "         33617,  4844, 26357, 26575, 26425, 51771,  2257, 29136, 34510,\n",
       "         50174, 29206,  2224, 52816, 52772, 67332, 29344, 31296, 66735,\n",
       "         52710, 31200, 51805, 44925, 66684, 31411, 34689, 44984, 51634,\n",
       "         45787, 28462,   984, 28491, 28492, 50113, 28575, 44544, 34011,\n",
       "         28669, 28675,  2384, 34744, 34731, 28598, 34796, 31094,  1971,\n",
       "         66484, 34117, 50298, 44800, 30219, 34306, 30286, 30029, 30806,\n",
       "         30665, 52387, 66636, 52378, 52371, 66556, 45533, 34247,  1221,\n",
       "         29981, 52574, 44726, 51916, 66308, 29698, 66339,  1805, 52631,\n",
       "         52569, 66357, 29905, 52054, 66668, 30883, 44845, 29953, 52575,\n",
       "         34071, 28334, 53001, 64153,  3366, 26956, 67029, 49829, 66868,\n",
       "         35580, 49845, 26869,  3332, 33813,   614, 65362, 35314, 66858,\n",
       "         33861, 27442, 53673,  3084, 26849, 26784,  3573, 65273, 26524,\n",
       "         53984, 26543,  3438, 49758, 35673, 50631, 26675, 35691, 26708,\n",
       "         53882, 46025, 26753, 26756, 50214, 35161, 27489, 65485, 45041,\n",
       "         44456, 50517, 31648,  2662, 28043, 28050, 33900, 34893, 51530,\n",
       "         51554], dtype=int64),\n",
       "  'feature_absent_idx': array([53212, 13219, 57825, 13221, 29097, 57821, 29094, 46294, 13233,\n",
       "         57811, 29086, 46299, 57807, 57801, 29098, 13243, 57795, 13247,\n",
       "         13249, 46304, 46305, 13255, 29071, 13259, 57782, 46312, 46314,\n",
       "         13269, 13271, 57796, 57772, 13217, 13214, 13167, 57860, 29133,\n",
       "         46274, 29131, 13173, 57857, 13176, 29127, 57856, 29123, 13183,\n",
       "         29119, 57835, 57850, 13193, 29115, 29114, 57846, 29111, 13201,\n",
       "         29110, 29107, 29105, 57840, 13209, 46284, 46287, 13190, 29135,\n",
       "         13273, 57770, 57735, 13328, 13329, 57731, 57730, 46341, 13333,\n",
       "         57725, 13338, 29020, 46342, 57723, 46343, 13322, 46344, 13345,\n",
       "         13347, 29012, 57718, 57717, 29008, 57715, 29007, 46349, 29004,\n",
       "         46350, 46353, 13362, 13344, 13274, 57736, 29029, 29058, 57768,\n",
       "         13280, 57766, 46316, 57762, 46317, 13288, 13290, 13292, 13293,\n",
       "         13295, 29042, 29028, 29041, 29040, 13301, 57750, 29039, 13307,\n",
       "         29035, 13311, 29033, 57745, 29032, 57741, 13317, 46334, 57753,\n",
       "         57864, 29139, 13161, 57975, 57974, 57973, 13014, 57972, 13016,\n",
       "         29252, 57971, 46183, 13020, 29249, 46184, 46187, 57977, 57968,\n",
       "         13029, 29239, 46198, 13037, 57960, 46199, 13040, 29229, 29226,\n",
       "         57955, 57953, 29219, 13052, 13028, 46209, 57978, 29254, 58029,\n",
       "         58021, 12960, 46162, 58017, 12964, 29287, 46163, 46164, 29284,\n",
       "         12969, 12970, 12971, 46182, 12973, 58000, 46168, 12983, 57998,\n",
       "         12987, 12989, 46172, 57991, 57990, 57988, 13002, 13003, 46180,\n",
       "         58006, 29214, 29213, 46214, 29175, 57911, 57908, 57907, 57901,\n",
       "         57900, 57899, 29170, 57898, 29161, 57887, 57885, 46258, 13112,\n",
       "         29152, 29147, 13146, 29146, 13148, 13149, 46268, 13151, 57876,\n",
       "         13154, 46271, 29140, 57867, 13160, 29149, 29177, 13108, 13106,\n",
       "         13065, 29205, 46228, 57940, 29200, 57938, 57937, 57933, 29199,\n",
       "         29196, 57929, 13079, 13081, 29194, 13084, 46237, 29191, 57927,\n",
       "         46239, 57924, 13095, 13096, 29184, 13098, 46241, 13101, 57922,\n",
       "         13103, 57919, 13364, 13365, 28994, 28993, 46480, 28805, 28803,\n",
       "         46482, 46486, 13637, 13638, 46487, 46488, 57480, 46489, 13647,\n",
       "         46490, 13631, 28792, 46493, 13654, 28788, 57468, 46494, 13659,\n",
       "         28784, 28783, 46495, 28779, 28778, 28777, 13671, 28791, 13672,\n",
       "         13626, 57501, 13577, 13579, 13582, 28840, 57526, 28839, 57525,\n",
       "         46458, 57524, 46462, 57518, 57516, 13595, 57493, 57513, 28827,\n",
       "         46472, 13606, 28823, 13608, 46473, 46475, 28818, 28817, 13615,\n",
       "         57502, 28815, 13620, 57511, 28775, 13675, 28772, 57423, 13731,\n",
       "         28738, 57422, 57420, 46538, 57415, 57413, 46542, 57405, 57403,\n",
       "         28727, 28724, 13729, 57401, 46546, 57395, 28715, 57392, 57391,\n",
       "         57389, 28714, 28713, 13767, 57386, 13772, 13773, 13774, 57399,\n",
       "         46536, 57425, 13725, 57450, 28768, 28767, 57447, 28765, 13688,\n",
       "         13689, 57442, 57441, 13692, 46510, 46511, 13696, 28759, 13698,\n",
       "         46513, 13701, 46518, 13705, 57437, 28754, 57433, 57430, 57429,\n",
       "         57428, 13718, 13719, 46530, 57427, 46449, 58030, 13571, 13568,\n",
       "         46383, 13429, 57643, 57642, 57641, 13435, 28942, 46389, 13441,\n",
       "         28940, 46390, 13446, 13448, 13426, 57629, 46393, 13454, 28933,\n",
       "         57626, 28932, 28929, 28928, 13463, 28927, 46399, 13466, 13467,\n",
       "         57611, 57628, 57609, 13425, 13423, 57699, 46361, 28986, 57688,\n",
       "         28983, 57683, 28982, 28981, 28976, 57676, 57670, 57667, 57666,\n",
       "         46382, 13399, 46372, 57662, 13405, 28964, 46374, 13410, 57656,\n",
       "         46377, 13415, 57650, 28957, 28954, 13422, 57665, 28924, 46402,\n",
       "         57605, 28880, 57571, 57570, 13532, 46426, 57568, 57567, 13536,\n",
       "         57566, 46427, 46428, 13541, 46434, 28881, 46439, 28865, 46442,\n",
       "         13551, 57550, 28860, 13557, 46446, 28853, 57544, 13564, 13565,\n",
       "         13566, 46447, 28868, 13524, 28887, 13520, 13476, 46406, 57601,\n",
       "         13485, 57599, 28909, 57596, 28907, 57594, 13494, 13495, 46417,\n",
       "         57591, 13498, 28905, 28902, 28901, 28900, 28897, 13507, 28896,\n",
       "         28895, 28893, 13511, 13513, 28890, 57579, 57578, 13519, 28850,\n",
       "         12952, 12951, 58032, 58476, 12367, 12368, 29727, 12372, 29726,\n",
       "         12374, 58465, 29720, 45892, 58460, 29717, 45895, 12365, 12390,\n",
       "         29709, 29708, 29705, 29703, 45899, 58450, 29701, 29700, 45900,\n",
       "         12404, 29696, 58444, 58443, 12391, 58442, 12363, 29731, 12315,\n",
       "         58513, 12318, 29771, 45863, 45864, 45865, 29765, 45872, 58506,\n",
       "         45874, 58502, 29758, 12362, 29757, 29754, 29751, 12338, 58491,\n",
       "         29750, 58489, 12344, 58488, 12346, 29745, 45879, 12356, 29735,\n",
       "         58496, 58439, 12411, 12412, 12468, 58388, 58385, 58380, 45935,\n",
       "         12484, 29640, 58373, 45939, 12490, 12491, 12494, 12495, 58389,\n",
       "         29635, 45945, 45948, 58364, 58363, 12506, 58361, 58360, 12510,\n",
       "         58358, 12512, 58357, 29628, 58354, 58367, 29654, 29656, 29658,\n",
       "         58438, 29693, 29692, 12418, 45903, 58434, 58429, 58428, 45904,\n",
       "         12428, 12431, 29683, 58416, 58415, 58413, 58411, 29675, 45923,\n",
       "         12446, 12447, 12448, 12452, 29666, 12454, 45927, 29661, 12459,\n",
       "         12460, 45929, 12313, 29624, 29776, 12308, 29903, 29899, 58635,\n",
       "         45779, 58632, 58631, 12158, 29891, 58628, 45786, 29887, 58621,\n",
       "         29883, 12143, 29882, 58615, 29879, 12178, 29876, 29875, 12184,\n",
       "         29870, 12186, 29867, 58601, 45800, 45803, 12198, 29880, 29857,\n",
       "         12142, 29907, 12087, 45726, 45731, 45732, 29957, 29956, 58672,\n",
       "         58671, 29950, 12104, 12106, 29943, 12108, 45769, 12109, 58666,\n",
       "         45740, 45743, 58657, 29929, 45747, 45758, 29920, 45761, 29915,\n",
       "         12132, 12134, 58643, 45736, 29856, 12202, 45807, 29817, 58553,\n",
       "         29815, 29814, 45826, 58548, 12267, 29811, 29808, 45828, 12279,\n",
       "         58538, 29799, 12258, 12283, 58536, 45843, 12292, 12293, 12294,\n",
       "         45846, 45847, 12297, 45849, 29788, 58526, 58519, 29782, 58537,\n",
       "         29822, 12254, 12253, 12205, 45809, 12207, 29851, 29849, 12212,\n",
       "         12215, 29845, 12218, 58573, 12224, 58572, 58571, 12230, 29834,\n",
       "         12234, 12236, 12239, 12240, 29831, 29830, 12243, 45823, 12247,\n",
       "         29825, 58559, 45824, 12251, 12252, 45856, 13776, 29622, 45953,\n",
       "         58151, 29410, 12799, 29408, 29406, 12805, 12807, 12811, 12812,\n",
       "         12813, 46100, 29393, 29392, 58152, 58132, 29389, 29388, 12824,\n",
       "         29387, 12826, 46110, 12829, 29383, 58122, 29382, 58118, 12835,\n",
       "         29380, 58130, 29377, 29413, 58158, 29453, 46066, 58191, 46067,\n",
       "         29444, 58179, 58178, 46071, 12762, 12763, 29436, 29433, 29432,\n",
       "         29414, 12768, 12770, 12771, 46075, 12773, 29430, 12777, 29424,\n",
       "         29423, 29422, 46088, 12782, 58163, 46089, 12769, 58112, 29372,\n",
       "         58110, 12898, 29329, 12901, 29326, 46146, 58060, 29320, 58057,\n",
       "         29317, 12915, 58052, 58049, 58046, 46138, 29308, 12930, 29305,\n",
       "         29304, 29303, 58039, 46158, 58037, 46159, 58036, 12943, 58034,\n",
       "         12947, 12948, 29306, 12894, 29334, 12892, 46117, 58106, 29368,\n",
       "         12851, 12852, 12854, 12858, 46120, 46124, 12862, 58092, 58090,\n",
       "         12865, 29357, 46128, 29353, 29352, 29350, 12877, 12878, 29349,\n",
       "         12880, 46129, 46130, 29346, 58072, 29345, 46135, 29335, 58195,\n",
       "         58349, 12742, 58197, 29572, 12586, 58305, 58301, 29569, 12592,\n",
       "         45990, 12595, 12596, 12597, 12598, 58297, 45993, 45986, 58294,\n",
       "         58292, 29558, 29552, 58286, 29549, 29548, 58285, 29547, 29544,\n",
       "         29543, 58283, 58277, 58274, 45994, 46006, 12583, 12581, 29615,\n",
       "         12527, 12530, 58340, 12534, 58337, 29608, 29605, 29602, 12544,\n",
       "         29601, 12546, 58333, 58310, 12550, 29597, 45969, 12557, 12562,\n",
       "         45976, 12568, 29580, 58318, 12574, 58316, 45984, 58311, 29574,\n",
       "         45968, 46007, 12633, 12634, 29495, 12693, 29490, 12696, 46036,\n",
       "         29483, 58221, 29482, 29481, 12707, 58215, 12710, 12711, 58236,\n",
       "         46047, 12717, 58208, 58207, 46049, 12721, 29470, 12723, 29465,\n",
       "         58203, 29462, 58200, 29461, 46063, 12714, 58237, 58239, 46028,\n",
       "         46008], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_unit': {'feature_present_idx': array([29630, 20592, 12539, 32352, 13114, 57773, 34635, 57448, 12499,\n",
       "         56206, 11928, 55774, 55453, 37268, 11568, 34157, 46502, 33544,\n",
       "          4913, 58748, 32868, 59306, 32565,  3347, 32176, 32020, 60738,\n",
       "         60792, 31422, 30364, 15064, 29912,  3849, 39088, 39280, 39317,\n",
       "          7936,  7771, 45605, 48044, 48104,  8578, 48373, 49008, 44383,\n",
       "         44270, 49161,  6946, 49482, 49559, 43594, 20044, 50090, 53223,\n",
       "         11171, 53154, 40812, 52195, 52029, 15585, 51604, 41387,  5858,\n",
       "         51535,  6126, 41958,  6215, 51595, 29454, 33907, 24281, 63592,\n",
       "         23280, 62567, 66201, 66114,  2120, 23036,   319, 65970, 22637,\n",
       "         65952, 17021, 18893, 23668, 24888, 65145, 25668, 66642, 63628,\n",
       "         23977, 64225, 27005, 63796, 28111, 17664, 18147, 28387,  2386,\n",
       "         61669, 28039, 22499, 41841, 41525, 39767, 39858, 10344, 41422,\n",
       "         40322, 18475, 18654, 41078, 40850, 42506, 18385, 40940, 40230,\n",
       "         42539,  9229, 42701, 20112, 20276, 45757,  8101,  8151, 19826,\n",
       "          8261,  8306, 45418, 45182, 20306, 21061, 45047, 19484, 22475,\n",
       "         44520, 21666, 21885, 44199, 44043, 22367,  9023, 43864, 22452,\n",
       "         43145,  9387, 22462, 43018, 42941, 42874, 44396, 39483, 15739,\n",
       "         11174, 13353, 16969, 33549, 13539, 33145, 25784, 33133, 32682,\n",
       "         25944, 32551, 26021, 32528, 14129, 32344, 32327, 26105, 26620,\n",
       "         31516, 27023, 27313, 14621, 14625, 14926, 27767, 30228, 27949,\n",
       "         15604, 29513, 29366, 13281, 23779, 13275, 34039, 39425, 39334,\n",
       "         23799, 23971, 38584, 11648, 17357, 11727, 36740, 36718, 11993,\n",
       "         24833, 12073, 36129, 35949, 12161, 35854, 12471, 24920, 35084,\n",
       "         24985, 25079, 34575, 12779, 25317, 34531, 13033, 17073, 17071,\n",
       "         34012,  7863,  9181, 20012,  3855, 52936, 58278, 58406,  5472,\n",
       "         52657,  1412, 64132, 52550, 52440, 51680, 51628, 51568,  5661,\n",
       "          5785,  6018,  1229, 51162, 50984,  3705, 50977,  2455, 61530,\n",
       "          5317, 58114, 57259, 57572, 57074,  4537, 62636, 56962, 56664,\n",
       "         56392, 62762,  4614, 61462, 62803, 55472,  1941, 55238, 57810,\n",
       "         63136,  1595, 54150, 60863, 53957, 53915, 56014, 59109,  1265,\n",
       "           558,  3031,  2883, 66073, 49449, 49106,  7006, 49072,  7165,\n",
       "         47213,  7198, 61363, 48141, 61124, 47357, 47602,  2793, 60835,\n",
       "         46751,  2628, 66776, 49817,    44,  7796, 49977,  2568,  6394,\n",
       "         49911,  7783, 65933,  1022, 60288, 49611, 67257, 59732, 65097,\n",
       "         59548, 65196, 61960, 61038, 27657, 60943, 27645, 30519, 30290,\n",
       "         27228, 61840, 27466, 60947, 61317, 61752, 61175, 29355, 29065,\n",
       "         29031, 62085, 28892, 61134, 29530, 28750, 27759, 28720, 28486,\n",
       "         28187, 29781, 61736, 29995, 30088, 28029, 27954, 61740, 28615,\n",
       "         26892, 24750, 26338, 64598, 64745, 23269, 64855, 64952, 22665,\n",
       "         22566, 22538, 65389, 65831, 22447, 22414, 22048, 21673, 66320,\n",
       "         21659, 21540, 66579, 21087, 66687, 20872, 20866, 66917, 67275,\n",
       "         20220, 23329, 64532, 23503, 23530, 62349, 62405, 62772, 25530,\n",
       "         25476, 25399, 62954, 63097, 63230, 63403, 63425, 63541, 62176,\n",
       "         24848, 24519, 24476, 63635, 24322, 63895, 64003, 24268, 24143,\n",
       "         24127, 23999, 64104, 64403, 24707, 30793, 46640, 31030, 50895,\n",
       "         42866, 42811, 42768, 42660, 42163, 41995, 51168, 51194, 40906,\n",
       "         40794, 40743, 50544, 40351, 40072, 40003, 39980, 52854, 39688,\n",
       "         39636, 53188, 53197, 53596, 39315, 54066, 38893, 40283, 50155,\n",
       "         43038, 43441, 46503, 46244, 46235, 46232, 45936, 45715, 46831,\n",
       "         45556, 47390, 45421, 47535, 45419, 45242, 45194, 47813, 45001,\n",
       "         44899, 44168, 44134, 49479, 43983, 43891, 43883, 49749, 43719,\n",
       "         49808, 43505, 38892, 38728, 54498, 38398, 58209, 58238, 33884,\n",
       "         33778, 58730, 33474, 33473, 46707, 33201, 59023, 33011, 32718,\n",
       "         59203, 59375, 59380, 32458, 32368, 59919, 32285, 60091, 60268,\n",
       "         31879, 31364, 31170, 31084, 31068, 31056, 58115, 30923, 57996,\n",
       "         57910, 37423, 54596, 54817, 55459, 55773, 36455, 56143, 36423,\n",
       "         36331, 36278, 56256, 35629, 35606, 35566, 35448, 35391, 35126,\n",
       "         57416, 57702, 57759, 57787, 34489, 34414, 34389, 34317, 57888,\n",
       "         34233, 34086, 33275, 67331, 16990, 10864, 10946,  9101,  8529,\n",
       "         14345,  6287, 11242,  3490,  9892, 14217, 15868,  9682, 14182,\n",
       "         15249,  8245, 13376,  2925, 14140,  8036, 16526,  6602, 14030,\n",
       "          2718,  3889, 16674, 15380, 18044, 15616,  5585,  4708, 14790,\n",
       "          4675, 15460,  5658,  8854, 17797,  4567, 16225,  2671, 17806,\n",
       "          8857,  4742, 17871,  6019, 10437,  6145,  4348, 10728,  6170,\n",
       "          4101, 10793, 15714, 14771,  2555, 13922,  1298,  5354,  7800,\n",
       "         13683,  1094, 13680,   981,  7698,  7392,  4971, 16372, 12518,\n",
       "         12691,   756,   716,  7690,  9259, 16262,  7624,   186, 12918,\n",
       "         13139, 16234,   109,   841, 16047,  1345, 11998,  2410, 19023,\n",
       "          6689, 19114,  9656,  6769, 11750,  7970, 13805, 19312,  2103,\n",
       "         16409,  5562,  4806,  7009,  2005, 12031,  9480,  1626,  7892,\n",
       "          1446,  1429, 19317,  9154, 43657, 19964, 43328, 43532, 19896,\n",
       "          8767, 47009, 46752, 46691, 46644,  7920, 46015, 45942, 45926,\n",
       "          8773, 45897, 45082, 45081, 45019,  8542, 44627, 44611, 44516,\n",
       "          8704, 45165, 45244, 10263, 43052, 38297, 37957, 37945, 37875,\n",
       "         37457, 37414, 11665, 37041, 11747, 36602, 36434, 36394, 36297,\n",
       "         36059, 36046, 12141, 35934, 12466, 35246, 35120, 12685, 34920,\n",
       "         34871, 34717, 12778, 12801, 34443, 12863, 34084, 38566, 43096,\n",
       "         38676, 11376, 42873, 42661, 42175, 42161, 42151, 42111, 41767,\n",
       "         41734, 41688, 41679, 41571, 10072, 10076, 10104, 41308, 10117,\n",
       "         10352, 40837, 10393, 10434, 10572, 10754, 40098, 10812, 11033,\n",
       "         11127, 39603, 39462, 11208, 11477,  7661,  6530, 47360,  2848,\n",
       "         60823, 60693, 60622, 60512, 60110, 60059, 59967, 59947, 59831,\n",
       "         59342,  3416, 59272,  3578, 58975, 58800,  3778, 57154,  4464,\n",
       "          4445, 57543,  4126, 57862, 61205,  4039, 58131, 58336, 58409,\n",
       "         58528, 58602, 58710, 58117,  4519,  2503, 62066, 67205,   172,\n",
       "         66789,   279, 66439,   359, 66287,   867, 65616, 65374, 65175,\n",
       "         65151,  1040, 64706, 64597,  1174, 64333, 62191, 62206, 62299,\n",
       "          2138, 62660,  2084, 61864,  2068,  1837, 63234,  1470, 63914,\n",
       "          1418,  1330, 62935, 57003, 56990,  4571, 51667,  5589, 51517,\n",
       "         51490, 51390, 51350, 50780, 50666,  6255, 50532, 50511, 50097,\n",
       "          6326, 50003,  6348,  6472,  6543,  7568,  7506,  7334, 48279,\n",
       "          7178, 48399, 52053, 48718,  7111,  6952, 49375,  6839,  6696,\n",
       "         49615, 48846, 52199, 52258, 52354, 55416,  4776,  4758, 55546,\n",
       "         55596, 55647, 55340, 55662, 55677, 55720, 55729, 55840, 56217,\n",
       "         56379, 55663, 47346, 55232, 55059,  5540,  5526, 52590, 52703,\n",
       "         52745, 53057, 55123,  5374, 53889, 54320, 54391,  4824, 55017,\n",
       "         55042,  5299, 33626,     8, 24293, 23808, 23920, 31999, 23939,\n",
       "         32013, 17824, 27928, 19448, 27822, 32279, 21567, 67321, 16495,\n",
       "         24473, 21531, 13949, 21361, 21206, 16554, 21142, 32673, 17223,\n",
       "         26740, 24896, 24903, 31794, 13790, 31759, 14403, 29884, 15385,\n",
       "         15241, 29486, 29473, 22964, 29469, 30295, 30347, 29390, 23106,\n",
       "         29082, 14874, 18460, 31033, 14747, 28730, 19210, 28670, 14433,\n",
       "         23580, 31472, 16007, 28401, 28272, 28176, 20877, 29919, 19625,\n",
       "         20136, 33012, 26568, 13517, 26542, 20494, 16992, 16796, 19818,\n",
       "         26137, 20155, 19835, 17192, 13550, 26579, 25286, 13594, 16866,\n",
       "         25284, 25531, 24917, 32951, 20856, 16920, 32939, 32947, 13785,\n",
       "         15905, 23493, 45670,  8905,  8170, 22935, 26095,  8938,  8879,\n",
       "         58353,  2943, 45563, 46074,  3832,  9099, 58250, 25559, 18168,\n",
       "         15343, 43723, 46483, 46583, 46612,  4830, 18189,  3594, 52214,\n",
       "         54076,  8739, 53844, 53894, 44487, 44491,  2961, 60040,  5180,\n",
       "         29583, 15736, 15786,  5356, 44971, 58761, 29091,  3261, 59503,\n",
       "         51781], dtype=int64),\n",
       "  'feature_absent_idx': array([53040, 59783, 53945, 10308, 10309, 53946, 44663, 59780, 59779,\n",
       "         48952, 30881, 48951, 10304, 48950, 10321, 18204, 30875, 59771,\n",
       "         30874, 10326, 48946, 30872, 59767, 10330, 30871, 59774, 44671,\n",
       "         30889, 44659, 44642, 53939, 53941, 48955, 44645, 10280, 10281,\n",
       "         10282, 30901, 18218, 59803, 59786, 30898, 59797, 10289, 59796,\n",
       "         59795, 53942, 24951, 59793, 53943, 18213, 10299, 10300, 59799,\n",
       "         18202, 53950, 59764, 30843, 59744, 53959, 24971, 30840, 10376,\n",
       "         10377, 48940, 59739, 59738, 30837, 10370, 59737, 59736, 59734,\n",
       "         18185, 10388, 30834, 10390, 10391, 10392, 10394, 10395, 53962,\n",
       "         10383, 30844, 24966, 10366, 10336, 30865, 44679, 10339, 30861,\n",
       "         44686, 10342, 10343, 24962, 10346, 44687, 53952, 10349, 59756,\n",
       "         59755, 59754, 10355, 53953, 10357, 30851, 18195, 59749, 30849,\n",
       "         10363, 53956, 30907, 24974, 59808, 10271, 44597, 10177, 59870,\n",
       "         18255, 59868, 18254, 44600, 59866, 18253, 59864, 30968, 53913,\n",
       "         10187, 10189, 10190, 10191, 30966, 53916, 48973, 44607, 24930,\n",
       "         59853, 59852, 44610, 30967, 30957, 30976, 48978, 18267, 48983,\n",
       "         44571, 10150, 30997, 24913, 10153, 24914, 59892, 44577, 24916,\n",
       "         24924, 44580, 44583, 44585, 59885, 44586, 44587, 59883, 30983,\n",
       "         53910, 59877, 44588, 30979, 24918, 30955, 10203, 30953, 10239,\n",
       "         48963, 44628, 10242, 30926, 53929, 18232, 44630, 44632, 10249,\n",
       "         10250, 30930, 59825, 30917, 44635, 59821, 10257, 59820, 59817,\n",
       "         53933, 18226, 18223, 10268, 59810, 44634, 53927, 59827, 59828,\n",
       "         10205, 18247, 30949, 24933, 59846, 44616, 10212, 59845, 59843,\n",
       "         10218, 30941, 10220, 59840, 30939, 10224, 48965, 48964, 59837,\n",
       "         10228, 44621, 18239, 10231, 24940, 18237, 18236, 59809, 44705,\n",
       "         59725, 53964, 10565, 44793, 18110, 18109, 18108, 18107, 44795,\n",
       "         44797, 10575, 10576, 18105, 25031, 10578, 44801, 25033, 48893,\n",
       "         48891, 10584, 25037, 30679, 59573, 30678, 10589, 54024, 10579,\n",
       "         59570, 30698, 30700, 30719, 25023, 59603, 25024, 30716, 54013,\n",
       "         10540, 18119, 54015, 10544, 54016, 18112, 10547, 10549, 59594,\n",
       "         30706, 30705, 59593, 59592, 59590, 59587, 10558, 48896, 30701,\n",
       "         18115, 48888, 18096, 48886, 25049, 10630, 44829, 10632, 10633,\n",
       "         10634, 30643, 30642, 10638, 44830, 10641, 18084, 10642, 10645,\n",
       "         10646, 30637, 59537, 10649, 30636, 30635, 30633, 10654, 18077,\n",
       "         59529, 44834, 10626, 59544, 59547, 44811, 30670, 25042, 30668,\n",
       "         59565, 10602, 59564, 25043, 44812, 59560, 30664, 30663, 54031,\n",
       "         10611, 30661, 30660, 18090, 59555, 54032, 44822, 10618, 18088,\n",
       "         30651, 44825, 18086, 44777, 54010, 59609, 54009, 30796, 30795,\n",
       "         24986, 30792, 10441, 10442, 44737, 53975, 24991, 30786, 44739,\n",
       "         30797, 30784, 10451, 59678, 30780, 59676, 18160, 59673, 30778,\n",
       "         59670, 59668, 59665, 30776, 24992, 59691, 48930, 59698, 10402,\n",
       "         44714, 30826, 18180, 30823, 10408, 24978, 18176, 48936, 44719,\n",
       "         30816, 53966, 59714, 53967, 59710, 30810, 44724, 53969, 44725,\n",
       "         53970, 44730, 30804, 30803, 30801, 44734, 44749, 24910, 24998,\n",
       "         10468, 10502, 10503, 59635, 18137, 48908, 25013, 30737, 48906,\n",
       "         10511, 30735, 30734, 59636, 10514, 30732, 25016, 10518, 10522,\n",
       "         25022, 59618, 18127, 59612, 10527, 18126, 44775, 48905, 30742,\n",
       "         48911, 59638, 30768, 53987, 53988, 18152, 10474, 18151, 30762,\n",
       "         30760, 10478, 30759, 53990, 18149, 30756, 30755, 48919, 53993,\n",
       "         18143, 59643, 10490, 59641, 53994, 44764, 59639, 10496, 25005,\n",
       "         18156, 10658, 31005, 31007,  9786,  9787, 49029, 18389, 53800,\n",
       "          9792, 24827,  9795, 60168, 18383, 31258, 18391, 31257, 60164,\n",
       "         60160, 31254,  9804, 53808, 44372, 31251,  9808, 31250, 53809,\n",
       "          9811, 24828,  9812,  9784,  9782,  9755, 60191, 31282, 44361,\n",
       "          9759, 60189, 60188, 31279, 31277,  9766, 31276, 18392, 53792,\n",
       "          9770,  9771, 31272, 60183, 53795, 44363,  9777,  9778, 60180,\n",
       "          9780, 60178, 31274, 60154, 53810, 44376,  9848, 60128, 24835,\n",
       "         60124, 24838, 53820, 31217,  9856, 44405, 44410, 31211, 53816,\n",
       "         31210, 18361, 44411, 53829, 49021,  9870, 31201, 60107, 53831,\n",
       "         60104, 18355, 44418, 60113,  9846,  9845, 60129,  9816, 53811,\n",
       "         31243, 31242,  9820, 44380, 31240,  9823, 18376,  9826, 53814,\n",
       "         24834, 18371, 60143, 60140, 60139,  9835, 60138, 31230, 31229,\n",
       "         31228, 18370, 31224, 18369, 60130, 53788, 60100,  9753, 18400,\n",
       "         60275, 60274, 60270, 44303, 31355, 44305, 49045,  9666,  9667,\n",
       "         49042, 24797, 31360, 31346,  9672, 60258, 44311, 60256, 44312,\n",
       "         44313, 24800, 60253, 44317, 60249, 60248, 60260, 18426, 60280,\n",
       "         24786, 31386, 53741,  9623, 53743, 60300, 49059,  9628, 18451,\n",
       "         31379, 44295, 24774, 53754, 60292, 24776, 24777, 24778, 24779,\n",
       "         60287,  9640,  9641, 24780, 49053, 24784, 31367,  9634, 53771,\n",
       "          9689, 44320,  9724, 44339, 49037,  9727, 44340, 24814, 31302,\n",
       "         31301, 44347, 53780, 60210, 44337, 60209, 60206, 18402, 53786,\n",
       "         31293,  9743, 44350,  9745, 31291, 31289, 44353,  9749, 53783,\n",
       "         53777,  9721, 49038, 60243, 24803, 18423, 31328, 18422, 24804,\n",
       "         18420, 60238, 53772, 60235,  9702, 44331, 44333, 24808,  9709,\n",
       "          9710, 60228, 44335, 24810,  9714,  9715, 18412, 31312, 24811,\n",
       "          9719, 24820, 53832, 24846, 31194, 59963, 31055, 53885, 31051,\n",
       "         10055, 59960, 53886, 59959, 59958, 59956, 53890, 59964, 44531,\n",
       "         10064, 24893, 59953, 53891, 59950, 44543, 10071, 10073, 31040,\n",
       "         31039, 59945, 44537, 10080, 44525, 18294, 18304, 31076, 10015,\n",
       "         59987, 10017, 59986, 10019, 59984, 10024, 44514, 31069, 10046,\n",
       "         48990, 48989, 53880, 10034, 31060, 31059, 10038, 59971, 10040,\n",
       "         10041, 10042, 10043, 44521, 59944, 59943, 10083, 24901, 59917,\n",
       "         24904, 10119, 59915, 24906, 59914, 53900, 31013, 10125, 59911,\n",
       "         59920, 10127, 59909, 10130, 10132, 53902, 44567, 24908, 59904,\n",
       "         10137, 59903, 10139, 59901, 44565, 59921, 31020, 59922, 59942,\n",
       "         10085, 31034, 10087, 53892, 18283, 31028, 59936, 59935, 44553,\n",
       "         59934, 59933, 53893, 10097, 24897, 10099, 59930, 53896, 10102,\n",
       "         24898, 10105, 24899, 10107, 10108, 31021, 31078, 44510, 24880,\n",
       "         24879, 31161,  9918, 31157, 60065, 18332, 31151, 18330, 60056,\n",
       "         31148, 53850, 31146, 18334, 60053, 53851, 53853, 44459, 31140,\n",
       "         60047, 44461, 53854, 60041, 60039,  9942, 18324, 31145,  9915,\n",
       "         18336, 18337, 24849, 44425, 60093, 24853, 49017, 44431,  9891,\n",
       "         53837, 60083, 60082,  9897, 44432, 18344, 44438, 31178, 31177,\n",
       "         44439, 18343, 49016, 53839, 31172, 60073, 24856, 24857, 24858,\n",
       "         60038, 59899, 44464, 44465,  9982, 31109, 44484, 60006,  9987,\n",
       "          9988, 31106, 49005, 31103, 44488, 31101, 44481,  9994, 31092,\n",
       "         31090, 53868, 10001, 59996, 10003, 10004, 59995, 24877, 59993,\n",
       "         59992, 49000,  9980, 31112,  9978, 60031, 49010, 31129,  9953,\n",
       "         60028, 31128, 31127, 53857, 44472, 60024, 24868,  9963,  9964,\n",
       "         60020, 31120, 44475, 60018, 31117, 44476, 18315,  9973, 60015,\n",
       "          9975, 60013, 24871, 31134, 10659, 54037, 30627, 45243, 17792,\n",
       "         59006, 11390, 30071, 11392, 45247, 59003, 45248, 45249, 11397,\n",
       "         25269, 30067, 11400, 17790, 30064, 45250, 45252, 45253, 25272,\n",
       "         58992, 45255, 11409, 11410, 54251, 17788, 45239, 59016, 54239,\n",
       "         11350, 11352, 11353, 11354, 11355, 48740, 59032, 30097, 11361,\n",
       "         45232, 45237, 11363, 11366, 45233, 54244, 54245, 11371, 30087,\n",
       "         30086, 17800, 17799, 45236, 11378, 54241, 45258, 25274, 58987,\n",
       "         11447, 30033, 17779, 48731, 48730, 58974, 48728, 17775, 11455,\n",
       "         45292, 30024, 45282, 30023, 17774, 54260, 11462, 30020, 17772,\n",
       "         11465, 54261, 48727, 45299, 17769, 25283, 11459, 30035, 30036,\n",
       "         45281, 30054, 11417, 11419, 30052, 45266, 11422, 11423, 17785,\n",
       "         45271], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  })},\n",
       " 'contains_wiki': {'feature_present_idx': [],\n",
       "  'feature_absent_idx': array([], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 0\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 0\n",
       "  })}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "20ca123e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contains_imperative': {'feature_present_idx': array([    0, 37052, 37166, 63623, 37169, 19311, 59715, 63680, 10356,\n",
       "         10324, 37512, 37564, 52061, 10175, 51849, 37589, 63782, 37658,\n",
       "          9933, 64067, 37737, 28958, 19471,  9748, 55875, 63725, 59905,\n",
       "         10805, 36871, 36271, 11942, 29172, 11918, 29081, 11859, 63050,\n",
       "         36426, 29070, 11631, 23682, 11552, 63208, 55863, 11316, 36727,\n",
       "         11090, 63440, 11060, 11034, 11031, 52135, 11007, 36776, 10950,\n",
       "          9708, 52179, 59438, 64190, 39316, 28143, 39468, 28130, 20241,\n",
       "         59341, 27976, 39812, 20329, 54979, 64563, 56161,  8024, 51100,\n",
       "         20511, 40234, 40412, 64685,  7724, 56389, 27566, 40555, 56475,\n",
       "         40668, 40037, 28186, 51399, 56031, 38109, 19605,  9279, 28755,\n",
       "          9196, 51645,  9167, 38430, 64234,  8971, 19703, 38545, 19718,\n",
       "         51561, 51501, 51476, 28662, 28611, 64424, 28511,  8655, 51410,\n",
       "          8538,  8492,  8489,  9644, 12002, 36246, 52196, 15752, 54142,\n",
       "         32646, 17840, 15526, 61383, 54110, 17893, 32873, 33008, 33033,\n",
       "         30302, 33113, 60583, 33319, 55285, 30260, 15208, 33357, 33410,\n",
       "         53789, 33477, 18197, 33651, 33210, 30310, 15793, 54328, 31154,\n",
       "         30970, 30933, 60620, 55045, 16831, 16577, 54534, 16535, 60925,\n",
       "         16375, 16323, 60593, 60948, 31769, 17548, 30587, 16202, 32073,\n",
       "         54411, 30548, 55173, 32155, 15874, 61148, 53546, 33719, 61951,\n",
       "         30056, 13439, 53043, 35389, 62573, 35516, 13303, 18713, 35570,\n",
       "         35609, 18863, 52865, 29546, 18949, 35761, 62887, 35823, 12590,\n",
       "         18975, 35907, 52737, 29409, 12304, 59983, 12124, 12096, 62340,\n",
       "         20678, 53052, 34993, 14538, 34010, 34167, 53505, 34211, 53467,\n",
       "         60519, 14196, 14155, 14153, 60471, 34419, 18259, 53416, 13994,\n",
       "         62157, 13928, 29973, 13847, 18528, 13714, 34934, 34961, 62324,\n",
       "         55494, 35287, 27485, 27964, 43932, 22086, 47212, 65764, 40880,\n",
       "          3479,   801,  3437, 58025, 44545, 25661,  3584,  3248, 25594,\n",
       "         65925, 25505, 47105, 44818, 49945, 44935,   856,   865, 48724,\n",
       "         44619, 44988, 50063, 44289,  4214,  4189, 43964, 26012, 57307,\n",
       "         44044, 25911,  4092,  4007,  3959,  3605,  3957, 57326, 66775,\n",
       "           767,  3794, 22063,  3760, 57372,  3732, 44223,  3644,  3930,\n",
       "          4228, 47021,  2840, 48941, 49612, 49599,  2200, 66275,  2062,\n",
       "         45893, 45931, 45947, 22659,  1235, 57877, 46178,  1605,  1286,\n",
       "         49064, 24706,  1579,  1507,  1482,  1380, 22770, 57886, 45000,\n",
       "         45571, 49697, 23017, 22332,   925, 66039, 66051,  2754, 58640,\n",
       "         45091, 58453, 66094, 22618, 45093,  1020, 46937, 49788, 48773,\n",
       "         57608, 25365, 66105, 25077, 45361, 66433,  2669,  4285,  1374,\n",
       "         50697, 58362, 26944,  6095, 67102, 50870, 50868, 47906, 26834,\n",
       "         42250, 42285,  5869, 47893,  5867, 58368, 26587,   727, 66939,\n",
       "           345, 47855,   124,  6248, 48593, 51015, 20955,  6748, 48209,\n",
       "          6725, 41316, 56609, 64876, 56642, 59148,  5619, 41579, 65010,\n",
       "         58326,  6561,  6970, 27139, 65080,  6475,  6977, 41821,    34,\n",
       "         42507, 21318,  5479, 23180, 65417, 27302, 65442, 21799, 43540,\n",
       "         23987, 26055, 43609, 43643, 58077, 23059, 65523, 43808, 43809,\n",
       "         43870, 50272,  4374, 43906, 50321, 59136, 20892, 43189, 65259,\n",
       "         47818,  5255, 47727, 26336, 42673, 23844,  5055,   520, 50549,\n",
       "         50472, 66842, 42832,  4968,  4947,  4938, 21555, 20868, 43108,\n",
       "         26196, 66838, 23715, 55365, 30253, 30927, 23837, 55076, 24507,\n",
       "         55120, 55132, 55279, 30388, 30321, 23792, 56539, 57390, 30128,\n",
       "         26183, 29002, 26270, 55894, 26331, 28766, 26417, 57215, 57211,\n",
       "         55927, 28701, 26763, 28586, 56011, 26891, 56034, 56074, 27103,\n",
       "         56772, 28112, 27158, 27263, 27889, 27794, 56285, 56424, 27321,\n",
       "         26164, 55411, 57246, 57258, 30058, 24667, 55417, 57935, 30008,\n",
       "         30006, 24983, 29960, 57555, 57497, 55554, 29768, 29685, 29684,\n",
       "         55560, 25483, 57462, 29579, 29537, 55579, 29374, 29283, 25734,\n",
       "         25742, 26022, 26037, 29030, 29003, 31179, 36531, 31315, 50891,\n",
       "         50876, 42074, 50782, 42343, 42396, 42442, 42583, 42593, 41881,\n",
       "         50551, 42691, 50444, 43001, 43160, 50440, 43340, 50317, 43538,\n",
       "         43546, 42625, 43547, 50913, 50932, 51196, 51116, 40172, 40207,\n",
       "         40434, 40503, 40542, 40652, 51063, 41792, 40821, 40912, 40930,\n",
       "         40941, 41273, 41393, 41396, 50948, 41439, 41459, 51054, 43802,\n",
       "         50240, 44034, 49556, 49514, 49300, 49292, 49119, 48913, 46948,\n",
       "         46989, 47119, 46017, 47237, 47399, 47412, 48671, 48598, 47942,\n",
       "         48042, 48570, 48196, 48505, 47383, 45981, 45537, 45424, 44041,\n",
       "         44085, 44096, 44106, 50111, 44122, 44169, 44382, 44529, 50034,\n",
       "         44707, 44756, 44936, 44981, 49900, 49894, 49811, 45144, 45227,\n",
       "         45277, 45330, 39993, 31216, 51203, 39686, 53734, 33534, 33588,\n",
       "         53693, 33610, 33929, 33940, 34277, 53449, 33452, 34458, 34767,\n",
       "         53315, 53298, 34932, 34971, 35054, 35343, 35522, 35551, 34698,\n",
       "         52988, 33347, 33220, 31378, 31437, 54919, 31505, 31514, 31560,\n",
       "         54798, 54531, 31779, 67249, 31939, 32107, 32119, 54362, 32160,\n",
       "         54333, 32489, 32591, 32659, 32736, 32103, 35586, 35632, 35665,\n",
       "         51728, 38281, 38452, 51596, 38622, 51525, 51465, 38874, 38884,\n",
       "         51764, 51444, 39119, 51347, 39266, 39272, 39283, 39364, 51281,\n",
       "         39616, 39647, 39089, 38098, 37908, 37874, 35696, 35709, 52812,\n",
       "         52758, 52656, 36007, 52554, 36104, 52204, 36289, 36419, 36460,\n",
       "         36633, 52067, 37203, 37373, 51967, 37558, 37722, 51780, 37830,\n",
       "         51251, 23611, 48337, 66258, 16570, 16632, 16795, 60779, 60775,\n",
       "          6837, 16304, 60669, 17051, 60630,  6637, 17119,  6566, 66760,\n",
       "          6767, 16269, 60952,   821, 15332,  7933, 15358, 64587,  7712,\n",
       "         61273, 64689, 61194,  7644,  7569,  7455, 66652,   883,   839,\n",
       "         61002,  6503,  7962,  6342, 65098, 65241,  5489,  5313,  5169,\n",
       "         65272, 18918,  5805, 60175,  5033,   599, 19065, 59940,  1742,\n",
       "         19275, 18966, 18351, 60437,  5838, 17464, 66432, 60592, 65125,\n",
       "         17610, 17635, 17700,  6066, 60570, 18027,  1739, 18055, 65140,\n",
       "         18183, 65201, 17358,  7969,  8057,  8158, 62872, 12836, 62863,\n",
       "         13071, 13107, 62827, 58244, 13252,  9253, 62563, 64245, 64286,\n",
       "          8876,  8871,  1582, 12337, 12147, 12076,  1355, 10683, 63483,\n",
       "         10979, 11122, 10421, 11364, 11583, 10294, 11714, 10227, 11930,\n",
       "         10222, 11986, 12019,  8863, 13710,  2278, 13712, 61988, 14831,\n",
       "         14881, 64471, 14949,  8346, 61778, 15076, 64533, 15087,  8249,\n",
       "         61685, 61605,  8208, 64544, 14734, 59596,  8365, 62144,  1238,\n",
       "          8809,  8798, 13858, 64398, 14000,  8740, 14022, 14108, 66437,\n",
       "          8698,  8646,  8568, 14128,  8440, 14472, 19364, 17573, 66834,\n",
       "         21873, 67161, 21740,  3679,  3737, 59004, 65760, 21396, 21312,\n",
       "          2219,  4102,  2204,   113, 66395, 59042,  4144, 67072,   242,\n",
       "          4335, 21090,  4337,  4383, 20962, 59131, 20957, 59228, 20750,\n",
       "            77,   383, 21935, 22045, 23444, 66239, 66126,  2497,  2519,\n",
       "          2622, 58396, 58484,  2682, 58549, 66087, 22742, 66079, 22548,\n",
       "          2829, 66038, 65962,    46,  3085, 22515, 22438,  2226,  3177,\n",
       "         65900,  3288, 58793, 58807, 21943, 20722, 10598,   511, 65409,\n",
       "         19588,  4818,  4814,   388, 59418, 20382, 19965,   395, 59355,\n",
       "          4752, 65446, 19851, 19723, 20243, 59332, 20114,  4513, 20223,\n",
       "         20537, 20567,  4415, 59442,  4549, 20013,  4842, 20719, 59429,\n",
       "         59256, 38124,  5485,  9170,  4735,  9506, 38229, 43496, 44623,\n",
       "          9247, 65862, 44898, 64215, 38453, 44941,  4643, 65232,  3094,\n",
       "          9600, 50007, 50763,  8827, 44807,  4710,  3111,  3160, 38377,\n",
       "         50026, 46078, 38083,  2580, 45194, 65378, 37517, 49762,  2420,\n",
       "         37489, 10157, 10387,  4987, 37336, 10456, 49193, 45433, 45434,\n",
       "         45445, 45341,  5086,  1429,  2656, 38053,  9670, 49826, 45075,\n",
       "          9737,  9767, 37791,  9954, 64182, 51835, 64168, 37734, 63902,\n",
       "         65278], dtype=int64),\n",
       "  'feature_absent_idx': array([33689, 60248, 60249, 18898, 60253, 18894, 42450, 18889, 51358,\n",
       "         18887, 42454, 18880, 60256, 60258, 42459, 60260, 18911, 42460,\n",
       "         18912, 42440, 42430, 60235, 18954, 18953, 18952, 18951, 18948,\n",
       "         18947, 18946, 18942, 60238, 18938, 42437, 42439, 60243, 18919,\n",
       "         18960, 18867, 18864, 51352, 51351, 18808, 60300, 42483, 18796,\n",
       "         18794, 18791, 42489, 60305, 42490, 18783, 18778, 42492, 42493,\n",
       "         60292, 51356, 42475, 60287, 42462, 18860, 60270, 18856, 18855,\n",
       "         18850, 60274, 18847, 60275, 18841, 42470, 60280, 42472, 18832,\n",
       "         18830, 18826, 18773, 42428, 18973, 42382, 19127, 19124, 19123,\n",
       "         19119, 60178, 51377, 51376, 60180, 51375, 60183, 19103, 42392,\n",
       "         19088, 19087, 19132, 19086, 19135, 19149, 19187, 19184, 19181,\n",
       "         42363, 60154, 19173, 60160, 42368, 51384, 60164, 51382, 19159,\n",
       "         42372, 60168, 42374, 42377, 42424, 19085, 19083, 42411, 42412,\n",
       "         19001, 18998, 42415, 42416, 42418, 18993, 18992, 60228, 18989,\n",
       "         51370, 18980, 18979, 18977, 42410, 19084, 42409, 60210, 19080,\n",
       "         19079, 60188, 60189, 19074, 60191, 19052, 19051, 19045, 60206,\n",
       "         19040, 19038, 19036, 19031, 60209, 19021, 42495, 18765, 42496,\n",
       "         60421, 42592, 60428, 18469, 60430, 42597, 42600, 60435, 51303,\n",
       "         18451, 42604, 60436, 60438, 60440, 18426, 60420, 18423, 18487,\n",
       "         42585, 18531, 18529, 18521, 18520, 42573, 18518, 51317, 18516,\n",
       "         42576, 60410, 18511, 18501, 42582, 18494, 42584, 42586, 18535,\n",
       "         18422, 42612, 18361, 60464, 18355, 18344, 18343, 42644, 42646,\n",
       "         18337, 18336, 18334, 18332, 51286, 18330, 60469, 60472, 18369,\n",
       "         18420, 18370, 42632, 18412, 51300, 42618, 51299, 18402, 60453,\n",
       "         18400, 18392, 18391, 42624, 18389, 18383, 51295, 18376, 42631,\n",
       "         18371, 18536, 18542, 60401, 60338, 18694, 42521, 18691, 60340,\n",
       "         60342, 60344, 60345, 42522, 42524, 18678, 42525, 18670, 18668,\n",
       "         18665, 18700, 51337, 18707, 18714, 18761, 42497, 18750, 42500,\n",
       "         51348, 51344, 42509, 18733, 18732, 42511, 18727, 60329, 60332,\n",
       "         18718, 18715, 18712, 18661, 18660, 18656, 18596, 60386, 18592,\n",
       "         60387, 18589, 42559, 42560, 18584, 60390, 18578, 42564, 42565,\n",
       "         60394, 18551, 18550, 42554, 60382, 18610, 18616, 18650, 18648,\n",
       "         60367, 42536, 42537, 18640, 51333, 19189, 60373, 18630, 42541,\n",
       "         18624, 18623, 18622, 18619, 18617, 60374, 51389, 19192, 19194,\n",
       "         59950, 19739, 42174, 59953, 42176, 19726, 19725, 59956, 59958,\n",
       "         19719, 19717, 42177, 59959, 19714, 59960, 42171, 19709, 19745,\n",
       "         19750, 59934, 59935, 42160, 19779, 59936, 51469, 19770, 19765,\n",
       "         19763, 59942, 42168, 19758, 59943, 59944, 59945, 19748, 19791,\n",
       "         59963, 19701, 59987, 19646, 42194, 19640, 19639, 19636, 59992,\n",
       "         51459, 59993, 19630, 59995, 59996, 42204, 19621, 19615, 19651,\n",
       "         19706, 59986, 51463, 59964, 19697, 19696, 19695, 19691, 42182,\n",
       "         19687, 59971, 42184, 19677, 42187, 19663, 19661, 19660, 59984,\n",
       "         19654, 59933, 51473, 51474, 19956, 59877, 59883, 19943, 42102,\n",
       "         59885, 19933, 19930, 42109, 19928, 42110, 42112, 19915, 59892,\n",
       "         19902, 19972, 19899, 42091, 19989, 20028, 20026, 42070, 20022,\n",
       "         20019, 20011, 59864, 42078, 59866, 42081, 59868, 19999, 19996,\n",
       "         19994, 59870, 19983, 51489, 42121, 42123, 19841, 19839, 59914,\n",
       "         19833, 19832, 19831, 59915, 19825, 59917, 59920, 59921, 59922,\n",
       "         59930, 42153, 19802, 59911, 51482, 59909, 42137, 19893, 42126,\n",
       "         19889, 19886, 19885, 19882, 19880, 42206, 59899, 59901, 19868,\n",
       "         59903, 19866, 59904, 51485, 51484, 19875, 18324, 51453, 42210,\n",
       "         60093, 19339, 42304, 19335, 60100, 51415, 19319, 19318, 60104,\n",
       "         60107, 42313, 19310, 60113, 19297, 19294, 51419, 19293, 19350,\n",
       "         60083, 51427, 19405, 19402, 19400, 19396, 60073, 51425, 19386,\n",
       "         19385, 19379, 19369, 42293, 19362, 42295, 60082, 19355, 19410,\n",
       "         19290, 19287, 60139, 60140, 42341, 19221, 19216, 51392, 60143,\n",
       "         51391, 19211, 19209, 19207, 42351, 19201, 19199, 19197, 60138,\n",
       "         19288, 19228, 51402, 42318, 51411, 19273, 19271, 42326, 19266,\n",
       "         60124, 60128, 19257, 19256, 60129, 60130, 51403, 19251, 19248,\n",
       "         19234, 42280, 51428, 19419, 19560, 19555, 42223, 19552, 19550,\n",
       "         19549, 42226, 19541, 19540, 19539, 19538, 19537, 60024, 51446,\n",
       "         19523, 60020, 19521, 19562, 19565, 19602, 60006, 51452, 42215,\n",
       "         19590, 19584, 60013, 19581, 60015, 19578, 19577, 19576, 19570,\n",
       "         60018, 19566, 19564, 51440, 60028, 19512, 19459, 19454, 60053,\n",
       "         60056, 19445, 42269, 19439, 60065, 19431, 19430, 42274, 42276,\n",
       "         19423, 19422, 19420, 60047, 19466, 42257, 42256, 19511, 60031,\n",
       "         19507, 19506, 19505, 51439, 19502, 19606, 51436, 42249, 60039,\n",
       "         60041, 42252, 19479, 19477, 19475, 60038, 20029, 42652, 42653,\n",
       "         17241, 17240, 60864, 17235, 17228, 17227, 51136, 43024, 60871,\n",
       "         60872, 51135, 17216, 17215, 60877, 17209, 17244, 17208, 17247,\n",
       "         17252, 17296, 17293, 17288, 17287, 17286, 51148, 17278, 43009,\n",
       "         60852, 17266, 17265, 60856, 43012, 60859, 17254, 17248, 60842,\n",
       "         43029, 17204, 17159, 17156, 17154, 43051, 17152, 43053, 17148,\n",
       "         17146, 60891, 51127, 60892, 43055, 60894, 17139, 60895, 60888,\n",
       "         60878, 17161, 17163, 60880, 17201, 43034, 60881, 43036, 17184,\n",
       "         17179, 17177, 43041, 17173, 43044, 17169, 43047, 17165, 43048,\n",
       "         17162, 60899, 51151, 42991, 60788, 17449, 42953, 17439, 17438,\n",
       "         17437, 17435, 51159, 17429, 17428, 17424, 17423, 17421, 17420,\n",
       "         42958, 60786, 17417, 17458, 17465, 60764, 42933, 17502, 51167,\n",
       "         17497, 17492, 17491, 60772, 17478, 60777, 17475, 60781, 17471,\n",
       "         17469, 17466, 17462, 60837, 17415, 17408, 60817, 17353, 17344,\n",
       "         17343, 60820, 17338, 60822, 17330, 17324, 17322, 17321, 17319,\n",
       "         17318, 42987, 42990, 17355, 42960, 60816, 17369, 60803, 17402,\n",
       "         17401, 17399, 17396, 17392, 17389, 42968, 60806, 60807, 17384,\n",
       "         42971, 60812, 42972, 42973, 17367, 17132, 17125, 43061, 16830,\n",
       "         43177, 16827, 16824, 61011, 16813, 16812, 16808, 16807, 61016,\n",
       "         16802, 16797, 16794, 16792, 16788, 16835, 16786, 51079, 16847,\n",
       "         51091, 60991, 43157, 43159, 43161, 16876, 16874, 16873, 43164,\n",
       "         16871, 16867, 51086, 16856, 16855, 16849, 16844, 16889, 16785,\n",
       "         43192, 16748, 16747, 43204, 43205, 43206, 16736, 16732, 16725,\n",
       "         16721, 16719, 61046, 16715, 16712, 16711, 16709, 16750, 16782,\n",
       "         16752, 43203, 16778, 16776, 16775, 51068, 16771, 16770, 16766,\n",
       "         43197, 43198, 61026, 61027, 16760, 61028, 51066, 43201, 16755,\n",
       "         43149, 16893, 60986, 60924, 17056, 17055, 17053, 17050, 17037,\n",
       "         43094, 17027, 43095, 17019, 43097, 51112, 60937, 17006, 17001,\n",
       "         43081, 60939, 60921, 60920, 17118, 60906, 17116, 17113, 17111,\n",
       "         43066, 17105, 43069, 17090, 60913, 43073, 17080, 43076, 17077,\n",
       "         17072, 17070, 16996, 43103, 16991, 60968, 51101, 43132, 43133,\n",
       "         51098, 43138, 43139, 16919, 43143, 60982, 43144, 16905, 16901,\n",
       "         16898, 16897, 16935, 16937, 16943, 60965, 16989, 16986, 43107,\n",
       "         16981, 43112, 16973, 43114, 42932, 16970, 43115, 43116, 43117,\n",
       "         43118, 51108, 60961, 16955, 60953, 17512, 17513, 42931, 18077,\n",
       "         18073, 18067, 60571, 60572, 60574, 18061, 60577, 18056, 18054,\n",
       "         42745, 60579, 51248, 18042, 18037, 18084, 60587, 18086, 18090,\n",
       "         42723, 51260, 60558, 18119, 42726, 18115, 60559, 18112, 18110,\n",
       "         18109, 18108, 18107, 18105, 18096, 42735, 18088, 18126, 18031,\n",
       "         60595, 17971, 60611, 42769, 42770, 60613, 17958, 60619, 51234,\n",
       "         60625, 17948, 17947, 42776, 17940, 60632, 17936, 17977, 18023,\n",
       "         17978, 42766, 18013, 18012, 18011, 18010, 60598, 18006, 42758,\n",
       "         42759, 17996, 42760, 42761, 42764, 17984, 42765, 60608, 42767,\n",
       "         18127, 60552, 18137, 18255, 18254, 18253, 42679, 60498, 18247,\n",
       "         51274], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_exlamation': {'feature_present_idx': array([24600, 66290, 45167, 35890, 35721, 35621, 34876, 33272, 33245,\n",
       "         33213, 32441, 36036, 32418, 32207, 32102, 31717, 31625, 31600,\n",
       "         32837, 36480, 34257, 36514, 42056, 41152, 40927, 40818, 38974,\n",
       "         38894, 38416, 38179, 38007, 37688, 37604, 37250, 37205, 36976,\n",
       "         36969, 31080, 30422, 30351, 30301, 24296, 24269, 24240, 24182,\n",
       "         23947, 23739, 23435, 22978, 22911, 22613, 22575, 22276, 22220,\n",
       "         21856, 21822, 24396, 42148, 24493, 24711, 30294, 30261, 29812,\n",
       "         29714, 29415, 29267, 28802, 28028, 28001, 27481, 27193, 26255,\n",
       "         25926, 25278, 24958, 24606, 42303, 44110, 21336, 58732, 57987,\n",
       "         57324, 57273, 57104, 57033, 56730, 56662, 56412, 56339, 56330,\n",
       "         56175, 55902, 55525, 55361, 58927, 54662, 59049, 59653, 67038,\n",
       "         66923, 66260, 66181, 65449, 65135, 65006, 63428, 63196, 62785,\n",
       "         62688, 61831, 60483, 60416, 59835, 59461, 54407, 54103, 53976,\n",
       "         47908, 47787, 47700, 47439, 47318, 46590, 46471, 46346, 46190,\n",
       "         46167, 45950, 45303, 44842, 44788, 44504, 48051, 48054, 48107,\n",
       "         48827, 53533, 53327, 52719, 52555, 52425, 52041, 51892, 43512,\n",
       "         51342, 50772, 50510, 50332, 49914, 49763, 49285, 48915, 51328,\n",
       "         21162, 67243, 20956, 14639,  8061, 14725,  7686,  7387,  7363,\n",
       "         14758,  7124, 15169,  6780, 14595,  6544, 15938,  5982, 16169,\n",
       "         16218,  5286,  5121,  4941, 17121,  4860,  4357, 15924,  8119,\n",
       "          8222,  8456, 12220, 12336, 12219, 12150, 12066, 13297, 11728,\n",
       "         11690, 13447, 11604, 13528, 11577, 11345, 13691, 13700, 10794,\n",
       "         13733, 13979, 10741,  9643,  8719,  8676, 14460,  4163,  3521,\n",
       "         16105, 12312,  1083,  2803,  2841, 19772, 19357,  2709, 18181,\n",
       "         18523, 19392, 20137, 17561, 19122, 18874,   396,  3140, 18813,\n",
       "         20235, 46539,  9921, 46596, 46300, 63870, 47900, 63834, 63620,\n",
       "         48014, 63589,  8269, 48069,  1271, 48631,  8142,  1348, 46837,\n",
       "         46085, 64516, 64201, 39011, 66986, 39653, 40313, 40632,   413,\n",
       "         40873, 40916,   487, 41810, 41885,   747,   807, 66133, 42936,\n",
       "         66122, 44304,   878, 44539, 64972, 10797, 64255, 45624, 64038,\n",
       "          8084, 58869,  1728, 54091,  5853,  5704, 54516, 54531, 55041,\n",
       "          5559, 55486,  5307, 59371, 56367, 60052, 59149, 56551, 59054,\n",
       "          3068, 56780, 56838,  4089,  3918, 57458, 57936,  3580, 58119,\n",
       "          4904,  1480, 60310, 53727, 49861, 49913, 58892, 50172, 62163,\n",
       "          7591, 51172,  7242, 51682, 51884,  1973, 38961, 61380, 52083,\n",
       "         52156, 52293, 52326, 61152, 52504, 60782, 53450, 60656,  2198,\n",
       "         53525,  7093,  8060, 11778,   151, 18066, 14775, 14752, 32461,\n",
       "         25174, 25120, 32906, 32940, 33027, 24794, 33115, 27595, 67220,\n",
       "         34361, 34469, 35045, 35069, 35091, 18939, 35661, 35746, 25340,\n",
       "         31464, 15512, 30603, 27821, 28023, 28181, 27269, 28242, 17155,\n",
       "         29125, 29156, 27157, 27043, 19265, 29259, 26713, 26494, 29468,\n",
       "         29631, 30102, 26422, 38744, 26293, 15587, 17699, 16240, 35767,\n",
       "         34203, 27301, 36972, 23981, 37627, 12686, 37988, 37741, 36944,\n",
       "         19414, 19995, 22649, 22208, 20245, 36008, 20067, 13392, 36907,\n",
       "         22471, 38425, 36087, 38319, 36576, 21500, 36425, 20765, 38340,\n",
       "         41089, 25977,  6694, 20569, 54756, 15680, 38492, 37660, 31102,\n",
       "         27651, 25930, 16933,  6494, 53676, 39490, 29791, 26479, 16255,\n",
       "         38083, 55323, 54428, 55280, 66458, 20600, 40698, 40326, 30105,\n",
       "         26520, 46149, 32021, 35719,  9713, 36517, 46657, 45286, 14459,\n",
       "         46960, 35375, 62122, 34476, 44750, 31989, 61775, 48635, 61460,\n",
       "         48466, 14814, 32500, 50832, 14743, 25242, 59862, 63964, 42645,\n",
       "         32608, 43901, 11683, 13393, 24279, 63518, 27180, 63158, 62928,\n",
       "         61442, 24716,  3939, 26305, 19316, 24713, 66365, 21843, 19452,\n",
       "         61448, 66637, 21844, 38624,  5182, 34132,  8535, 17130, 46204,\n",
       "         45902, 11380, 44186, 51488, 43593, 12783, 41751, 41597, 12587,\n",
       "         40205, 39019, 38485, 37331, 15511, 53112, 54897, 54332, 52420,\n",
       "         29458, 52908, 53362, 30449,  6500,  5654, 54674, 12148, 24305,\n",
       "         46814, 41048, 21018, 40772, 28734, 39807, 49573, 66665, 66730,\n",
       "         50682,  2379, 21809, 56933, 15667, 25783, 42025, 25848, 57720,\n",
       "         66752, 55549,   960, 22660, 53985, 44443, 25193, 14289, 62812,\n",
       "         62686, 14631, 33850, 34109, 52031, 51380, 18171, 24530,  8686,\n",
       "         42322, 22757, 49830, 32656, 54489, 37540, 10185, 10700],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([52728, 57594, 57591, 28378, 12768, 12769, 12770, 12771, 12773,\n",
       "         28374, 45634, 12777, 45635, 28371, 12763, 28370, 45638, 45639,\n",
       "         57579, 57578, 28361, 57571, 12799, 57570, 57568, 57567, 57566,\n",
       "         12805, 12807, 12782, 45643, 12762, 28382, 28416, 12714, 12717,\n",
       "         12721, 28410, 12723, 45615, 28408, 28407, 57629, 45616, 57628,\n",
       "         57626, 57596, 45618, 28398, 28397, 12739, 12742, 57611, 57609,\n",
       "         45626, 57605, 45628, 28388, 57601, 28383, 57599, 45619, 28350,\n",
       "         12811, 12812, 28299, 12877, 12878, 45695, 12880, 45696, 57502,\n",
       "         57501, 45699, 57493, 45701, 12892, 12894, 57511, 45704, 12898,\n",
       "         12901, 45711, 45713, 28274, 45716, 45717, 28267, 12915, 28265,\n",
       "         57480, 28264, 45722, 45705, 57513, 57516, 57518, 12813, 45652,\n",
       "         28341, 28337, 12824, 45664, 12826, 57550, 12829, 28333, 28331,\n",
       "         12835, 57544, 45671, 45672, 45674, 28316, 45683, 12851, 12852,\n",
       "         12854, 28310, 57526, 12858, 57525, 57524, 12862, 12865, 28304,\n",
       "         12711, 45725, 12710, 57641, 28529, 12562, 28525, 57753, 57750,\n",
       "         12568, 45535, 28521, 28520, 28519, 12574, 57745, 57741, 28530,\n",
       "         12581, 57736, 57735, 12586, 45542, 57731, 57730, 45544, 12592,\n",
       "         12595, 12596, 12597, 12598, 45553, 12583, 28504, 12557, 28536,\n",
       "         57807, 57801, 57796, 12506, 57795, 45509, 45511, 12510, 12512,\n",
       "         28562, 57782, 28558, 12527, 28534, 12530, 45520, 57772, 12534,\n",
       "         57770, 28548, 28544, 12544, 57768, 12546, 57766, 12550, 57762,\n",
       "         28537, 28552, 45557, 57725, 28501, 12667, 28447, 57676, 28445,\n",
       "         28441, 45598, 12675, 12676, 28439, 57670, 57667, 57666, 57665,\n",
       "         28448, 28436, 45600, 57662, 57656, 12693, 28429, 12696, 45603,\n",
       "         57650, 28421, 45609, 57643, 57642, 12707, 45599, 12664, 12663,\n",
       "         28450, 57723, 28500, 28498, 28494, 57718, 57717, 28493, 57715,\n",
       "         45565, 45567, 28487, 28482, 45573, 28478, 28476, 12633, 12634,\n",
       "         28473, 45576, 57699, 12644, 45583, 57688, 12653, 45592, 57683,\n",
       "         45594, 28452, 12661, 45611, 57811, 45726, 45731, 45856, 57257,\n",
       "         13173, 57256, 13176, 45863, 45864, 45865, 57254, 57252, 13183,\n",
       "         57251, 28064, 57261, 28063, 57247, 13190, 28056, 13193, 45874,\n",
       "         28051, 13201, 28047, 45879, 57237, 28042, 13209, 57232, 45872,\n",
       "         13214, 13167, 28078, 57303, 57301, 57299, 57297, 28097, 45843,\n",
       "         28093, 28091, 45846, 57283, 28088, 45847, 13146, 28076, 45849,\n",
       "         13149, 28085, 13151, 28084, 57271, 13154, 28082, 57266, 57265,\n",
       "         13160, 13161, 28080, 28079, 13148, 57230, 28034, 13217, 13280,\n",
       "         45935, 45939, 13288, 13290, 13292, 13293, 45945, 13295, 27967,\n",
       "         45948, 27963, 13301, 45929, 57156, 27958, 13307, 27957, 27955,\n",
       "         13311, 13317, 27946, 57133, 57131, 13322, 57130, 45968, 13328,\n",
       "         45953, 45927, 13274, 13273, 57227, 13219, 13221, 57224, 57221,\n",
       "         45892, 28026, 57218, 45895, 13233, 28018, 45899, 57209, 57208,\n",
       "         13243, 28013, 13247, 45900, 13249, 45903, 45904, 13255, 57188,\n",
       "         13259, 27994, 27992, 45923, 13269, 13271, 57305, 57468, 57306,\n",
       "         28109, 45758, 12973, 57430, 57429, 57428, 57427, 28213, 57425,\n",
       "         57423, 12983, 45761, 28209, 57422, 12971, 12987, 12989, 28207,\n",
       "         57420, 28205, 57415, 57413, 13002, 13003, 57405, 57403, 57401,\n",
       "         57399, 28191, 28208, 57395, 12970, 28218, 45732, 12930, 28248,\n",
       "         28247, 45736, 28241, 28240, 28238, 45740, 12943, 57450, 28233,\n",
       "         57447, 12969, 12947, 28232, 45743, 12951, 12952, 57442, 57441,\n",
       "         45747, 28225, 28224, 57437, 12960, 57433, 12964, 12948, 45769,\n",
       "         13014, 13016, 28140, 13079, 28136, 13081, 28135, 13084, 57336,\n",
       "         57334, 28128, 28126, 13095, 13096, 28124, 57339, 13098, 45824,\n",
       "         13101, 57329, 13103, 57325, 13106, 45826, 13108, 28117, 45828,\n",
       "         13112, 28114, 28113, 45823, 57341, 57344, 45809, 28188, 57392,\n",
       "         57391, 13020, 57389, 28182, 45779, 57386, 13028, 13029, 45786,\n",
       "         57381, 28173, 13037, 13040, 28167, 57367, 57366, 57365, 13052,\n",
       "         57362, 45800, 57359, 45803, 28150, 45807, 57352, 13065, 57350,\n",
       "         28108, 12495, 12494, 45504, 58239, 58237, 58236, 45172, 28994,\n",
       "         11952, 28993, 45178, 28986, 11959, 28983, 28982, 28981, 58240,\n",
       "         28976, 58221, 11975, 11976, 45188, 58215, 28964, 58208, 11984,\n",
       "         11985, 58207, 11987, 28957, 58203, 11968, 11994, 58242, 11939,\n",
       "         29032, 58283, 29029, 29028, 11902, 45148, 58277, 58274],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 557\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 557\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 557\n",
       "    })}}},\n",
       " 'contains_negation': {'feature_present_idx': array([25342,  8916, 44753, 56681, 56714, 19156,  8887,  8865, 19165,\n",
       "          8835, 56809, 56825,  8921, 28965, 56855, 44693, 56876, 44692,\n",
       "          8735, 34027, 44677, 19230, 44660, 34018, 57007, 19166, 33979,\n",
       "         19130, 44771,  9189,  9188, 56300, 56326, 18943, 44875, 18982,\n",
       "         56404, 56409,  9115, 44865, 26666, 37090,  9094,  9078, 19013,\n",
       "         56517, 19035,  9045, 19068, 37101, 44828, 56575, 56613, 56507,\n",
       "          9210, 57050, 19277, 57322,  8367, 19470, 19472, 44428, 57421,\n",
       "         57440, 33924,  8323, 29157, 57490, 44474, 44415, 33895, 44390,\n",
       "         57542, 57546, 57573, 57602, 44336, 33874, 44329, 19587, 44309,\n",
       "          8290, 44601, 57300, 57291, 57070, 57081, 44594, 33959,  8621,\n",
       "          8619, 37171, 44568, 57118, 44556, 29060, 19461, 19368,  8499,\n",
       "         33945,  8471, 26605, 44519, 19446, 26598,  8427,  8424,  8411,\n",
       "         33944, 19376, 57726, 44916, 56244, 10151, 18248, 55223, 45581,\n",
       "         55289, 26816, 55313, 10093, 10070, 34381, 28679, 55193,  9972,\n",
       "         18444, 18453, 26792, 45420, 28692, 55642, 18471, 45394, 55666,\n",
       "         34371, 18524, 45450, 18526, 55174, 18240, 54832, 36842, 45906,\n",
       "         18053, 36881, 10449, 54931, 45817, 18082, 28614, 10425, 18242,\n",
       "         45798, 28619, 45721, 45694, 36887, 18172, 10307, 55095, 18179,\n",
       "         28673, 55144, 45662, 55005, 44918, 28707, 55757,  9526, 45099,\n",
       "          9489, 26751, 34263, 56063, 28807, 56081, 34245,  9419,  9418,\n",
       "         56009,  9379, 34216,  9351,  9339, 34193, 44990, 26727, 56157,\n",
       "         56216,  9256, 18910,  9230, 34219, 34364, 56000, 45143, 45312,\n",
       "         55792,  9799, 34354, 18559, 34308,  9741, 37004,  9735,  9734,\n",
       "          9725, 18731, 18599, 28741, 55845, 18628, 18634, 26771, 55905,\n",
       "         55910,  9609, 45176, 45173,  9588, 18607, 44298,  8167, 19629,\n",
       "         59250, 26437, 20653, 43301, 20679, 37403, 59308, 59314,  6531,\n",
       "         20688, 29642, 43339, 43275, 59367, 33615, 43230, 26413,  6437,\n",
       "         43185, 59458, 59507, 59524, 20830,  6360, 43265, 33513,  6583,\n",
       "         59225, 20539, 20543, 20549,  6812, 43408,  6794, 20562, 43404,\n",
       "         67339, 59118, 59125, 43354,  6730, 59135, 29590, 59152,  6646,\n",
       "          6641,  6639, 59177, 29596, 37355, 43358, 29613, 20581, 37341,\n",
       "          6354,  6337,  6010,  5990, 60037, 33402, 21153, 42775, 26314,\n",
       "         21183,  5906, 42751, 37649, 42794, 26294, 60198, 26288, 33372,\n",
       "         60241, 60269, 37664, 26277,  5770, 21256, 42611,  5759,  5857,\n",
       "          6341,  6039,  6045, 20853, 33486, 59688, 43071,  6270,  6267,\n",
       "         37534,  6250,  6249, 20925,  6240, 21126, 42996, 33454,  6169,\n",
       "         59860,  6136, 26341, 42906, 26339,  6073,  6064,  6062, 33416,\n",
       "          6217, 20527, 59082, 29551, 58162, 43910, 29282, 58190,  7822,\n",
       "          7812, 58225, 43890, 19903, 33777, 58257, 29279, 58264, 58345,\n",
       "         19916, 29298,  7708, 43868,  7679, 43867, 43861, 19925, 58390,\n",
       "         43841, 29291, 58408, 58150, 43927, 26586, 44216, 44161, 19662,\n",
       "         44138, 44086, 44083, 44061,  8032, 29222, 57944,  7857, 19767,\n",
       "         19784, 58015, 43977, 58062,  7905, 19844,  7876, 58100, 58123,\n",
       "         43934, 58137, 57984, 29318,  7550, 58447, 33703, 37291, 20312,\n",
       "          7183,  7172, 43489, 58777, 43482, 20368, 20375, 58854, 20279,\n",
       "         20383, 29501, 43442,  7057, 20400,  7049, 58916,  7011, 58968,\n",
       "         20460, 59051, 59074, 43449, 29464, 20207, 58722, 19946, 19952,\n",
       "          7517, 58477, 49652,  7504,  7478, 58500,  7476,  7463,  7427,\n",
       "          7403, 29371,  7391, 43610, 37287, 58641, 20159, 20160,  7324,\n",
       "         20173,  7311, 29439, 58705, 58716, 18028, 42606, 45944, 34565,\n",
       "         13461, 51340, 13436, 48244, 48233, 15932, 48226, 15949, 15951,\n",
       "         48212, 15973, 13478, 51420, 15977, 16008, 13310, 48170, 51544,\n",
       "         51556, 51569, 13232, 51582, 16096, 36133, 13360, 27940, 13486,\n",
       "         13496, 48612, 36071, 13721, 48576, 51089, 13694, 35432, 15720,\n",
       "         13648, 35431, 27324, 36112, 13628, 48545, 36076, 51161, 36101,\n",
       "         48483, 15759, 27311, 15804, 15830, 13506, 35368, 51140, 48618,\n",
       "         27942, 13155, 51889, 12843, 16368, 51902, 36192, 47723, 47706,\n",
       "         12787, 47675, 47650, 47605, 28027, 27197, 47589, 47584, 12713,\n",
       "         28048, 36216, 12699, 28057, 12660, 47532, 52062, 16472, 51979,\n",
       "         51676, 35245, 12874, 13120, 13080, 51733, 13057, 48074, 47983,\n",
       "         47979, 27241, 13017, 51775, 12993, 51863, 47923, 47856, 51839,\n",
       "         35259, 27240, 12923, 27984, 47807, 47790, 47789, 36185, 47780,\n",
       "         47862, 16478, 48643, 15691, 15055, 49407, 50072, 14509, 27668,\n",
       "         49384, 14485, 15095, 15096, 15101, 50175, 14569, 50185, 35889,\n",
       "         35636, 49364, 50208, 50229, 35902, 15147, 49338, 49336, 15177,\n",
       "         49326, 15114, 14364, 35672, 35683, 35738, 14816, 14852, 14861,\n",
       "         14868, 49585, 14787, 49702, 27540, 27588, 35708, 49951, 49533,\n",
       "         27615, 35697, 27632, 49494, 14660, 35814, 14652, 14648, 49902,\n",
       "         27640, 49473, 14934, 13755, 15201, 14339, 48944, 48942, 50671,\n",
       "         36000, 35562, 50754, 15552, 50755, 50756, 13914, 15562, 14036,\n",
       "         13902, 50810, 48797, 50846, 48782, 15580, 13832, 15605, 27781,\n",
       "         15638, 13789, 13781, 27774, 35909, 27752, 50519, 15230, 49297,\n",
       "         14274, 49265, 49261, 49245, 50325, 14234, 50331, 49236, 49229,\n",
       "         35573, 49188, 35599, 49103, 50387, 35969, 49002, 14060, 14057,\n",
       "         35984, 50473, 50486, 50487, 50337, 47480, 12627, 35219, 46619,\n",
       "         17285, 11277, 46594, 11251, 53776, 17323, 28369, 11229, 11213,\n",
       "         17346, 11305, 17349, 34791, 53867, 17372, 26961, 11153, 46504,\n",
       "         17425, 11088, 46464, 54004, 54052, 11201, 11030, 11327, 46629,\n",
       "         53334, 34921, 53396, 27017, 53437, 17120, 46734, 11509, 46723,\n",
       "         46676, 53460, 46620, 11458, 11433, 11426, 53554, 11404, 46650,\n",
       "         46649, 53624, 17243, 28329, 17256, 34856, 53500, 53307, 17516,\n",
       "         46420, 17829, 17855, 54421, 54440, 54459, 54514, 10672, 34596,\n",
       "         54610, 10656, 54630, 28528, 17908, 10612, 10604, 54660, 28591,\n",
       "         10545, 10535, 10534, 45992, 54740, 10493, 54749, 10620, 17552,\n",
       "         36754, 17780, 54132, 34726, 10985, 17594, 54157, 46371, 46363,\n",
       "         54186, 10940, 54212, 10936, 17787, 46345, 34687, 54247, 46264,\n",
       "         17695, 10857, 34675, 17703, 17723, 26929, 46238, 46224, 26942,\n",
       "         34924, 46786, 53269, 28129, 36385, 52407, 52412, 16730, 52477,\n",
       "         12237, 52497, 16768, 36413, 52557, 47268, 52561, 27100, 12154,\n",
       "         52598, 12137, 52612, 12117, 36437, 16840, 27090, 12107, 36470,\n",
       "         35155, 12091, 52332, 52327, 47425, 12614, 27176, 36239, 47389,\n",
       "         16520, 36279, 16542, 25349, 16545, 28104, 12343, 16563, 12508,\n",
       "         36288, 52242, 35180, 52250, 47324, 12429, 52268, 47302, 52300,\n",
       "         12400, 52213, 52681, 47071, 52694, 17010, 53016, 11840, 17039,\n",
       "         11808, 53041, 35026, 11753, 46859, 53088, 11735, 46925, 11725,\n",
       "         11719, 53098, 53108, 34962, 34952, 46807, 17078, 17082, 53206,\n",
       "         11621, 53262, 11723, 35038, 53000, 52960, 52699, 35130, 52726,\n",
       "         35128, 52762, 28170, 16921, 36521, 12005, 52781, 11988, 16953,\n",
       "         11955, 36552, 52850, 46947, 52851, 52874, 35053, 16985, 36564,\n",
       "         11901, 35046, 52954, 11889, 54773,  5755, 58480,  5741, 30667,\n",
       "         23211,  2866, 64128, 64146,  2844, 64186,  2820,  2786, 23175,\n",
       "         25815, 23294,  2745, 23312, 23323,  2722,  2719, 40391, 40375,\n",
       "         32269, 23268, 23353, 30653, 64046, 63733, 63775, 40612, 23032,\n",
       "         23041, 23050, 63807, 40566, 23053,  5753, 38142, 63878,  3053,\n",
       "          3047, 63909,  3016, 63945, 30632, 40497, 23140,  3062,  3157,\n",
       "         40362, 32253, 25740, 32136, 64626,  2383, 64633, 40050,  2346,\n",
       "         40048, 40022, 32166, 40008, 64709,  2251, 64743, 64759, 64771,\n",
       "          2207, 64807, 31991, 64843, 23548, 40299, 25763, 64510, 64355,\n",
       "         32223, 64367, 32222, 30749, 40279,  2601, 23406,  2588,  2441,\n",
       "          2578, 40266,  2563, 40245, 23459, 64467, 40214, 64502, 30753,\n",
       "         40208,  2573,  2130, 40659,  3169,  3926, 41161,  3884, 62977,\n",
       "         41149], dtype=int64),\n",
       "  'feature_absent_idx': array([52160, 60143, 11668, 11669, 33114, 60140, 11672, 11673, 60139,\n",
       "         11676, 60138, 54655, 11679, 33112, 33111, 20302, 33109, 20301,\n",
       "         20300, 46712, 20299, 60130, 33104, 11695, 33117, 50448, 33120,\n",
       "         11659, 11630, 20316, 33136, 33135, 20315, 54646, 11636, 33130,\n",
       "         11638, 33129, 20313, 11696, 11641, 11644, 11647, 54650, 11649,\n",
       "         54651, 11651, 11653, 50450, 46703, 11656, 54653, 60154, 60129,\n",
       "         11699, 11700, 33079, 33077, 46729, 46730, 33073, 46731, 60107,\n",
       "         27111, 60104, 11749, 33070, 11739, 54666, 60100, 33067, 11758,\n",
       "         46737, 50434, 27113, 27114, 33059, 11765, 11766, 33057, 46735,\n",
       "         11629, 11738, 11736, 33100, 11704, 20294, 11706, 11707, 11708,\n",
       "         60128, 50446, 11711, 50442, 60124, 11737, 27104, 33093, 33092,\n",
       "         11722, 54665, 33086, 33082, 20281, 11731, 60113, 11733, 11734,\n",
       "         20290, 11628, 60160, 11626, 20350, 60235, 46609, 11530, 27066,\n",
       "         50462, 46617, 11534, 11535, 33209, 11538, 33218, 11539, 33203,\n",
       "         60228, 46632, 11546, 11549, 33196, 46638, 50460, 54629, 11557,\n",
       "         33191, 33207, 11559, 50463, 11520, 46588, 60258, 46589, 60256,\n",
       "         33241, 11493, 33239, 33238, 11498, 60253, 11501, 20352, 11502,\n",
       "         60248, 46591, 54623, 27061, 54625, 50465, 11513, 60243, 46602,\n",
       "         46603, 60238, 60249, 60093, 33187, 27075, 11598, 33162, 60183,\n",
       "         46671, 33158, 60180, 54639, 11607, 60178, 20321, 33152, 11597,\n",
       "         11611, 54641, 11615, 50452, 33143, 60168, 33142, 46688, 20317,\n",
       "         60164, 33139, 33138, 46679, 46647, 46670, 50457, 60210, 11565,\n",
       "         27076, 11567, 60209, 60206, 33181, 50459, 50458, 11573, 33178,\n",
       "         11591, 11575, 27080, 20331, 60191, 27081, 60189, 11584, 60188,\n",
       "         11586, 27082, 20327, 11589, 54632, 11486, 54670, 20267, 54723,\n",
       "         59971, 46832, 11975, 11976, 50406, 50405, 59964, 59963, 32914,\n",
       "         11984, 11985, 59960, 11987, 20197, 59959, 59958, 59956, 11994,\n",
       "         11995, 46835, 20196, 59953, 27171, 54719, 54718, 11968, 11931,\n",
       "         59992, 46812, 46815, 54705, 46816, 11939, 11940, 27160, 59987,\n",
       "         59986, 46844, 59984, 54712, 11952, 46818, 32936, 32935, 27166,\n",
       "         11959, 32931, 54715, 32926, 32925, 27164, 59950, 32899, 50403,\n",
       "         12045, 12046, 12047, 27183, 50400, 59922, 32876, 59921, 12056,\n",
       "         32875, 59920, 32880, 12059, 12062, 54735, 12064, 20181, 59917,\n",
       "         54736, 59915, 20179, 59914, 32867, 59911, 46863, 59993, 59930,\n",
       "         59933, 32896, 46851, 12013, 12014, 12015, 12017, 59945, 20191,\n",
       "         59944, 12022, 59943, 46862, 59942, 46852, 12029, 32891, 32890,\n",
       "         12033, 27181, 59936, 59935, 46860, 59934, 54734, 54730, 59995,\n",
       "         59996, 20219, 33025, 46759, 20252, 11817, 60065, 11821, 20249,\n",
       "         20248, 11826, 11827, 11828, 11811, 60056, 33014, 11832, 20246,\n",
       "         11834, 60053, 50427, 46769, 20244, 54688, 20242, 33007, 11830,\n",
       "         60047, 27129, 11806, 60083, 11777, 60082, 11779, 27121, 11781,\n",
       "         50432, 11784, 11785, 54675, 27123, 11809, 46747, 46749, 27126,\n",
       "         60073, 50430, 33036, 33035, 46755, 11802, 54678, 11804, 11805,\n",
       "         20261, 20268, 33004, 11850, 27156, 32974, 32971, 60015, 60013,\n",
       "         11902, 20224, 54700, 11906, 32965, 20222, 60018, 60006, 46802,\n",
       "         11914, 32959, 20221, 46804, 32956, 32955, 11922, 11923, 54702,\n",
       "         32953, 32963, 11848, 46787, 11885, 60041, 60039, 60038, 27143,\n",
       "         27144, 60031, 60028, 54694, 11861, 32998, 32996, 60020, 46783,\n",
       "         50424, 60024, 11874, 46784, 11876, 27147, 32986, 27148, 32983,\n",
       "         11882, 50422, 32993, 12075, 11484, 11482, 33555, 11065, 33553,\n",
       "         11069, 11071, 26936, 46406, 50555, 26940, 60478, 60477, 11080,\n",
       "         60475, 20501, 60472, 50554, 50553, 60469, 54542, 33537, 46417,\n",
       "         11094, 50552, 33556, 46402, 60489, 11059, 33575, 20520, 20519,\n",
       "         20518, 46389, 33570, 50558, 46390, 11036, 11037, 60498, 33532,\n",
       "         46393, 11044, 11045, 26932, 60495, 60494, 11052, 11053, 60492,\n",
       "         11055, 46399, 20508, 11042, 54546, 33530, 33528, 11139, 60438,\n",
       "         60436, 11142, 33497, 60435, 60430, 20475, 11150, 46434, 20474,\n",
       "         20478, 60428, 33485, 11159, 46439, 20472, 46442, 11164, 20471,\n",
       "         60421, 60420, 46446, 46447, 33489, 33577, 46428, 60440, 60464,\n",
       "         54547, 26948, 33523, 11110, 20488, 50541, 33516, 11116, 33515,\n",
       "         33514, 46427, 11119, 26965, 54550, 11123, 11124, 20482, 50535,\n",
       "         33507, 33506, 33505, 46426, 33501, 60453, 33578, 60515, 60517,\n",
       "         20559, 60579, 10905, 26905, 26906, 10910, 10911, 50564, 10913,\n",
       "         60577, 33637, 50566, 60574, 10922, 60572, 54503, 60571, 46361,\n",
       "         33633, 10928, 10931, 10932, 20552, 20551, 10921, 26910, 10900,\n",
       "         54499, 10866, 54495, 46341, 46342, 33679, 20575, 46343, 10874,\n",
       "         46344, 60587, 26897, 46353, 10879, 10882, 10883, 33664, 33663,\n",
       "         46349, 46350, 54497, 10889, 33653, 10893, 10894, 26899, 46449,\n",
       "         10938, 10943, 10986, 10987, 60535, 60533, 10991, 60531, 33594,\n",
       "         33593, 20530, 60529, 60526, 33596, 60524, 33590, 60523, 11006,\n",
       "         46382, 11010, 20525, 46383, 33583, 54525, 33581, 11018, 54520,\n",
       "         54509, 10982, 20533, 60559, 10947, 60558, 46372, 60552, 60551,\n",
       "         26915, 10958, 20540, 10960, 46374, 26920, 33609, 33608, 10967,\n",
       "         20538, 26918, 50561, 54518, 54519, 33601, 46377, 10978, 60547,\n",
       "         10963, 60260, 33471, 20469, 11371, 33330, 20396, 33327, 46546,\n",
       "         11378, 33324, 54587, 50493, 33315, 11390, 27037, 11392, 33306,\n",
       "         33305, 33304, 11397, 60305, 46558, 11400, 33302, 33300, 60300,\n",
       "         33334, 46542, 27022, 11366, 33363, 60338, 33362, 20411, 11340,\n",
       "         20409, 33356, 50498, 27013, 46530, 60332, 11409, 11350, 11353,\n",
       "         11354, 11355, 20403, 60329, 27018, 46536, 11361, 11363, 46538,\n",
       "         50496, 11352, 11410, 33295, 50479, 46573, 33269, 11455, 46575,\n",
       "         50475, 11459, 33266, 33265, 11462, 33263, 54614, 50476, 11465,\n",
       "         54616, 60275, 60274, 11471, 33256, 46582, 11476, 60270, 33249,\n",
       "         33248, 33246, 60280, 20412, 60287, 33276, 11417, 60292, 11419,\n",
       "         46563, 33290, 11422, 11423, 46564, 33288, 11427, 11428, 46572,\n",
       "         11429, 11432, 11434, 33287, 11437, 33283, 20374, 33280, 27046,\n",
       "         33278, 20372, 11447, 11430, 11331, 60340, 60342, 26982, 26983,\n",
       "         11217, 11219, 11220, 54562, 33438, 11223, 50523, 11226, 54564,\n",
       "         11214, 11230, 11233, 60394, 46480, 33429, 54566, 33426, 20439,\n",
       "         46482, 11244, 33421, 46486, 26987, 11248, 46475, 20452, 11176,\n",
       "         11177, 26974, 20465, 46458, 54558, 50527, 60410, 54559, 54560,\n",
       "         50526, 11211, 11191, 20456, 11194, 33453, 11196, 46462, 33451,\n",
       "         11202, 20454, 46472, 46473, 60401, 33456, 33470, 60390, 11254,\n",
       "         20426, 33387, 54571, 46510, 33384, 54573, 20423, 11303, 50507,\n",
       "         11306, 11307, 60367, 33380, 46513, 20420, 20419, 11314, 20418,\n",
       "         50506, 33367, 11321, 60345, 60344, 46518, 46511, 33418, 33390,\n",
       "         33394, 60387, 60386, 46487, 46488, 11259, 46489, 46490, 46493,\n",
       "         60382, 46494, 33407, 27000, 50515, 11274, 50512, 11276, 60374,\n",
       "         60373, 11281, 20430, 11285, 33396, 11287, 54568, 46495, 33689,\n",
       "         59909, 12079, 12877, 12878, 32328, 12880, 47238, 59426, 19899,\n",
       "         47240, 47244, 54922, 32316, 12892, 47249, 12894, 47251, 32312,\n",
       "         12898, 32311, 47253, 12901, 32309, 27401, 32306, 27399, 59435,\n",
       "         27398, 19902, 32348, 54907, 47218, 27394, 54909, 54912, 59456,\n",
       "         59454, 27395, 59452, 12851, 27402, 12852, 12854, 59449, 47227,\n",
       "         12858, 32338, 47229, 12862, 59444, 12865, 54915, 59441, 32340,\n",
       "         47264, 59412, 59411, 59387, 12951, 12952, 32278, 59385, 59384,\n",
       "         59383, 12960, 32276, 27413, 12964, 47282, 19875, 12969, 12970,\n",
       "         12971, 47286, 12973, 59368, 59363, 47289, 59358, 59357, 27417,\n",
       "         32270, 59460, 12948, 59389, 19893, 47269, 32297, 12915, 59406,\n",
       "         19889, 32293, 47274, 19886, 19885, 32287, 12947, 12930, 50273,\n",
       "         32284, 27408, 59395, 59393, 19882, 59392, 19880, 59391, 27409,\n",
       "         12943], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_conjunctions': {'feature_present_idx': array([26169, 41912, 16226, 41918, 16212, 16211, 55436, 16244, 16200,\n",
       "         16177, 16174, 16168, 41966, 41967, 41977, 16193, 16249, 16258,\n",
       "         62494, 41760, 16400, 55465, 41801, 16337, 41824, 16324, 41829,\n",
       "         41833, 41846, 55457, 16309, 41864, 41865, 41869, 16145, 16144,\n",
       "         16124, 62519, 15854, 15847, 15807, 15797, 31721, 15770, 42255,\n",
       "         62626, 15726, 62631, 15708, 15706, 42290, 15663, 15659, 42186,\n",
       "         41754, 42167, 15911, 55421, 62525, 42007, 62527, 16062, 42021,\n",
       "         42030, 16029, 42072, 15993, 42079, 42090, 62571, 15928, 42141,\n",
       "         15889, 16433, 16439, 62419, 41363, 16960, 41381, 16949, 16942,\n",
       "         41411, 16917, 62259, 16904, 16899, 62270, 16864, 16862, 62285,\n",
       "         62291, 41357, 16833, 16965, 62223, 41251, 17109, 17102, 17095,\n",
       "         17083, 17058, 17054, 55606, 17025, 17018, 41323, 41325, 16995,\n",
       "         41353, 16983, 16975, 15642, 16815, 16789, 16550, 41648, 62371,\n",
       "         62382, 16527, 62384, 41677, 41683, 41690, 16475, 55473, 41712,\n",
       "         16467, 62411, 16451, 55489, 41463, 16608, 41590, 16773, 62319,\n",
       "         41491, 41508, 41514, 55553, 41519, 41527, 16704, 55551, 41547,\n",
       "         16688, 16678, 16659, 41588, 55518, 17150, 15608, 15601, 62960,\n",
       "         43067, 14777, 14776, 55092, 43085, 14795, 62973, 14736, 43124,\n",
       "         14724, 14720, 43129, 63006, 43090, 43064, 43060, 62953, 42980,\n",
       "         62933, 42989, 14913, 14902, 62938, 14880, 14876, 62945, 55109,\n",
       "         43017, 43021, 14841, 43040, 43050, 14699, 14683, 14682, 14676,\n",
       "         14519, 55044, 14516, 43299, 14475, 55034, 14456, 14450, 63068,\n",
       "         63071, 43325, 14391, 14375, 43363, 55027, 14520, 42977, 43261,\n",
       "         14556, 14672, 14666, 14650, 14646, 43172, 14618, 43174, 43175,\n",
       "         43179, 14597, 14591, 14588, 14579, 43207, 43218, 14532, 14939,\n",
       "         42959, 14955, 15427, 42540, 15420, 42542, 15403, 42587, 42599,\n",
       "         42609, 62746, 15350, 15349, 62756, 42662, 42675, 42695, 42529,\n",
       "         42700, 15449, 42478, 42355, 15581, 15574, 62646, 15570, 62659,\n",
       "         15548, 55283, 42405, 42419, 62665, 15522, 15503, 15496, 15471,\n",
       "         15455, 62645, 15278, 15268, 55130, 42904, 62876, 15035, 15022,\n",
       "         62880, 42927, 15001, 62886, 62891, 14984, 42947, 14970, 62897,\n",
       "         42954, 55136, 55191, 15079, 55150, 15237, 15232, 15231, 15222,\n",
       "         15203, 62800, 62819, 42736, 42744, 42803, 42839, 15123, 15117,\n",
       "         42848, 15110, 42876, 14300, 17151, 17183, 40026, 40035, 19063,\n",
       "         40049, 19048, 19024, 19081, 40079, 55907, 18987, 18983, 61784,\n",
       "         18957, 55891, 40082, 40006, 19095, 19097, 39897, 39911, 55941,\n",
       "         55940, 19219, 39950, 19203, 19186, 39953, 55935, 39959, 39982,\n",
       "         19153, 19136, 19126, 18935, 61797, 61805, 55889, 18747, 18739,\n",
       "         40291, 40295, 18709, 40332, 61843, 40376, 40383, 18633, 40395,\n",
       "         40399, 18625, 18618, 40417, 40286, 39896, 18757, 18766, 18895,\n",
       "         18882, 18878, 40164, 18845, 18837, 40224, 55869, 18822, 40231,\n",
       "         18804, 18793, 40242, 18781, 40281, 18762, 19276, 39893, 61691,\n",
       "         19749, 19738, 19728, 39662, 55990, 61551, 19705, 61552, 39695,\n",
       "         19682, 61555, 61556, 19653, 61564, 39722, 39635, 19628, 19761,\n",
       "         19769, 39565, 39568, 39579, 39581, 39584, 39604, 19845, 19843,\n",
       "         19822, 56021, 56008, 61524, 19797, 19789, 19781, 39634, 55838,\n",
       "         55985, 61574, 19388, 19387, 19384, 39841, 19382, 19378, 19372,\n",
       "         61670, 39871, 61680, 61681, 19307, 55957, 39891, 19292, 19397,\n",
       "         61571, 19424, 61652, 39742, 61580, 39755, 61593, 19536, 61600,\n",
       "         19508, 19503, 39794, 19497, 19496, 19492, 19483, 39815, 39833,\n",
       "         39836, 17166, 18577, 61875, 40908, 55714, 55711, 17662, 17644,\n",
       "         17641, 17706, 17639, 62063, 17628, 17622, 17621, 17604, 40983,\n",
       "         40955, 17712, 17717, 17738, 17890, 55745, 55743, 17877, 62036,\n",
       "         17860, 40800, 55724, 17843, 17811, 40845, 17801, 17795, 17760,\n",
       "         55719, 40985, 55693, 62071, 41026, 17304, 62135, 41182, 17290,\n",
       "         17284, 41191, 17250, 17249, 41221, 55640, 41230, 55629, 17200,\n",
       "         17188, 17186, 17305, 62014, 17332, 41148, 17565, 17551, 17501,\n",
       "         17496, 17479, 17463, 17451, 17436, 41111, 62097, 17403, 17390,\n",
       "         17374, 62115, 41136, 41162, 17907, 17917, 17930, 55821, 40494,\n",
       "         18382, 40512, 18360, 40514, 18347, 18338, 40524, 40526, 18317,\n",
       "         18312, 40541, 18286, 18285, 40487, 18268, 18416, 55825, 40420,\n",
       "         18556, 18555, 40422, 40423, 18500, 61900, 40442, 18467, 18463,\n",
       "         40456, 40464, 18456, 40471, 18430, 18418, 55830, 40556, 18231,\n",
       "         18034, 55767, 55761, 18020, 18016, 40669, 18000, 61993, 61994,\n",
       "         55756, 17975, 40695, 40701, 40703, 40728, 18035, 18245, 61987,\n",
       "         55789, 40572, 18219, 40579, 18192, 61971, 40608, 18162, 18148,\n",
       "         40615, 18134, 40631, 18099, 18092, 18079, 40645, 40651, 14299,\n",
       "         14282, 63094, 54324, 54307, 10360, 10322, 10315, 54305, 45797,\n",
       "         54304, 10269, 10261, 10254, 10247, 10246, 45861, 10276, 10407,\n",
       "         10410, 45794, 64193, 10551, 54356, 45702, 45707, 54352, 10512,\n",
       "         54345, 64210, 10483, 10471, 10470, 45745, 45764, 45782, 10221,\n",
       "         10208, 45881, 10201, 46033, 46057,  9984, 64371,  9968, 46064,\n",
       "          9958, 46094,  9922,  9914, 64387,  9911,  9910, 46112, 46127,\n",
       "         10036, 54358, 10052, 10079, 45889, 45890, 45891, 45894, 10179,\n",
       "         10165, 64317, 45910, 54292, 45925, 45937, 45958, 45973, 45978,\n",
       "         45979, 45991, 10566, 45668, 10573, 64048, 10983, 10969, 10968,\n",
       "         10965, 45472, 64059, 10907, 45492, 10899, 10890, 10881, 10880,\n",
       "         10875, 10868, 45412, 10860, 45408, 11009, 11165, 45314, 11133,\n",
       "         11106, 11104, 45325, 45336, 11083, 45362, 45380, 45392, 11028,\n",
       "         45399, 11017, 11014, 64031, 46139, 10851, 45519, 64156, 64158,\n",
       "         45617, 64167, 64173, 45623, 45627, 45633, 10600, 10596, 10594,\n",
       "         10586, 45656, 10581, 64179, 45614, 45514, 45585, 64147, 64087,\n",
       "         10826, 10823, 10816, 10814, 64095, 45534, 10783, 10781, 45539,\n",
       "         10751, 10748, 10731, 64144, 45559, 45569, 54427, 46142, 46157,\n",
       "         46715,  8868, 46722,  8841, 64772,  8831,  8877, 46750,  8804,\n",
       "         46776,  8786,  8783,  8780, 46788,  8826,  8906,  8909,  8910,\n",
       "         46600,  9065, 64698,  9039, 64702,  9013,  9000,  8988, 46645,\n",
       "         64711,  8957,  8955,  8944,  8943, 46681, 46797,  8761,  8759,\n",
       "         46801, 46915, 46918,  8570,  8564,  8562,  8561, 64865, 46920,\n",
       "          8533,  8521,  8509, 46950, 46951, 53998,  8477,  8576, 54119,\n",
       "          8587,  8631, 54034,  8753, 64804, 54028,  8713,  8710, 46824,\n",
       "         46834, 46839, 64825, 46848,  8652, 54023, 54008, 64837,  8600,\n",
       "          9110, 54121,  9139, 46240,  9663,  9660, 54201,  9652,  9636,\n",
       "         64519, 46275, 46281, 46310,  9548,  9545, 46327,  9534,  9531,\n",
       "         64495, 46328,  9690,  9722, 64436, 46161,  9854, 46170,  9830,\n",
       "          9814,  9809,  9798, 54236, 54234, 64470,  9757,  9740, 64484,\n",
       "         46213,  9720, 46147,  9516,  9484, 54177, 46461, 46465, 64624,\n",
       "          9264, 54151, 46477,  9248, 54126, 46527, 46535, 46541, 64661,\n",
       "          9142, 46554,  9318,  9501,  9336, 46443, 64559,  9465,  9452,\n",
       "         46357, 46362, 64571,  9427, 46369, 46376,  9415, 46378,  9396,\n",
       "         46392, 46418,  9349,  9337, 11184, 54431, 45289, 13200, 13196,\n",
       "         13177, 13169, 63434, 54803, 13203, 44114, 13100, 13085, 13077,\n",
       "         54790, 44172, 63470, 54797, 13212, 44057, 13227, 13373, 43973,\n",
       "         13363, 43991, 43998, 13318, 44003, 13306, 54818, 63395, 44037,\n",
       "         44048, 44054, 13239, 44055, 44182, 13023, 13021, 54771, 44290,\n",
       "         54728, 12830, 63531, 44319, 54725, 44354, 12775, 12766, 44358,\n",
       "         12754, 12740, 12736, 63553, 44367, 12893, 63351, 12895, 44268,\n",
       "         44191, 12995, 44194, 12984, 12981, 44200, 44209, 44221, 44226,\n",
       "         63507, 44229, 12938, 12933, 12932, 12925, 44283, 54841, 13419,\n",
       "         13442, 43514, 14061, 43517, 14048, 13966, 13959, 63187, 43574,\n",
       "         13931, 43595, 13906, 13893, 43608, 13876, 13874, 43511, 13865,\n",
       "         43510], dtype=int64),\n",
       "  'feature_absent_idx': array([13565, 58941, 33888, 58937, 16458, 58935, 16462, 33887, 33885,\n",
       "         58933, 33883, 16474, 33880, 16477, 33878, 58928, 33875, 58925,\n",
       "         16490, 50016, 33867, 16493, 16494, 16496, 50021, 58919, 16504,\n",
       "         33860, 16453, 50024, 33889, 16444, 33932, 16378, 16380, 16382,\n",
       "         49999, 33927, 50000, 16393, 16394, 16397, 58966, 16401, 16407,\n",
       "         33916, 33914, 16414, 16415, 16420, 16422, 16424, 33904, 16428,\n",
       "         33903, 33902, 58951, 58950, 16443, 33892, 16376, 58915, 58914,\n",
       "         16579, 33817, 50046, 16585, 16586, 16588, 50049, 33808, 33804,\n",
       "         33802, 58865, 33798, 33797, 16607, 58859, 50055, 33792, 33790,\n",
       "         33788, 16626, 16627, 33787, 58851, 50058, 50060, 33783, 58842,\n",
       "         16578, 16510, 16575, 58884, 58912, 16517, 33855, 58907, 16522,\n",
       "         16532, 16533, 16534, 33840, 16537, 58897, 16539, 58894, 16543,\n",
       "         16544, 33836, 16551, 33835, 33834, 16560, 33827, 33825, 16564,\n",
       "         16566, 33821, 33820, 58885, 58882, 50062, 49994, 58974, 16173,\n",
       "         49931, 16178, 34066, 34065, 16182, 34064, 34054, 59073, 16196,\n",
       "         34053, 34050, 16201, 49941, 16203, 34047, 34046, 34043, 16216,\n",
       "         34040, 16219, 59058, 34033, 16222, 16223, 16227, 34029, 59087,\n",
       "         34026, 59088, 16165, 16117, 49891, 49897, 49898, 16122, 16123,\n",
       "         16125, 16126, 16129, 49901, 59112, 59110, 16135, 16136, 16138,\n",
       "         34093, 34092, 59106, 16142, 49923, 16151, 59104, 16155, 34077,\n",
       "         59093, 59092, 16164, 59089, 16373, 49948, 59045, 33970, 49976,\n",
       "         16321, 49978, 33966, 33961, 16332, 33960, 58992, 16339, 16340,\n",
       "         16343, 49985, 49988, 16347, 33954, 58987, 16350, 16356, 58982,\n",
       "         16358, 58981, 16360, 16364, 33939, 33937, 16369, 16316, 34022,\n",
       "         16313, 33975, 16241, 16242, 59043, 34013, 16250, 16252, 59040,\n",
       "         49954, 59038, 16260, 59037, 34009, 34005, 16266, 59032, 49960,\n",
       "         16278, 59016, 33996, 33995, 16285, 33989, 16294, 59006, 16300,\n",
       "         59003, 49973, 16308, 16640, 33779, 16644, 33577, 16991, 33575,\n",
       "         16996, 50165, 58672, 58671, 17001, 33570, 17006, 50176, 58666,\n",
       "         50180, 17019, 33556, 33555, 33553, 17027, 50184, 50194, 33537,\n",
       "         17037, 58657, 50200, 33532, 33530, 33528, 16989, 17050, 33578,\n",
       "         16981, 58714, 50154, 58713, 16919, 58712, 58708, 33609, 33608,\n",
       "         16935, 16937, 33601, 16943, 58697, 33596, 33594, 33593, 16955,\n",
       "         58694, 33590, 50161, 16970, 58687, 58684, 16973, 58680, 33583,\n",
       "         33581, 16986, 58718, 33523, 17055, 17116, 17118, 33471, 33470,\n",
       "         17125, 50232, 17132, 58601, 33456, 17139, 33453, 33451, 17146,\n",
       "         50241, 17148, 17152, 17154, 17156, 33438, 17159, 17161, 17162,\n",
       "         17163, 17165, 17169, 58573, 58572, 17113, 17053, 58615, 50223,\n",
       "         17056, 50203, 50205, 33516, 58643, 33515, 33514, 17070, 33507,\n",
       "         17072, 33506, 58635, 33505, 58632, 17077, 58631, 17080, 33501,\n",
       "         33497, 58628, 17090, 33489, 58621, 33485, 50215, 17105, 50218,\n",
       "         17111, 50151, 16905, 16901, 16719, 16721, 16725, 50084, 58799,\n",
       "         58797, 58796, 50087, 16732, 33727, 33726, 16736, 50092, 16747,\n",
       "         16748, 16750, 16752, 50103, 16755, 16760, 33710, 58781, 16766,\n",
       "         58780, 50104, 16770, 16771, 16715, 58779, 33734, 16711, 33772,\n",
       "         16654, 50070, 58827, 16661, 50074, 58821, 16668, 58820, 33751,\n",
       "         16675, 33748, 16681, 58814, 33747, 16685, 16692, 16694, 33739,\n",
       "         58809, 16697, 16698, 16699, 16702, 33737, 33736, 16709, 16712,\n",
       "         16775, 16776, 33706, 16847, 50139, 16849, 33653, 50141, 16855,\n",
       "         16856, 58747, 16867, 58746, 16871, 16873, 16874, 58744, 16876,\n",
       "         33637, 58741, 58740, 58739, 50142, 16889, 33633, 16893, 50143,\n",
       "         16897, 16898, 50145, 16844, 50131, 33663, 33664, 16778, 58776,\n",
       "         16782, 16785, 16786, 16788, 16792, 16794, 33700, 58770, 16797,\n",
       "         58769, 33693, 49890, 16802, 50112, 16807, 16808, 33689, 16812,\n",
       "         16813, 33679, 50122, 16824, 16827, 58754, 16830, 16835, 33692,\n",
       "         17173, 34116, 16108, 15433, 34543, 34541, 15437, 15440, 49661,\n",
       "         59486, 59484, 59479, 59473, 15459, 15462, 49666, 59467, 34526,\n",
       "         34524, 59460, 49667, 34522, 49668, 49677, 15485, 59456, 49678,\n",
       "         49679, 59454, 15490, 34546, 15493, 15429, 59499, 15364, 15365,\n",
       "         15370, 15372, 15376, 34583, 59519, 15383, 34579, 49648, 59515,\n",
       "         34573, 15392, 34572, 34570, 49649, 59509, 59508, 15406, 49654,\n",
       "         15410, 34556, 59500, 15417, 34554, 34553, 34552, 34547, 34587,\n",
       "         59452, 59449, 15576, 15577, 49703, 59395, 15586, 59393, 34462,\n",
       "         15590, 34457, 15592, 15594, 49707, 15598, 49708, 59392, 15602,\n",
       "         59391, 59389, 34445, 34441, 34440, 59387, 59385, 59384, 15619,\n",
       "         49712, 49713, 34468, 34512, 15571, 15563, 59444, 15509, 49686,\n",
       "         59441, 15514, 15516, 15519, 34500, 59435, 15524, 34498, 59426,\n",
       "         15530, 34495, 34493, 15534, 15535, 49691, 34488, 15541, 59412,\n",
       "         15547, 59411, 34483, 59406, 15560, 49696, 15566, 59383, 59529,\n",
       "         15354, 15172, 34703, 15176, 34702, 34701, 59618, 15182, 15188,\n",
       "         59612, 15190, 15195, 59609, 15198, 34691, 59603, 34688, 15205,\n",
       "         49586, 34685, 49588, 15212, 34679, 49590, 49594, 15217, 15220,\n",
       "         15226, 15171, 15227, 15170, 49578, 34740, 34738, 34727, 34725,\n",
       "         15134, 15136, 34722, 49570, 59643, 15144, 59641, 49572, 34714,\n",
       "         15149, 59639, 15151, 59638, 15154, 34710, 15157, 15159, 59636,\n",
       "         15161, 49574, 15165, 15166, 59635, 49579, 49642, 15228, 15235,\n",
       "         15299, 15300, 34628, 59570, 59565, 59564, 15315, 15316, 15320,\n",
       "         34612, 59560, 59555, 34611, 15326, 34607, 15330, 34605, 59547,\n",
       "         15336, 15337, 34600, 59544, 34598, 49639, 34593, 59537, 15353,\n",
       "         34634, 59594, 15290, 15284, 15236, 15239, 59593, 59592, 59590,\n",
       "         15246, 34664, 59587, 15250, 15251, 34663, 34661, 34659, 15255,\n",
       "         15256, 15257, 15260, 15263, 49605, 49606, 15266, 15267, 34650,\n",
       "         49609, 15279, 49610, 15281, 59573, 15624, 34434, 59368, 15931,\n",
       "         34235, 59198, 34227, 59195, 59191, 15942, 15943, 34218, 34214,\n",
       "         34212, 15957, 59183, 34207, 34205, 34204, 15964, 49825, 15968,\n",
       "         59179, 49831, 15972, 34198, 59178, 49837, 15984, 15988, 59199,\n",
       "         49847, 59206, 15922, 59243, 34274, 49800, 15872, 59241, 59240,\n",
       "         59237, 59236, 15881, 15882, 34269, 59235, 15887, 15891, 34262,\n",
       "         49803, 15898, 15901, 34253, 49809, 59212, 15908, 59211, 34243,\n",
       "         59210, 34241, 15921, 15925, 15863, 15994, 15997, 16070, 16071,\n",
       "         16072, 34139, 34138, 59134, 16078, 34136, 16081, 34134, 34133,\n",
       "         34131, 49885, 16088, 34128, 16091, 16092, 34127, 59128, 34126,\n",
       "         34123, 16098, 16099, 16103, 16104, 34120, 59123, 16067, 34179,\n",
       "         59139, 34147, 49851, 59170, 59168, 34174, 34173, 49854, 49855,\n",
       "         16016, 49856, 34168, 59163, 34164, 34162, 59158, 59154, 16033,\n",
       "         16036, 49865, 16040, 16042, 16044, 34153, 59147, 16050, 34149,\n",
       "         16056, 16057, 34145, 15862, 49796, 34282, 59326, 15688, 34393,\n",
       "         59323, 15694, 49732, 59320, 34382, 15704, 15705, 34380, 15709,\n",
       "         34378, 49739, 49742, 15722, 15723, 15724, 15727, 34366, 15730,\n",
       "         15731, 15732, 15733, 15737, 34362, 59301, 15686, 49752, 34395,\n",
       "         34399, 34433, 15630, 15632, 15634, 59363, 15637, 34427, 34426,\n",
       "         15641, 34422, 34420, 59358, 34417, 59357, 15652, 49725, 34413,\n",
       "         15656, 15657, 15660, 59349, 59348, 15670, 15676, 59339, 15679,\n",
       "         59330, 49729, 59299, 34359, 34357, 15802, 15803, 34316, 15808,\n",
       "         15812, 15813, 34314, 15815, 59265, 59264, 15823, 59262, 59261,\n",
       "         15826, 15827, 15829, 34304, 34302, 15834, 15835, 34298, 15837,\n",
       "         15843, 15848, 34285, 59249, 34283, 15800, 59268, 59270, 34319,\n",
       "         34353, 15750, 59293, 15754, 15756, 49760, 59286, 49761, 59283,\n",
       "         15766, 15768, 34338, 34335, 34119, 15773, 34334, 15777, 15780,\n",
       "         49767, 49768, 34328, 34326, 34325, 15787, 34324, 59274, 59273,\n",
       "         49771, 15774, 34741, 50245, 17177, 57898, 50672, 32590, 57887,\n",
       "         32585], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_interrogative_clause': {'feature_present_idx': array([66745, 38631, 39392, 49591, 16437, 54056, 57672, 58691, 26559,\n",
       "         60865,  8777,  8428, 10297, 64994, 64338, 16314, 31518, 12393,\n",
       "         15689, 22089, 52727, 66371, 45297, 33603, 60061, 41905, 62732,\n",
       "         29772, 57729, 39724, 45905, 32055,  6030, 11246, 10918, 24382,\n",
       "         21348, 20969,  9262, 18476, 20515, 20039, 19411, 13094, 52459,\n",
       "         59404, 16972, 43557, 49394, 37986, 36296, 35521, 32788, 65185,\n",
       "         30237, 57155, 12352,  2917, 46668, 48561, 57872, 30146, 29990,\n",
       "         56445,  9141,   169, 53349, 51146, 16541, 60695, 19330, 38408,\n",
       "         54238, 30862, 16502, 25048, 26565,  1533], dtype=int64),\n",
       "  'feature_absent_idx': array([38026, 57568, 57567, 57566, 28248, 12707, 28247, 12710, 12711,\n",
       "         45576, 12714, 28241, 28240, 12717, 57570, 28238, 12723, 28233,\n",
       "         28232, 57550, 45583, 28225, 57544, 28224, 45592, 12739, 45594,\n",
       "         28218, 12742, 12721, 28213, 45573, 12696, 57609, 45535, 57605,\n",
       "         12653, 57601, 45542, 12661, 57599, 12663, 12664, 45544, 12667,\n",
       "         57596, 57571, 28274, 57591, 45553, 12675, 12676, 45557, 28267,\n",
       "         28265, 28264, 57579, 57578, 45565, 45567, 12693, 57594, 45598,\n",
       "         45599, 28209, 12799, 28173, 12805, 12807, 28167, 12811, 12812,\n",
       "         12813, 45626, 45628, 57480, 12824, 12826], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 78\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 78\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 78\n",
       "    })}}},\n",
       " 'contains_question': {'feature_present_idx': array([67304, 30335,  8182, 17677,  7867, 17730, 45181, 17377, 18354,\n",
       "         25737, 61799, 28326, 20561, 51808, 41298,  6213,  8421, 59876,\n",
       "         35393, 32552, 13483, 56966, 11768, 11633, 42474, 11341, 43286,\n",
       "         58230, 41988, 10121, 34482,  9733, 31593, 55548, 20820,  3529,\n",
       "         57289, 23512, 23649, 65462,   535,  2201, 26590, 48472, 48832,\n",
       "         64955, 66383, 46867, 24654, 43450, 31821, 56247, 55919, 44496,\n",
       "         16804, 31043, 16886, 48918, 30947, 55055, 48943, 44891, 46795,\n",
       "         44906, 30456, 44723, 15506, 48705, 27286, 13387, 48121, 26224,\n",
       "         13547, 57197, 13596, 57057, 57018, 26290, 14272, 48443, 14318,\n",
       "         25390, 14523, 32302, 56925, 56741, 14632, 42966, 47291, 32065,\n",
       "         56250, 44952, 50971, 17654, 28596, 46026, 50266, 19960, 20015,\n",
       "         20147, 20153, 20528, 28038, 22889, 20799, 22583, 51801, 28087,\n",
       "         46549, 51206, 21852, 22565, 21963, 21979, 21985, 51022, 22258,\n",
       "         52139, 50500, 19694, 52920, 27648, 27902, 27966, 45029, 17781,\n",
       "         23330, 17882, 54033, 18278, 53751, 23289, 45485, 53580, 18696,\n",
       "         28010, 18854, 28992, 23173, 53173, 19182, 19235, 52999, 45933,\n",
       "         52858, 38879, 47911,  5691,  5361, 36443,  5548, 36414, 36356,\n",
       "          5664, 57541,  5803, 36325, 36314,  5229, 36242, 37429, 36074,\n",
       "          6654,  2293, 61054, 35951, 60815,  6959,  7206, 60627,  2449,\n",
       "          2766, 61871, 62035, 40199,  3042, 40311, 64266, 64101, 36787,\n",
       "         36723, 36679, 37113, 40899,  2459, 63219,  2569,  4029, 41092,\n",
       "         62940, 62890, 62842, 62528,  4669,  4823, 36448, 63105, 37582,\n",
       "         65187,  7382, 41682, 10106,   784,   628, 58085, 37984,   248,\n",
       "         11132, 11547, 11726, 11800, 66406, 33329, 12043, 38070, 12353,\n",
       "         33189, 12609, 12615, 42504, 57545, 10008, 65981, 34208,  8848,\n",
       "         59645, 41980, 35572, 35133, 60177, 35610, 34978,  1551,  8358,\n",
       "          9239,  8113, 65646, 58792, 58755, 60353, 40179, 47709, 46626,\n",
       "         37913, 37618, 39630, 26272, 37748, 39955, 26651, 47309, 47183,\n",
       "         39250, 40116, 37552, 42528, 28044, 67232, 32490, 42783, 42233,\n",
       "         33535, 33619, 33823, 33861, 34158, 32003, 31827, 34514, 31510,\n",
       "         34673, 36970, 34937, 35316, 35490, 35649, 30083, 41479, 45456,\n",
       "         45665, 29136, 36161, 28330, 46216, 40902, 36648, 36655, 34987,\n",
       "         32666, 53289, 38459, 58875, 65576,  9304, 58586,  9992, 10092,\n",
       "         58570, 10543, 10718, 57931, 25671, 10997, 11579, 11872, 12414,\n",
       "         12624, 12764, 13181, 13391, 13634, 14067, 14544, 63996, 59008,\n",
       "          2499,  8889, 59220,  2933,  3360, 63674, 63400, 63035,  4110,\n",
       "          4133, 62080,  5379,  2685,  5645, 56299,  5942,  2600,  6069,\n",
       "          6224,  2585,  7270,  7380, 60626,  8258,  8345,  8389, 59259,\n",
       "         61642, 14961, 56486,  1305, 19377, 52086, 51934, 51865, 19909,\n",
       "         20444, 51795, 51288, 50485, 23278,   456, 23485, 23566, 49328,\n",
       "         23979, 24579,   144, 24821, 25036, 25197, 48275, 25482, 25537,\n",
       "         16031, 66315,  3090, 55931,  1004, 16513, 16345, 16679, 16759,\n",
       "         55445, 54954, 17221,   922, 65784, 55778, 17555, 56069, 54417,\n",
       "         54312, 17846, 53768, 53702, 18605, 53470, 17477, 64503, 39215,\n",
       "         38959, 39715, 39405, 65519, 39158, 65621, 38931, 40005, 47353,\n",
       "         63698, 48772, 48783, 49600, 50250, 50707, 53459, 45848, 54733,\n",
       "         55686, 44326, 43941, 43367, 57816, 58521, 41834, 58948, 59095,\n",
       "         41783, 61041, 61174, 61703, 63735, 57823,    63, 32881, 22388,\n",
       "         30186, 22330, 30586, 30863,  3791, 22008, 10842, 30025, 21658,\n",
       "         31403, 31517,  3344, 20980, 17281,  3165,  8978, 32231, 21466,\n",
       "         22527, 23081,  8586, 24719,  6785, 24869, 25400,  6714, 25664,\n",
       "          6793,  6024, 26221,  5555,  7236, 26403, 10919, 26668,  5167,\n",
       "         28074,  4654, 17968, 12680, 32243,  2855,  9037, 32874, 36890,\n",
       "         32555, 36929, 13187, 37211, 37367, 18955,   916, 37699,   441,\n",
       "         37782, 10236, 18078, 37930, 38023, 38119, 18819,  1027, 24694,\n",
       "         33442, 36542,  1755, 35040,  9137,  1979, 35886, 19731,  2783,\n",
       "         17844,  9426, 10171, 17773, 52049, 10918, 24483, 54225, 19856,\n",
       "         18480, 52264, 49368, 52420, 23474, 53308, 49670,  9907, 59408,\n",
       "         52668,  8535, 23065, 58619, 58789, 19328, 23639, 38676, 28490,\n",
       "         24713, 55988, 33481, 42041, 65157, 34209, 16326, 41751, 36508,\n",
       "         40898, 65652, 40390, 40205, 13549, 40075, 37614,   815, 37762,\n",
       "         39369,   157, 56378, 38990, 64386, 24666, 64345, 64058, 25862,\n",
       "         25945, 55123, 47245, 46998, 27244, 46523, 57615,  3866, 31733,\n",
       "         29154, 29612, 45085, 30199, 16558,  3671, 31300, 16334,  3320,\n",
       "         29187, 54097, 57364, 58001, 57456, 61786,  9368, 66863, 66163,\n",
       "         66109,  2301,  2717, 64589,  3657, 63544, 58250,  3788, 62689,\n",
       "          5554, 13809, 60783,  8114, 59549,  8879,  9175,  4412, 13905,\n",
       "         38371, 34073, 19449, 47299, 42101, 42242, 31923, 51864, 43652,\n",
       "         51782, 21849, 43818, 50080, 43824, 44366, 44717, 44824, 48695,\n",
       "         45723, 28734, 27245, 19152, 19139, 14571, 18310, 14702, 37788,\n",
       "         15696, 16348, 39402, 39446, 18657, 37028, 16972, 37062, 17076,\n",
       "         53844, 36459, 35882, 17206, 64358,  3397, 40785,  2236, 44779,\n",
       "         43734, 65956, 66564,  4629,  2771, 28318,  4973, 39164, 26634,\n",
       "         53189, 19888, 19598, 58402, 57473, 10375, 20779,  8690, 54876,\n",
       "         49850,  7456, 52625, 17110, 49298, 24420, 25473, 57720, 16622,\n",
       "         61085, 47421, 12886, 26320, 14631, 19768, 40664, 58016, 65516,\n",
       "         12864, 14222, 14762,  5983,  4280, 31245, 61783, 23425, 15448,\n",
       "         64174, 52031,  8282,  3091, 34564, 62926, 40611, 62554, 65556,\n",
       "         36644, 67055,  4985, 49206, 29057, 32378, 43054], dtype=int64),\n",
       "  'feature_absent_idx': array([29915, 12813, 57611, 57609, 28436, 45674, 57605, 12824, 57601,\n",
       "         12826, 28429, 57599, 12829, 45683, 12812, 57596, 57594, 28421,\n",
       "         28416, 57591, 28410, 45695, 28408, 12851, 12852, 57579, 12854,\n",
       "         57578, 28407, 12835, 45696, 12811, 12807, 57650, 12762, 12763,\n",
       "         45652, 12768, 12769, 12770, 12771, 12773, 12777, 12782, 57643,\n",
       "         57642, 28439, 57641, 28452, 28450, 57629, 57628, 28448, 57626,\n",
       "         28447, 12799, 28445, 45671, 45672, 12805, 28441, 45664, 12858,\n",
       "         45699, 12862, 45726, 12915, 28361, 57526, 57525, 57524, 45731,\n",
       "         45732, 57518, 12930, 28350, 45736, 57516, 45725, 45740, 57513,\n",
       "         28341, 57511, 28337, 12943, 45747, 28333, 12947, 12948, 28331,\n",
       "         12951, 12952, 57502, 45743, 28370, 28371, 45722, 45701, 12865,\n",
       "         45704, 57571, 57570, 57568, 57567, 57566, 28398, 28397, 45705,\n",
       "         12877, 12878, 12880, 45711, 28388, 57550, 28383, 12892, 28382,\n",
       "         12894, 45713, 12898, 28378, 12901, 45716, 45717, 28374, 57544,\n",
       "         28473, 57501, 57656, 28478, 28592, 28589, 57772, 45592, 28583,\n",
       "         57770, 28580, 57768, 45594, 57766, 57762, 45598, 45599, 45583,\n",
       "         45600, 12634, 28562, 45603, 57753, 57750, 28558, 12644, 28552,\n",
       "         57745, 12653, 28548, 57741, 45609, 12633, 57736, 12598, 12596,\n",
       "         12550, 28630, 45565, 57811, 12557, 45567, 28624, 28622, 12562,\n",
       "         28621, 57807, 57801, 12568, 12597, 57796, 12574, 28612, 45573,\n",
       "         45576, 12581, 28605, 12583, 12586, 57782, 28602, 12592, 28595,\n",
       "         12595, 57795, 57735, 28544, 12661, 45628, 12714, 57688, 12717,\n",
       "         28504, 12721, 12723, 57683, 28501, 28500, 28498, 28494, 28493,\n",
       "         12711, 57676, 45635, 45638, 12739, 28487, 45639, 12742, 57670,\n",
       "         57667, 57666, 57665, 28482, 57662, 45643, 45634, 12710, 45626,\n",
       "         12707, 12663, 12664, 57731, 12667, 57730, 45611, 57725, 28537,\n",
       "         12675, 12676, 28536, 57723, 28534, 45615, 45616, 28530, 28529,\n",
       "         57718, 57717, 57715, 12693, 28525, 45618, 12696, 45619, 28521,\n",
       "         28520, 28519, 57699, 28476, 12546, 57493, 12960, 28124, 28117,\n",
       "         28114, 28113, 13233, 57271, 45923, 28109, 28108, 57266, 57265,\n",
       "         45927, 13243, 28126, 57261, 45929, 13249, 57257, 57256, 57254,\n",
       "         13255, 57252, 57251, 13259, 28097, 57247, 45935, 28093, 13247,\n",
       "         28091, 13221, 13219, 13167, 45879, 13173, 13176, 13183, 28150,\n",
       "         57306, 57305, 13190, 45892, 13193, 57303, 45895, 57283, 57301,\n",
       "         28140, 13201, 57299, 45900, 28136, 57297, 28135, 13209, 45903,\n",
       "         45904, 13214, 13217, 28128, 45899, 45939, 13269, 13271, 13317,\n",
       "         28056, 13322, 28051, 57188, 13328, 13329, 28047, 45968, 13333,\n",
       "         45969, 28042, 13338, 57208, 28034, 13345, 13347, 45976, 28026,\n",
       "         45984, 45986, 28018, 13362, 13364, 13365, 28013, 57156, 45990,\n",
       "         13344, 13311, 28063, 28064, 57237, 13273, 13274, 28088, 28085,\n",
       "         57232, 28084, 13280, 57230, 57227, 28082, 57224, 57221, 13288,\n",
       "         28080, 13290, 28079, 13292, 13293, 28078, 13295, 57218, 28076,\n",
       "         13301, 45945, 45948, 45953, 13307, 57209, 28167, 45758, 45874,\n",
       "         13160, 28264, 57437, 13028, 13029, 45807, 57433, 45809, 13037,\n",
       "         57430, 13040, 57429, 57428, 57427, 28265, 57425, 57423, 28247,\n",
       "         13052, 57422, 57420, 28241, 28240, 28238, 45823, 57415, 57413,\n",
       "         13065, 45824, 28248, 28233, 45803, 13020, 45761, 12964, 28316,\n",
       "         12969, 12970, 12971, 28310, 12973, 57480, 28304, 45769, 12983,\n",
       "         28299, 28267, 12987, 45779, 57468, 45786, 13002, 13003, 57450,\n",
       "         28274, 57447, 13014, 57442, 13016, 45800, 57441, 12989, 57405,\n",
       "         57403, 28232, 57362, 45846, 45847, 57359, 45849, 28191, 57352,\n",
       "         57350, 28188, 57344, 45856, 57341, 57339, 57365, 28182, 13146,\n",
       "         57336, 13148, 13149, 45864, 13151, 57334, 45865, 13154, 45872,\n",
       "         57329, 28173, 57325, 45863, 57366, 57367, 45843, 57401, 57399,\n",
       "         45826, 57395, 45828, 13079, 13081, 28225, 28224, 13084, 57392,\n",
       "         57391, 28218, 57389, 13095, 13096, 13098, 28213, 13101, 57386,\n",
       "         13103, 13106, 13108, 57381, 28209, 28208, 13112, 28207, 28205,\n",
       "         13161, 57821, 12544, 28634, 29041, 58243, 29040, 58242, 29039,\n",
       "         12013, 12014, 12015, 45233, 12017, 58240, 58239, 58237, 29042,\n",
       "         12022, 29035, 29033, 29032, 45236, 12029, 45237, 29029, 29028,\n",
       "         12033, 45239, 45243, 58221, 29020, 58236, 45247, 58246, 45223,\n",
       "         58301, 58297, 58294, 58292, 29086, 11952, 45197, 11959, 58286,\n",
       "         45199, 58285, 11968, 58283, 45232, 29071, 58274, 11975, 11976,\n",
       "         58267, 45212, 11984, 11985, 11987, 29058, 11994, 11995, 45220,\n",
       "         58254, 58277, 45248, 58215, 12045, 28986, 28983, 28982, 28981,\n",
       "         45281, 45282, 28976, 12104, 12106, 12108, 12109, 45292, 58163,\n",
       "         58178, 58158, 45299, 58152, 58151, 28957, 45304, 28954, 45305,\n",
       "         45310, 12132, 12134, 28942, 28940, 58132, 28964, 58179, 12087,\n",
       "         45275, 12046, 12047, 45249, 45250, 45252, 58208, 58207, 45253,\n",
       "         29012, 12056, 45255, 12059, 58203, 12062, 29008, 12064, 29007,\n",
       "         58200, 29004, 58197, 58195, 45258, 12075, 58191, 45266, 12079,\n",
       "         45271, 28994, 28993, 11940, 58130, 11939, 29094, 29200, 58416,\n",
       "         58415, 58413, 58411, 29199, 29196, 29194, 11802, 11804, 11805,\n",
       "         11806, 45135, 11785, 29191, 11811, 29184, 11817, 11821, 58389,\n",
       "         58388, 11826, 11827, 11828, 29177, 11830, 58385, 11832, 11809,\n",
       "         11834, 11784, 29205, 11739, 58465, 45111, 45113, 29229, 58460,\n",
       "         11749, 29226, 45117, 58450, 29219, 11758, 29214, 58428, 58444,\n",
       "         58443, 11765, 11766, 58442, 58439, 58438, 45122, 58434, 11777,\n",
       "         58429, 11779, 45128, 11781, 29213, 58380, 29175], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 709\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 709\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 709\n",
       "    })}}},\n",
       " 'contains_coreferences': {'feature_present_idx': array([20751, 45961, 59415, 58102, 22240, 40621, 58742, 56156, 52691,\n",
       "         50136, 25990, 49557, 60565,  8758, 49248, 26309,  8504, 61001,\n",
       "         26411, 26584, 26946, 48744, 27352, 27915, 48102, 47872,  7123,\n",
       "          6963, 25116, 20658, 59826, 15357, 52307, 57354, 57434, 14404,\n",
       "         21815, 57995, 56292, 58024, 12516, 24584, 52161, 11383, 20170,\n",
       "         58445, 10980, 10975, 58646, 10727,  6891,  9639, 11384, 62290,\n",
       "          8270, 36785,  4299, 32856, 33038, 64098, 33862, 34379, 44612,\n",
       "         62386, 32320, 37338, 65903,  2252,  1997, 42814, 66815, 41202,\n",
       "         41619, 42156, 37391,  4400, 55301, 63631, 31415, 46974, 46686,\n",
       "          5653,  5587, 55178, 52516, 52460, 21287, 42265, 21534, 40644,\n",
       "         42212, 21862, 21899, 43137, 28991, 21398, 41892, 41241, 43361,\n",
       "         54397, 54198, 17894, 41735, 29367, 53761, 53603, 19807, 19819,\n",
       "         20107, 29176, 20406, 41291, 20455, 52951, 29023, 22407, 30122,\n",
       "         26501, 35283, 34674, 24627, 44711, 50410, 44742, 50778, 25528,\n",
       "         27598, 31330, 33172, 27093, 45658, 32210, 25753, 38918, 28234,\n",
       "         50834, 51906, 47391, 38459, 51855, 37916, 23151, 24025, 30271,\n",
       "         23290, 28332, 35732, 44540, 51519, 23525, 43819, 29463, 32260,\n",
       "         41946, 60133, 60125,  9091,  9098, 59630,  9432,  1328, 61275,\n",
       "          9668, 10169,  1325, 11349, 58101, 12786, 13320, 13366, 58875,\n",
       "         61562,  8199,  7736,  2763,  2827,  2832, 65133, 64513,  3510,\n",
       "          2030,  4771, 63294,  6685,  6695,  6888,  7048, 66328,  7404,\n",
       "          7520,  7715, 13724, 66957, 65541,   103, 14444, 56493, 56723,\n",
       "         56170, 15160, 67135, 56278, 56792, 15824, 56035, 31562, 31868,\n",
       "         31895, 30852, 39482,  1872, 31281, 45778, 31029, 30916,  5214,\n",
       "         63708, 13884, 39639, 46034, 54453, 47257, 29900,  5788, 30012,\n",
       "         54638, 30538, 46360, 30204, 46313,  5618, 30419, 30523, 45637,\n",
       "         30201, 43188, 39219, 32236, 17044,  3063,  2127, 44374, 44276,\n",
       "         44118, 65094, 43451, 16918, 37147, 15917,  2581, 37864,  2556,\n",
       "         16945, 44688, 17115, 34657,  4325, 32648, 45075,  4292, 63958,\n",
       "         45043, 39079,  3670, 44898, 44863, 34156, 17292, 15876, 34450,\n",
       "          3460, 45552, 29285, 17830,  6819, 23935, 23999,  9656, 24092,\n",
       "         56242, 50774, 23930, 24537, 14985, 53183, 50297, 53254, 66568,\n",
       "         25208, 14755, 29262, 20381, 14614, 20980, 21581, 21594, 41367,\n",
       "         57559, 57669, 51418, 22039, 41469, 66909, 22418, 11542, 23138,\n",
       "         11004, 22200, 50026, 59829, 42192, 29171, 56976, 28990, 62088,\n",
       "         47859, 54174, 28720, 28395, 18063,  7585, 28148, 28138, 48519,\n",
       "         53300, 48555, 40180,   518, 60293,  8963,  1726, 60959, 49228,\n",
       "         53926, 49222, 18256, 66547,  7964, 43496, 48783,  7845, 49126,\n",
       "         42672, 43015, 43491, 42711, 42199, 55303, 44029, 54969, 56062,\n",
       "         53858, 53318, 56774, 52754, 56982, 57223, 58050, 58610, 59307,\n",
       "         50285, 60594, 61584, 49100, 48625, 61970, 56027, 63234, 46059,\n",
       "         45719, 63462, 63894, 45219, 64021, 64429, 65424, 43624, 62078,\n",
       "            48, 28812, 26740, 26867, 12884, 27180, 12599, 11747, 10762,\n",
       "         10450,  9620, 19356,  9089, 29659,  9053, 30533, 30876, 26317,\n",
       "         26225, 13400, 25418, 19625, 19649, 20466, 20937, 17316, 21192,\n",
       "         22528, 31181, 22662, 14492, 14425, 24382, 13985, 24878, 24976,\n",
       "         25191, 14704,  8277, 18138, 40453, 36002, 36654,  4238,  4907,\n",
       "         35407, 37076, 35025,  5712,  1411,  5874, 40019, 40507,  3511,\n",
       "         33915,  1833,  7269,   967, 37719, 40705,  1804,  7357,  8176,\n",
       "          7685, 38608, 38020, 15363, 14643, 55370, 15710, 61057, 17220,\n",
       "         16664, 55253, 14346, 66665, 54895, 66863, 54469, 41709, 17870,\n",
       "         17923,  1054, 18133, 55330, 14325, 57249, 64978,  8526, 60954,\n",
       "         60644, 61712,  8751,  8825, 60555,  8966, 60086,  6444, 59373,\n",
       "         59361,  5799, 10848, 63408, 12619, 57982,  3940, 57767, 57527,\n",
       "         64658, 13809, 13843, 57205, 57088,  2980, 41535, 67310, 33098,\n",
       "         28734, 44273, 50602, 35918, 43845, 50599, 39613, 50286, 27879,\n",
       "         25361, 42301, 47121, 23572, 29932, 44420, 38681, 67183, 32715,\n",
       "         48686, 51781, 49915, 32162, 50080, 21062, 21329, 34480, 46653,\n",
       "         11329, 58314, 27234, 11064, 47267, 58622, 58752,  4491,  9433,\n",
       "          9224, 59728, 29586, 30265, 63243, 31742,  8318, 45439, 45110,\n",
       "         64282, 27137, 28793, 16224, 19003, 53386, 19582,   291, 66981,\n",
       "         17410, 20815, 17311, 55038, 40920, 51765, 16448,  1499, 51573,\n",
       "         15178,  3348, 12957, 49773,  3306, 50179, 39426, 50981, 24239,\n",
       "         14055, 51550, 63896, 34109, 44804, 38993, 65475, 34294,  2487,\n",
       "          2361, 40108,  4620,  3403, 66422, 41274, 36262, 17809, 32212,\n",
       "         53160, 53085, 52889, 22757, 51609, 15875, 51575, 23343, 23393,\n",
       "         56482, 56603, 56845, 13930, 57538, 45015, 13261, 27115, 28030,\n",
       "         30526, 10162, 30163, 53427,  8984, 57621, 31324, 51745, 19109,\n",
       "         28851,  4344,  4278, 57382, 47894,  8342, 26291, 35310, 42748,\n",
       "          9117], dtype=int64),\n",
       "  'feature_absent_idx': array([19123, 30459, 10137, 10139, 17905, 53687, 53688, 44250, 48583,\n",
       "         48581, 59643, 59641, 30460, 17899, 53694, 10153, 48580, 59639,\n",
       "         30446, 59638, 59636, 59635, 44262, 24612, 30442, 10150, 53700,\n",
       "         44248, 10132, 53679, 10105, 44236, 10107, 10108, 48600, 24595,\n",
       "         59678, 59676, 24598, 59673, 48592, 44239, 10119, 59670, 44242,\n",
       "         59668, 17912, 17911, 10125, 59665, 10127, 53684, 10130, 44241,\n",
       "         30438, 30436, 44267, 10203, 59593, 10205, 59592, 59590, 44285,\n",
       "         53718, 30404, 30403, 10212, 59587, 48573, 53719, 10218, 10220,\n",
       "         53726, 44295, 10224, 53730, 30389, 10228, 30387, 10231, 30385,\n",
       "         30398, 24622, 59594, 53712, 24616, 17888, 59618, 53703, 59612,\n",
       "         10177, 30429, 30428, 48574, 53705, 59609, 44272, 24618, 30420,\n",
       "         24619, 10187, 59603, 10189, 10190, 10191, 44277, 53708, 44279,\n",
       "         30414, 24620, 10102, 48603, 17921, 10099, 10004, 44193, 59764,\n",
       "         48633, 53660, 30546, 48630, 30543, 30542, 10015, 59756, 10003,\n",
       "         10017, 10019, 59754, 44198, 53662, 10024, 59749, 44203, 48628,\n",
       "         30535, 30534, 44204, 59755, 30552, 10001, 59767, 30576, 17971,\n",
       "         24550, 24552,  9973, 59783,  9975, 53652, 59780,  9978, 24553,\n",
       "          9980, 59779,  9982, 48641, 59774,  9987,  9988, 44189, 30559,\n",
       "         30558,  9994, 53657, 59771, 17958, 17948, 48564, 17947, 10034,\n",
       "         30506, 17934, 10071, 10073, 44222, 30499, 59714, 17932, 10080,\n",
       "         59710, 10083, 17936, 17928, 10087, 30489, 30488, 24589, 59698,\n",
       "         17924, 24590, 59691, 44230, 10097, 30483, 10085, 30508, 10064,\n",
       "         30510, 53664, 30527, 10038, 24569, 10040, 10041, 10042, 10043,\n",
       "         30524, 59739, 10046, 59738, 59737, 59736, 59734, 44212, 48624,\n",
       "         10055, 44214, 17940, 24576, 30513, 24577, 30511, 59725, 59744,\n",
       "         59786, 59573, 44303, 59435, 44405, 17799, 24689, 30248, 59426,\n",
       "         30247, 30246, 44410, 44411, 53800, 17800, 30241, 24693, 30236,\n",
       "         17792, 59412, 59411, 48514, 17790, 59406, 30232, 44418, 53808,\n",
       "         24690, 17788, 30255, 48517, 30276, 59456, 10383, 59454, 30272,\n",
       "         53783, 59452, 10388, 30269, 10390, 10391, 10408, 10392, 10394,\n",
       "         10395, 24684, 53786, 59444, 53788, 59441, 10402, 53792, 53795,\n",
       "         30257, 59449, 24696, 48513, 59395, 30209, 30208, 53811, 10474,\n",
       "         24699, 59363, 17775, 10478, 30203, 17774, 30200, 53810, 44431,\n",
       "         59358, 59357, 17772, 53814, 44432, 10490, 59349, 59348, 30191,\n",
       "         44438, 44439, 48511, 17779, 10468, 59368, 10441, 10442, 17785,\n",
       "         30224, 59393, 44425, 30222, 59392, 30221, 10451, 59391, 17784,\n",
       "         17783, 59389, 17782, 59387, 59385, 59384, 59383, 30217, 30216,\n",
       "         53809, 48512, 30213, 30212, 44380, 10377, 10376, 59460, 10271,\n",
       "         30352, 44320, 59547, 59544, 10280, 10281, 10282, 30346, 30345,\n",
       "         30344, 59555, 30343, 59537, 10289, 59529, 24652, 30334, 44331,\n",
       "         10299, 10300, 44333, 10304, 17838, 53754, 24643, 10268, 44317,\n",
       "         44305, 10239, 17862, 53735, 10242, 30375, 59570, 30373, 30371,\n",
       "         10249, 10250, 44311, 30367, 30366, 59565, 59564, 10257, 44312,\n",
       "         44313, 59560, 53741, 17856, 48560, 53743, 30358, 44335, 30383,\n",
       "         24656, 10309, 30300, 10346, 59486, 59484, 10349, 44361, 30297,\n",
       "         24669, 59479, 10355, 44363, 10343, 10357, 59473, 24675, 10363,\n",
       "         53777, 10366, 44372, 53780, 10370, 59467, 24678, 44376, 30292,\n",
       "         10342, 44353, 10339, 59519, 44337, 30325, 59515, 53771, 44339,\n",
       "         44340, 53772, 59509, 10321, 24659, 59508, 24660, 44347, 10326,\n",
       "         17828, 30312, 10330, 30311, 48548, 59500, 59499, 44350, 10336,\n",
       "         30306, 10308, 10496, 30577,  9963, 60053, 44014,  9616, 53570,\n",
       "          9618, 18088, 30804,  9623, 60047, 30803, 30801, 30810, 18086,\n",
       "         44023, 60041, 60039, 60038, 53571,  9634, 30797, 30796, 30795,\n",
       "         18084,  9640,  9628,  9641, 18090, 44012, 30834, 44002, 53561,\n",
       "         53562,  9585,  9587,  9589, 44006,  9591, 30826,  9593, 60056,\n",
       "         53565,  9596, 53566, 30823, 18096, 44007, 60065, 24464, 44009,\n",
       "         30816,  9608, 53568, 60073, 44026, 30792, 60031, 48697, 53582,\n",
       "         53584, 30762, 59996, 44047, 59995, 30760, 59993,  9689, 30759,\n",
       "         30768, 59992, 30756, 30755, 53590, 59987, 59986,  9702, 18061,\n",
       "         59984, 53591, 53592,  9709, 18067, 18073, 60006, 24477, 44030,\n",
       "         24469, 24470, 60028, 44031, 24471, 60024, 30786, 30784, 44035,\n",
       "         24472, 60020, 60018, 30780, 48702, 60015, 30778, 18077, 30776,\n",
       "          9666,  9667, 60013, 44038,  9672, 44042, 44001, 53560, 60082,\n",
       "         30837,  9487, 60143, 24438, 60140, 60139, 60138,  9494,  9495,\n",
       "         48727, 43956,  9498, 30907, 30901, 18127, 43961,  9503, 43962,\n",
       "          9505, 18126, 60130, 60129, 53547, 24444, 43966, 30898, 48728,\n",
       "         24436,  9483, 24423,  9453,  9456,  9457,  9458, 60168, 24426,\n",
       "          9461, 30930, 43933, 60164, 18143, 60160,  9467, 30926,  9469,\n",
       "         24431, 18137,  9475, 60154, 30917, 43947, 48731, 48730, 43951,\n",
       "         30889], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 622\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 622\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 622\n",
       "    })}}},\n",
       " 'contains_number': {'feature_present_idx': array([32942, 37010, 32408,  5274, 21268, 43757, 16605,  7396, 57308,\n",
       "         12038, 32396, 62679, 52830, 43098, 57103, 11795, 53037, 30349,\n",
       "         43925,  1651,  1407, 57739, 65065, 12741, 53368, 22914, 10719,\n",
       "         11782, 12629, 49243,  4291, 34762,  7264, 64717,  3301,  5327,\n",
       "          9847, 19975, 57045, 57032, 52151, 20593, 31753, 51126, 17445,\n",
       "         60884, 38327, 10973, 25204, 41460, 17688, 33893, 51534, 51917,\n",
       "         33897, 41345, 38171, 17347,  4783, 21025, 31052, 25867, 25790,\n",
       "         10211, 42929, 31189, 25895, 25707, 23314, 23325, 52505,  4919,\n",
       "         11369, 32239, 50964, 31195, 29764, 49081, 53621, 28451, 58248,\n",
       "         55383,   494, 61569, 35486,  8679, 15080, 47656, 27436, 15204,\n",
       "         29744,  5826,  6683, 19905, 45306, 27441,  8729, 35802, 27584,\n",
       "         58614, 22265, 46748, 67250, 58598, 22329, 46999, 46077, 28103,\n",
       "         58575, 14168, 58511, 61794, 35784, 66952, 66947, 54980, 22557,\n",
       "         45226, 39978, 61048, 27072, 44424, 39257, 48665, 53918, 19961,\n",
       "         48741, 46699, 48482, 35203, 19921, 33259, 59536, 21707, 16128,\n",
       "         21791, 23945, 48056, 48831, 35468, 35402, 48222, 36433,  4175,\n",
       "         44932, 24047, 29240, 56072, 39252,  8584, 55506,  8578,  8056,\n",
       "          8515, 56087, 19800,  8400, 19804, 39231, 55453,  8648, 20044,\n",
       "         39144, 55728, 19901, 56064, 55873, 55702, 39312,  8317, 55787,\n",
       "         38865, 38634, 55580, 39280, 39088, 21606,  7995, 36728, 21469,\n",
       "         57747, 57755, 36649, 57771,  6988, 57773, 36612,  6946,  6922,\n",
       "         36411, 36328, 58041,  6706, 58063, 58087, 36140,  6632,  6618,\n",
       "         58088, 36066,  6495, 35929,  6417,  6416,  6398,  6370, 22238,\n",
       "         21457, 21404,  7204, 36940, 38478, 20371,  7936, 56206, 38348,\n",
       "         38255, 38237, 56511,  7771, 20813, 37668, 37644, 20897, 56770,\n",
       "         56128, 56935, 37522, 55188, 21114, 21243, 57287,  7424, 37268,\n",
       "         57340, 37093, 57412, 57448, 21351,  7317,  7255,  7634, 57198,\n",
       "         18497, 55006, 49208, 49183, 44163, 49075, 49022, 49008, 44213,\n",
       "         44270, 48900, 44351, 48815, 48733, 44383, 48589, 48578, 49221,\n",
       "         49256, 49318, 12548, 49873, 16846, 49755, 43594, 49587, 49559,\n",
       "         49482, 44452, 49465, 16483, 12380, 49447, 43976, 43985, 12499,\n",
       "         44063, 16501, 49899, 13224, 48458, 47407, 15064, 47363, 15047,\n",
       "         45733, 14115, 15002, 45770, 14166, 45928, 14313, 46292, 14330,\n",
       "         46502, 46587, 45729, 13938, 15121, 45605, 13276, 48373, 44906,\n",
       "         15674, 15585, 13574, 48104, 48460, 45155, 47819, 45425, 47792,\n",
       "         15274, 47725, 13837, 47601, 48044, 11928, 43154, 43088, 40838,\n",
       "         53466, 53322, 53223, 18671, 18580, 53154, 18569, 41059, 41091,\n",
       "         58629, 41192, 41217, 18340, 41261, 40812, 53651, 53815, 18893,\n",
       "         54997, 19734, 54960, 39658, 19591, 19525,  9041, 18147, 54589,\n",
       "         40115, 40235,  9299, 40637,  9416, 40660,  9449,  9145, 52200,\n",
       "         52195, 10431, 17328, 42376, 11309, 17312, 42469, 42581, 50745,\n",
       "         17371, 50700, 50428, 50366, 50261, 11568, 17021, 50128, 50090,\n",
       "         50641, 55063, 11187, 42188, 41387, 52029, 17989, 41840, 51604,\n",
       "         51598, 51595, 11171, 51535, 17674, 17664, 51184, 10955, 11050,\n",
       "         42143, 51119, 41958, 58662, 14551, 58725, 63303, 25277, 32066,\n",
       "         63199, 32075, 32087, 63306, 32176,  3011, 32183, 62795, 62726,\n",
       "          6233, 24888, 25032, 24866, 25280, 63358,  2386, 63796,  2411,\n",
       "         31422, 31428, 31431, 63340,  2545, 63592,  2589, 25403, 31819,\n",
       "          2704, 32020, 63628, 24859, 62567,  3304, 24281, 32957, 24237,\n",
       "         24202, 33075, 61671,  3971, 61669, 24168,  4190, 23994, 23977,\n",
       "         23852, 23832, 61616,  3969,  3872, 32868,  3342,  3347, 32410,\n",
       "         32504,  3456, 32565, 24554, 62044, 24515,  3682, 24514, 61894,\n",
       "         24402, 61821, 24383, 25668,  4309, 64124,  2180, 28819, 27475,\n",
       "         28969, 27420,   754, 27350, 66587,   786, 66132, 27276, 29186,\n",
       "         65974, 65970, 65952, 66201, 65915, 66628, 28427, 28039, 67244,\n",
       "         27788, 67163, 27741, 66992, 66642, 66966,   207,   250, 66859,\n",
       "           319, 28387,   419, 28282, 27110, 27098, 65575, 30364, 64595,\n",
       "          1792, 64591, 30617, 30676, 26497, 30902, 64395, 31004, 25936,\n",
       "          2120,  2129, 25886,  1942, 26505, 30287, 64829, 27005, 29454,\n",
       "         26895, 65145, 65136,  1384, 29912, 30003, 65022, 26625, 26608,\n",
       "         64939, 64880,  1528, 30096, 64225, 33544, 32352, 22936, 59175,\n",
       "         34163, 34379,  5156, 34157, 34944,  5159,  5140,  5537, 60717,\n",
       "         34396, 59144, 34537, 60279, 59719, 59070, 34877, 23414, 23253,\n",
       "          5069, 59401,  5748, 60701, 22544, 60728, 23280, 60738, 60792,\n",
       "          5054, 60818, 35473,  5056, 59306,  5858, 60858,  5893, 35215,\n",
       "          5263, 34839, 59686, 22637,  4523, 58917, 22317, 61076, 61059,\n",
       "         33907,  6126,  6031, 22982, 22256,  5441, 22303, 60105, 23036,\n",
       "         34635,  6215, 61184, 23680, 35491, 59069, 23668, 34796, 35243,\n",
       "         26620, 43145, 21666, 16276, 44199, 21677, 22648, 25944, 36740,\n",
       "         43083, 36896, 21709, 29770, 31048, 36213, 16184, 16969, 22685,\n",
       "         16684, 35162, 16630, 26105, 30611, 36718, 21527, 43554, 34829,\n",
       "         26219, 16829, 16505, 43864, 30522, 30914, 35084, 43318, 26558,\n",
       "         22868, 30228, 30181, 44043, 30176, 30124, 16307, 22712, 36429,\n",
       "         16906, 26607, 26021, 34812, 20012, 35430, 22203, 22367, 22452,\n",
       "         28685, 35853, 27493, 45546, 28321, 35949, 15196, 22462, 22475,\n",
       "         35974, 29030, 36099, 45418, 22016, 21949, 45754, 45757, 27844,\n",
       "         27794, 14621, 14625, 46403, 46300, 35691, 35575, 28046, 27767,\n",
       "         14782, 14835, 14926, 45775, 35754, 14957, 46084, 29733, 27343,\n",
       "         21924, 44541, 27150, 15918, 44520, 27106, 27092, 15974, 44576,\n",
       "         43018, 16041, 27023, 44396, 27002, 29429, 16111, 26966, 29418,\n",
       "         15474, 29338, 15833, 45251, 27313, 21915, 21885, 29126, 22499,\n",
       "         27232, 44667, 15604, 27212, 21845, 45055, 44950, 36129, 15739,\n",
       "         44747, 45069, 29366, 42627, 17071, 32637, 19065, 40322, 40292,\n",
       "         19169, 23438, 19193, 38460, 34072, 40230, 40174, 40150, 19280,\n",
       "         24512, 40099, 32682, 19242, 40097, 38385, 24583, 18682, 18697,\n",
       "         40914, 24791, 34171, 40850, 40844, 40702, 32528, 32551, 18769,\n",
       "         24667, 18859, 40747, 32581, 24628, 18753, 40917, 40096, 24434,\n",
       "         38686, 38785, 24170, 39015, 33133, 33145, 24036, 19869, 33695,\n",
       "         23971, 33483, 33495, 33519, 23857, 23779, 33549, 33654, 40059,\n",
       "         20225, 20276, 34039, 19484, 24405, 20306, 34012, 39858, 39824,\n",
       "         39334, 39767, 38584, 24324, 32815, 38625, 39488, 33819, 23634,\n",
       "         19686, 22953, 23381, 40940, 31432, 17357, 31516, 25486, 31659,\n",
       "         34455, 31776, 25546, 17543, 42107, 42096, 17624, 31949, 32007,\n",
       "         25317, 32025, 23156, 41938, 34555, 42506, 17073, 34724, 42941,\n",
       "         25784, 25755, 42874, 42862, 34575, 42809, 31345, 42733, 25605,\n",
       "         23799, 34642, 25598, 42539, 25660, 34259, 41928, 17749, 32271,\n",
       "         32327, 41219, 24920, 32344, 18385, 18443, 24985, 20861, 37817,\n",
       "         37831, 41014, 24833, 24831, 40966, 18654, 18475, 41909, 18144,\n",
       "         34275, 37404, 23204, 41841, 32052, 21061, 41713, 41525, 18142,\n",
       "         41512, 25261, 37493, 41422, 34360, 25079, 41348, 37531, 41473,\n",
       "         13759, 27949,  6613, 56014, 63336,  8261, 63400, 55946,  8306,\n",
       "         55849, 63509,  8540, 55482,  8592, 55472,  2628, 55409, 55350,\n",
       "         55275,  2568,  8760, 55238, 63654, 63669,  8202, 63334,  8151,\n",
       "          2883, 57074,  7580, 62762, 56962, 62766, 62769, 56664,  3031,\n",
       "          7740, 62803, 54964, 56602,  7796, 62835, 56479,  7863, 56392,\n",
       "         56240, 63088, 56203, 56197, 56177,  7783, 62740,  2455, 63747,\n",
       "         64296,  9592,  2020,  9758,  1941,  9794, 53275, 53273,  9867,\n",
       "         53213,  9940, 53174, 53077, 53066, 52936, 10078, 52921, 64493,\n",
       "         10195, 10210, 52732, 53915, 53957, 53972,  9403, 54788, 54716,\n",
       "          9023, 63749, 63883, 64044, 64132, 64214, 54425, 61040, 63718,\n",
       "          2230,  9229,  9251, 54136,  2185, 54095, 64283, 53999,  2148,\n",
       "          9387], dtype=int64),\n",
       "  'feature_absent_idx': array([25272, 31258, 11164, 43418, 43416, 60018, 11176, 11177, 60020,\n",
       "         43397, 43395, 31272, 20452, 43393, 31276, 43386, 20439, 60024,\n",
       "         43380, 11191, 31277, 11194, 31279, 11196, 43372, 31274, 31257,\n",
       "         20454, 11159, 11123, 11124, 65527, 43476, 43475, 43472, 43470,\n",
       "         20465, 60006, 43456, 43454, 11139, 65524, 11142, 31250, 31251,\n",
       "         60013, 31254, 65522, 11150, 43437, 20456, 43435, 43433, 60015,\n",
       "         43370, 43368, 11202, 31282, 20423, 43311, 62073, 43305, 11244,\n",
       "         20420, 20419, 20418, 11248, 43297, 43296, 31301, 31302, 43288,\n",
       "         11254, 62072, 11259, 65514, 20412, 20411, 20409, 43278, 43276,\n",
       "         60038, 43273, 60031, 31243, 60028, 43333, 43364, 43362, 43360,\n",
       "         11211, 65520, 43357, 11214, 43355, 31289, 11217, 43353, 11219,\n",
       "         11220, 43351, 31291, 11223, 43345, 43344, 11226, 20430, 43341,\n",
       "         62075, 11230, 31293, 11233, 20426, 43481, 31242, 11119, 20518,\n",
       "         43634, 11010, 31161, 43632, 43631, 43630, 43629, 43627, 11018,\n",
       "         63918, 59992, 43623, 43621, 43617, 59993, 43611, 31172, 20508,\n",
       "         11036, 11037, 43601, 31177, 11042, 31178, 20519, 11044, 11006,\n",
       "         43644, 43688, 63916, 59984, 20533, 10978, 43682, 31148, 10982,\n",
       "         43678, 20530, 10986, 10987, 31151, 65554, 10991, 43672, 20525,\n",
       "         43669, 43668, 43666, 59986, 59987, 62101, 31157, 43647, 20520,\n",
       "         60039, 11045, 20501, 43522, 43521, 43515, 31224, 11094, 20482,\n",
       "         31228, 31229, 31230, 20478, 43499, 43498, 43497, 65533, 20475,\n",
       "         20474, 65530, 11110, 20472, 20471, 65529, 20469, 11116, 31240,\n",
       "         43486, 31217, 59995, 43531, 31211, 59996, 11052, 11053, 11055,\n",
       "         43578, 43576, 11059, 43575, 31194, 43569, 43567, 11065, 65540,\n",
       "         43566, 43561, 11069, 43560, 11071, 43556, 31201, 43551, 43542,\n",
       "         11080, 31210, 20488, 43533, 31312, 11274, 11276, 43012, 11482,\n",
       "         43009, 11484, 31435, 11486, 31438, 60083, 42991, 42990, 11493,\n",
       "         42987, 65488, 20321, 11498, 11501, 11502, 31445, 65487, 20317,\n",
       "         20316, 42973, 42972, 42971, 11513, 60082, 42968, 20327, 31429,\n",
       "         43061, 11447, 43055, 43053, 43051, 31414, 43048, 43047, 11455,\n",
       "         60073, 43044, 43041, 11459, 31416, 31417, 11462, 43036, 31418,\n",
       "         11465, 43034, 43029, 20331, 11471, 31426, 43024, 11476, 43066,\n",
       "         20315, 20313, 11557, 65482, 11559, 31469, 63948, 42911, 20294,\n",
       "         11565, 11567, 60100, 20290, 11573, 11575, 42897, 60104, 42891,\n",
       "         42890, 60107, 42888, 31477, 42885, 11584, 42883, 11586, 42881,\n",
       "         31467, 31453, 42919, 20299, 31455, 11520, 42960, 31456, 42958,\n",
       "         63944, 42953, 11530, 60093, 11534, 11535, 11538, 11539, 20302,\n",
       "         42933, 42932, 42931, 20301, 42928, 11546, 20300, 65483, 11549,\n",
       "         42925, 42924, 42920, 43691, 43069, 31399, 43203, 11321, 43201,\n",
       "         43198, 43197, 63931, 43192, 62056, 11331, 60053, 31355, 65505,\n",
       "         43177, 65504, 62055, 11340, 63933, 31360, 43164, 43161, 11350,\n",
       "         43159, 11352, 11353, 11354, 43204, 11355, 43205, 11314, 20403,\n",
       "         60041, 11281, 62068, 43248, 11285, 43244, 11287, 43243, 43241,\n",
       "         43239, 43237, 43235, 65508, 60047, 31328, 20396, 43226, 11303,\n",
       "         43222, 11306, 11307, 43220, 62058, 31346, 43206, 11437, 65503,\n",
       "         20374, 60065, 31386, 63937, 43097, 43095, 43094, 11409, 11410,\n",
       "         65495, 31389, 11417, 20352, 11419, 43081, 11422, 11423, 20350,\n",
       "         43076, 11427, 11428, 11429, 11430, 11432, 43073, 11434, 43103,\n",
       "         43157, 11400, 11397, 31367, 20372, 11361, 43149, 11363, 60056,\n",
       "         11366, 43144, 43143, 11371, 43139, 43138, 43133, 11378, 65500,\n",
       "         43132, 31379, 43118, 43117, 11390, 43116, 11392, 43115, 43114,\n",
       "         43112, 43107, 42880, 43692, 31146, 10575, 10576, 44132, 10578,\n",
       "         10579, 59899, 30941, 44127, 44125, 10584, 44124, 44133, 44123,\n",
       "         10589, 59901, 59903, 44112, 44111, 59904, 44108, 44105, 44100,\n",
       "         30949, 10602, 44119, 63891, 30939, 44143, 20701, 30898, 44189,\n",
       "         30901, 30907, 20694, 10540, 59892, 10544, 30917, 65622, 10547,\n",
       "         10549, 44171, 30926, 44160, 20685, 44158, 10558, 44156, 65618,\n",
       "         30930, 44151, 44148, 10565, 44097, 44095, 30953, 44091, 10645,\n",
       "         10646, 62131, 10649, 20650, 59917, 30976, 10654, 30979, 44047,\n",
       "         44042, 10658, 10659, 65609, 62129, 44038, 20646, 10665, 10666,\n",
       "         44035, 44031, 44030, 59920, 59921, 10673, 62132, 44193, 44058,\n",
       "         10641, 30955, 30957, 10611, 20664, 20663, 10618, 59909, 62133,\n",
       "         20659, 59911, 44069, 10626, 30966, 59914, 44065, 10630, 59915,\n",
       "         10632, 10633, 10634, 30967, 30968, 10638, 44059, 65612, 10642,\n",
       "         10527, 30889, 44198, 44340, 44339, 59870, 44337, 44335, 44333,\n",
       "         44331, 30823, 30826, 44320, 44317, 44313, 44312, 44311, 44305,\n",
       "         44303, 10441, 10442, 20746, 30834, 20744, 44295, 20743, 30837,\n",
       "         44285, 59868, 10451, 59866, 30816, 44380, 10376, 10377, 20773,\n",
       "         44376, 30804, 10383, 44372, 59864, 62170, 10388, 30810, 10390,\n",
       "         10391, 10392, 10394, 10395, 44363, 20768, 44361, 20767, 44353,\n",
       "         10402, 44350, 44347, 10408, 44026, 20739, 44279, 44230, 20720,\n",
       "         30872, 10496, 30874, 44222, 30875, 10502, 10503, 62154, 59885,\n",
       "         62153, 20712, 44214, 44212, 10511, 65626, 10514, 30881, 62152,\n",
       "         10518, 20707, 44204, 44203, 10522, 30871, 30840, 10490, 30865,\n",
       "         30843, 44277, 30844, 44272, 44267, 63884, 65635, 44262, 30849,\n",
       "         30851, 10468, 59877, 20731, 20729, 10474, 62158, 65631, 44250,\n",
       "         10478, 44248, 30861, 44242, 44241, 44239, 59883, 44236, 30983,\n",
       "         44023, 10677, 59960, 62111, 31092, 10874, 31101, 43803, 43798,\n",
       "         10879, 62108, 31103, 10882, 10883, 43794, 43791, 31106, 31109,\n",
       "         10889, 43784, 62107, 43780, 10893, 10894, 59963, 31112, 59964,\n",
       "         65579, 10900, 20575, 10866, 31069, 20584, 10836, 31076, 10838,\n",
       "         10839, 43839, 65583, 10843, 31078, 10846, 65582, 65581, 43833,\n",
       "         10850, 43831, 10852, 59956, 43828, 43827, 43825, 20577, 31090,\n",
       "         59958, 59959, 43816, 59953, 31117, 43767, 43732, 43728, 10938,\n",
       "         31134, 10943, 10947, 31140, 43715, 20540, 62102, 43711, 20538,\n",
       "         65559, 43707, 10958, 43706, 10960, 43705, 43703, 10963, 65558,\n",
       "         31145, 43701, 10967, 43700, 43733, 43768, 31129, 10931, 65572,\n",
       "         10905, 20559, 43762, 43761, 43759, 10910, 10911, 43758, 10913,\n",
       "         31120, 43751, 62104, 31127, 20552, 10921, 10922, 43742, 20551,\n",
       "         43740, 59971, 43738, 10928, 31128, 43735, 10932, 43694, 43852,\n",
       "         43860, 43986, 10716, 10717, 10720, 31007, 65597, 10723, 63898,\n",
       "         43970, 43966, 10730, 31013, 43962, 10734, 43961, 10736, 10737,\n",
       "         43956, 10740, 20622, 10742, 20620, 43951, 10746, 31020, 43987,\n",
       "         43947, 31005, 10711, 59922, 65604, 10680, 20641, 20639, 44014,\n",
       "         10686, 10687, 44012, 44009, 65602, 44007, 44006, 44002, 44001,\n",
       "         10697, 20635, 10699, 30997, 43996, 65598, 10706, 10708, 43993,\n",
       "         10710, 43992, 43856, 59930, 59934, 65589, 10790, 43898, 59944,\n",
       "         43895, 20601, 10799, 43888, 10801, 59945, 10803, 31051, 43882,\n",
       "         10806, 43879, 20599, 59950, 20597, 31055, 31059, 31060, 65586,\n",
       "         65585, 10821, 10822, 10787, 59933, 10785, 43904, 59935, 59936,\n",
       "         31021, 10758, 43933, 31028, 62121, 10763, 43928, 10765, 31034,\n",
       "         10767, 63903, 43921, 43918, 65591, 10773, 20608, 31039, 65590,\n",
       "         20606, 31040, 43908, 59942, 10782, 59943, 30803, 11589, 42877,\n",
       "         31904, 41856, 19972, 41853, 41851, 41850, 41848, 41847, 31905,\n",
       "         41844, 41843, 12374, 31907, 12391, 31910, 41832, 41828, 61957,\n",
       "         31918, 60287, 41818, 41817, 12404, 65326, 12390, 12372, 31902,\n",
       "         31898, 60275, 61963, 41899, 41898, 12344, 41897, 12346, 41896,\n",
       "         31882, 65335, 60280, 41887, 41884, 31886, 12356, 19983, 31888,\n",
       "         31889, 41867, 12362, 12363, 12365, 12367, 12368, 31897, 41807,\n",
       "         65324, 12411, 12412, 12454, 41744, 41742, 41741, 12459, 12460,\n",
       "         41738, 19933, 41731, 41729, 31973, 12468, 41722, 19930, 41719,\n",
       "         41718], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_accompanier': {'feature_present_idx': array([48840, 40407, 25521, 63754,  2544, 62778, 48572, 23131, 25243,\n",
       "          1586,  6768, 28633, 30987, 31771, 33192, 57868, 67295, 21997,\n",
       "         62683, 20523, 20009, 19634, 17498, 17099, 15935, 15229, 12977,\n",
       "         23966, 66921, 35941, 34751, 57026, 55358, 54726, 58587, 53270,\n",
       "         51588, 48059, 47488, 47014, 46051, 60560, 42923, 42278, 39536,\n",
       "         38920, 61828, 61855, 37272, 37019, 35989, 64359, 62309, 64680,\n",
       "         28123,  5769,  9138,  4377,  6001,  2688,  5110,  6851,  2368,\n",
       "          7372,  3934,  1001,  7831,  4054, 38164, 35174, 61929, 35671,\n",
       "         62017, 38102,  4457, 12067, 33148,  6551,  6727, 30578, 29704,\n",
       "         29688, 28433, 62735, 26650, 25465, 11835, 38553, 39745, 39278,\n",
       "           486, 55588, 55258,  1472, 58819, 53077, 52109, 59340, 51305,\n",
       "         60010, 60017, 49908, 38635, 49613,  2007, 48693, 60221, 48369,\n",
       "         48142,  2548,  3412, 45789, 45328, 43409, 43257, 24850, 49371,\n",
       "         24427, 65549, 17329, 21375, 21090, 20204,  9240, 19010, 18724,\n",
       "         18687, 17315, 17142, 64708, 15510, 10583, 15206, 11286, 64218,\n",
       "         11415, 11671, 12125, 12084, 21510, 21737, 58073,  8512, 23792,\n",
       "         44680, 58861, 43319, 17239, 52809,  3838, 12922, 28146, 41414,\n",
       "         53343, 53819, 39443, 63776, 39146, 38979, 15384, 18070, 40629,\n",
       "         26304, 26247,  3282, 23382, 15187, 14755, 16204, 64007, 13981,\n",
       "         50881, 59801, 47718, 47490, 64215, 16787, 46710, 60299, 46456,\n",
       "         63240, 46080, 66512, 54982, 63736, 20076, 56211, 56268, 34996,\n",
       "         31233, 65007, 56508, 27189, 18250, 62569, 31868, 33457,  5827,\n",
       "         31880, 56549, 34520, 27288, 27750, 35601, 18554, 37848, 12382,\n",
       "         55262, 29108, 55404, 30928, 29518,  7354,  5188, 35680, 21278,\n",
       "         18976, 32615, 57674, 57756, 54969, 58387,  8176, 52264, 59307,\n",
       "         58420, 56003, 53114,  1778, 23433, 24743, 24511, 54601, 12188,\n",
       "          1834, 54620, 45219, 10037, 18241, 38417, 23012,  4505,  4511,\n",
       "         26754, 18875, 35558, 19279, 62045, 22218,  5583, 33274, 64946,\n",
       "         32192,  8615, 29625, 18214, 65574, 39304, 61702, 48590, 48317,\n",
       "         16312,  2454, 16413, 46701, 46254, 46156, 26114, 63871, 63811,\n",
       "         43023, 62815,  8483, 61451,  9617,  4066, 43873, 63518, 60783,\n",
       "         34629, 27779, 34647, 25363,  8637, 40377,  9955, 20481,  8626,\n",
       "         17236, 18050, 51090, 51648, 52285, 16254, 52630, 54207, 50480,\n",
       "          5554, 12582, 63493, 13075, 63103, 26320, 27247, 35557, 35148,\n",
       "         12963, 37401, 38551, 39461, 42697, 65648, 46520, 48626, 59238,\n",
       "         54166, 34264, 12781,  4280,  1169, 56357, 21734, 56701, 50837,\n",
       "         24325, 36744, 45964, 16978, 33339,   106], dtype=int64),\n",
       "  'feature_absent_idx': array([50750, 48510, 17828, 44151, 10097, 59603, 10099, 44156, 10102,\n",
       "         44158, 30325, 10105, 48511, 24518, 10108, 24520, 59594, 44160,\n",
       "         59593, 59592, 59590, 53652, 59587, 48502, 10119, 10107, 48498,\n",
       "         59609, 48512, 10064, 30352, 59636, 59635, 17838, 10071, 53641,\n",
       "         10073, 53643, 30346, 30345, 30334, 30344, 48514, 10080, 44143,\n",
       "         53645, 10083, 59618, 10085, 48513, 10087, 59612, 44148, 30343,\n",
       "         24529, 30312, 10125, 59560, 53662, 53664, 59555, 24546, 17800,\n",
       "         44198, 17799, 44203, 59547, 59544, 44193, 30276, 24547, 30272,\n",
       "         59537, 10177, 24550, 30269, 59529, 24552, 17792, 44212, 44214,\n",
       "         44204, 53660, 10153, 59564, 30311, 10127, 44171, 24531, 10130,\n",
       "         10132, 24534, 30306, 24535, 24536, 10137, 59573, 10139, 30300,\n",
       "         48494, 59570, 30297, 24539, 53657, 24540, 59565, 30292, 44189,\n",
       "         10150, 24542, 53639, 59638, 59639, 53638,  9964, 53613, 30420,\n",
       "         53617, 53619,  9973, 59714,  9975, 30414, 59710,  9978,  9963,\n",
       "         24488, 17862,  9982, 44091, 24491, 44095,  9987,  9988, 44097,\n",
       "         30404, 30403,  9994,  9980, 24477, 30428, 30429, 44058, 59744,\n",
       "         44059, 24470, 24471, 30446, 53600, 53601, 53602, 59739, 59738,\n",
       "         59737,  9942, 30442, 59736, 24472, 59734, 44065, 30438, 44069,\n",
       "         30436, 48548,  9953, 53606, 59725, 59698, 24553, 44100, 17856,\n",
       "         44125, 10034, 30375, 30373, 10038, 44127, 10040, 10041, 10042,\n",
       "         10043, 30371, 44124, 24502, 30367, 30366, 44132, 53636, 24506,\n",
       "         44133, 10055, 48517, 30358, 59643, 59641, 10046, 59665, 44123,\n",
       "         44119, 30398, 10001, 44105, 10003, 10004, 24496, 44108, 53626,\n",
       "         44111, 44112, 30389, 59678, 53627, 30387, 10015, 59676, 10017,\n",
       "         24498, 10019, 59673, 30385, 59670, 10024, 59668, 30383, 59691,\n",
       "         24469, 10187, 10189, 10349, 44285, 59392, 59391, 30145, 59389,\n",
       "         10355, 30144, 10357, 30143, 59387, 59393, 24590, 59384, 10363,\n",
       "         30141, 59383, 10366, 17731, 48444, 10370, 53718, 53719, 30133,\n",
       "         59385, 24595, 59395, 30147, 30168, 53705, 44272, 10321, 17743,\n",
       "         17742, 53708, 59412, 10326, 59411, 44277, 10346, 17740, 30157,\n",
       "         59406, 44279, 10336, 17737, 10339, 17735, 53712, 10342, 10343,\n",
       "         24589, 10330, 59368, 10376, 10377, 48433, 44311, 59330, 48431,\n",
       "         59326, 30103, 44312, 59323, 53735, 44313, 59320, 53730, 17710,\n",
       "         17708, 44317, 24612, 30087, 30086, 44320, 48424, 53741, 53743,\n",
       "         10441, 10442, 30097, 59339, 10408, 44305, 48441, 30130, 59363,\n",
       "         44295, 10383, 59358, 24598, 59357, 30126, 10388, 10390, 10391,\n",
       "         10392, 17721, 10394, 10395, 59349, 59348], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 330\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 330\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 330\n",
       "    })}}},\n",
       " 'contains_age': {'feature_present_idx': array([27711, 60720, 23624, 44495, 62843, 12259,  6693, 62067, 58291,\n",
       "         11140,  2920, 15258, 34068, 33285, 39334, 25944, 13033, 42019,\n",
       "         59109, 42539, 55472, 39432,  9402, 55238, 11993, 57141, 50984,\n",
       "         60863,  5885, 67114,  5472, 65133,  3855, 36664, 29818, 64201,\n",
       "         49977,  2455, 21223, 22677, 23329, 43451, 23083, 42768, 44374,\n",
       "         39636, 41995, 25476, 40155, 40003, 45421, 39315, 28187, 38398,\n",
       "         36121, 29261, 30088, 35126, 23549, 45936, 67229, 19114,   186,\n",
       "         64532,  2555, 63230, 62772, 61736,  7970,  8528, 59380,  9441,\n",
       "          9480, 59203, 19312, 56033, 14217, 32285, 46244, 15714, 16047,\n",
       "         16409, 31879, 18720, 50155, 14345, 32947, 66287, 65616, 33626,\n",
       "         65175, 64706, 45019, 41734, 63783, 48279, 50511, 50780, 51390,\n",
       "         52745, 55546, 44631, 57862,     8, 31688,  5540, 20856, 20494,\n",
       "         20136, 19625, 26137, 26568,  7661, 10104,  7568, 11477, 17824,\n",
       "         29082,   131, 31500, 10393, 31033, 44491, 50937, 56627, 58761,\n",
       "         17206, 45670,  8938, 19325, 45206, 18189, 15736, 28820,   918,\n",
       "          1796, 13497,  2271, 34390, 27236,  2943, 41788,  4412, 23493,\n",
       "         62670, 26157,   128, 55784, 55785, 66752, 12621,  7456, 57506,\n",
       "          2737, 63989, 65956, 61630, 16772, 43764, 22787, 50346, 28145,\n",
       "         52419, 25473, 47047, 16890, 31873, 21993, 22011,  3978, 39177,\n",
       "         37407, 34684, 33573, 23150,  9586, 31504, 18043, 55868, 55347,\n",
       "         45759, 54489, 33776, 52715, 30595, 28837, 55440, 14186, 52787,\n",
       "          3536, 16541, 43065, 11134, 47660, 16421, 46506, 16502, 25048,\n",
       "          1533, 26565], dtype=int64),\n",
       "  'feature_absent_idx': array([19040, 30297, 17800, 10083, 59603, 10085, 17799, 10087, 24496,\n",
       "         30292, 53645, 44143, 10080, 24498, 10097, 59593, 10099, 59592,\n",
       "         59590, 10102, 44148, 10105, 59587, 10107, 10108, 59594, 17792,\n",
       "         59609, 53643, 30325, 24491, 59636, 44119, 10055, 59635, 53636,\n",
       "         53638, 44123, 44124, 44125, 30300, 53639, 10064, 30311, 44127,\n",
       "         53641, 59618, 30306, 10071, 44132, 10073, 59612, 44133, 30312,\n",
       "         44151, 17790, 44156, 48478, 30248, 30247, 10150, 30246, 59555,\n",
       "         10153, 17775, 44189, 17774, 30241, 17779, 48477, 59544, 17772,\n",
       "         44193, 30236, 53657, 17769, 59537, 48475, 30232, 59529, 48471,\n",
       "         59547, 59560, 30255, 30257, 30276, 44158, 24502, 44160, 30272,\n",
       "         10119, 17788, 30269, 17785, 10125, 59573, 10127, 17784, 17783,\n",
       "         10130, 44171, 10132, 59570, 17782, 53652, 24506, 10137, 59565,\n",
       "         10139, 59564, 59638, 59639, 10046, 24488,  9953, 30389, 48513,\n",
       "         30387, 53617, 30385, 53619, 59714, 30383, 59710,  9963, 44059,\n",
       "          9964, 44069, 17838, 48512, 30375, 30373,  9973, 30371,  9975,\n",
       "         59698,  9978,  9980, 44065, 48514, 44058, 53613, 59749,  9918,\n",
       "         44035, 53600, 44038, 30414, 53601, 59744, 17856, 44042, 53602,\n",
       "         59739, 44047, 59738, 59737, 59736, 30404, 59734, 30403, 53606,\n",
       "         24448,  9942, 30398, 48517, 59725, 30367, 53660,  9982, 30366,\n",
       "         10017, 30345, 10019, 30344, 30343, 44097, 24477, 10024, 44100,\n",
       "         48498, 44105, 59665, 30334, 10034, 44108, 44111, 44112, 10038,\n",
       "         59643, 10040, 10041, 10042, 10043, 59641, 48494, 10015, 30346,\n",
       "         44095, 24464], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 200\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 200\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 200\n",
       "    })}}},\n",
       " 'contains_beneficiary': {'feature_present_idx': array([   75, 41159, 22656,  2869, 32544, 23123, 52985, 30777, 52704,\n",
       "         42822, 38517, 41080,  4458, 50259, 50011, 49653, 12458, 28811,\n",
       "         47624, 26363, 47010, 46959, 27384, 50620, 56080,  2489, 20631,\n",
       "           135, 67113,  9555, 14355, 14351, 17261, 64303, 14303, 37229,\n",
       "         62882,  2077, 33635, 61356, 57700,  8962, 20062, 20034, 11002,\n",
       "         14070, 40396, 45428, 18071, 39908, 28894, 32769, 35712, 28756,\n",
       "         28356, 32128, 29732, 24990, 26904, 16611, 17385, 17460, 17482,\n",
       "         17687, 18827, 18896, 19542, 27479, 20554, 21676, 22968, 24008,\n",
       "         24172, 24787, 25025, 26184, 26278, 21174, 37607, 41651, 38533,\n",
       "         53864, 54765, 55906, 56133, 56164, 56680, 57030, 57181, 57941,\n",
       "         58226, 58399, 58510, 58623, 59107, 62677, 63406, 63859, 65009,\n",
       "         65981, 66725, 67105, 53766, 53062, 53046, 52934, 38683, 38740,\n",
       "         39946, 40831, 41570, 16253, 42383, 42860, 43541, 44126, 38138,\n",
       "         44225, 46561, 46726, 46974, 47496, 47679, 48246, 49840, 50684,\n",
       "         52359, 52683, 44787, 15122, 67346,  6478,  2967, 13640,  9888,\n",
       "          4030,  1322,  1109,  9257,  3830,  9195,  1461, 11268, 13341,\n",
       "         11479,  6399, 12392,   664,  1539, 11460, 29156, 35728, 35283,\n",
       "         57692, 54026, 33901, 33858, 54609, 33161, 10856, 32593, 55028,\n",
       "         12295, 27093, 32489, 11170, 27716, 28183, 46665, 11231, 30275,\n",
       "         28625, 56672, 32663, 31524,  3946, 37152,  5093, 41842, 42113,\n",
       "         42207, 49200, 42756, 14932, 42998, 44004, 44170, 44821, 44985,\n",
       "         45182, 45344, 43979, 53380,  4703, 40821,  3886, 37995, 25420,\n",
       "         51883, 51776,  9402,  4461, 38796, 51568, 39259, 39432, 50950,\n",
       "         39776,  4433, 38878,  1557, 41285, 65072, 58539, 21630, 66375,\n",
       "         23049, 62388, 22922, 66252, 12926, 58805, 21935, 65928, 14763,\n",
       "         13304, 22457,  1360, 22268, 21899, 62003, 17956, 21515, 60476,\n",
       "         12779, 60097, 15369, 18775, 16825, 18362, 66578,  9468, 61887,\n",
       "         50653, 39196,   756, 60684, 52808, 13542,  9399, 38777, 18466,\n",
       "         52221, 18433, 62183, 38639, 38205, 12589,   685, 45560, 67142,\n",
       "          6374,   225, 45035,  6201, 15649,   672, 47037, 47219,  5339,\n",
       "          5303, 15753, 41089, 66493, 43555, 47914, 43513, 43462, 43317,\n",
       "         42878, 48422, 42408, 48662,   675, 41672,  8696, 16482, 47910,\n",
       "         57958, 53183, 31450, 13027, 13123, 12788, 27112, 32099, 12034,\n",
       "         11936, 12844, 27899, 31972, 54990, 36364,  2445,  2232, 31191,\n",
       "         31018, 28403, 13104, 56644, 30350, 30227, 22929,  1680, 32763,\n",
       "         12098, 26631, 53686,  2825, 25727, 53932, 35480, 12518, 57451,\n",
       "         21098, 34951, 34909, 60007, 21099, 34832, 10691, 54854, 57190,\n",
       "         21382, 26358, 13007,  1555, 34777, 54167,  1554, 56999, 47457,\n",
       "          1627,  5701, 56861,  1619, 57166, 60162, 48607, 53226, 53114,\n",
       "         61155,  1324, 52051, 51828, 54320, 60061, 51635, 54965, 62601,\n",
       "         62652, 63239, 59359, 64386, 55215, 64581, 64701, 55729, 50037,\n",
       "         65021,  5142, 56287, 48068, 55840, 14924, 16157,  9430,  9578,\n",
       "         38506, 38481, 38216, 37945, 15965, 10178, 36388, 16063, 19838,\n",
       "         34544, 33262, 16334, 32097, 32059, 16591, 31506, 46398, 30134,\n",
       "         17210, 14341, 27727, 24961, 22727, 22680, 17507, 21546, 18314,\n",
       "         15841, 15725, 19151, 41573, 42291,  8452, 15561, 41201,  6573,\n",
       "         15145, 44963, 45538, 39655, 43917,  9263, 40804,   871, 47114,\n",
       "         64185, 44584, 56894, 11783,  7847, 26264,  5549, 64589, 16683,\n",
       "         57388, 15710, 25639, 13385, 13351, 17923, 45011, 14141, 24854,\n",
       "         26232, 58353, 58001, 14278, 57952, 25105, 44219, 25520,  6942,\n",
       "         14643,  8052, 31329, 66017, 15979, 49838,  3181,  8825, 37494,\n",
       "          3832, 10060, 52724, 66428, 52564,  8833,  8834, 38498,  4460,\n",
       "         53293, 56109, 36251,  8549, 51078, 42898, 11103, 66830, 36060,\n",
       "          2586, 33539, 33759, 34438, 65427, 10546, 54722, 32740, 14235,\n",
       "         64094, 16297, 62484, 64556, 15178, 17294, 45684, 20867,  8318,\n",
       "          5189,  8433, 50993, 38815,  3397, 36806, 36709, 53509, 35875,\n",
       "         54918, 67226, 31762, 30831, 30439,  1977, 24428, 22009,  1702,\n",
       "         25050, 57400,  1935, 57067, 28145, 26979, 34781,   969, 13416,\n",
       "         23425, 38046, 22169, 39230, 56198, 13713, 13642, 46878, 13268,\n",
       "         11896], dtype=int64),\n",
       "  'feature_absent_idx': array([59089, 12769, 12770, 12771, 28378, 12773, 45638, 45639, 12777,\n",
       "         57599, 28374, 12782, 57596, 57594, 12768, 57591, 28370, 45643,\n",
       "         28361, 57579, 12799, 57578, 12805, 12807, 45652, 28350, 12811,\n",
       "         12812, 12813, 28371, 57571, 45635, 12763, 12717, 57643, 57642,\n",
       "         45619, 12721, 28416, 12723, 57641, 28410, 28408, 28407, 57629,\n",
       "         57628, 57601, 45626, 45628, 12742, 28398, 57626, 28397, 57611,\n",
       "         57609, 28388, 45634, 57605, 28383, 28382, 12762, 12739, 57570,\n",
       "         57568, 57567, 12880, 57516, 28299, 57513, 45699, 57511, 45701,\n",
       "         45704, 12892, 45705, 12894, 12898, 45711, 57518, 12901, 57502,\n",
       "         57501, 57493, 45716, 45717, 28274, 12915, 45722, 45725, 28267,\n",
       "         45726, 28265, 28264, 45713, 12878, 12877, 45696, 57566, 45664,\n",
       "         12824, 28341, 12826, 12829, 28337, 45671, 12835, 28333, 45672,\n",
       "         28331, 45674, 57550, 45683, 57544, 12851, 12852, 12854, 28316,\n",
       "         12858, 28310, 12862, 12865, 28304, 45695, 57526, 57525, 57524,\n",
       "         45618, 45731, 12714, 28421, 57762, 12568, 28529, 28525, 12574,\n",
       "         45542, 45544, 57753, 57750, 28521, 28520, 12581, 28519, 28530,\n",
       "         12583, 57745, 45553, 12592, 45557, 12595, 12596, 12597, 12598,\n",
       "         57741, 45565, 57736, 57735, 28504, 12586, 45567, 57766, 12562,\n",
       "         57811, 12506, 12510, 57807, 12512, 57801, 57796, 57795, 45520,\n",
       "         28562, 12527, 28558, 12530, 57768, 12534, 28552, 28548, 12544,\n",
       "         28544, 12546, 12550, 57772, 28537, 57770, 28536, 12557, 45535,\n",
       "         28534, 57782, 57731, 57730, 28501, 57683, 28450, 28448, 28447,\n",
       "         12675, 12676, 28445, 45603, 28441, 28439, 57676, 57670, 57667,\n",
       "         28452, 57666, 28436, 12693, 45609, 12696, 57662, 28429, 45611,\n",
       "         57656, 57650, 12707, 45615, 12710, 12711, 57665, 12667, 45600,\n",
       "         45599, 28500, 28498, 57725, 28494, 28493, 57723, 45573, 28487,\n",
       "         57718, 45576, 28482, 12633, 12634, 28478, 57717, 57715, 28476,\n",
       "         28473, 12644, 45583, 57699, 12653, 45592, 45594, 45598, 12661,\n",
       "         57688, 12663, 12664, 45616, 57821, 57480, 45732, 45865, 13183,\n",
       "         57271, 45872, 28064, 28063, 57266, 13190, 57265, 13193, 45874,\n",
       "         28056, 45879, 45864, 13201, 28051, 57257, 57256, 13209, 28047,\n",
       "         57254, 28042, 13214, 57252, 57251, 13217, 13219, 13221, 57261,\n",
       "         45892, 45863, 28076, 57306, 28097, 57305, 57303, 57301, 13146,\n",
       "         45849, 13148, 13149, 57299, 13151, 28093, 57297, 13176, 13154,\n",
       "         28088, 13160, 13161, 45856, 28085, 28084, 28082, 13167, 57283,\n",
       "         28080, 28079, 28078, 13173, 28091, 57247, 28034, 45895, 13288,\n",
       "         13290, 13292, 13293, 45935, 13295, 45939, 13301, 45945, 45948,\n",
       "         13307, 45953, 13311, 27992, 27967, 13317, 13322, 27958, 27957,\n",
       "         27955, 13328, 13329, 57156, 45968, 45969, 13333, 13338, 27946,\n",
       "         27963, 57188, 27994, 13280, 13233, 57237, 45899, 28026, 45900,\n",
       "         45903, 57232, 57230, 13243, 45904, 57227, 13247, 57224, 13249,\n",
       "         57221, 28018, 57218, 13255, 13259, 28013, 57209, 57208, 45923,\n",
       "         13269, 13271, 13273, 13274, 45927, 45929, 45847, 12930, 45846,\n",
       "         28108, 57437, 57433, 28213, 12983, 28209, 28208, 12987, 57430,\n",
       "         12989, 28207, 57429, 28205, 45769, 28218, 57428, 57425, 13002,\n",
       "         13003, 57423, 57422, 57420, 57415, 57413, 13014, 13016, 28191,\n",
       "         57405, 13020, 57427, 28188, 45761, 12971, 45736, 45740, 28248,\n",
       "         28247, 45743, 57468, 12943, 28241, 28240, 28238, 12947, 12948,\n",
       "         12951, 12973, 12952, 28232, 45747, 57450, 12960, 57447, 28225,\n",
       "         28224, 12964, 45758, 57442, 57441, 12969, 12970, 28233, 45779,\n",
       "         57403, 13028, 28136, 57350, 28135, 45824, 45826, 57344, 13095,\n",
       "         13096, 13098, 28128, 13101, 28126, 13103, 57352, 57341, 13108,\n",
       "         57339, 28124, 13112, 45828, 57336, 57334, 28117, 28114, 57329,\n",
       "         28113, 57325, 28109, 13106, 45823, 13084, 13081, 13029, 57401,\n",
       "         28182, 57399, 45786, 57395, 13037, 13040, 57392, 57391, 57389,\n",
       "         28173, 57386, 28167, 13052, 57381, 45800, 45803, 45807, 45809,\n",
       "         13065, 57367, 28150, 57366, 57365, 57362, 57359, 13079, 28140,\n",
       "         45843, 57825, 28580, 12495, 28993, 58243, 11959, 58242, 28986,\n",
       "         28983, 28982, 58240, 11968, 58239, 58237, 28981, 58236, 28994,\n",
       "         45188], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 532\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 532\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 532\n",
       "    })}}},\n",
       " 'contains_concession': {'feature_present_idx': array([23226, 35633, 63486, 50914, 54074, 16851, 51364,  1370, 23819,\n",
       "          9326, 33632, 57148, 62215, 22099, 52389,  9604, 18117, 38465,\n",
       "         56194, 44767, 13082, 43776, 37332, 28618, 42918, 44919, 36048,\n",
       "         37513,  8464, 19774, 31463, 19786, 38762, 17575,  7268,  6244,\n",
       "          8406, 56827, 16777, 16765,  6070, 53233, 17839, 54524, 17879,\n",
       "           167, 52292, 14077, 12327, 12140, 43564, 45875, 45998, 43424,\n",
       "         11605, 11512, 14796, 42426, 39151, 15423, 48201, 42012, 41990,\n",
       "         48926, 50909, 41076, 40712, 39943,  9272, 51497, 51601, 47846,\n",
       "          5750, 13370, 33364, 34671,  3027, 31110, 31266,  2698, 33674,\n",
       "         31835,  2564, 23708, 63786,  2139, 57171,  2065, 63602, 32950,\n",
       "         24187, 63399, 28941, 35009, 21839, 60255, 66573, 19365,  4887,\n",
       "         57964, 59035, 28011, 20848,   341, 59708, 24302, 65537, 43212,\n",
       "         14454, 27842, 32446, 13629, 43502, 31965, 44115, 13891, 31917,\n",
       "         14018, 25332, 28045, 41800, 43167, 14413, 31614, 30974, 28037,\n",
       "         43422, 43982, 14872, 36894, 15578, 38797, 17043, 17573, 35106,\n",
       "         21001, 17646, 34860, 38234, 36599, 18811, 19450, 18871, 36817,\n",
       "         19112, 35690, 41563, 16891, 22182, 41413, 66977, 33021, 40565,\n",
       "         39872, 16205, 21709, 23212, 16306, 22956, 39761, 33950, 38822,\n",
       "         22269, 16276, 18594, 12119,  5211,  6108, 51331,  9614, 51502,\n",
       "         57710, 53184,  8612,  3293, 53778, 53917,  8174, 54360,  7596,\n",
       "         51097,  1738,  7303,  7263, 54850, 63322, 63287,  6875, 63049,\n",
       "         56134,  2173,  2283,  5100, 57471,  2668,  1805,  1013, 58877,\n",
       "         10335, 60266, 45262, 66124, 12757, 60087,   297, 45679, 65948,\n",
       "         12044,   516, 11990, 46432,  3092, 46936, 11401, 65359, 47248,\n",
       "           980, 50035,  4157, 64252,  3551, 64893, 44942,  3208, 47829,\n",
       "         59394, 47431, 48469, 61999, 33771, 61939, 34182, 34662, 33766,\n",
       "         33963, 63342, 62661, 26927, 27738, 28004, 65682, 65333, 29964,\n",
       "         30469, 62176, 64056, 31650, 63947, 63766, 63720, 63520, 62968,\n",
       "         62885, 31591, 61300, 45228, 60516, 39780, 40527, 50954, 40851,\n",
       "         41264, 49258, 48931, 48851, 48436, 51455, 42306, 46823, 46265,\n",
       "         45708, 26893, 45590, 45358, 45291, 44639, 44666, 47134, 51536,\n",
       "         52433, 53680, 35104, 35406, 59347, 35937, 58850, 57805, 36790,\n",
       "         57636, 57406, 56508, 37397, 56231, 56151, 56149, 37573, 37723,\n",
       "         38012, 55998, 55507, 54591, 54545, 61146, 26706, 32937, 17902,\n",
       "         12920,  1492,  4136,  8397, 13379, 16383, 16112,  3635, 16043,\n",
       "          3310, 24863, 12788,  9252, 14497, 22476, 14617, 15903, 22870,\n",
       "         18150, 23385, 24353,  8234, 15635, 15529, 24826, 21273, 21642,\n",
       "         25545, 11107,   402,   526,  6079,   813, 26068, 20473, 17704,\n",
       "         23902,  1244,  4257,  4515, 37611, 15542, 53699, 37675, 11054,\n",
       "         37808,  8216, 39552,  8130, 39329, 40932, 15725, 16531, 38249,\n",
       "         56399, 54175, 39587,  6839, 16013, 56347, 54317, 40338, 56287,\n",
       "          6361, 39741, 16188,  5951,  6530, 42993, 52952, 49496, 12303,\n",
       "         12018, 49438, 11776, 46062, 46188, 46194, 46218, 45453, 11652,\n",
       "         11406, 46993, 11356, 10810, 48853, 10895, 47955, 48816, 48237,\n",
       "         49283, 13048, 45163, 50037, 42423, 52278, 51970, 15140, 43078,\n",
       "         43096,  9118, 43236,  9238, 43447, 43524, 43636, 14399, 14324,\n",
       "         44066, 44120, 10037, 13726, 10176, 10415, 50449, 15435, 18403,\n",
       "         10908, 57270, 25284,  3230, 29458, 24124, 24104,  3235, 33042,\n",
       "         29164, 33262, 23889, 29148, 60823, 22717, 60663, 60604, 32449,\n",
       "         31268, 61491,  5365, 25035, 31451, 25001, 24843, 31620,  2626,\n",
       "         24768, 25191, 30745, 32028,  2138, 32038, 32089, 32097, 63210,\n",
       "         61644,  3260, 22374, 64645, 36094, 65406, 20334, 58802, 20991,\n",
       "         27797, 28918, 21022, 19493, 27724, 27983, 58336, 65986, 21196,\n",
       "         34838,  4108, 26048, 66147, 36915, 59658, 25905, 28142, 25609,\n",
       "         66607, 63594, 66768,   237,  4662,   537, 62873, 63582, 50382,\n",
       "         49073, 10513,  1583, 64100, 49359,  1190, 49623,  1453, 49476,\n",
       "         10546, 51229,  2881, 62464,  7149, 55999, 59512, 56109, 59373,\n",
       "         59019,  6755, 56153, 60229, 59011, 56691, 56698, 57000, 57115,\n",
       "          5063, 57527, 57476,  5146, 58756, 51335, 55046,  7358,  9354,\n",
       "         62370,  2644,  2661,  2845,  9144, 51651, 51797,  7150,  9035,\n",
       "         61221,  8626, 53605, 61093, 61077,  3309, 60259,  7497,  8700,\n",
       "         26582, 67046, 25915, 14654, 15009, 43006, 36638, 42517, 15162,\n",
       "         24559, 26229, 27747, 31754, 15419, 31329, 41786, 14400, 18840,\n",
       "         41504, 26107, 15603, 18818, 41226, 37822, 37888, 40263, 40094,\n",
       "         38436, 38511, 17504, 39734, 37340, 26264, 24435, 13762, 26550,\n",
       "         21983, 32224, 32972, 33379, 33433, 12407, 11682, 46829, 34480,\n",
       "         11149, 22007, 47916, 11084, 11558, 32550, 12291, 29934, 32273,\n",
       "         35208, 44446, 13639, 44691, 35152, 21583, 13215,  1924, 30183,\n",
       "         35466, 35557,  1977, 58624, 17040, 19768, 31836, 17889,  2389,\n",
       "         60161,  1719, 48579, 58299, 35061, 62736, 34759,  2104, 33853,\n",
       "          5200, 16486, 43077, 44050, 27223, 66347, 51129, 10035, 50993,\n",
       "         45025,   183, 49881, 49773, 49487, 26481, 26484, 49397, 10537,\n",
       "         49139, 11261, 11125, 65812,  8724, 27512, 64094, 34060,   936,\n",
       "           656, 41236,  1565,  1239, 39932, 27802,  6898,   746, 15431,\n",
       "         39721, 64271, 28190, 29786, 63424,   745, 66422, 25216, 28005,\n",
       "         32190, 27488, 63350, 28967, 33857, 48690, 40108, 15929, 34048,\n",
       "         40080, 53427, 53361, 52890, 52527, 52446,  6241, 42414, 17809,\n",
       "         52010, 37881, 40515, 37354, 45200,  3403, 59879, 34619, 49460,\n",
       "         14762, 21734,  7909, 13163,  9833, 44103, 19270,  5090,  4280,\n",
       "         53349,  9752, 53742, 11896, 42773, 34564,  1335, 35913, 19620,\n",
       "         57621, 19109, 38408, 59623, 39003, 56262,  6593, 39868, 22900,\n",
       "         28851, 28658, 39071, 32822,  8105, 30279,  8342, 25068,  4856,\n",
       "         15651, 27515, 55501, 45461], dtype=int64),\n",
       "  'feature_absent_idx': array([18529, 12763, 61709, 12768, 12769, 12770, 12771, 41762, 12773,\n",
       "         12777, 27776, 49503, 12782, 49500, 12762, 41772, 64797, 27763,\n",
       "         49493, 41775, 41776, 49490, 12799, 41777, 49489, 27758, 64792,\n",
       "         27757, 12805, 41773, 12807, 49507, 49509, 41747, 12710, 12711,\n",
       "         57329, 27820, 12714, 61700, 12717, 49532, 12721, 12723, 49529,\n",
       "         27811, 49508, 49526, 49523, 27805, 64806, 12739, 27801, 12742,\n",
       "         27799, 27796, 49516, 61704, 27792, 27791, 49511, 49524, 12707,\n",
       "         49486, 12811, 49450, 27712, 49446, 49445, 27710, 49444, 12877,\n",
       "         12878, 57339, 12880, 27708, 27707, 49439, 27713, 64779, 64778,\n",
       "         49437, 57341, 49434, 12892, 27703, 12894, 41802, 27701, 64776,\n",
       "         12898, 12901, 41807, 61724, 27754, 27715, 41798, 12812, 12813,\n",
       "         61717, 57334, 58897, 58894, 12824, 49474, 12826, 57336, 12829,\n",
       "         49471, 12835, 12865, 27735, 27731, 49468, 49466, 49463, 27726,\n",
       "         27725, 12851, 12852, 27723, 12854, 49456, 12858, 12862, 27733,\n",
       "         27693, 41744, 49546, 27946, 12544, 12546, 12550, 64851, 27937,\n",
       "         64850, 12557, 27931, 12562, 64849, 64847, 12568, 41671, 49610,\n",
       "         64845, 12574, 49606, 58915, 58914, 12581, 64840, 12583, 49605,\n",
       "         12586, 41694, 41695, 12592, 49609, 27910, 27955, 27957, 27992,\n",
       "         12490, 12491, 57303, 12494, 12495, 49654, 49649, 41649, 49648,\n",
       "         41650, 12506, 41653, 12534, 12510, 12512, 41655, 49639, 41658,\n",
       "         27967, 57305, 41664, 27963, 12527, 57306, 58919, 12530, 27958,\n",
       "         49642, 61698, 12595, 12597, 64820, 64819, 27861, 12661, 27860,\n",
       "         12663, 12664, 12667, 41729, 49560, 41731, 12675, 12676, 27863,\n",
       "         27845, 49558, 41738, 41741, 64814, 57325, 12693, 41742, 49549,\n",
       "         12696, 49548, 27831, 61695, 27828, 64816, 12596, 64821, 12653,\n",
       "         12598, 27908, 41697, 49594, 49590, 64833, 49588, 41703, 27891,\n",
       "         64831, 49586, 41706, 27883, 27864, 58912, 12634, 27877, 49579,\n",
       "         49578, 58907, 41718, 12644, 41719, 49574, 41722, 49572, 49570,\n",
       "         64822, 12633, 49431, 58885, 27688, 13173, 41913, 64725, 13176,\n",
       "         41914, 49271, 49269, 13183, 27486, 41916, 61765, 61766, 49263,\n",
       "         49272, 13190, 13193, 61767, 41922, 61771, 27471, 13201, 61772,\n",
       "         58865, 64721, 41929, 27464, 13209, 49255, 41919, 13214, 13167,\n",
       "         27500, 27531, 41896, 27527, 64730, 49309, 57362, 41897, 41898,\n",
       "         41899, 27516, 49294, 64728, 49291, 57367, 49290, 13146, 13148,\n",
       "         13149, 41908, 13151, 49284, 13154, 61762, 57365, 49281, 57366,\n",
       "         13160, 13161, 27506, 27535, 27459, 49254, 49215, 27409, 64699,\n",
       "         27408, 57381, 13288, 13290, 13292, 13293, 13295, 27402, 27401,\n",
       "         27399, 49216, 27398, 27395, 27394, 13307, 49202, 13311, 27389,\n",
       "         27388, 57386, 13317, 27386, 41970, 49196, 13322, 13301, 13217,\n",
       "         13280, 27413, 13219, 27458, 13221, 41932, 27451, 41935, 27449,\n",
       "         13233, 58859, 27439, 49241, 13243, 41949, 41962, 13247, 27431,\n",
       "         27430, 49235, 13255, 13259, 49226, 27417, 64704, 13269, 13271,\n",
       "         13273, 13274, 49219, 13249, 49315, 13112, 13108, 12960, 49400,\n",
       "         12964, 61737, 49398, 12969, 12970, 12971, 27641, 12973, 41843,\n",
       "         49391, 27638, 27650, 27637, 41844, 12983, 27631, 12987, 41847,\n",
       "         12989, 41848, 49383, 41850, 41851, 27625, 27624, 57350, 61739,\n",
       "         64756, 61735, 27653, 27686, 41817, 41818, 12915, 61727, 49425,\n",
       "         58884, 49424, 27676, 49421, 61729, 49418, 12930, 61734, 41828,\n",
       "         57344, 61730, 12943, 49411, 64766, 41832, 12947, 12948, 27658,\n",
       "         12951, 12952, 61733, 27656, 58882, 41853, 49378, 49377, 27586,\n",
       "         49345, 27582, 27581, 49340, 27576, 13065, 27573, 27571, 27568,\n",
       "         27567, 61751, 27561, 13052, 13079, 27557, 13084, 41884, 57359,\n",
       "         27548, 13095, 13096, 13098, 41887, 13101, 64737, 13103, 13106,\n",
       "         13081, 27590, 49350, 27591, 61742, 13002, 13003, 57352, 27621,\n",
       "         49374, 49373, 27620, 49369, 27616, 13014, 13016, 27612, 41856,\n",
       "         13020, 27607, 49362, 64749, 27606, 64748, 13028, 13029, 27605,\n",
       "         49360, 64747, 13037, 13040, 27593, 41867, 12484, 27994, 64866,\n",
       "         49661, 28448, 28447, 28445, 57237, 11902, 49978, 49976, 11906,\n",
       "         28441, 28439, 49973, 64988, 11914, 28450, 28436, 64984, 11922,\n",
       "         11923, 28429, 41416, 49960, 28421, 11931, 41419, 28416, 49954,\n",
       "         11939, 11940, 41406, 64981, 28452, 61565, 28494, 28493, 28487,\n",
       "         65004, 61557, 57232, 11848, 11850, 28482, 65001, 61559, 50000,\n",
       "         49999, 49985, 28478, 28476, 11861, 49994, 64997, 28473, 64996,\n",
       "         11874, 61563, 11876, 49988, 11882, 58966, 11885, 41389, 11834,\n",
       "         28410, 28408, 41444, 28361, 64964, 12013, 12014, 12015, 41448,\n",
       "         12017, 61582, 49901, 12022, 28350, 49898, 57247, 49897, 41455,\n",
       "         41457, 57251, 12033, 49891, 49890, 28341, 64956, 57252, 28337,\n",
       "         12045, 12046, 12047, 12029, 49948, 64967, 11994, 28407, 11952,\n",
       "         41429, 28398, 28397, 11959, 49941, 41432, 61578, 28388, 41436,\n",
       "         11968, 28383, 11995, 28382, 11976, 49931, 28378, 41440, 41441,\n",
       "         28374, 11984, 11985, 61579, 11987, 28371, 28370, 49923, 11975,\n",
       "         11832, 65005, 11830, 57221, 11679, 28592, 28589, 61537, 50084,\n",
       "         61538, 28583, 28580, 11695, 11696, 65025, 41346, 11676, 11699,\n",
       "         41347, 57224, 11704, 11706, 11707, 11708, 41349, 11711, 41351,\n",
       "         11722, 28562, 50074, 28558, 11700, 50070, 50087, 11673, 28621,\n",
       "         11636, 61527, 11638, 61528, 11641, 41331, 11644, 28612, 50104,\n",
       "         11647, 50103, 11649, 28595, 41333, 11653, 11656, 58974, 11659,\n",
       "         28605, 57218, 65036, 41337, 50092, 28602, 11668, 11669, 11672,\n",
       "         11651, 11731, 11733, 11734, 11785, 28525, 41369, 28521, 65012,\n",
       "         28520, 28519, 57230, 50024, 50021, 11802, 41375, 11804, 11784,\n",
       "         11805, 41376, 11809, 11811, 11817, 50016, 28504, 11821, 28501,\n",
       "         28500, 11826, 11827, 11828, 28498, 11806, 11781, 11779, 28529,\n",
       "         11736, 11737, 11738, 11739], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 742\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 742\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 742\n",
       "    })}}},\n",
       " 'contains_condition': {'feature_present_idx': array([47560, 38572, 51255, 41352, 52650, 34451, 31876, 15175, 49321,\n",
       "          5415, 18566, 58348, 20666, 66616, 40388, 27340,  1486, 28539,\n",
       "          1395,   140, 26971, 27307, 51818, 37270, 62692, 63105, 20791,\n",
       "          8976, 25337, 47426, 64082, 39102,  6776,  6512, 11759, 24303,\n",
       "         13356, 26188, 61261, 14279, 67003, 55725, 60945, 60352, 17868,\n",
       "         21425, 29671, 19129, 58934, 55122, 23336, 60830, 52402, 65063,\n",
       "         48970, 66545, 49470, 66591,  1136,  4025, 45234, 66332, 65131,\n",
       "         41037,  3278,  5621, 45712, 45999, 17610, 60046, 17376, 17331,\n",
       "         13934, 17273, 30654, 17133, 61173, 17128, 14321,  3159, 42265,\n",
       "         31083, 16869, 14629, 16025,  2585,  2827, 32720, 31673, 54067,\n",
       "         49210, 31315, 59616, 30055, 56136, 24158, 24005, 46412, 25282,\n",
       "         22881, 47593, 26762, 55478,   371, 27053, 22064, 21965, 59814,\n",
       "         57272, 27833, 44595,  1975, 44288, 54986, 19829, 59335, 29373,\n",
       "         18708, 18590, 54205, 13913, 29824, 44756, 53682, 24613,  6888,\n",
       "         51738,  8309, 10372, 62604,  4443, 64610, 37435,  9916, 39173,\n",
       "         49943,  9668, 51827,  9603,  9249, 39047, 40902, 64425, 37731,\n",
       "         38169,  7457, 64131,  8490,  8243, 38744,  9557, 40539, 39016,\n",
       "         52206, 49388, 39855, 11216, 13225, 39582, 65825, 35144, 41882,\n",
       "         12883, 64891, 41410, 35914, 36200,  5693, 35319, 28216, 49928,\n",
       "         44589, 25144, 40344, 27572, 55245, 39688, 39892, 26056, 39506,\n",
       "         55323, 45308, 39405, 26992, 26356, 26591, 50191, 40216, 53608,\n",
       "         29746, 40723, 33826, 53240, 32806, 42232, 53187, 32721, 53095,\n",
       "         34941, 34996, 53841, 31899, 31699, 36621, 36660, 31292, 30963,\n",
       "         37167, 28746, 50679, 42907, 54711, 54538, 49754, 28744, 42073,\n",
       "         30069, 51424, 37449, 30201, 41145, 30909, 42790, 32421, 67008,\n",
       "         62001, 10141, 10842, 10956, 62143, 11108, 11643, 61501, 61304,\n",
       "         63263, 13748, 14580, 14928, 15695, 15991, 16357, 17134, 17268,\n",
       "         60196, 13765, 59466,  8827, 63897,   150,  1547,  2177,  2826,\n",
       "         66046,  3460,  3465,  4283,  8586,  4473, 65519,  5328,  5632,\n",
       "         64754,  6232,  6359,  6439, 64512,  4518, 18637, 23935, 57327,\n",
       "         22665, 24063, 22527, 22508, 21814, 22800, 23477, 56816, 19351,\n",
       "         57319, 22192, 21838, 64946, 65175, 39550, 49979, 26225,  5824,\n",
       "         64615, 22989,  5914, 55497, 19096, 50380, 37762, 54926, 63346,\n",
       "         38246, 50811,  8615, 38382, 56779, 38821, 50568, 39017,  7389,\n",
       "         39111,  4794,  7113,  6926,  4754, 56111,  4343,   777, 47793,\n",
       "           389,   246, 47670, 66880,  1516, 24486,    68,    56, 46484,\n",
       "         46701, 46790, 47046, 45830, 24673, 56440, 48258, 65667, 41490,\n",
       "         41901,  3847, 42218, 25286, 23746,  2986, 42596, 49167,  2486,\n",
       "         66356, 66439, 48404, 48266, 25862, 22218, 22290, 24610, 34516,\n",
       "         18058, 27724, 27793, 58735, 34085, 33998, 37641, 57798, 53812,\n",
       "         55155, 13826, 61044, 20937, 61029, 32505, 28176, 60993, 32184,\n",
       "         53888, 32031, 31946, 15041, 15085, 30940, 54116, 15734, 17002,\n",
       "         28490, 20761, 34623, 30034, 34690, 10072, 37322, 19057, 18875,\n",
       "         27108, 57140, 62061, 36751, 11664, 36523, 36354, 52246, 59427,\n",
       "         36247, 12701, 29794, 24526, 12599, 18138, 34802, 34898, 52258,\n",
       "         12425, 61504, 12286, 12180, 61965, 12068, 52260, 11970, 19856,\n",
       "         60622, 47704, 59642, 47992, 62710, 48071, 62266, 50874, 50599,\n",
       "         63919, 56627, 52742, 48006, 55777, 53314, 55815, 61181, 65771,\n",
       "         48686, 60954, 55260, 65525,    21, 22403, 17585, 17923, 18003,\n",
       "         18158, 18189, 19334, 19668, 20373, 21849, 17076, 21926, 25412,\n",
       "         26843, 27245, 28149, 28551, 28667, 29340, 29795, 31824, 22596,\n",
       "         16916, 15831, 15019,  2972,  3216,  3835,  4155,  4830,  5501,\n",
       "          5622,  5703,  5799,  5878,  7693,  8040,  8905,  9764, 10318,\n",
       "         11322, 11900, 12470, 12980, 14346, 14739, 33013, 34388, 32728,\n",
       "         38870, 38371, 38042, 35864, 38903, 37788, 34713, 45112, 38324,\n",
       "         36797, 44109, 36836, 43092, 36928, 40263,  8318, 58314, 58874,\n",
       "          9732, 42812, 51573, 64271, 58626, 50537, 17410, 39205, 39461,\n",
       "         15767, 15178, 40681, 13750, 13699, 13487, 49881, 10213, 41933,\n",
       "         41236, 20913, 64285, 57066, 28736,  1987, 31742, 47978, 35345,\n",
       "         54812, 53828,  7432, 36211, 36341, 27673,  3997,  1924, 26385,\n",
       "         34192, 34331,  5193,  5200, 43255, 25106, 56572, 45684,   183,\n",
       "         62019, 34801,  2239, 42400, 64435,  2415, 45200,  3978, 62974,\n",
       "         44260, 65516, 42414,  6935, 62845, 10365, 34684, 49460, 53024,\n",
       "         32864, 53887, 32139, 55385, 51953, 26110, 55882, 55918, 10992,\n",
       "         21993, 58095, 24289, 40727, 20180, 19963, 37645, 57621, 62554,\n",
       "         14088, 52715, 29341, 40611, 44718, 42635, 18655, 43781,  8691,\n",
       "          8282, 51745, 36982,  7444, 21750, 25470, 45482, 26291, 12115,\n",
       "         29057, 35310,  2437, 32378, 43054], dtype=int64),\n",
       "  'feature_absent_idx': array([15619,  9161,  9162, 55939, 50943, 23501, 23502, 45282, 17928,\n",
       "          9169, 45281, 17932, 29532,  9173, 14365, 63820, 29529, 25921,\n",
       "          9178, 17924,  9180, 29526, 29525, 50688, 55938, 38072, 25919,\n",
       "         38066, 17940,  9135, 29558, 49771, 14369, 24760, 17936, 53418,\n",
       "         29552, 45292, 17934, 38068,  9147, 29549, 29548,  9150, 29547,\n",
       "         63833,  9153, 52562, 29544, 29543, 55943, 63840,  9184, 29522,\n",
       "         17911,  9215, 40167,  9217, 45266, 25924,  9220, 58283, 29495,\n",
       "         16067, 17912, 63804, 17905, 49796, 63800, 29490, 25927,  9231,\n",
       "         42883, 52080, 55960, 29483, 60421, 24758,  9211, 29504,  9187,\n",
       "         29521, 17921,  9190, 38075, 45275, 14363, 55948, 29516, 60420,\n",
       "         58286, 55950, 58285, 45271,  9201, 55951, 40169,  9204, 55954,\n",
       "         29508,  9207, 14362, 24759, 42194, 29482, 63841,  9129, 23470,\n",
       "         40184, 58301,  9056, 45317, 38044, 55911, 38045, 29608, 25906,\n",
       "         29615, 42184, 38049, 16057, 29602, 29601,  9069, 14380,  9071,\n",
       "         25908, 14378, 29597, 29605, 55908, 42182, 63884, 63891,  9027,\n",
       "         60401, 17978, 49760,  9031, 29628, 17977, 51747, 16056, 29624,\n",
       "         14384, 49761, 29622, 45323, 23467,  9042, 14383, 17971, 58305,\n",
       "         45321,  9047,  9048, 51753, 23495,  9076, 17958,  9106, 63850,\n",
       "         17948, 55926, 38059, 17947, 29574, 63849, 29572, 42885, 55925,\n",
       "         49767, 29569, 45299, 58292,  9122, 14371,  9124, 63843,  9126,\n",
       "         55933, 49768, 58294, 29580, 63852,  9102,  9079, 38054, 38055,\n",
       "          9082, 45310, 55916, 55917, 25909, 25910, 58297, 23484,  9090,\n",
       "         42187,  9092, 63860, 60410, 24763,  9096, 55922, 45305, 45304,\n",
       "         23486, 61115,  9077, 45331, 63795, 45258, 29393,  9375,  9376,\n",
       "         29392, 17856, 29389, 29388, 63738, 29387, 56004, 42223, 63737,\n",
       "         43456, 25946, 29383,  9389, 29382,  9391,  9393, 29380, 24756,\n",
       "         56006,  9385, 57365, 45212,  9370, 29413, 60438, 29410, 45223,\n",
       "         52547, 29408, 45220, 58267, 29406,  9356, 42881,  9358, 17862,\n",
       "          9360, 38113, 50930, 38114, 38115,  9365, 57366, 56001, 63742,\n",
       "         60440, 29377,  9346, 25949, 42880,  9428,  9429, 17838, 24755,\n",
       "         63717, 29353, 29352, 50923, 29350, 29349, 52543, 52085, 29345,\n",
       "         63715, 14319,  9443, 63713,  9445, 57359,  9447, 14317, 40146,\n",
       "         29346, 29357, 50462,  9424, 29372, 63728, 63727, 23557, 40151,\n",
       "         23559,  9407, 29368, 45199, 57362, 52544,  9412,  9413,  9414,\n",
       "         51770, 45197,  9417, 25952, 50465, 50463, 56013,  9422, 61808,\n",
       "         42226, 29481,  9345, 29414,  9268, 38094,  9270,  9271, 45247,\n",
       "         39327,  9274, 55976, 55977, 49800, 29461, 55978, 49803, 51767,\n",
       "         38095, 63772, 63771,  9285, 29453, 17888, 63768, 60430, 45243,\n",
       "         29462, 23528, 60428, 52081, 61801, 38085, 17899, 45255, 25931,\n",
       "          9246, 23523, 55970, 40162, 29470, 45253, 63784, 45252, 58277,\n",
       "         52556, 50689,  9258, 45250, 45249, 45248, 50938, 29465, 63767,\n",
       "          9344, 42204, 16070, 29432, 25940, 45233, 45232, 29430, 55989,\n",
       "         61804, 60435, 38105, 52548, 29433,  9331, 29423, 29422, 55993,\n",
       "         60436, 42215, 14340, 39322, 25942,  9341, 49809, 29424,  9319,\n",
       "         50934, 16072, 16071,  9295, 45239, 25937,  9298, 29444, 42206,\n",
       "         57367, 43454,  9303, 45237, 63761, 42210, 23536, 45236, 63759,\n",
       "          9310,  9311,  9312,  9313, 58274, 29436, 63758, 63765,  9450,\n",
       "         55904, 58310, 49725, 51731,  8730,  8731, 29857, 29856, 42891,\n",
       "         37963,  8736, 14427, 40218,  8738, 18090, 49729, 29849, 23388,\n",
       "         18088, 29845, 64009,  8747, 14426, 18086, 29851, 23383, 18096,\n",
       "         64017, 18105, 55820, 29883, 29882, 37956, 29880, 29879, 64022,\n",
       "         25874, 23376, 29876, 29875, 52604, 25875, 52603, 16042, 29870,\n",
       "         25877, 40219, 29867, 61765, 61766, 55824, 58340, 61762, 18084,\n",
       "         61767, 29817, 50953, 29815, 29814, 23401, 29811, 61123, 18067,\n",
       "         29808, 49739, 55834, 23403,  8793,  8794, 42890, 63982,  8797,\n",
       "         63981, 55837, 14417, 60367, 55839,  8792, 58333, 16044, 18073,\n",
       "         45415, 45414, 64001, 45413, 14424, 25879, 64000, 29834, 58337,\n",
       "         45411, 45410, 63994, 14422, 29831, 49732, 29830,  8770, 18077,\n",
       "         23397, 42153, 29825, 25880, 29822, 23391, 37975, 29887, 55817,\n",
       "         18137, 60340,  8622, 45457, 16040, 14443, 40226,  8627, 57392,\n",
       "         49707, 23358, 23363, 60342, 49708, 60344, 29929,  8636, 50962,\n",
       "         18127, 18126, 14441,  8641, 55790, 60338,  8617, 29943,  8591,\n",
       "         64070, 52619, 45467, 55779, 29957, 29956, 14448, 55781, 14447,\n",
       "         29950,  8602, 23355,  8604, 45462, 18143, 64062, 49703, 45460,\n",
       "         39711, 45458, 52616,  8614, 37939, 18107, 64045, 50961, 55805,\n",
       "          8675, 55806, 29903, 23371, 57391, 18112, 29899, 64037, 64036,\n",
       "         18115, 23373, 18110,  8687, 49712, 18109, 37951, 49713,  8693,\n",
       "          8694, 18108, 29891, 55813, 64040], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 608\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 608\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 608\n",
       "    })}}},\n",
       " 'contains_consist_of': {'feature_present_idx': array([56146,  3253, 65940, 65743, 38657,  4006,  4403, 51994, 51614,\n",
       "         27463, 50965,  5634, 16022, 27925, 60616, 28891, 11058, 29520,\n",
       "         61172, 34641, 34484, 56410, 30332, 61955, 33221,  5920, 44441,\n",
       "         32033,  1194,  1024, 18498, 41758, 21620, 20753, 55961,  1759,\n",
       "         19855, 17957,  1086,  2016, 42922, 29132, 50277, 11898, 21810,\n",
       "         50397,  8975, 28502, 28431, 50744, 27993, 31861, 31924, 11278,\n",
       "         49964, 31002, 60870,  9051, 20126, 49711, 27917, 61544, 19707,\n",
       "         20609, 30226, 61595, 61844, 20018,  9635,  9602, 31652, 21179,\n",
       "         54517, 17771, 59027, 54552, 57547, 24607, 58830, 58678, 22930,\n",
       "         25223, 24256, 16559, 16648, 24177, 16968, 24046, 23906, 17394,\n",
       "         54051, 42863, 53340, 15004, 13490, 21903, 27339, 59657, 13848,\n",
       "         52307, 27028, 26131, 26928, 26809, 52483, 21977, 67211, 26518,\n",
       "         52848, 26171, 18377, 14368, 61633,  6498,   661, 40134, 38184,\n",
       "         63109,  1442, 49050,  6678,  2618, 37835,  1566, 36021, 45692,\n",
       "         41341, 63487, 46352, 37247,  4747, 36257, 66173, 64753,  4989,\n",
       "         66326, 45884, 39691, 42034,  1002,  2863,  8502, 62225,   174,\n",
       "         62347, 43033, 33291,   267, 48061, 62505, 42185, 47666, 62619,\n",
       "          7780, 47625, 47041, 39573, 34653, 34321, 45384, 42055, 40483,\n",
       "         39731, 24728, 24525, 40069, 24377, 40106, 39336, 24574, 39844,\n",
       "         24806, 53714, 39750, 48675, 23793, 42466, 42146, 42120, 55609,\n",
       "         55220, 21328, 21541, 55218, 21805, 43195, 41800, 43318, 40350,\n",
       "         22141, 22432, 22470, 54597, 54590, 39185, 41456, 41096, 23094,\n",
       "         41041, 23213, 23284, 54416, 22202, 39027, 38048, 25757, 28603,\n",
       "         50383, 46514, 35659, 46652, 46654, 29399, 34749, 34743, 49882,\n",
       "         29702, 49774, 34742, 29989, 30032, 49735, 49543, 47537, 33767,\n",
       "         30472, 30696, 30946, 31299, 49099, 31795, 33124, 48473, 28561,\n",
       "         25384, 36028, 28334, 25765, 52867, 45192, 38404, 26306, 26386,\n",
       "         38185, 52509, 26715, 38129, 26796, 37958, 37716, 27078, 52276,\n",
       "         27309, 45870, 36894, 51393, 45914, 51051, 51034, 27876, 45974,\n",
       "         46039, 50809, 36218, 50735,    25, 54986, 20326, 10110, 10161,\n",
       "         61435, 10361, 10403, 10439, 61136, 10923, 11062, 60669, 11609,\n",
       "         11818, 11852, 12175, 60227, 12333, 12785, 15303, 14770, 14756,\n",
       "         14408, 14154, 14137, 20340, 14121, 13944, 59578, 59687, 13304,\n",
       "         59854, 59912, 14074,  9768,  9444,  8919, 66008,  2554,  2373,\n",
       "         66239, 66392,  1975, 64836,  1387, 66472, 66508,   532, 66611,\n",
       "           148,    60,  1385, 15391,  3880,  4686,  8605,  8436, 62599,\n",
       "         62920,  7294,  7208,  4328,  7140,  6525,  6426,  6310, 63608,\n",
       "          5557,  5313, 63322, 59223, 61660, 15967, 16175, 18754, 58275,\n",
       "         16743, 18503, 19091, 18685, 18905, 15836, 17189, 18449, 56570,\n",
       "         19698, 18170, 18483,  6645, 56829, 47162, 55115, 46109, 63522,\n",
       "         45983, 36749,  5485, 18604,  5046,  4987, 55216, 37275, 36156,\n",
       "         34662, 25186, 21931, 54799, 32994, 48610, 18250, 48394, 48341,\n",
       "         62360, 62503, 53353, 47865, 54826, 33585, 62852, 22015, 62921,\n",
       "         47490, 47448, 47225, 18357, 34376,  7245, 34557, 37533,  7154,\n",
       "         45710,  4185,  4515,  2481, 21223,  2285, 21217, 40658, 41322,\n",
       "          1799,  1744, 41531,  2483,  1458, 55949, 19359,   610,   553,\n",
       "         43147,   523, 42271, 43035, 42531, 21002, 40104, 44710,  2607,\n",
       "         64764, 45660, 56731, 62009,  3925,  3896, 45551, 38323, 21416,\n",
       "          3623, 38562, 38810,  3462,  3429, 39260, 65480, 39514, 39530,\n",
       "          2959,  2652, 39759, 64761, 49080,  8139,  8689, 51372, 53940,\n",
       "         27888, 60007, 12648, 12589, 12194, 28293, 32181, 51383, 17430,\n",
       "         12039, 57752, 11716, 28878, 11680, 28925, 57697, 28968, 23352,\n",
       "         12129, 13470, 13480, 13641, 59130, 15466, 25376, 53400, 25485,\n",
       "         15272, 15130, 15067, 14785, 24750, 59231, 52551, 14411, 26589,\n",
       "         59468, 14311, 53572, 27012, 58497, 27262, 59591, 60805, 23351,\n",
       "         28373, 42746,  9859, 31558, 31540, 49382, 49195, 18008, 22912,\n",
       "         17897, 61859, 18155, 57564, 30791,  9486, 60975, 18235,  8885,\n",
       "         17572, 31334, 57691, 31031, 43999, 48068, 47919, 43917, 44402,\n",
       "         56697, 43820, 59126, 59427, 48274, 54786, 43458, 42899, 48958,\n",
       "         56111, 55964, 48771, 53297, 62005, 53542, 53284, 43184, 62206,\n",
       "         61965, 55663, 43234, 49127, 43322, 53477, 58866, 60901, 49163,\n",
       "         63046, 63209, 60612, 54389, 46957, 63280, 63341, 46526, 49769,\n",
       "         63346, 55205, 49843, 64597, 46225, 55190, 57275, 57756, 45645,\n",
       "         57162, 59561, 52287, 66120, 51949, 61743, 49167, 58381, 52449,\n",
       "         47485, 65207, 51080, 44963, 61644, 64963, 49257, 45406, 47328,\n",
       "         53737, 32031, 42704, 27793, 27528, 27433, 27178, 27131, 27108,\n",
       "         27928, 26780, 26048, 24798, 24768, 24460, 42743, 24214, 26429,\n",
       "         28159, 28535, 28812, 33274, 33186, 33123, 33048, 32588, 32402,\n",
       "         31743, 31268, 30980, 30077, 30070, 29930, 29737, 29390, 28966,\n",
       "         23433, 22837, 22780, 22155,  9558,  9255,  9158,  9118,  8006,\n",
       "          7389,  6926,  6842,  6246,  3847,  3468,  2531,  2229,  2181,\n",
       "           237,  9827, 33277, 10629, 11054, 22102, 21836, 21758, 21326,\n",
       "         20944, 20387, 18146, 17937, 17833, 17578, 17456, 16971, 15760,\n",
       "         13786, 11970, 10648, 33335, 67348, 33443, 34745, 42404, 38557,\n",
       "         35710, 37900, 36116, 36310, 42161, 34690, 36489, 36793, 36800,\n",
       "         38376, 42069, 41643, 37137, 37599, 41796, 36658, 34667, 38246,\n",
       "         42596, 33459, 34172, 33938, 40578, 33957, 44653, 44345,  8549,\n",
       "         11322, 15447,  8457,  8407, 45267, 45324, 12181, 14654, 22282,\n",
       "         14325, 38332, 41717, 12800, 23673, 54267, 54162, 54117,  8335,\n",
       "         21582, 21563, 38436, 44706, 61387, 44605, 44219, 16053, 10640,\n",
       "         10318, 61535, 18541, 10147, 15992, 33376, 19154, 56647, 44273,\n",
       "          9807, 20342,  9442, 11046, 41320, 20677, 61870,  8924, 17455,\n",
       "         44185, 40107,  3377, 34110, 27618, 51335,  3317, 27870, 49112,\n",
       "         50920, 46414, 34079, 31070, 28526, 46467,  2852, 49963, 30681,\n",
       "         42330, 49607,  2182, 46459, 66497,  1155, 65478, 42004, 37651,\n",
       "         33182,  6404, 32622, 48509, 47696, 52789, 48604, 27004,  5651,\n",
       "         32978, 32924, 65293, 64149, 25150, 66560, 60167,   656, 12732,\n",
       "         63103,  9946,  2610, 13210,  7658,  7769,  6568, 63493,  6012,\n",
       "         64292,  4419, 42319,  8613, 41550, 41358, 65911,  7070,  3306,\n",
       "         42912,  6656, 56707, 20192, 19808, 56492, 24239, 27247, 20594,\n",
       "         55833, 26420, 21643, 26409, 54813, 25279, 22511, 24668, 13750,\n",
       "         38269, 27255, 18642, 24665, 17925, 47729, 13818, 33849, 30183,\n",
       "         30129, 15424, 27453, 29753, 15467, 34854, 29539, 15948, 35148,\n",
       "         27881, 63722, 52403, 36963, 25731,  3645, 30450, 24737,  6869,\n",
       "         46269,  5806, 59782, 23399, 53817, 13855, 14401, 12016, 16012,\n",
       "         16392, 44827,  7052, 40693, 20756, 55752, 10051, 21117, 62919,\n",
       "         21734, 45475,  8034, 52787, 14088, 49273, 11134, 25470, 53876,\n",
       "         45263, 36485, 27689, 39992,  8350, 44498,  7968, 44970,  4613,\n",
       "         45013, 15573, 51811, 34226, 59622, 35310], dtype=int64),\n",
       "  'feature_absent_idx': array([52990, 21019, 32276, 51721, 41932, 21016, 51718, 32278, 15365,\n",
       "          9407, 51712, 21020, 51709,  9412,  9413,  9414, 21011, 51705,\n",
       "          9417, 32284, 32286, 32287, 41935, 15364, 51727, 51731, 32270,\n",
       "         41916,  9370, 51767, 32251, 41919,  9375,  9376, 32254, 21030,\n",
       "         51753, 15372, 32262, 51747, 41922, 51743,  9385, 51742, 21026,\n",
       "         15370,  9389,  9391, 41929,  9393,  9422,  9424, 32293, 32297,\n",
       "          9458, 51660, 20988,  9461, 15353, 20985, 20984, 51646,  9467,\n",
       "         20983,  9469, 32338, 51638, 20981, 32340, 51632,  9475, 20979,\n",
       "         20977, 41962, 51620, 32348, 18283,  9457, 51770,  9456, 15354,\n",
       "         37057,  9428,  9429, 37054, 32306, 51685, 32309, 32311, 32312,\n",
       "         32316, 41949, 51675, 32328, 37051,  9443,  9445, 51671,  9447,\n",
       "         51669,  9450, 20990, 51665,  9453, 51661, 21036, 15376,  9365,\n",
       "         51922,  9285, 32186, 51915, 51914, 41884, 21071, 51909, 32194,\n",
       "          9295, 21068, 32195,  9298, 51900, 51895, 21066, 32199,  9303,\n",
       "         21064, 15392, 51886, 41887, 32203, 51924, 51878, 51928, 51935,\n",
       "         51977, 21083,  9258, 51972, 51968, 32167, 51958, 51957, 32169,\n",
       "         51954, 32170,  9268, 37083,  9270,  9271, 32177, 51945,  9274,\n",
       "         37081, 51943, 51941, 32179, 51937, 51933,  9483,  9310,  9312,\n",
       "          9341, 51810,  9344,  9345,  9346, 51809, 41908, 51807, 51806,\n",
       "         37069, 51799, 51793, 51791, 51788,  9356, 37067,  9358, 51785,\n",
       "          9360, 51784, 41913, 32245, 41914, 32235,  9311, 51819, 15383,\n",
       "          9313, 51877, 21060, 32209, 51868, 51867,  9319, 32215, 51859,\n",
       "         51856, 41896, 51853, 41897, 41898, 51848, 41899, 18267,  9331,\n",
       "         32226, 32227, 32228, 32230, 32232, 51820, 51978, 32351,  9487,\n",
       "         20909, 51358, 51356, 42009,  9634, 51352, 51351, 51348, 51344,\n",
       "          9640, 42008,  9641, 42011, 51337, 51333, 15320, 42014, 42015,\n",
       "         51317, 32459, 42016, 51303, 20907,  9628, 20911, 37024, 51415,\n",
       "         51411, 32435, 15326, 51403,  9608, 51402, 20916, 51392, 51391,\n",
       "         51389, 51384, 51382,  9616, 51377,  9618, 51376, 51375, 42006,\n",
       "         51370,  9623, 20914, 32440, 32464, 15316, 51300, 51299, 51248,\n",
       "         42031, 32506, 42037,  9689, 51234, 42039, 32509, 20879, 32511,\n",
       "         32514, 32515, 32518, 20874, 42050, 20871,  9702, 51199, 37012,\n",
       "         32524, 51195, 51190, 32525, 37014, 51419, 32495, 20888, 15315,\n",
       "         51295, 51286, 51280, 18294, 32472, 37022, 51275, 51274,  9666,\n",
       "          9667, 37017, 51269, 51268,  9672, 51267, 32483, 51264, 20891,\n",
       "         51262, 32486, 51260, 42024, 32493, 42005, 32431, 32430, 15337,\n",
       "         32388, 32392, 15336, 41989, 51540,  9525, 37031, 20948, 20947,\n",
       "         32399, 20945, 32400, 51526, 51523, 32401,  9535, 32404,  9537,\n",
       "          9538,  9539, 41992,  9541, 51552, 51513,  9515, 37036, 37040,\n",
       "         41970, 51593, 32362, 51585,  9494,  9495, 32364, 32365,  9498,\n",
       "         20965, 41971, 51578, 32371,  9503, 51572,  9505, 37039, 41973,\n",
       "         41976, 20959, 51558, 51557,  9514, 20972, 20939, 51506, 51453,\n",
       "         51452,  9576, 20929, 51446, 32423, 51440, 51439, 20927, 51436,\n",
       "         20926,  9585, 32424,  9587, 32427,  9589,  9591, 20922,  9593,\n",
       "         51428, 51427,  9596, 51425,  9573, 51508, 42001,  9570, 41994,\n",
       "         41996, 32411, 32412, 32415,  9551, 51489, 51485, 51484, 51482,\n",
       "         20933, 15330,  9559,  9560, 51474,  9562, 51473, 51469, 32417,\n",
       "          9566, 51463, 51459,  9569,  9571,  9709, 21084, 21086, 52503,\n",
       "         31918, 52501, 18223, 21228,  8947,  8948,  8949, 52493, 52492,\n",
       "         21231, 21227, 37126, 52481, 52480,  8958, 18226, 21221, 21220,\n",
       "         31934, 21218, 52468, 52486, 41747, 52508, 52518,  8913, 52544,\n",
       "         52543, 41741, 52541, 31904,  8920, 52539, 52537,  8923, 31905,\n",
       "         52535,  8927, 41742, 31907,  8930, 31910,  8932, 21235, 21234,\n",
       "          8935,  8936, 41744, 31935, 52465, 21215,  8969, 52406, 21200,\n",
       "         41762, 18232, 52396,  9006,  9007,  9008, 31973, 18236, 52385,\n",
       "         41772, 41773, 31982, 41775,  9018, 41776, 52376, 21188, 52369,\n",
       "         41777, 52364, 18237, 21202, 21242,  8998,  8996, 52462, 52461,\n",
       "         31937, 31938,  8974, 52452, 52450, 52445, 52444, 15462, 31943,\n",
       "         21209, 31944, 52429, 31948, 37122, 52418, 15459,  8990, 52414,\n",
       "         31954, 52409,  8995, 52408, 52547, 52548, 31902, 41703, 31837,\n",
       "         52695, 37135, 41706, 31845, 31846, 31848, 52680, 52679, 21275,\n",
       "         52676,  8842, 15485, 52671,  8845, 31854, 52669, 52664,  8849,\n",
       "         52662, 52661, 21271, 52698, 18218, 15490, 31828, 31803, 52740,\n",
       "         41695, 52738, 52734, 52733, 31806,  8807,  8808, 31807, 52728,\n",
       "         52725, 52721, 31811,  8815, 52718, 52714, 41697,  8819, 18213,\n",
       "         15493,  8822, 31826, 37139,  9027, 21269, 52640, 52596, 52595,\n",
       "          8888, 37128, 52591, 21251, 52585, 31888, 31889,  8895, 52581,\n",
       "         52580,  8898,  8899, 41738, 37127,  8902, 31897, 52562, 31898,\n",
       "         21244,  8907, 52556,  8884, 41718, 31886,  8881, 31859, 52637,\n",
       "         21266, 52635, 41719,  8862, 21264, 52627, 41722, 52623, 52620,\n",
       "         52619, 52616, 31866, 31870, 31872, 31874, 41729, 52604, 52603,\n",
       "         41731, 31882, 52599, 37129, 21085, 31994, 32000,  9173, 52119,\n",
       "         32098, 32105, 52115,  9178, 52114,  9180, 32106, 21116, 32096,\n",
       "         52108, 52103, 52102,  9187, 52096, 15417,  9190, 52094, 52090,\n",
       "         52085, 41844,  9184, 52121, 21122,  9169, 52160, 32093, 52153,\n",
       "          9147, 21129, 52149,  9150, 52148, 21128,  9153, 52143, 52140,\n",
       "         52136, 41843, 21125,  9161,  9162, 52131, 21124, 52129, 52127,\n",
       "         21123, 52124, 32113, 52081, 52080, 32115, 41853, 52037, 18255,\n",
       "         21100, 15406,  9231, 32141, 52023, 32142, 41856, 52016, 32146,\n",
       "         52011, 37088, 32154, 37086, 41867, 51998,  9246, 32158, 51992,\n",
       "         37085, 51987, 41851, 32091, 52043, 52046, 18253, 52074,  9201,\n",
       "         18254, 52072,  9204, 52071, 41847,  9207, 32126, 52063, 32130,\n",
       "          9211, 41848, 41850, 52057,  9215, 52055,  9217, 52050, 52048,\n",
       "          9220, 52047, 15410, 32086, 52170, 52172, 41807, 52312, 52310,\n",
       "         52305, 52303, 32024, 21165, 21164, 15433,  9069, 52296,  9071,\n",
       "         32030, 32032, 41817, 32040,  9076,  9077, 41818,  9079, 52279,\n",
       "         52277,  9082, 37107, 37104, 52318, 52323,  9031, 52349, 37110,\n",
       "         52346, 52345, 32005, 21178, 52342, 52341, 32008, 41798,  9042,\n",
       "         21175, 52335, 32010, 15440,  9047,  9048, 37109, 52331, 21171,\n",
       "         41802, 15437,  9056, 18239, 32047, 52270, 52210, 52208, 52207,\n",
       "         32077, 52202, 52201,  9122, 52194,  9124, 52192,  9126, 37098,\n",
       "         41832,  9129, 32082, 21137, 52181, 37097, 21135,  9135, 52176,\n",
       "         21134, 52173, 52212, 32050, 41828, 52219, 32051, 32057, 52265,\n",
       "          9090, 52263,  9092, 15429, 52254, 32061,  9096, 52249, 52248,\n",
       "         52243, 21149, 21148,  9102, 32063, 52237, 21146,  9106, 52225,\n",
       "         52224, 37099, 18247,  9710, 42053, 51183, 20597, 10308, 10309,\n",
       "         50273, 33014, 36905, 15166, 50262, 15165, 42274, 36906, 42276,\n",
       "         42280, 10321, 50249, 15161, 18361, 50245, 10326, 33035, 50241,\n",
       "         20584, 33025, 20599, 10304, 50279, 10280], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 888\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 888\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 888\n",
       "    })}}},\n",
       " 'contains_degree': {'feature_present_idx': array([35893, 58860, 52697,  9864,  9819, 58886, 42937,  9776,  9763,\n",
       "         52689, 22719, 42870,  9696, 47905,  9654, 58903, 58855, 22730,\n",
       "         52739,  9909, 16790, 10118, 28215, 10096, 58765, 16801, 42985,\n",
       "         22706, 58771, 28386, 52796,  9991, 42956, 16860, 58826, 22767,\n",
       "         28308, 42787, 58910, 28601, 59151, 42519, 59172,  9243, 47969,\n",
       "         28852, 22627, 28785, 28861, 52540, 48002, 17214, 28972,  9109,\n",
       "         28977, 28999, 42457, 58711,  9386, 28774, 47951, 28626, 58986,\n",
       "          9594, 22672, 28704, 42689, 59124, 59044, 28729, 17041, 42544,\n",
       "          9436,  9435, 28769, 42533, 42685, 43079, 28127, 43087, 10885,\n",
       "         10884, 10859, 58231, 27736, 27746, 10784, 43488, 22991, 22983,\n",
       "         16583, 10749, 58266, 16592, 10639, 27823, 58245, 58407, 58205,\n",
       "         43506, 11057, 57918, 27526, 47529, 23054, 57999, 58043, 58194,\n",
       "         58059, 27589, 47565, 27642, 10944, 43579, 53061, 58192, 43619,\n",
       "         22535, 10564, 47638, 28003, 28015, 28036, 43211, 52873, 10233,\n",
       "         16693, 10284, 47746, 10200, 52866, 43151, 58690, 10184, 43123,\n",
       "         22795, 22813, 16616, 58647, 10320, 10523, 22932, 43401, 58485,\n",
       "         52886, 58525, 43289, 43214, 43287, 10418, 10404, 27924, 10369,\n",
       "         43242, 47742, 43221, 10426, 43674, 59443, 59470, 60564, 41500,\n",
       "         30009,  7763, 41478, 17550, 48405, 22274, 22225, 60702, 30090,\n",
       "         41407, 52177, 52175,  7629, 41526, 29962,  7829, 60549,  8007,\n",
       "         60456, 29852,  7989, 60480, 48278, 22342, 60762, 41642,  7945,\n",
       "         41617,  7924, 60520,  7896, 60530,  7865, 29866,  7618, 60776,\n",
       "         30173, 52130,  7423, 30318, 41228,  7361,  7338, 17718, 48440,\n",
       "         60992, 41203,  7232, 48446, 22165, 61042,  7174, 48462, 22186,\n",
       "         60449, 52133, 17691, 24224, 41377, 60809,  7574, 41334, 41324,\n",
       "         60840,  7452,  7554,  7523, 35900,  7514, 41272, 17666, 17685,\n",
       "         60912, 30214, 29810, 60399,  8023, 17334,  8766, 29321, 59970,\n",
       "         60019, 42150, 29343, 59815, 42128, 60076,  8671, 60089, 29370,\n",
       "         29376, 17365,  8582, 42115,  8530, 42245,  8872, 48046, 42317,\n",
       "          8999, 42289, 48091,  8970, 29167, 59694, 42272, 29179, 42268,\n",
       "         42263, 29228, 29257, 29268, 29270, 59588, 17230, 17368, 29416,\n",
       "         60346, 29647, 29673,  8149,  8141, 41880, 29711, 29618, 29724,\n",
       "         60371, 48261, 60391, 29783,  8071, 41748,  8025, 41806, 29405,\n",
       "         41953, 60262, 42057, 52432, 42017, 29493, 22380, 29507,  8395,\n",
       "          8240,  8385, 41984, 29575, 29578,  8313, 52360, 60246, 52317,\n",
       "         29512, 43679, 11100, 27447, 25207, 13665, 45840, 25240, 13630,\n",
       "         25250, 25309, 47118, 25339, 54036, 13560, 25353, 23659, 55563,\n",
       "         55583, 13702, 13758, 25185, 45901, 23821, 55374, 45997, 13915,\n",
       "         25098, 47038, 13885, 55634, 13879, 55408, 13859, 13854, 15553,\n",
       "         13836, 55471, 45930, 55395, 23643, 55653, 55664, 53931, 13204,\n",
       "         13185, 47173, 13174, 45471, 45468, 55836, 55942, 15735, 13097,\n",
       "         25721, 45448, 13058, 13053, 13049, 23597, 25074, 13222, 53949,\n",
       "         15620, 25426, 45669, 13433, 25490, 25522, 45601, 15683, 53981,\n",
       "         45580, 55758, 25561, 13298, 25582, 45568, 55819, 55750, 54094,\n",
       "         46090, 23869, 54731, 46727, 54747, 46282, 54760, 54769, 14812,\n",
       "         54729, 54793, 46280, 24484, 54869, 54874, 14688, 54888, 24045,\n",
       "         24451, 14664, 15286, 24351, 24231, 24126, 15100, 46537, 15023,\n",
       "         46474, 24079, 15265, 24068, 46386, 14946, 54607, 46717, 14920,\n",
       "         54617, 24340, 15225, 15749, 14658, 46247, 15411, 23924, 55087,\n",
       "         24793, 24809, 15434, 46144, 46911, 24884, 24943, 23886, 55221,\n",
       "         54217, 14072, 55257, 46113, 46137, 24549, 24747, 24736, 14613,\n",
       "         46233, 46231, 14575, 14567, 54913, 54941, 24742, 24614, 46778,\n",
       "         14513, 15387, 24653, 24658, 24702, 14397, 46775, 53787, 56005,\n",
       "         47188, 26777, 26795, 23236, 26862, 11720, 47410, 26911, 23261,\n",
       "         11691, 53282, 11661, 16344, 26941, 57313, 26964, 44294, 23223,\n",
       "         53281, 57093, 11851, 12000, 44482, 26606, 26622, 53412, 11965,\n",
       "         11963, 47374, 23317, 44419, 56957, 44416, 11871, 26750, 23279,\n",
       "         57073, 53407, 44512, 44258, 16367, 23160, 43936, 23127, 11318,\n",
       "         11308, 11300, 11297, 57788, 27280, 27316, 11203, 16471, 53120,\n",
       "         43752, 57884, 53101, 11215, 44256, 27168, 44025, 57435, 57439,\n",
       "         44192, 53214, 57461, 44072, 11540, 27159, 11536, 57562, 11508,\n",
       "         11497, 11494, 44060, 53203, 57664, 57522, 61127, 12025, 16097,\n",
       "         56166, 12725, 47207, 26030, 56239, 45009, 56245, 56158, 12682,\n",
       "         12666, 23570, 23568, 47215, 15920, 12556, 15936, 26072, 53696,\n",
       "         53752, 25996, 12953, 56018, 53779, 56040, 25786, 53774, 25803,\n",
       "         12810, 25808, 25923, 56124, 15861, 25981, 25985, 12823, 25987,\n",
       "         12866, 44538, 23563, 23522, 56510, 56554, 56557, 44689, 44668,\n",
       "         56641, 12131, 44794, 12121, 44606, 44581, 53452, 56700, 26511,\n",
       "         56721, 12057, 56665, 15971, 16065, 12305, 12489, 26253, 56416,\n",
       "         12469, 15996, 12443, 44902, 12285, 23494, 56463, 56469, 26296,\n",
       "         26312, 44848, 47254, 53538, 56456, 17767,  7598, 41163,  2816,\n",
       "         65422,  2805, 50910, 19381,  2769, 34176, 19403,  2750, 37844,\n",
       "         34199, 20987, 65538, 65570, 65571,  2828,  2831, 65412, 37909,\n",
       "         65177, 19309,  2977, 34032, 49458, 34051, 65245, 49644, 65255,\n",
       "         65284, 65305, 21003, 65317, 65336, 19363, 34151,  2907,  2635,\n",
       "         49647, 50840, 34424, 37491, 19599, 19619, 37415,  2329, 65863,\n",
       "          2432, 49682, 37376, 34527,  2231, 65954, 50701, 37361, 65987,\n",
       "         20873,  2991, 65768, 50739, 65592, 50802,  2595, 49662, 34295,\n",
       "          2572, 19529, 65752, 20908,  2530, 34352, 34377, 65700, 50740,\n",
       "         37548, 37527, 19557, 33985, 65110,  3076, 49279,  3689, 18962,\n",
       "         33369, 18971,  3669, 33382,  3742, 38640,  3601, 48476, 64373,\n",
       "         51154, 64399, 64433, 64472,  3606,  3554, 33317, 38700, 51224,\n",
       "         33118, 38798,  3991,  3972, 64142, 38791, 18900, 64172,  3906,\n",
       "         51204,  3863, 64198, 18876, 33183, 49198, 49192, 20857, 19009,\n",
       "         19018, 19138,  3259, 64929,  3256, 19142, 38121, 50960, 19137,\n",
       "         19232, 64959, 21041, 19239, 38064, 38038, 19254, 65038, 33865,\n",
       "         64561,  3290, 33655, 64579,  3492, 51142, 38567, 33517, 33538,\n",
       "         33546, 64916, 51028, 33582, 21076, 64696, 33607, 33611, 38420,\n",
       "         49304, 49303,  4059,  2121, 20804,   719, 66846, 66851, 50344,\n",
       "         20100, 20447, 36177,   531,   481, 20156, 66910, 50152,   442,\n",
       "         49950,   421,   720,   732, 36261, 66797, 35301, 36334, 66690,\n",
       "           890, 66709,   874, 66712, 49962, 35307, 35337,   793, 36322,\n",
       "         50348,   758, 35401, 66778, 66731, 20408, 66920, 35541, 49990,\n",
       "         67195, 67202, 36012, 50006, 20332, 67216, 67179,    80, 35798,\n",
       "         20273, 35923, 67281, 35825, 35921, 35905, 67240, 49912, 36016,\n",
       "         49984, 35553,   318,   317,   306, 66948,   292, 20210, 36019,\n",
       "         35614, 35617,   217, 35625, 66973, 66991, 66996, 67015,   235,\n",
       "           924, 66646,   961, 36995, 20735,  1732, 66176,  1709, 20716,\n",
       "         50531, 19846, 20706, 66229, 34900, 36923, 36865, 19895,  1532,\n",
       "         50524, 66226,  1520, 34840, 34808,  1984, 20801,  1945, 34700,\n",
       "         19764, 49751, 37296,  1801, 37071, 37044, 34792, 37009,  1853,\n",
       "         49784,  1849,  1825,  1906, 19678, 34998, 66304, 66429, 36483,\n",
       "         36474, 66451, 66457, 35249, 66533,  1120, 66544, 36381,  1026,\n",
       "         50374, 36358, 49877,   976, 66620, 66577,  1490, 49841,  1139,\n",
       "          1440, 20638,  1396,  1388, 50455, 36687,  1337, 20625, 66373,\n",
       "         66379,  1248, 49820, 36622, 35114, 36608,  1161,  1314,  4062,\n",
       "         54532, 62980,  6578, 62734, 61640, 31842, 40922,  5539, 40012,\n",
       "          5552,  5568, 48700, 51720, 48689,  5595, 31809, 31006, 31804,\n",
       "          5640, 17891, 38831, 40919, 61697, 18198, 61719,  5660,  6518,\n",
       "          6511, 18187, 51729, 51748, 31062, 61677, 62555,  6629, 62760,\n",
       "         51975,  6716, 17864, 62992,  5202,  5205, 40944, 32109, 51599,\n",
       "         61546], dtype=int64),\n",
       "  'feature_absent_idx': array([39377, 46402, 46406, 13606, 57656, 13608, 29424, 29423, 29422,\n",
       "         57650, 13615, 29414, 29413, 13620, 57643, 57642, 57641, 13626,\n",
       "         29410, 29408, 13631, 29406, 13637, 13638, 46417, 57629, 57628,\n",
       "         57626, 29430, 57662, 29432, 29433, 29462, 57699, 13551, 29461,\n",
       "         13557, 29453, 13564, 13565, 13566, 46389, 13568, 57688, 13571,\n",
       "         13647, 46390, 13577, 29444, 13579, 13582, 46393, 57676, 29436,\n",
       "         57670, 57667, 57666, 13595, 57665, 46399, 57683, 29393, 29392,\n",
       "         29389, 29353, 13701, 29352, 13705, 29350, 29349, 46442, 57579,\n",
       "         57578, 29346, 29345, 46446, 57571, 13698, 13718, 46447, 57570,\n",
       "         29335, 57568, 13725, 57567, 29334, 57566, 13729, 13731, 46449,\n",
       "         29329, 29326, 13719, 46383, 29357, 46439, 29388, 13654, 29387,\n",
       "         57611, 13659, 57609, 29383, 29382, 29380, 57605, 13671, 13672,\n",
       "         29377, 13696, 13675, 57601, 46427, 57599, 29372, 57596, 46428,\n",
       "         57594, 29368, 13688, 13689, 57591, 13692, 46434, 46426, 29465,\n",
       "         46382, 13541, 57825, 57821, 29572, 29569, 13399, 57811, 13405,\n",
       "         57807, 57801, 13410, 29558, 57796, 13415, 29574, 57795, 13422,\n",
       "         13423, 13425, 13426, 29552, 13429, 29549, 29548, 57782, 13435,\n",
       "         29547, 29544, 29543, 46334, 46341, 57835, 57840, 13338, 29615,\n",
       "         57876, 46299, 13344, 13345, 13347, 29608, 29605, 46304, 29602,\n",
       "         57867, 57864, 46317, 29601, 46305, 29597, 13362, 13364, 13365,\n",
       "         57857, 57856, 57850, 46312, 57846, 46314, 46316, 29580, 57860,\n",
       "         46458, 46342, 46343, 13495, 57736, 13498, 29495, 57735, 29490,\n",
       "         13507, 13511, 57731, 13513, 57730, 29483, 29482, 13494, 13519,\n",
       "         57725, 29481, 13524, 46372, 57723, 46374, 46377, 13532, 57718,\n",
       "         57717, 13536, 57715, 29470, 13520, 13441, 46361, 13485, 46344,\n",
       "         13446, 57772, 13448, 57770, 29532, 13454, 57768, 57766, 29529,\n",
       "         57762, 46349, 29526, 57741, 29525, 46350, 29522, 13466, 13467,\n",
       "         29521, 46353, 57753, 57750, 29516, 13476, 29508, 29504, 57745,\n",
       "         13463, 46294, 29320, 57550, 46572, 14028, 57336, 57334, 14033,\n",
       "         14034, 14035, 29115, 29114, 57329, 46573, 29111, 57325, 29110,\n",
       "         29107, 29105, 46575, 29098, 14054, 14056, 29097, 14059, 29094,\n",
       "         14062, 46582, 57306, 57305, 14026, 29119, 29123, 14021, 13974,\n",
       "         13975, 13976, 29152, 46558, 57367, 13986, 29149, 13988, 57366,\n",
       "         57365, 57362, 29147, 29086, 57359, 57352, 57350, 29140, 29139,\n",
       "         29135, 29133, 46563, 57344, 29131, 46564, 29127, 57341, 57339,\n",
       "         29146, 57303, 14073, 57301, 14135, 29042, 57247, 29041, 29040,\n",
       "         29039, 14143, 46617, 14146, 29035, 29033, 57237, 29032, 14134,\n",
       "         57232, 14157, 14158, 29029, 57227, 29028, 14162, 14163, 14164,\n",
       "         57224, 46632, 14169, 57221, 29020, 57230, 13973, 46609, 57251,\n",
       "         57299, 14078, 14079, 57297, 46588, 14085, 46589, 46591, 29071,\n",
       "         14091, 57283, 14099, 14102, 14131, 46602, 14110, 14111, 29058,\n",
       "         14113, 57266, 57265, 46603, 57261, 57257, 57256, 57254, 14127,\n",
       "         57252, 57271, 29161, 57381, 13964, 13804, 13808, 57502, 46480,\n",
       "         57501, 13815, 46482, 57493, 46486, 13823, 13825, 46487, 46488,\n",
       "         13801, 13829, 46490, 29254, 46493, 29252, 46494, 13840, 29249,\n",
       "         57480, 46495, 57468, 29239, 46510, 46511, 46489, 46513, 13799,\n",
       "         13796, 46462, 57544, 29308, 29306, 29305, 29304, 29303, 13767,\n",
       "         13772, 13773, 13774, 13776, 13778, 57511, 57526, 57524, 29287,\n",
       "         46472, 57518, 57516, 13788, 46473, 29284, 13791, 57513, 46475,\n",
       "         13794, 13795, 57525, 29317, 13864, 13868, 46536, 29191, 46538,\n",
       "         57420, 46542, 13933, 57415, 57413, 13936, 13937, 29184, 13941,\n",
       "         57405, 57422, 57403, 29177, 57399, 13950, 46546, 57395, 29175,\n",
       "         57392, 57391, 57389, 13958, 29170, 13961, 57386, 57401, 13867,\n",
       "         13921, 57423, 13869, 29229, 13872, 29226, 46518, 57450, 57447,\n",
       "         29219, 57442, 57441, 29214, 29213, 57437, 13920, 46530, 29205,\n",
       "         57430, 13900, 13901, 57429, 57428, 29200, 13908, 57427, 29199,\n",
       "         57425, 29196, 29194, 57433, 46638, 13333, 13329, 30023, 30020,\n",
       "         46013, 46016, 58318, 58316, 12762, 12763, 58311, 46018, 12768,\n",
       "         12769, 12770, 12771, 12773, 30007, 12777, 58310, 30005, 30004,\n",
       "         12782, 58305, 46023, 58301, 46024, 58297, 29997, 30024, 46008,\n",
       "         46007, 46006, 12696, 58358, 30064, 58357, 58354, 45990, 12707,\n",
       "         58349, 12710, 12711, 30054, 12714, 30052, 46028, 45993, 45994,\n",
       "         12721, 12723, 30044, 30040, 58340, 58337, 30036, 58333, 30035,\n",
       "         30033, 12739, 12742, 12717, 58294, 58292, 12799, 58242, 12858,\n",
       "         29950, 58240, 12862, 58239, 12865, 58237, 58236, 29943, 12877,\n",
       "         12878, 12880, 58243, 46063, 46066, 58215, 12892, 46067, 12894,\n",
       "         29929, 12898, 46071, 12901, 46075, 29920, 29915, 58208, 58221,\n",
       "         58360, 58246, 12852, 58286, 58285, 29988, 12805, 29987, 12807,\n",
       "         29986, 58283, 12811, 12812, 12813, 58277, 58274, 12854, 46036,\n",
       "         12824, 58267, 12826, 12829, 29971, 12835, 29969, 46047, 46049,\n",
       "         29957, 29956, 58254, 12851, 29979, 12693, 58361, 58363, 58488,\n",
       "         12527, 12530, 30191, 12534, 30188, 30185, 30184, 45923, 30180,\n",
       "         12544, 58476, 12546, 58489, 30178, 12550, 45927, 58465, 30170,\n",
       "         12557, 45929, 30168, 12562, 58460, 45935, 12568, 30157, 58450,\n",
       "         30177, 12574, 30200, 30203, 30232, 58526, 58519, 45899, 45900,\n",
       "         45903, 12484, 30224, 45904, 30222, 12490, 12491, 30221, 58491,\n",
       "         12494, 58513, 30217, 30216, 30213, 30212, 58506, 12506, 58502,\n",
       "         30209, 12510, 12512, 58496, 30208, 12495, 58207, 45939, 58444,\n",
       "         12633, 12634, 30103, 45968, 45969, 12644, 30097, 58389, 58388,\n",
       "         58385, 12653, 58380, 30087, 30116, 30086, 12663, 12664, 12667,\n",
       "         45976, 58373, 12675, 12676, 30071, 45984, 45986, 58367, 30067,\n",
       "         58364, 12661, 12581, 58411, 58413, 12583, 58443, 58442, 12586,\n",
       "         58439, 58438, 30147, 45945, 12592, 30145, 30144, 12595, 12596,\n",
       "         30117, 12597, 58434, 30143, 30141, 58429, 58428, 45948, 30133,\n",
       "         30130, 30126, 45953, 58416, 30121, 58415, 12598, 29622, 46088,\n",
       "         12915, 29717, 46228, 46237, 46239, 13183, 29709, 57978, 57977,\n",
       "         13190, 29708, 13193, 57975, 57974, 57973, 29705, 46241, 13201,\n",
       "         57972, 29703, 57971, 29701, 29700, 13209, 57968, 13214, 29696,\n",
       "         13217, 13176, 57988, 13173, 57990, 58034, 58032, 29745, 58030,\n",
       "         58029, 46198, 46199, 58021, 58017, 29735, 46209, 13146, 29731,\n",
       "         13219, 13148, 13151, 58006, 13154, 58000, 57998, 13160, 13161,\n",
       "         29727, 29726, 13167, 46214, 29720, 57991, 13149, 13221, 29693,\n",
       "         29692, 13280, 57919, 57911, 57908, 57907, 13288, 13290, 13292,\n",
       "         13293, 13295, 13301, 57901, 57900, 57922, 57899, 29640, 13307,\n",
       "         46284, 13311, 29635, 46287, 13317, 57887, 13322, 29628, 29624,\n",
       "         57885, 13328, 57898, 58036, 57924, 13274, 57960, 13233, 46258,\n",
       "         29683, 57955, 29675, 57953, 13243, 46268, 46271, 13247, 13249,\n",
       "         29666, 29654, 29661, 57940, 46274, 13259, 57938, 57937, 57933,\n",
       "         29658, 29656, 13269, 57929, 13271, 57927, 13273, 13255, 58037,\n",
       "         29750, 29751, 46124, 29870, 12969, 12970, 12971, 12973, 58152,\n",
       "         58151, 29867, 12983, 46128, 29857, 12987, 12964, 29856, 46129,\n",
       "         29851, 29849, 46130, 58132, 58130, 29845, 13002, 13003, 46135,\n",
       "         58122, 58118, 58112, 12989, 46138, 29875, 12960, 58203, 29907,\n",
       "         58200, 58197, 29903, 58195, 58191, 29899, 46100, 12930, 46110,\n",
       "         29891, 29887, 58158, 46117, 12943, 58178, 29883, 12947, 12948,\n",
       "         29882, 46120, 12951, 12952, 29880, 29879, 58163, 29876, 58179,\n",
       "         46089, 13014, 13016, 58060, 13079, 13081, 29776, 46180, 13084,\n",
       "         58057, 46182, 29771, 46183, 46184, 29765, 13095, 46172, 13096,\n",
       "         58052, 46187, 13101, 13103, 58049, 13106, 58046, 13108, 29758,\n",
       "         29757, 13112, 29754, 58039, 13098, 58110, 29782, 46168, 29834,\n",
       "         13020, 29831, 29830, 58106, 46146, 29825, 13028, 13029, 29822,\n",
       "         13037], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_destination': {'feature_present_idx': array([ 1048, 66468, 62455, 58639, 48836, 43916, 39551, 30107, 24467,\n",
       "         17819, 14642, 12331, 38940,  8265, 57652, 36096,  4712, 57732,\n",
       "         57783, 39546, 63231, 45916, 57588, 10333,  7481, 32984, 38222,\n",
       "         38621,  1301, 39387, 26475, 24718, 65625,  7639, 57390, 24456,\n",
       "         53749, 51857, 65140, 62228, 43411, 43137, 12716, 18289, 55798,\n",
       "         54294, 46677, 40799, 50670, 40882, 56129, 53400, 46313, 36147,\n",
       "         47884, 51147, 55532, 55216, 50303, 33463, 65501, 12138, 15695,\n",
       "         63626, 63344,  6717, 21477, 33466, 22024, 58720, 22866,  5788,\n",
       "         25122, 10956, 58010, 57668,  2999, 57631,  9247, 31292, 31475,\n",
       "         14836, 13573, 61865, 58344, 57203, 65178, 41423, 66843, 46059,\n",
       "         10935, 13584, 14987, 17232, 17314, 18157, 21836, 27122, 47610,\n",
       "         29906, 27330, 42747, 45003,  3213, 45221, 37952, 35918, 53451,\n",
       "         15667, 30330, 39744,  1550, 21240, 62004,  1927, 22282, 66708,\n",
       "         63313,  3082, 29687, 51514, 59671, 26963, 17301, 61596, 34294,\n",
       "         57538, 52572, 45964, 27689, 52232,  9117], dtype=int64),\n",
       "  'feature_absent_idx': array([10511, 43828, 12490, 12491, 62479, 12494, 12495, 43827, 26983,\n",
       "         26982, 43825, 62475, 56734, 26974, 12506, 12510, 12512, 43816,\n",
       "         26965, 56742, 56746, 56747, 56748, 12527, 62461, 12530, 26948,\n",
       "         12534, 26987, 56726, 56725, 12484, 38616, 12431, 49994, 62497,\n",
       "         56706, 56710, 27022, 27018, 49999, 12446, 12447, 12448, 27013,\n",
       "         38647, 12452, 43839, 12459, 12460, 62490, 62489, 12468, 27000,\n",
       "         52037, 43833, 43831, 50000, 62483, 56724, 12454, 26940, 62456,\n",
       "         12544, 12598, 62427, 62426, 38654, 26906, 26905, 38655, 62423,\n",
       "         26899, 43784, 26897, 56765, 50016, 12597, 62418, 38664, 26878,\n",
       "         12633, 12634, 38666, 26870, 52016, 56775, 12644, 26865, 62410,\n",
       "         26863, 26860, 43780, 12428, 12596, 12592, 56750, 12546, 62454,\n",
       "         43803, 26936, 12550, 62452, 26932, 12557, 12562, 38651, 43798,\n",
       "         62443, 12595, 12568, 62442, 12574, 43794, 26918, 26915, 12581,\n",
       "         62435, 12583, 43791, 12586, 62431, 52023, 26910, 26920, 62500,\n",
       "         56704, 43852, 12267, 49973, 27144, 62551], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 132\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 132\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 132\n",
       "    })}}},\n",
       " 'contains_direction': {'feature_present_idx': array([   88, 43141, 42103, 41911, 40335, 39588, 37691, 37053, 36313,\n",
       "         35870,  9001, 35583,  9448, 34273, 33464, 32850, 30225, 29603,\n",
       "         14453, 15879, 15989, 16447, 16680, 17352, 50540, 17631, 21167,\n",
       "         21260, 22279, 22954, 26038, 10756, 20031, 52015, 15422,  2492,\n",
       "         61068, 59918,  1656, 58232,  1596, 61324,  1302, 62828, 61664,\n",
       "         60448, 63882, 65436, 64029,   658, 31002, 32049, 16060, 66529,\n",
       "         61279, 28375, 16101, 28214, 27817, 26783, 66414, 26534, 18639,\n",
       "         25667, 24813, 24548, 24012, 33147, 22408, 21997, 21989, 61684,\n",
       "         20544, 63413, 19642, 64665, 25688, 51861, 35260, 53674, 53054,\n",
       "         42481, 42772, 43136, 52897, 43552, 41562, 44542, 45963, 47643,\n",
       "         48039, 48151, 49602, 50367, 52768, 45352, 52655, 41029, 40561,\n",
       "         59937, 35616, 59281, 36055, 57875, 36964, 56948, 40915, 37247,\n",
       "         38470, 38929, 39366, 54942, 15669, 39683, 54549, 55616, 39594,\n",
       "         32698, 11899,  6015,  7664, 10712, 12881,  5888, 12856, 10994,\n",
       "          2862,  2773,  2776, 11162, 10448,  2950,   189,  5730, 25836,\n",
       "         29889, 10676, 28991, 45344, 54088, 24512, 24525, 11852, 43802,\n",
       "         24633, 28315, 54198, 27151, 45784, 55554, 26763, 55609, 41289,\n",
       "         41431, 46767, 25370, 25627, 26103, 11504, 25933, 57472, 11021,\n",
       "         54168, 30271, 48758, 35611, 35743, 35775, 35891, 36146, 36400,\n",
       "         35441, 46533,  8436, 39712, 47737,  7798,  8309, 47579, 39266,\n",
       "         46766, 49056, 49068,  4903,  7375, 10222, 31213, 31512,  3734,\n",
       "         40285, 52660, 32647, 52104, 32736, 32910, 33179,  5557, 33950,\n",
       "         34039, 50691,  4837, 53756, 53721, 26152, 43526, 44864, 65515,\n",
       "         43693,   352,  6503, 20243, 65409, 65238, 20007, 61692, 16795,\n",
       "         60302,   475, 19484, 13515, 17378, 19073, 18836,  5978, 18318,\n",
       "         64513, 18289, 63854, 64334, 19561,   205, 64008, 15087, 59692,\n",
       "         45048, 23442, 59902, 66957, 23290, 23043, 12128, 59693, 12126,\n",
       "         37275,  8219, 43737, 16909,  5308, 39166, 39219, 33255, 15318,\n",
       "         51418,  7861, 17487, 10007,  4031,  7821, 10048, 46779, 51030,\n",
       "         49228, 16631, 66568, 14627, 66279, 44253, 36749, 36424, 65746,\n",
       "         48251, 13798, 37652, 39903, 13742,  8349, 16106, 38339, 35668,\n",
       "         35629, 48406, 16362,  9170, 48653, 43779, 38623, 38099,  8785,\n",
       "         23997, 32648, 26800, 61032, 60826, 26688, 60377, 26503, 60144,\n",
       "         44915,  3184, 12480, 12433,  6953, 25896, 22076, 25741, 11253,\n",
       "         22483, 25613, 25454, 22538, 22566, 24719, 59436, 24594, 24557,\n",
       "          6865, 58977, 21237, 52228,  7074, 21217,  3807, 32236, 31763,\n",
       "          3585, 59002, 62921, 40801,  3490, 30523, 44263, 29961, 61090,\n",
       "         19614, 44352, 29721, 53770, 29386, 28543, 13073, 61366, 44708,\n",
       "         28100, 40828, 40903, 54799, 29836, 39592, 46202, 45771, 45911,\n",
       "         15233, 47735, 58595, 59272, 59967,  1833,  1630,  1315,  1240,\n",
       "         58384, 61838, 63013, 63108, 63801,   751, 64963, 65960, 66843,\n",
       "         62046, 58327, 58093, 56960, 47919,  5017, 48167, 48274,  4931,\n",
       "         51324, 52754, 52908, 52925, 53242, 53477, 54523,  3468, 55160,\n",
       "         55190,  3213, 56687, 46957, 43999, 67320, 43739, 28352, 38935,\n",
       "         38648, 25956, 21283, 10812, 37375, 18175, 16207, 26754, 28479,\n",
       "         26962,  9158, 26984, 35499, 27034,  9513, 34920, 21225, 17223,\n",
       "         34745,  9669, 12731, 21192, 15142, 29659, 12300, 21536,  6543,\n",
       "         31280, 21344, 23580, 19432, 42357, 21332, 42069, 23998, 13202,\n",
       "         15860, 41785,  7180, 30971, 30733, 39905, 13481, 67213, 39766,\n",
       "         29930, 13985, 20737, 10892, 30244, 56491, 43958, 21492, 23863,\n",
       "         24021,  2076, 58356, 11844, 60568, 60767,  3107, 57830, 21299,\n",
       "         57205, 26359, 19344, 61057, 27771, 31522, 52093, 19008, 47964,\n",
       "         37651, 38388, 15992, 47523,  7834, 39756, 13843,  5305, 46217,\n",
       "         40377, 42004, 66665, 66818, 15626, 44653, 15507,  6260, 66142,\n",
       "         62978, 65415,  9860,  1155, 32484, 52285, 32728, 21547, 32990,\n",
       "          4623, 48479, 33476, 18190, 21751, 18069, 64603, 49098, 35472,\n",
       "           746, 13780, 20780, 66219, 13487, 15767, 19603, 63755, 16432,\n",
       "         18799, 65938, 13744, 55073, 52236, 44695, 42433, 44851,  6656,\n",
       "         40114, 39520,  8470, 34801, 49896, 34329, 50893, 52658, 10213,\n",
       "         31836, 27169, 39426, 59353, 23970, 24239, 55038,  3306, 25682,\n",
       "         20718, 22703, 15741, 25216,  8547,  8686, 17106, 18043, 34294,\n",
       "         64690, 59879, 31504, 22011, 52446, 55135, 30640, 45759, 45964,\n",
       "         46506, 55440, 47660,  3536, 41819, 63180, 49880, 33776, 53840,\n",
       "         42793, 26143,  8474, 25048, 47561, 31613,  1158, 22503,  1533,\n",
       "         26565], dtype=int64),\n",
       "  'feature_absent_idx': array([27955, 49383, 27707, 27703, 49378, 64756, 49377, 12707, 27701,\n",
       "         12710, 12711, 12714, 49374, 49373, 27708, 12717, 27693, 12723,\n",
       "         49369, 41649, 41650, 27688, 41653, 27686, 41655, 49362, 41658,\n",
       "         12739, 27676, 12721, 12742, 12696, 12693, 49411, 12653, 41631,\n",
       "         61650, 64766, 58796, 27735, 12661, 27733, 12663, 12664, 41634,\n",
       "         27731, 27710, 12667, 27726, 27725, 12675, 12676, 27723, 49398,\n",
       "         41638, 27715, 57208, 49391, 27713, 27712, 57209, 49400, 41628,\n",
       "         49360, 27658, 12807, 12811, 12812, 12813, 27616, 41695, 64737,\n",
       "         27612, 57224, 49315, 12824, 12826, 41697, 27620, 27607, 27606,\n",
       "         27605, 49309, 12835, 41703, 27593, 27591, 27590, 12851, 12852,\n",
       "         49294, 12854, 27586, 12829, 41664, 12805, 41694, 49350, 57218,\n",
       "         27656, 49345, 41671, 12762, 12763, 27653, 27650, 12768, 12769,\n",
       "         12770, 12771, 27621, 12773, 64749, 49340, 27641, 64748, 12782,\n",
       "         64747, 27638, 27637, 27631, 27625, 12799, 57221, 27624, 12777,\n",
       "         41706, 41626, 12644, 12495, 27864, 49486, 27863, 57188, 27861,\n",
       "         27860, 64806, 12506, 58814, 49474, 12510, 41558, 12494, 12512,\n",
       "         49468, 41565, 41566, 27845, 49466, 12527, 49463, 12530, 12534,\n",
       "         41572, 27831, 27828, 61627, 49471, 12544, 12491, 49489, 61607,\n",
       "         49516, 41530, 58821, 49511, 49509, 12446, 12447, 12448, 61608,\n",
       "         12452, 49508, 12454, 12490, 49507, 12459, 12460, 58820, 27891,\n",
       "         49503, 61611, 12468, 27883, 49500, 27877, 49493, 12484, 49490,\n",
       "         41533, 61648, 49456, 41580, 12595, 12596, 12597, 12598, 49434,\n",
       "         61637, 49431, 58799, 64779, 27776, 49425, 41614, 64778, 12592,\n",
       "         58797, 49424, 49421, 61641, 27763, 27758, 27757, 12633, 12634,\n",
       "         41624, 27754, 61646, 49418, 61647, 64776, 12546, 27791, 49437,\n",
       "         64797, 12550, 27820, 61629, 41582, 12557, 58809, 41584, 27811,\n",
       "         12562, 49450, 64792, 61632, 27792, 12568, 49446, 49445, 12574,\n",
       "         49444, 27801, 27799, 12581, 41591, 12583, 27796, 49439, 12586,\n",
       "         41593, 27805, 12858, 49291, 49290, 27386, 57261, 61733, 27381,\n",
       "         49133, 49131, 49130, 27376, 27374, 13146, 57265, 13148, 13149,\n",
       "         49140, 49125, 49124, 64668, 13154, 57266, 27371, 13160, 13161,\n",
       "         41798, 61734, 27365, 13167, 27364, 27363, 13151, 61735, 27388,\n",
       "         27389, 13079, 13081, 13084, 27417, 49164, 27413, 13095, 13096,\n",
       "         27409, 13098, 57256, 27408, 13101, 49143, 13103, 13106, 61729,\n",
       "         13108, 27402, 13112, 27401, 57257, 49153, 27399, 27398, 61730,\n",
       "         27395, 27394, 49160, 41777, 27361, 13173, 13221, 49088, 49087,\n",
       "         61742, 49084, 27319, 13233, 49082, 27317, 41828, 27314, 64650,\n",
       "         49078, 49089, 13243, 13247, 13249, 27306, 27304, 49067, 13255,\n",
       "         13259, 49062, 64646, 27298, 49060, 49059, 27294, 41832, 49111,\n",
       "         13219, 64654, 27360, 27359, 13176, 27356, 41802, 49108, 13183,\n",
       "         64663, 58754, 64662, 41807, 49102, 13190, 13217, 27349, 57271,\n",
       "         61737, 41817, 13201, 27337, 61739, 49094, 13209, 41818, 49091,\n",
       "         27331, 27329, 13214, 13193, 41776, 49168, 41775, 41719, 27561,\n",
       "         27557, 41722, 49263, 27548, 12915, 64721, 41729, 27535, 49255,\n",
       "         49254, 12930, 12901, 41731, 57237, 61695, 27527, 12943, 61698,\n",
       "         27516, 12947, 12948, 41738, 12951, 12952, 61700, 49241, 27531,\n",
       "         12960, 41718, 12898, 12862, 64730, 12865, 27582, 27581, 64728,\n",
       "         49284, 57227, 58781, 58780, 49281, 27576, 12877, 58776, 12878,\n",
       "         58779, 57230, 27573, 64725, 27571, 57232, 49272, 49271, 12892,\n",
       "         27568, 12894, 27567, 49269, 12880, 27506, 12964, 41741, 13028,\n",
       "         13029, 27458, 41762, 49196, 57251, 13037, 13040, 27451, 27449,\n",
       "         57252, 49186, 58769, 27459, 49185, 13052, 49182, 27439, 49181,\n",
       "         41772, 41773, 27431, 13065, 27430, 61727, 49174, 49173, 57254,\n",
       "         61724, 57247, 49202, 13020, 41742, 49235, 12969, 12970, 12971,\n",
       "         41744, 12973, 27500, 61704, 41747, 49226, 12983, 64704, 12987,\n",
       "         12989, 27486, 61709, 58770, 49219, 13002, 13003, 49216, 64699,\n",
       "         49215, 27471, 13014, 13016, 61717, 27464, 64814, 27908, 64816,\n",
       "         12431, 58865, 11832, 49825, 11834, 41270, 28361, 28350, 64948,\n",
       "         11848, 11850, 41279, 41282, 28341, 11830, 28337, 49809, 11861,\n",
       "         64943, 64941, 28333, 57112, 28331, 49803, 11874, 41296, 11876,\n",
       "         49800, 11882, 41290, 28316, 11828, 11826, 11785, 49851, 61507,\n",
       "         49847, 64956, 61508, 41257, 28388, 11802, 28383, 11804, 11805,\n",
       "         11806, 11827, 28382, 11811, 28378, 49837, 41262, 28374, 61510,\n",
       "         11817, 57107, 28371, 28370, 11821, 49831, 41266, 11809, 11784,\n",
       "         11885], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 577\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 577\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 577\n",
       "    })}}},\n",
       " 'contains_domain': {'feature_present_idx': array([38730, 62404, 62375,  7285, 47765,  7343,  7346,  7355, 62314,\n",
       "         26540, 47896, 26439, 47977, 48017, 26303,  7578, 26885,  7169,\n",
       "         26887, 26938, 62824, 46988, 27596, 27551, 27525, 27514, 47060,\n",
       "          7588, 47090, 62718, 27219, 47375, 27019, 27011, 47536, 47581,\n",
       "         27392,  7617,  7692, 62141, 24954,  8466, 24890, 49159,  8546,\n",
       "         61502,  8603, 61591, 24635, 49386,  8744,  8897, 49547, 49565,\n",
       "         24123, 49641, 61412, 46945, 49018,  8218, 26047, 26032, 62125,\n",
       "         62092, 48352, 62051, 48412,  8228, 25883, 48425, 61982, 25758,\n",
       "          8038, 61857, 61848, 48747, 25882, 46929,  6513,  6435, 44929,\n",
       "          4922,  4937, 30235, 63826,  5030, 45211, 63862, 29985, 45313,\n",
       "         63743, 29748, 29695, 29663, 45452, 45524, 45217, 45541, 63873,\n",
       "         44785, 43822, 43984, 64085, 31122, 31066, 30996, 64024, 44912,\n",
       "         44147, 30811, 30669,  4645,  4658, 30554, 30531,  4698, 44249,\n",
       "         24061, 29536, 29503, 28531, 28467, 28412,  5986, 63132, 28249,\n",
       "         28220, 46288, 28132, 46765, 27853,  6365, 62874, 27800,  6415,\n",
       "          6428, 27995, 63668, 46195, 28916, 63648, 45698, 45781, 29420,\n",
       "         29342,  5420, 29294, 46125,  5481, 29185, 29181, 29137, 63494,\n",
       "         29084, 45996, 46068,  5491, 61111, 49860, 23964, 12602, 17686,\n",
       "         17665, 54687, 16672, 58563, 16589, 54494, 13091, 58401, 16449,\n",
       "         16410, 55273, 16298, 16280, 16120, 55162, 58313, 58871, 12463,\n",
       "         18797, 18677, 53968, 18674, 59227, 12136, 18641, 12535, 12170,\n",
       "         12245, 54182, 18413, 12299, 12340, 12397, 18276, 18481, 18934,\n",
       "         55673, 55707, 14145, 57454, 56715, 14173, 14898, 14878, 14230,\n",
       "         56705, 57380, 14290, 56834, 14370, 56977, 57029, 57064, 57094,\n",
       "         14810, 15990, 56666, 15269, 15916, 15811, 15794, 15492, 13627,\n",
       "         56370, 15401, 56531, 56429, 13811, 56468, 57754, 13850, 13861,\n",
       "         13888, 57619, 57820,  4286, 59267, 59277,  9995, 22494, 22448,\n",
       "         22197, 10053, 10111, 51430,  9938, 51565, 51592, 51686, 21558,\n",
       "         21397, 21386, 21212, 21166, 21955, 21115, 51035, 50939, 61100,\n",
       "         23926, 23757, 61079,  9265,  9273, 61053, 22751,  9378,  9411,\n",
       "         50436,  9642, 23034,  9685, 50720, 50823, 50207, 53738, 60282,\n",
       "         20954, 19986, 59785, 19927, 19887, 59745, 19623, 11606, 11386,\n",
       "         53292, 53350, 11721, 19305, 38689, 59310, 11907, 53678, 19548,\n",
       "         10774, 59848, 11311, 20901, 20850, 20837, 52583, 52601, 20675,\n",
       "         20626, 52972, 52648, 11081, 52687, 11111, 20347, 20275, 20262,\n",
       "         59988, 20493, 43777, 62315, 64178, 41169, 34844, 32624,  3257,\n",
       "         40432, 37597, 36072, 41258, 40017, 32645, 36229, 66307,  2261,\n",
       "         66535, 34807, 40406, 41793, 65721, 35058, 39532, 37732, 32386,\n",
       "         40871, 43074,   468, 43039, 32422, 33614,  2647, 34984, 65423,\n",
       "         32535, 40157, 36345, 64762, 66148, 36456, 41454, 34471, 42486,\n",
       "         41613, 42485, 33125, 42432, 41542,  2994, 32975, 40175, 66282,\n",
       "          2953, 42449, 32855, 64858, 34492, 41749, 66770, 34597,  3123,\n",
       "         37515, 42719, 32778, 42334, 40126, 36541, 41652, 41392, 37450,\n",
       "         37374, 32807, 42142, 39127, 35872,  3474, 64305,  3721, 35327,\n",
       "         33712,   888, 31830, 43613, 65802, 64287, 35211, 31601, 33640,\n",
       "         35231, 38808, 39624, 38963, 38930,   992, 38875,  3877,  2381,\n",
       "         40784, 39713, 67110, 38501, 41854, 35744,  3718,  2320, 43186,\n",
       "         66413,   370,   832, 31402, 35520, 33870, 31377,  3579, 35356,\n",
       "         35647,    67, 36725, 31423, 38626, 33799, 43421,  2532, 66511,\n",
       "         32068, 39036, 31490, 34015, 36730, 43509, 31519, 53089, 36724,\n",
       "         36535, 19906, 18959, 19907, 18994, 53697, 40038, 53164, 53558,\n",
       "         19236, 53530, 19213, 19281, 19178, 19170, 39806, 39929, 19331,\n",
       "         53575, 19158, 53473, 39946, 39971, 53340, 53667, 53322, 39804,\n",
       "         19604, 19050, 36719, 19608, 19624, 53232, 53133, 40140, 20393,\n",
       "         20051, 21390, 21360, 52039, 21279, 52060, 52122, 21216, 40732,\n",
       "         40712, 52189, 52220, 21118, 40586, 52292, 21092, 35725, 21050,\n",
       "         51950, 51926, 40832, 21902, 21839, 51603, 21810, 51606, 21763,\n",
       "         51650, 21685, 51800, 21657, 21644, 21615, 40774, 51872, 51938,\n",
       "         40584, 21033, 21008, 20363, 36372, 20335, 52702, 52736, 40343,\n",
       "         40294, 20254, 36452, 52793, 20237, 52800, 20172, 52956, 36479,\n",
       "         36747, 20459, 36281, 20502, 52447, 35926, 52515, 40485, 20889,\n",
       "         35979, 35982, 19958, 20809, 20730, 52602, 36098, 36215, 52652,\n",
       "         20516, 20503, 20782, 53751, 54268, 39779, 55979, 56088, 56123,\n",
       "         15729, 56159, 56233, 15579, 56263, 39159, 56295, 56336, 56362,\n",
       "         39144, 37760, 15397, 15390, 56460, 39172, 39054, 55802, 15934,\n",
       "         55463, 55555, 16206, 16198, 16197, 16160, 16133, 16131, 37555,\n",
       "         16069, 39227, 55590, 16018, 37613, 15975, 55679, 39178, 37670,\n",
       "         55442, 37917, 37983, 38403, 38405, 14873, 14828, 38548, 38799,\n",
       "         56837, 56860, 14759, 56922, 38745, 56938, 14601, 38733, 38669,\n",
       "         14557, 57097, 38345, 37934, 38253, 15025, 39045, 15351, 56480,\n",
       "         15312, 15304, 15301, 56523, 56527, 38071, 38123, 15200, 38132,\n",
       "         15180, 15102, 15039, 15030, 15027, 38230, 18839, 39234, 55290,\n",
       "         18333, 54220, 18207, 18200, 18193, 54278, 54279, 18165, 18135,\n",
       "         54344, 39440, 18075, 54393, 54432, 17967, 17935, 17895, 18345,\n",
       "         17867, 39547, 39548, 18764, 53869, 36781, 36826, 36852, 36860,\n",
       "         18667, 39656, 54012, 18601, 18576, 18491, 54149, 18473, 18439,\n",
       "         39573, 37007, 54196, 39275, 17813, 37209, 54994, 54995, 39419,\n",
       "         37346, 16641, 16637, 16635, 16600, 55064, 55070, 16521, 16500,\n",
       "         37484, 37502, 39310, 16430, 55271, 16710, 37177, 16764, 54834,\n",
       "         17765, 37238, 54504, 37259, 37280, 17652, 17630, 17529, 17474,\n",
       "         54680, 17393, 17361, 37318, 17026, 54825, 54830, 16941, 16821,\n",
       "         51460, 23021, 51323, 46686, 27906, 32779, 46777, 27884, 27869,\n",
       "         42713, 46672, 42633, 32918, 42546, 27795, 27773, 46898, 27761,\n",
       "         27744, 46840, 28168, 28175, 28204, 42796, 28641, 28533, 32658,\n",
       "         46364, 28514, 46419, 42780, 46440, 32742, 46534, 46592, 28362,\n",
       "         28339, 42721, 28262, 32765, 27687, 27671, 46944, 27623, 33351,\n",
       "         42195, 26970, 33385, 47667, 26907, 42180, 33430, 42152, 33508,\n",
       "         47753, 26852, 42145, 47769, 26712, 26711, 33622, 47517, 46136,\n",
       "         33329, 27031, 42482, 27570, 33005, 33038, 33106, 27482, 27437,\n",
       "         27273, 47230, 33202, 47234, 27233, 47319, 42310, 47401, 27074,\n",
       "         47477, 42307, 26687, 42835, 28787, 31667, 31695, 31720, 30496,\n",
       "         43686, 44888, 44904, 30629, 30339, 43651, 30328, 31885, 31896,\n",
       "         30258, 45068, 45109, 43677, 31663, 44515, 30690, 43837, 31275,\n",
       "         43876, 43920, 31206, 43938, 43949, 31124, 43755, 31542, 44140,\n",
       "         31552, 30942, 44271, 31619, 44368, 44460, 45121, 43559, 31951,\n",
       "         43507, 29275, 29236, 29215, 45867, 32467, 32491, 42997, 29151,\n",
       "         42983, 45912, 32568, 29118, 32580, 28951, 42855, 46044, 46104,\n",
       "         45844, 28757, 45829, 29403, 29839, 29832, 43331, 29716, 43298,\n",
       "         29611, 29604, 32128, 43279, 43209, 32300, 29460, 43093, 32381,\n",
       "         29438, 45748, 32383, 45821, 40841, 26648, 33672, 41286, 41283,\n",
       "         23903, 23712, 23691, 49967, 49991, 23953, 49998, 50032, 50101,\n",
       "         41139, 50211, 41119, 23263, 50224, 23496, 34735, 41341, 23969,\n",
       "         24385, 24359, 24336, 34591, 24256, 49589, 24197, 24138, 49637,\n",
       "         34609, 24095, 34660, 24059, 49812, 23995, 34677, 23984, 23240,\n",
       "         23206, 50339, 50362, 51019, 22678, 22646, 22633, 51036, 35266,\n",
       "         22583, 22524, 51106, 35273, 22449, 22400, 22283, 40905, 51291,\n",
       "         22167, 51310, 50971, 24416, 40924, 35201, 23153, 23072, 50529,\n",
       "         35087, 50538, 40993, 40949, 50598, 22996, 22959, 22957, 50690,\n",
       "         22933, 50712, 35179, 22898, 22889, 50827, 57106, 49441, 24510,\n",
       "         26111, 26108, 41930, 33879, 26019, 41926, 25993, 26112, 33952,\n",
       "         48391, 25928, 48396, 41904, 41868, 34076, 25835, 33965, 41987,\n",
       "         26168], dtype=int64),\n",
       "  'feature_absent_idx': array([39735, 13564, 13565, 13566, 13568, 57924, 13571, 57922, 57919,\n",
       "         13577, 29640, 13579, 13582, 29635, 57927, 57911, 57907, 46802,\n",
       "         57901, 57900, 57899, 13595, 57898, 29628, 46804, 29624, 29622,\n",
       "         13606, 13608, 57908, 57887, 46787, 57929, 46759, 29683, 13507,\n",
       "         46769, 13511, 57960, 13513, 29675, 13519, 13520, 57955, 13524,\n",
       "         57953, 13557, 29666, 29661, 46783, 13536, 46784, 29658, 29656,\n",
       "         13541, 57940, 57938, 57937, 57933, 29654, 13551, 13532, 13498,\n",
       "         46812, 13615, 57850, 13675, 57846, 29558, 57840, 46851, 29552,\n",
       "         13688, 13689, 57835, 46852, 13692, 57825, 13672, 29549, 13696,\n",
       "         29548, 13698, 29547, 13701, 29544, 29543, 13705, 46860, 46862,\n",
       "         57811, 46863, 57807, 57821, 29615, 13671, 29569, 57885, 46815,\n",
       "         46816, 13620, 29608, 29605, 13626, 29602, 29601, 13631, 57876,\n",
       "         46818, 29597, 46844, 13637, 57867, 57864, 57860, 13647, 46832,\n",
       "         29580, 13654, 57857, 57856, 13659, 29574, 29572, 46835, 13638,\n",
       "         29692, 29693, 13495, 13328, 13329, 13333, 13338, 46703, 29788,\n",
       "         13344, 13345, 13347, 29782, 46712, 58072, 29776, 29799, 13362,\n",
       "         13365, 29771, 58060, 29765, 58057, 58052, 29758, 58049, 58046,\n",
       "         29757, 29754, 58039, 29751, 13364, 58037, 58090, 13322, 29834,\n",
       "         29831, 29830, 13280, 58122, 46671, 58118, 58112, 13288, 13290,\n",
       "         29825, 13292, 13293, 58092, 13295, 58110, 13301, 29817, 58106,\n",
       "         13307, 29815, 29814, 46679, 13311, 29811, 13317, 29808, 46688,\n",
       "         29822, 58036, 58034, 29750, 46747, 13454, 57991, 57990, 57988,\n",
       "         29709, 13463, 29708, 13466, 13467, 29705, 46749, 57978, 13448,\n",
       "         57977, 13476, 29701, 57975, 57974, 29700, 57973, 13485, 46755,\n",
       "         57972, 57971, 29696, 57968, 13494, 29703, 29717, 13446, 57998,\n",
       "         58032, 13399, 29745, 58030, 58029, 46729, 13405, 46730, 58021,\n",
       "         13410, 46731, 58017, 13415, 29735, 46735, 29731, 13422, 13423,\n",
       "         13425, 13426, 13429, 29727, 29726, 58006, 46737, 13435, 58000,\n",
       "         13441, 29720, 57801, 46670, 29532, 13718, 57596, 57594, 57591,\n",
       "         13986, 46986, 13988, 29335, 29334, 29329, 57579, 47002, 29326,\n",
       "         57578, 29345, 47004, 29317, 57571, 57570, 57568, 57567, 14021,\n",
       "         57566, 29308, 29306, 14026, 29305, 14028, 29304, 29320, 29303,\n",
       "         57599, 13976, 29372, 13936, 13937, 29368, 13941, 46962, 57629,\n",
       "         57628, 57626, 13950, 46964, 57611, 57609, 29346, 13958, 46976,\n",
       "         13961, 57605, 13964, 29353, 29352, 29350, 29349, 57601, 46977,\n",
       "         13973, 13974, 13975, 29357, 13933, 14033, 14035, 47049, 57511,\n",
       "         14110, 14111, 29239, 14113, 57502, 57501, 47056, 57493, 29229,\n",
       "         14127, 29226, 57513, 47061, 47064, 14134, 14135, 29219, 47066,\n",
       "         14143, 29214, 14146, 29213, 47070, 57480, 47072, 47073, 14131,\n",
       "         14034, 14102, 47044, 47013, 47016, 57550, 29287, 29284, 14054,\n",
       "         14056, 57544, 14059, 47025, 14062, 47028, 47030, 14099, 14073,\n",
       "         14079, 47036, 29254, 57526, 14085, 57525, 57524, 29252, 14091,\n",
       "         47039, 57518, 29249, 57516, 14078, 46953, 57641, 57642, 13774,\n",
       "         57750, 13776, 13778, 29483, 29482, 29481, 46896, 57745, 13788,\n",
       "         46899, 57741, 13791, 13773, 13794, 13796, 57736, 13799, 13801,\n",
       "         57735, 13804, 46905, 57731, 29470, 13808, 57730, 46906, 46908,\n",
       "         13795, 13815, 13772, 29490, 13719, 29529, 57795, 13725, 29526,\n",
       "         29525, 46871, 13729, 29522, 13731, 29521, 46872, 29516, 57753,\n",
       "         57782, 46882, 29504, 57772, 46883, 57770, 57768, 46884, 46886,\n",
       "         57766, 29495, 46890, 57762, 13767, 29508, 46909, 29465, 57725,\n",
       "         29410, 57676, 29408, 29406, 57670, 57667, 57666, 57665, 46938,\n",
       "         57662, 13900, 13901, 29393, 29413, 29392, 57656, 13908, 29389,\n",
       "         29388, 29387, 57650, 29383, 29382, 13920, 13921, 29380, 29377,\n",
       "         57643, 46943, 29414, 46932, 13872, 57723, 29462, 29461, 13823,\n",
       "         13825, 57718, 13829, 57717, 57715, 29453, 29444, 13840, 46919,\n",
       "         57699, 29436, 29433, 29432, 29430, 57688, 46924, 29424, 29423,\n",
       "         57683, 13864, 29422, 13867, 13868, 13869, 46930, 57796, 29205,\n",
       "         13274, 58130, 46389, 46390, 12675, 12676, 30257, 46393, 30255,\n",
       "         58573, 58572, 58571, 46399, 30248, 12693, 30269, 30247, 12696,\n",
       "         58559, 46402, 46406, 30241, 58553, 30236, 12707, 12710, 12711,\n",
       "         58548, 12714, 30232, 30246, 12717, 12667, 12664, 58631, 30325,\n",
       "         46349, 58628, 46350, 46353, 30312, 58621, 30311, 30306, 46361,\n",
       "         30300, 12633, 46383, 12634, 58615, 30292, 12644, 46372, 46374,\n",
       "         58601, 12653, 46377, 30276, 46382, 12661, 30272, 12663, 30297,\n",
       "         58632, 12721, 12723, 12777, 58506, 30184, 58502, 12782, 46434,\n",
       "         58496, 30180, 30178, 30177, 46439, 58491, 58489, 30185, 58488,\n",
       "         46442, 12799, 30168, 12805, 12807, 46446, 12811, 12812, 12813,\n",
       "         46447, 30157, 58476, 46449, 30170, 46417, 30188, 46428, 30224,\n",
       "         30222, 30221, 58538, 58537, 58536, 30217, 30216, 58526, 12739,\n",
       "         30213, 30212, 12742, 12773, 30209, 58519, 30203, 30200, 58513,\n",
       "         12762, 12763, 46426, 30191, 46427, 12768, 12769, 12770, 12771,\n",
       "         30208, 46344, 58635, 46343, 58741, 58740, 58739, 46274, 12446,\n",
       "         12447, 12448, 30446, 12452, 12454, 30442, 12459, 12460, 12431,\n",
       "         30438, 46284, 12468, 30429, 30428, 58718, 58714, 58713, 46287,\n",
       "         12484, 58712, 30420, 12490, 12491, 30436, 12494, 12428, 58746,\n",
       "         12363, 30506, 12365, 58776, 12367, 12368, 46241, 12372, 12374,\n",
       "         30499, 58770, 58769, 30489, 58744, 30488, 12391, 30483, 46258,\n",
       "         12404, 58754, 12411, 12412, 46268, 12418, 46271, 30460, 30459,\n",
       "         58747, 12390, 12495, 46294, 58708, 30371, 12557, 30367, 12562,\n",
       "         58666, 30366, 12568, 30358, 58657, 12574, 30352, 46334, 12581,\n",
       "         30373, 12583, 30346, 58643, 30345, 30344, 30343, 12592, 46341,\n",
       "         12595, 12596, 12597, 12598, 46342, 30334, 12586, 30375, 12550,\n",
       "         58671, 30414, 46299, 12506, 30404, 12510, 58697, 12512, 30403,\n",
       "         46304, 58694, 46305, 30398, 58687, 58684, 12527, 58680, 12530,\n",
       "         46312, 30389, 46314, 12534, 30387, 30385, 30383, 46316, 46317,\n",
       "         12544, 12546, 58672, 58465, 13273, 12824, 12829, 13103, 46573,\n",
       "         13106, 29957, 13108, 29956, 58246, 13112, 58243, 58242, 46575,\n",
       "         29950, 58240, 13101, 58239, 58236, 29943, 46582, 46588, 46589,\n",
       "         29929, 46591, 58221, 13146, 13148, 13149, 13151, 58215, 58237,\n",
       "         13154, 46572, 13098, 58292, 46546, 30007, 30005, 58286, 30004,\n",
       "         13052, 58285, 29997, 58283, 58277, 58274, 13065, 58254, 46558,\n",
       "         29987, 58267, 29986, 13079, 29979, 13081, 46563, 13084, 46564,\n",
       "         29971, 29969, 13095, 13096, 29988, 13040, 13160, 46602, 13214,\n",
       "         29875, 58179, 13217, 58178, 13219, 13221, 29870, 29867, 46647,\n",
       "         13233, 58163, 29857, 29876, 29856, 13243, 29851, 13247, 58152,\n",
       "         13249, 58151, 29849, 13255, 29845, 13259, 13269, 58132, 13271,\n",
       "         58158, 13161, 29879, 29880, 29920, 46603, 58208, 13167, 58207,\n",
       "         29915, 13173, 13176, 46609, 58203, 29907, 13183, 58200, 13209,\n",
       "         29903, 58197, 13190, 58195, 13193, 29899, 29891, 46632, 13201,\n",
       "         58191, 29887, 29883, 29882, 46638, 46617, 13037, 58294, 46542,\n",
       "         46475, 12880, 58416, 58415, 30117, 58413, 30116, 58411, 12892,\n",
       "         12894, 46480, 12898, 12901, 12878, 30103, 30097, 46486, 46487,\n",
       "         46488, 12915, 58389, 58388, 46489, 58385, 46490, 58380, 30087,\n",
       "         30086, 46482, 58373, 12877, 58428, 46458, 30147, 58460, 12835,\n",
       "         30145, 30144, 30143, 30141, 46462, 58450, 30133, 58444, 12851,\n",
       "         30121, 12852, 12854, 58442, 58439, 12858, 58438, 12862, 30130,\n",
       "         12865, 30126, 46472, 58434, 46473, 58429, 58443, 46493, 12930,\n",
       "         46494, 12987, 12989, 30044, 46530, 58333, 30040, 30036, 13002,\n",
       "         13003, 30035, 30033, 46536, 58318, 58337, 58316, 58311, 13016,\n",
       "         46538, 58310, 13020, 30024, 30023, 30020, 58305, 13028, 13029,\n",
       "         58301, 58297, 13014, 30052, 12983, 30054, 46495, 30071, 58367,\n",
       "         12943], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_duration': {'feature_present_idx': array([    3, 43271, 41957, 40883,  3326,  3337, 36115, 35631, 33896,\n",
       "          3927, 32237, 32233, 47429, 28101, 26733, 24640, 23031, 22040,\n",
       "         20432, 18132, 17823, 17129, 13559, 12935, 11903, 27237, 47652,\n",
       "         39863, 59244, 60400, 47716, 60867, 58003, 63371, 53681, 52834,\n",
       "         64121, 65754, 60190, 50916, 66603, 49568, 14893, 10016, 11263,\n",
       "         22814, 61625, 62477, 19267, 13198, 65991, 13114, 63867, 25590,\n",
       "         15762, 12376, 17690, 49161, 27221, 46631, 45491, 49208, 43037,\n",
       "         42706, 49709, 51104, 40730,  7716, 39317, 38381, 37568, 37119,\n",
       "         55774, 57797, 58748, 31163, 29835, 59046, 26768,  7541, 32537,\n",
       "          4673,   137,  2981,  4913,  1820, 50052, 49892, 49817, 13821,\n",
       "         20306, 14129, 46601, 49106, 48141, 14808, 47585, 47213, 19826,\n",
       "         34531, 13539, 49449, 51680, 33145, 56664, 12507, 31516, 31643,\n",
       "         39483, 55375, 32528, 53957, 53915, 13275, 13281, 13353, 13367,\n",
       "         52550, 33133, 19724, 45757, 15381, 30228, 41678, 41422, 36740,\n",
       "         41078, 40850, 38467, 40739, 40542, 40230, 40191, 38584, 40071,\n",
       "         39839, 39767, 18385,  3135, 35084, 17071, 42874, 15604, 45537,\n",
       "         15739, 45047, 44728, 44520, 44327, 44195, 35854, 35949, 42995,\n",
       "         16503, 16780, 42941, 16969,  3031, 12073, 32327, 57331,   619,\n",
       "         26105, 26620,  8151, 26779, 26901,  8754, 62762, 62636, 23252,\n",
       "         23192, 61530,  9023, 56962, 61462, 61453,  9074, 64132, 26021,\n",
       "          7796,  7783, 24833, 66799, 24985, 25466,  6394, 65933,  6569,\n",
       "         23971, 27163, 25759,  7165,  7243,  7316, 65376, 65097, 64961,\n",
       "         23799,  5317,  7006, 61124, 18208, 29366, 58406, 22452, 11284,\n",
       "         59533, 29160,  1265, 27949, 22367, 58461, 60433, 29513, 11174,\n",
       "          9181,  9843, 60832,  9387,  1022, 29704, 60629,  4348, 30793,\n",
       "         32368, 24848, 29355, 31972, 39443, 31116, 25664, 31709, 38480,\n",
       "         31364, 37965, 34317, 28609, 28750, 33884, 27315, 34414, 33866,\n",
       "         27645, 35391, 33474, 33341, 33275, 32874, 35566, 26892, 26828,\n",
       "         27954, 26338, 28486, 36604, 34156, 28720, 33011, 35629, 34489,\n",
       "          5692, 39631, 61038, 60943, 60268, 60127, 59919, 59375,  1298,\n",
       "         61134, 58730, 58044, 57910,  1616, 57787, 57759, 57702, 56880,\n",
       "         58238, 56840, 61840, 62943, 67142, 66902, 66687, 66579, 66320,\n",
       "           330, 65694, 62474, 65389, 64189, 64104, 64003,   716, 63425,\n",
       "         63387, 62954, 64855, 56256, 56143,  1626, 24750, 46232, 45715,\n",
       "         45591, 45419, 45242, 44134, 46707, 43891, 42866, 41359, 41264,\n",
       "         40753,  3384, 40072,  3490, 43202, 46958, 47037, 48422, 55773,\n",
       "         55740, 55568, 55404, 54498, 54066, 53802, 53188, 52383, 52304,\n",
       "         51194,  2005, 50544, 49808, 49749,  2103, 48451, 39464, 24707,\n",
       "          3797, 67331, 17871,  4742, 17806, 17797, 19821,  8854, 22414,\n",
       "         13376, 22447, 13379, 13504, 22538, 22665, 17044,  8036, 16990,\n",
       "         16262,  8914,  9028, 18044,  4675, 20082, 20220, 19317, 20790,\n",
       "         20866, 20872, 10946, 12349,  7894, 21087, 12691, 12844, 21378,\n",
       "          5303, 12918,  5008,  9656, 21673, 10793,  7800, 15187, 24322,\n",
       "         13805, 23530, 15616, 24476, 24143, 13922, 14030, 23999,  6019,\n",
       "         16225,  7437, 23269, 16256,  6170, 24127, 15249, 24268, 12466,\n",
       "          2503,  3578, 56217, 43096, 19006, 12801, 55677, 55662, 55647,\n",
       "          2848, 18999, 55597, 37957, 37041, 36602, 36841, 34717, 11747,\n",
       "         34920, 35025, 47009, 57543, 57495, 15241, 11944, 56379, 19448,\n",
       "         57154, 46015,  3671, 57003, 56990, 36434, 45423, 45942, 56519,\n",
       "         57183, 12863, 55123, 55452, 52199, 52053, 16007, 17223, 17192,\n",
       "         51517, 51490, 41688, 41767, 13550, 13576, 42661, 13594, 16992,\n",
       "         42873, 16920, 13790, 43657, 50003, 49375, 44516, 44608, 44709,\n",
       "         55416, 39413,  4824, 18460, 14874, 54391, 45165, 18024, 45081,\n",
       "         38676, 14747, 48607, 54320, 54317, 48846, 53889, 49054,  4758,\n",
       "         53616, 53540, 14451, 17316, 11665,  2810, 62299, 62206,  6543,\n",
       "          6348, 29679, 62191, 25905, 29884, 61864, 30295, 30347,  9053,\n",
       "         23808,  9620, 64514, 31160,  4126, 23920, 21567, 29469,  9977,\n",
       "          6696, 29390, 27518,  5369, 27928, 65151,   867,  4244, 65374,\n",
       "         28185, 26740, 63234, 65424, 28647, 28670,  8542,  8767,  8773,\n",
       "         26542,  6839, 28961, 23580, 31472, 64102, 60527, 10812,  5299,\n",
       "         34201, 59263, 24917, 32951,  6255, 20877, 33012,  4464,  1330,\n",
       "          5874, 20806, 11033, 24896, 24895,  1470, 58710, 24976, 58541,\n",
       "         58131, 31549,  1174, 66718, 21361, 31999, 10434, 10572, 67205,\n",
       "         60059, 59967,  6161, 58081, 21142, 59947, 10754, 32279, 46820,\n",
       "         64691, 14896,  7490, 64868, 14359, 67092,  2289, 49464, 65643,\n",
       "         49112, 47040,  4830, 66830, 47456, 66393, 48326, 66492, 48008,\n",
       "          6964, 47776, 11480, 63919, 54948,  9764, 60719, 55505, 10044,\n",
       "         55945, 56260, 59503, 59373, 56627,  5180, 12332, 58841, 57138,\n",
       "         57249, 11198, 57527, 58353, 11328,  9157, 61590,  8905, 13208,\n",
       "         63671, 50480, 63408,  8457,  4832, 51223, 63172, 51395, 62712,\n",
       "         50212, 51781, 52214, 52234, 13385, 11348,  1669, 53342,  1640,\n",
       "         53844, 62095, 62614,   871, 24543, 15309, 21464, 17354, 21563,\n",
       "         31273, 40835, 17295, 30395, 30242, 41131, 21974, 36877, 17251,\n",
       "         41442, 41535, 17164,  4789, 42308, 29932, 42479, 31729, 21240,\n",
       "         32517, 32715, 36960,  3594, 19099, 37753, 38181, 46612, 19465,\n",
       "         38599, 35166, 42732, 34775, 18189, 34438, 19850, 34042, 33539,\n",
       "         33422, 21007, 32740, 17663,  3497, 29583, 41155, 15905, 26736,\n",
       "         29337, 27024, 15831, 26095,  4273, 45563, 15343, 25559, 44682,\n",
       "         15786, 45670, 22935, 27916,  4294,  2912, 44487, 22772, 22743,\n",
       "         46583,  4580, 24817, 36158, 20045, 58171, 26409, 23684, 56572,\n",
       "           183, 24420, 56663, 19269,  5275, 57654, 56890, 66953, 19611,\n",
       "         57473,  6252, 35875, 24969, 11951,  1590, 22312, 59353,  4629,\n",
       "          4201, 28825, 28799,  8672, 61798, 28793, 62972, 62979, 61781,\n",
       "         63835, 64005,  9540, 30956, 27513, 21653, 31397, 31502, 27443,\n",
       "          4491, 64263, 64271,  3997, 23075, 23450, 65332, 59132, 33446,\n",
       "          3824, 36806,  5417, 56277, 54876, 54813, 13067,  4973, 49414,\n",
       "         17807, 14289, 13210, 40114, 14174, 40210, 49793, 44291, 40225,\n",
       "         16049, 16297, 50373, 50981, 17294, 56445, 53015, 17311,  3240,\n",
       "         39289, 48710, 39585, 40785, 48582, 45647, 55807, 19003, 55639,\n",
       "         38577, 46429, 47267, 55477, 12679, 15011, 46842, 39164, 48183,\n",
       "         24200,   908, 51716, 43853, 42322, 30163, 25446, 30783, 28960,\n",
       "         61783,  4252,  2487, 64174, 45015, 15845, 64859, 31100,  7940,\n",
       "         49175,  8034, 27630,  7318, 14762, 65475, 23554, 15929, 45254,\n",
       "         25899, 65672, 30250, 15118, 19436, 57311, 13261, 53887, 33119,\n",
       "         57414, 53472, 58686, 38993, 39230, 34716, 39947, 52403, 34619,\n",
       "         19708, 38151,  3501, 19775, 60201, 59818,  4112, 13314, 40664,\n",
       "         53171, 37717, 38046, 56845, 36706, 36262, 32473, 32139, 46093,\n",
       "         37540, 36766, 23788, 48312, 18515, 57382, 35855, 34564, 57041,\n",
       "         45263, 26922,  4278,  2429, 28821, 40611, 32822, 62554, 13678,\n",
       "         22049, 49830,  8282, 42773,  2391, 20288, 52209, 52572, 52454,\n",
       "         32656, 25068,  4613, 26291, 25542, 44970, 47894,  7968, 39992,\n",
       "         44498, 58255, 27941, 52232, 11019, 22847, 23423, 59622, 32378,\n",
       "         51811, 44386,  9117, 45013,  2437, 45074], dtype=int64),\n",
       "  'feature_absent_idx': array([24363, 60209, 60210, 51180, 18678, 42109, 42110, 18670, 18668,\n",
       "         42112, 51177, 18665, 18661, 18660, 18656, 60228, 18691, 18650,\n",
       "         51183, 42102, 60180, 60183, 18733, 18732, 18727, 60188, 60189,\n",
       "         60191, 18718, 18715, 18714, 18712, 18707, 18700, 60206, 18694,\n",
       "         60178, 18648, 18640, 18592, 60256, 18589, 18584, 60258, 18578,\n",
       "         60260, 60270, 60274, 18551, 18550, 60275, 42153, 60280, 18542,\n",
       "         51167, 60235, 42137, 60253, 60238, 42121, 60243, 18630, 42123,\n",
       "         18624, 18623, 18622, 42126, 18619, 18617, 18616, 60248, 18610,\n",
       "         60249, 18596, 18536, 18750, 18761, 18898, 60113, 18894, 42031,\n",
       "         18889, 18887, 42037, 42039, 18880, 60124, 18867, 18864, 60128,\n",
       "         60129, 18860, 42024, 60130, 18911, 60107, 18953, 18952, 18951,\n",
       "         42011, 18948, 18947, 18946, 18942, 18938, 60100, 42014, 42015,\n",
       "         42016, 18919, 60104, 18912, 42091, 18856, 42050, 18808, 51195,\n",
       "         18796, 18794, 60160, 18791, 42078, 60164, 18783, 18778, 42081,\n",
       "         60168, 51190, 18773, 18765, 60154, 18855, 42070, 42067, 18850,\n",
       "         18847, 42053, 18841, 42054, 60138, 60139, 60140, 18832, 60143,\n",
       "         18830, 18826, 42062, 51199, 42066, 42068, 18535, 18531, 18529,\n",
       "         42276, 18223, 18218, 60401, 18213, 51112, 18204, 18202, 42280,\n",
       "         18195, 60410, 18185, 18180, 18176, 51108, 18226, 42293, 42274,\n",
       "         60394, 42256, 42257, 18267, 60382, 42269, 18255, 18254, 18253,\n",
       "         60386, 60387, 18247, 60390, 18239, 18237, 18236, 18232, 60374,\n",
       "         60420, 60421, 18119, 18115, 18112, 18110, 18109, 18108, 18107,\n",
       "         18105, 42318, 18096, 51091, 18090, 42326, 18088, 18086, 60440,\n",
       "         42295, 42313, 18127, 18160, 18156, 18152, 18151, 18149, 51101,\n",
       "         60428, 60430, 18143, 42304, 60435, 18137, 60436, 51098, 60438,\n",
       "         18126, 18283, 60373, 18294, 18469, 42182, 42184, 18451, 42187,\n",
       "         42194, 51151, 18426, 51148, 18423, 18422, 18420, 18412, 42204,\n",
       "         60329, 60305, 60332, 42177, 60300, 42160, 18521, 18520, 18518,\n",
       "         51159, 18516, 60287, 18511, 18501, 42168, 18494, 60292, 42171,\n",
       "         18487, 42174, 42176, 18402, 18400, 42206, 18343, 51136, 51135,\n",
       "         18337, 18336, 18334, 18332, 18330, 51127, 18324, 18315, 18304,\n",
       "         60367, 42249, 42252, 18344, 42226, 42223, 18355, 18392, 18391,\n",
       "         42210, 18389, 18383, 60338, 42215, 18954, 18376, 18370, 18369,\n",
       "         60340, 18361, 60342, 60344, 60345, 18371, 42009, 42008, 18960,\n",
       "         19502, 51300, 51299, 41832, 59899, 59901, 59903, 59904, 51295,\n",
       "         19479, 41843, 19477, 41844, 19475, 19466, 41828, 41847, 19505,\n",
       "         19507, 19552, 19550, 19549, 41818, 51303, 19541, 19540, 19539,\n",
       "         19538, 19537, 19523, 19521, 59892, 19512, 19511, 19506, 41817,\n",
       "         59909, 41848, 19419, 19410, 19405, 19402, 19400, 19396, 59930,\n",
       "         59933, 59934, 19386, 19385, 59935, 19379, 59936, 41867, 19420,\n",
       "         19459, 19422, 59922, 59911, 19454, 41850, 59914, 59915, 41851,\n",
       "         19445, 41853, 19439, 59917, 59920, 59921, 19431, 19430, 41856,\n",
       "         19423, 19555, 19560, 19562, 19696, 19695, 19691, 19687, 59837,\n",
       "         19677, 41772, 41773, 59840, 59843, 19663, 19661, 19660, 59845,\n",
       "         59846, 19697, 41775, 41762, 19706, 59817, 19745, 41747, 19739,\n",
       "         59820, 59821, 19726, 19725, 59825, 19719, 19717, 59827, 19714,\n",
       "         59828, 19709, 19701, 19654, 19651, 41776, 41802, 19590, 19584,\n",
       "         59877, 41807, 19581, 19578, 19577, 19576, 19570, 59883, 19566,\n",
       "         19565, 19564, 59885, 51317, 59870, 19602, 41798, 59852, 41777,\n",
       "         19646, 59853, 51337, 51333, 19640, 19369, 19639, 19630, 19621,\n",
       "         59864, 59866, 19615, 59868, 19606, 19636, 18084, 51286, 59942,\n",
       "         19119, 51248, 60038, 60039, 60041, 19103, 41962, 19088, 19087,\n",
       "         19086, 19085, 19084, 19083, 19080, 19079, 19123, 60047, 19124,\n",
       "         41949, 60015, 41929, 19173, 60018, 41932, 60020, 51260, 41935,\n",
       "         60024, 19159, 60028, 19149, 60031, 19135, 19132, 19127, 51262,\n",
       "         19074, 60053, 60083, 41992, 18993, 18992, 18989, 41994, 41996,\n",
       "         18980, 18979, 18977, 18973, 42001, 60093, 42005, 42006, 18998,\n",
       "         41970, 60082, 41989, 41971, 60056, 41973, 19052, 19051, 41976,\n",
       "         19045, 60065, 19040, 19038, 19036, 19031, 51234, 19021, 60073,\n",
       "         19001, 19181, 19184, 60013, 59971, 41887, 19310, 19297, 19294,\n",
       "         19293, 19290, 19288, 19287, 51275, 51274, 41896, 41897, 41898,\n",
       "         19273, 59964, 19271, 59963, 19319, 19355, 59943, 19350, 59944,\n",
       "         59945, 59950, 19339, 59953, 51280, 19335, 59956, 41884, 59958,\n",
       "         59959, 59960, 19318, 59984, 19266, 59986, 41916, 60006, 19211,\n",
       "         19209, 41919, 19207, 19201, 19199, 41922, 19197, 19194, 19192,\n",
       "         51264, 19189, 19187, 19216, 41914, 19221, 41913, 41899, 59987,\n",
       "         19257, 19256, 59992, 19251, 59993, 19362, 19248, 59996, 51269,\n",
       "         41908, 19234, 51268, 19228, 51267, 59995, 19748, 60453, 51086,\n",
       "         16981, 50949, 42707, 16973, 60837, 16970, 50943, 42715, 60842,\n",
       "         16955, 42717, 16943, 42723, 50938, 42726, 42699, 16937, 16986,\n",
       "         16989, 17037, 42682, 42684, 17027, 60820, 42686, 17019, 42687,\n",
       "         60822, 42690, 17006, 17001, 16996, 50953, 16991, 42696, 60817,\n",
       "         16935, 50934, 42758, 16874, 16873, 42759, 16871, 60881, 16867,\n",
       "         42760, 42761, 50923, 42764, 16856, 16855, 42765, 16849, 16876,\n",
       "         60852, 60880, 60877, 60856, 42735, 16919, 60859, 60864, 16905,\n",
       "         16901, 42745, 16898, 16897, 50930, 16893, 60871, 60872, 16889,\n",
       "         60878, 42766, 60816, 17050, 17179, 17177, 50972, 17173, 17169,\n",
       "         17165, 17163, 17162, 17161, 17159, 17156, 17154, 60772, 17152,\n",
       "         17148, 17184, 17146, 42632, 50976, 60754, 17228, 17227, 50980,\n",
       "         60756, 42618, 17216, 17215, 17209, 17208, 50978, 42624, 17204,\n",
       "         60764, 17201, 42631, 42679, 42644, 42646, 42666, 17090, 60803,\n",
       "         50961, 17080, 17077, 60806, 60807, 17072, 17070, 42674, 60812,\n",
       "         17056, 17055, 17053, 50962, 50966, 17105, 17111, 60777, 17139,\n",
       "         60781, 17132, 60786, 60788, 42652, 17125, 42653, 42654, 17118,\n",
       "         42656, 17116, 17113, 42658, 42659, 16847, 42767, 16844, 16626,\n",
       "         42847, 60965, 42850, 50896, 60968, 42853, 16607, 42857, 42859,\n",
       "         42861, 50892, 42867, 16588, 16586, 16627, 16585, 60961, 60953,\n",
       "         60937, 60939, 16668, 42824, 16661, 42827, 42828, 42829, 42831,\n",
       "         16654, 50900, 16644, 42840, 16640, 50898, 42843, 16675, 42869,\n",
       "         16578, 16543, 42890, 16539, 42891, 16537, 50883, 16534, 16533,\n",
       "         16532, 50882, 42897, 50877, 16522, 16517, 50872, 16544, 16579,\n",
       "         60991, 42888, 42871, 16575, 42875, 42877, 60982, 42880, 16566,\n",
       "         42881, 16564, 42883, 16560, 50887, 42885, 60986, 50885, 16551,\n",
       "         16681, 16685, 42821, 16797, 60899, 16794, 16792, 16788, 16786,\n",
       "         16785, 16782, 16778, 16776, 16775, 50911, 60906, 16771, 16770,\n",
       "         42782, 16766, 16802, 16808, 60888, 16835, 42769, 16830, 42770,\n",
       "         16827, 60891, 16824, 60892, 42776, 60894, 42778, 60895, 16813,\n",
       "         16812, 16807, 16760, 60913, 16755, 60924, 16715, 16712, 16711,\n",
       "         42815, 16709, 50904, 42817, 16702, 16699, 16698, 16697, 42820,\n",
       "         16694, 16692, 50905, 16719, 50906, 16721, 16752, 16750, 42798,\n",
       "         16748, 16747, 42799, 60920, 60753, 16736, 60921, 16732, 42807,\n",
       "         42808, 16725, 50907, 42810, 42804, 60752, 17235, 42612, 42430,\n",
       "         17775, 17774, 17772, 17769, 42437, 42439], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 924\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 924\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 924\n",
       "    })}}},\n",
       " 'contains_example': {'feature_present_idx': array([15765, 46813, 48197, 32016, 49024, 29112, 29038,  7689, 12461,\n",
       "         42515,  5522,  8840, 30309, 54409, 60976, 33752,   400, 24065,\n",
       "         31098,  2792, 64148, 38832, 17219, 15933, 35548, 35669, 29428,\n",
       "         45162, 22327, 38803, 35891, 44800, 42756, 41999, 14175, 41791,\n",
       "         29792, 16814, 45104, 29243, 12126,  8830,   352,   677, 63069,\n",
       "         21468, 61692, 24927, 20691, 58317,  9249, 48842,  8435, 53989,\n",
       "         50219,  6083, 52931,  6375, 54137, 50663,  6809, 26611, 31166,\n",
       "         28420, 24594, 26039, 29759, 24290, 26165,     6, 34778, 65312,\n",
       "         63539, 62349, 61656, 60286, 59614, 57816, 56728, 56112, 34267,\n",
       "         52606, 49531, 47884, 45967, 45917, 41615, 41506, 41269, 40060,\n",
       "         37742, 50132, 23026, 30580, 12793, 14903,  3590,  3553, 13918,\n",
       "         15287,  4784, 16385, 13503, 13389, 13153, 16922, 14314,  4927,\n",
       "         17582,  1493, 14226, 10819, 10662, 12523, 21930,  7946, 21357,\n",
       "         11666, 38755, 52442, 52415,  6405,  4116, 39237, 13621, 56960,\n",
       "         40138, 58327,  5395, 48661,  8078, 52801, 47228, 56685, 56490,\n",
       "         56352, 12873, 45919, 10869, 43320, 43905, 44090, 44113, 40477,\n",
       "         67247, 37461, 50349, 17023, 17351, 17886, 60060, 63193, 27405,\n",
       "         16884,   771, 20565, 25568, 64411, 25058, 20949, 23630, 20379,\n",
       "         29846, 28522, 16762, 14993, 60295, 34057, 33326, 32326, 61447,\n",
       "         32752,  7493, 16284, 30688, 61769,  3422, 52316, 66741,  3823,\n",
       "           528, 65116, 62329,  6318, 54754,  4155,  5970,  1545, 63832,\n",
       "          3133,  5533,  1155, 63526, 62831, 53762, 22628, 49888, 39207,\n",
       "         37765, 37593, 14969, 34320, 32198, 31342, 30818, 66878, 29992,\n",
       "         28400, 27636, 19563, 26583, 25305, 21895, 23863, 40221, 13094,\n",
       "         44178, 48999, 42000, 48390, 13006,  9908, 44712, 11900, 56485,\n",
       "         49442, 52347,  8495, 15527,  6471, 50651, 54792,  7823, 58782,\n",
       "         14044, 66564, 28144, 49401,  7909, 65516, 23519, 61852, 46266,\n",
       "         15127, 22703, 39190, 40131, 59381, 18928, 29057, 43054],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([55813, 37571, 37569, 37567, 37565, 37562, 37559, 13767, 37551,\n",
       "         13772, 13773, 13774, 59519, 13776, 13778, 37545, 64505, 37539,\n",
       "         13788, 13791, 37532, 13794, 13795, 13796, 13799, 37524, 13801,\n",
       "         37523, 37521, 13804, 59515, 37575, 37578, 37584, 37657, 13701,\n",
       "         59499, 59500, 13705, 37646, 64525, 37642, 37640, 37635, 13718,\n",
       "         13719, 37634, 37633, 13808, 37632, 13729, 13731, 37617, 37616,\n",
       "         64521, 59508, 59509, 37610, 37609, 37606, 64518, 64517, 37587,\n",
       "         37585, 13725, 13698, 64497, 13815, 37440, 13872, 37439, 37438,\n",
       "         37432, 37430, 64478, 37427, 64477, 37426, 37425, 37411, 37410,\n",
       "         37409, 37408, 37402, 37398, 59544, 37396, 13900, 13901, 37387,\n",
       "         37386, 13908, 59547, 37363, 13920, 13921, 37360, 37441, 13869,\n",
       "         13868, 13867, 37508, 37504, 64494, 37500, 37499, 13823, 37497,\n",
       "         13825, 59529, 37495, 13829, 37490, 37485, 37482, 37509, 37481,\n",
       "         13840, 64486, 37466, 37464, 37460, 37459, 64482, 59537, 37453,\n",
       "         37452, 64480, 13864, 37447, 37446, 37479, 13696, 37666, 13692,\n",
       "         64566, 37868, 37867, 13541, 37865, 37863, 64562, 37856, 64560,\n",
       "         13551, 37854, 37853, 37850, 59456, 64557, 13557, 37841, 13564,\n",
       "         13565, 13566, 13568, 37837, 13571, 37834, 37829, 37825, 13577,\n",
       "         13579, 37820, 13536, 59454, 13532, 59452, 59444, 13485, 37924,\n",
       "         37921, 37919, 37918, 13494, 13495, 37914, 64576, 13498, 37904,\n",
       "         37901, 59449, 13582, 13507, 13511, 37895, 13513, 37894, 37892,\n",
       "         64570, 37890, 13519, 13520, 37889, 37887, 13524, 37883, 37882,\n",
       "         64572, 59460, 37816, 37810, 59479, 64540, 37729, 64537, 13647,\n",
       "         37726, 37725, 59484, 13654, 37714, 13659, 37707, 37704, 37703,\n",
       "         37736, 37701, 59486, 37696, 13671, 13672, 13675, 64534, 64531,\n",
       "         37684, 64530, 64528, 37677, 37676, 13688, 13689, 37700, 37351,\n",
       "         13638, 37740, 37806, 37804, 37803, 64550, 13595, 64549, 37795,\n",
       "         37794, 64548, 59467, 37789, 13606, 37784, 13608, 13637],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 251\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 251\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 251\n",
       "    })}}},\n",
       " 'contains_extent': {'feature_present_idx': array([33795, 20468, 37855, 18795, 17495, 46942, 52705, 12904, 53903,\n",
       "         10148, 25577,  7207, 65881,  5923, 62788,  3696, 62787, 55134,\n",
       "         30599, 30984, 39234, 40492, 42172, 42458, 43245, 45646, 46828,\n",
       "         62477, 47343, 29330, 61509, 59200, 55822, 47611,   137, 16731,\n",
       "         14730, 19890, 16757, 12747, 16102, 18608, 22898,  2752,  1540,\n",
       "          7019, 48268, 46076, 48336, 14493, 42623, 14850, 42347, 19713,\n",
       "         47681, 36024,  7798, 33366, 20223, 61568, 28457, 19030, 53343,\n",
       "         55764,  7557, 56878, 26516, 15187, 45591, 27214, 27465, 30329,\n",
       "         32236, 21286, 16739, 43367, 34063,  4721, 35918, 49098,  5305,\n",
       "          6964, 24299, 66580, 66665, 59530, 61781, 61302, 57538, 52010,\n",
       "         65447, 41687], dtype=int64),\n",
       "  'feature_absent_idx': array([59444, 57938, 57937, 12212, 57933, 12215, 36093, 57929, 12218,\n",
       "         36092, 57927, 47630, 25508, 57924, 12224, 47634, 57922, 47635,\n",
       "         12230, 25503, 57919, 12234, 12236, 12239, 12240, 12243, 36088,\n",
       "         47641, 25511, 57940, 12207, 25512, 57971, 25543, 57968, 47613,\n",
       "         39515, 39516, 47618, 25536, 57960, 47620, 12178, 47623, 57955,\n",
       "         39528, 12184, 12186, 57953, 39521, 36097, 47626, 25519, 12198,\n",
       "         25517, 25516, 12202, 25514, 47627, 12205, 25526, 57972, 12247,\n",
       "         12251, 34005, 41164, 57876, 47669, 12308, 47671, 25457, 25456,\n",
       "         12313, 12315, 57867, 12318, 57864, 25452, 57860, 57857, 34009,\n",
       "         57856, 47680, 47682, 57850, 12338, 25438, 57846, 47684, 12344,\n",
       "         47687, 47664], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 92\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 92\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 92\n",
       "    })}}},\n",
       " 'contains_frequency': {'feature_present_idx': array([52941, 25425, 46547, 25002, 60926, 47031,  8165, 23959, 23529,\n",
       "          8422, 47476,  8599, 48024, 60664, 22415, 48777, 25534, 14656,\n",
       "          6969, 46192, 43807, 44016, 44107, 44401, 44403, 62187, 27064,\n",
       "         48821, 61889, 26683, 26621,  6228,  6295, 26321, 26191, 45808,\n",
       "         61763, 49944, 59897, 59889, 13060, 17541, 53287, 13178, 53372,\n",
       "         56823, 53374, 17812, 13294, 13505, 56565, 16148, 16094, 16028,\n",
       "         54899, 15531, 13350, 28849, 12791, 57869, 10350, 21280, 20966,\n",
       "         50423, 50705, 19926, 11473, 18477, 19736, 19704, 50903, 51047,\n",
       "         59039, 11884, 12226, 18686, 59162, 28944, 25699, 40092, 35213,\n",
       "         31260, 41447, 35086, 41229, 31782, 38644,  1406, 64739, 32529,\n",
       "          1564, 65008, 40604, 32901, 40405, 33930, 65384, 29021, 33462,\n",
       "         33370, 33166,  2422, 65839, 31133,   863,  2032, 66802, 67022,\n",
       "         38370, 42463, 35805, 43082, 42446, 62794, 30078,   158, 35811,\n",
       "         43166, 30727, 30384, 15461, 50624, 39031, 40065, 15956, 19129,\n",
       "         15017, 33923, 15242, 39102, 39407, 33576, 33571, 15792, 20083,\n",
       "         19922, 20054, 36194, 19985, 19830, 51602, 51192, 38474, 16865,\n",
       "         38359, 53491, 35072, 17272, 35014, 53558, 34901, 17575, 53276,\n",
       "         38263, 50468, 17969, 18123, 37292, 16209, 52367, 34358, 52030,\n",
       "         18491, 51990, 38908, 19015, 38737, 43272, 21029, 25382, 46445,\n",
       "         41217, 41305, 31382, 41356, 46058, 45806, 45767, 26257, 31015,\n",
       "         45523, 30864, 25338, 26764, 45092, 29937, 27087, 44972, 27728,\n",
       "         27777, 27848, 29435, 43990, 43814, 28631, 43736, 28743, 42388,\n",
       "         33253, 25323, 25154, 21053, 50314, 40087, 50295, 50114, 49981,\n",
       "         22029, 48972, 33141, 33105, 22678, 48302, 23019, 25296, 23259,\n",
       "         47484, 23354, 23429, 47426, 32619, 23854, 40694, 24137, 32366,\n",
       "         24625, 46917, 46794, 41125, 32977, 14498, 67221,  7307,  9561,\n",
       "          9718, 60050, 62759, 63137,  4179,  3667, 63872, 63965, 63991,\n",
       "          7335,  3342, 64274, 59098, 11774, 64750, 58352, 12271, 57946,\n",
       "         12423, 65091, 65321,  2589, 62726,  2476, 62637,  5127, 61260,\n",
       "         61445,  7107, 60919,  7972,  8185,  6691, 61623,  8472,  8539,\n",
       "         60799,  6205, 61713, 60688,  6096, 60548,  5877, 62289, 60279,\n",
       "          5635, 62473,  5322,  9277, 60158,  2440, 11334, 66056, 57139,\n",
       "         66298, 13182,  1414, 56817, 13570, 13622, 13129, 65551,  1232,\n",
       "         66394,  1127, 56335, 67040, 56214, 14334, 56558,  1753,  7424,\n",
       "         57394, 66139,  1883, 39467, 65037, 35711, 38217, 35533, 26782,\n",
       "         45245,  5998, 45055, 66776,  5785, 44900, 44781, 44633, 44497,\n",
       "         38524, 66536,  1118, 62380, 66836, 26618, 37978, 37858, 55793,\n",
       "         37321, 36617,  6838, 46145, 37365, 37470, 46133,  6798,  6743,\n",
       "         37531, 36157, 61689, 26442, 45678, 61693, 45455, 45416, 26601,\n",
       "         62416, 32268, 35017,  1814,  3050,  3913, 41587,  3698,  1553,\n",
       "          1595, 40684,  3110, 63996, 30382, 31411, 41312, 66192, 32374,\n",
       "         31648, 64703, 31799,  1756,  3208, 40973,  1730, 40437, 41820,\n",
       "          4482, 27971, 28050,  5217, 39912,  2865,  5126,  5031, 40506,\n",
       "         39710, 40641, 38671,  4828, 28946,  1284, 38739,  2982,  4701,\n",
       "          4644,  4614, 62765, 28856, 34548, 56017,  7446, 57455, 57572,\n",
       "         52936, 52862, 57810, 51664, 12204, 18743, 18792, 11713, 50864,\n",
       "         11663, 19762, 11474, 11443, 20012, 59420, 59644, 59769, 59798,\n",
       "         10829, 20602, 50383, 50360, 50353, 10601, 21001, 12687, 53104,\n",
       "         17887, 17791, 14354, 15044, 15090, 15398, 15399, 55021, 14027,\n",
       "         13970, 15878, 54359, 13797, 56505, 54323, 10582, 13679, 54059,\n",
       "         53870, 13289, 16655, 56859, 16887, 53296, 17282, 17357, 17450,\n",
       "         57225, 17597, 17613, 54150, 21061, 59222, 37000, 22348, 60893,\n",
       "         24149, 48577, 22475, 22573,  8163,  8261, 48430, 22664,  9050,\n",
       "         22863, 60599, 23767, 59882, 23237, 60647, 47309, 47587, 23333,\n",
       "         60889, 22297, 24178, 23538, 49631, 46923,  9403, 10197, 49777,\n",
       "         21570, 21462,  7473, 60103,  7798, 61120, 49072, 37480, 53755,\n",
       "         66942, 61381, 38786, 38893, 47417, 39028, 55543, 45693, 46223,\n",
       "         67112, 54294, 38321, 38212, 54854, 54815, 56498, 66719, 66958,\n",
       "         61459, 60960, 38031, 55139, 61541, 38539, 55419, 47127, 47242,\n",
       "         66674, 59849, 60805, 64409, 50760, 61292, 62594, 48998, 49035,\n",
       "         59624, 49070, 50563, 41495, 49531, 63344, 62706, 63240, 63198,\n",
       "         63162, 43689, 60216, 48654, 51076, 51121, 39482, 39522, 57143,\n",
       "         39693, 39980, 57369, 48259, 62064, 66321, 40329, 57764, 44755,\n",
       "         58091, 48527, 51313, 64957, 58124, 58523, 48323, 45402,    32,\n",
       "         33341,  9936, 21294, 10456, 11200, 11667, 27859,  9774, 11684,\n",
       "         27502, 27466, 27333, 12529, 12638, 26880, 11858, 26859, 29300,\n",
       "         29530, 31579,  7861, 31357, 31323, 31064,  7870, 29431,  7946,\n",
       "         30093, 29591,  8543,  8963,  9235,  9584, 30304,  7690, 12912,\n",
       "         26563, 23434, 16540, 23274, 16751, 16938, 18404, 16158, 22385,\n",
       "         22292, 22281, 18565, 19161, 19528, 20757, 36967, 26570, 23606,\n",
       "         23845, 12922, 13139, 26406, 26068, 26054, 25979, 23806, 25799,\n",
       "         25388, 14039, 24874, 15219, 24687, 24287, 13918,  7435, 29189,\n",
       "         21331, 33526,  4874, 33684,  4257,  1965,  4240,  3750,  3553,\n",
       "          3383,  2332,  2395,  1094, 34217, 35606, 34336,  3266, 31927,\n",
       "         34515, 35537, 34521,  3167, 35433,  3081,  3020, 34305,   770,\n",
       "          1682,  6662, 32973, 33522,  6079,  5985, 32882,  6362,  6145,\n",
       "         32589,   441,  6264, 36562, 32439,  5008, 33463, 20201,  2575,\n",
       "         16063, 20297, 54823, 54364, 65667, 50449, 54327, 20379, 54786,\n",
       "         20617, 20816, 18485, 53750, 20133,   912,  1078,   570, 51804,\n",
       "         52295, 18480, 52458, 15661, 17024,  1686, 66232, 19279, 16623,\n",
       "          1778, 16558, 67118, 19818, 16405, 15569,  7125, 65325,  4571,\n",
       "         11189, 59626, 11099, 11001, 10526, 10074,  5505,  5828,  4506,\n",
       "         62045, 61743,  8644,  8415,  8413, 60901,  6526, 60987,  6833,\n",
       "         61451, 61990, 15441, 11820,  4342, 65021, 14324, 64784, 13549,\n",
       "         56986,  3183, 56992, 57006, 13121, 58800, 13010,  3320,  3376,\n",
       "         12655, 57841, 58069, 12330, 11891, 58473, 58501, 64701, 57129,\n",
       "         36823, 50099, 31732, 31568, 41596, 42327, 42889, 43052, 43290,\n",
       "         43524, 28660, 43749, 41050, 28522, 21449, 44379, 27740, 27727,\n",
       "         27362, 45474, 26551, 45926, 25494, 46907, 43873, 46952, 32811,\n",
       "         32915, 36396, 37599, 37611, 37747, 36094, 37996, 35866, 38557,\n",
       "         34670, 38983, 40469, 34023, 39355, 33683, 33625, 39603, 39819,\n",
       "         67165, 33235, 33163, 33159, 40390, 39208, 23543, 52278, 22104,\n",
       "         21746, 47610, 48449, 49266, 22105, 22654, 48237, 21546, 23297,\n",
       "         18740, 40570, 61753, 32633, 51417, 32224, 30818, 22352, 18684,\n",
       "         53986, 18988, 41947, 29583, 60273, 22594, 43398, 18328, 43958,\n",
       "         11480, 22772, 44436, 60907, 41781, 62230, 44691,   160, 66869,\n",
       "         21583, 66654, 37952, 20309, 49561, 38332, 35176, 65118,  2748,\n",
       "         38511, 64971, 34485, 63829, 63582, 63526, 50850, 19657, 33775,\n",
       "         49098,  4704,  5305,  5501,  5575,  5928, 58217, 22588, 54456,\n",
       "         54674, 53451, 25821, 13601, 13676, 45103, 15693, 24631, 26912,\n",
       "         14421, 23454, 14436, 16095, 54104, 48113, 12415, 16230, 12440,\n",
       "         14554, 12467, 26197, 57767, 54460, 22277, 46842, 33853, 41142,\n",
       "          7200,  2771, 26106, 40920, 51875, 35148, 53631, 54792,  3397,\n",
       "         63755, 34908, 63103, 27429, 63609, 46623, 64414,  3308, 21802,\n",
       "         59530, 63493, 58171, 36158, 28223, 17741,   693, 59671, 53015,\n",
       "           746, 18252, 21670, 53794, 60068,  9481, 15368, 47267, 35232,\n",
       "         47146, 57349,  8690, 16277, 54444, 36114,  8613, 46857, 67044,\n",
       "         36262, 63650, 46878,   745, 35695, 34206, 35769, 23343,  2621,\n",
       "         15929, 50656, 38606, 21734,   702, 54843, 12016, 47703, 13248,\n",
       "         22169, 31504,  7935, 26458,  8839, 57503, 52890, 57622, 11157,\n",
       "         17898, 28030, 44886, 44501, 44573, 13261, 56624, 51103, 18961,\n",
       "         13736], dtype=int64),\n",
       "  'feature_absent_idx': array([63587, 49468, 49466, 64779, 64778, 64776, 49463, 27820, 41772,\n",
       "         12799, 41773, 41775, 27811, 12805, 12782, 41776, 41777, 27805,\n",
       "         12811, 12812, 12813, 49456, 58842, 27801, 27799, 49450, 12824,\n",
       "         27796, 12826, 12807, 49446, 27828, 12777, 12723, 41744, 41747,\n",
       "         49503, 49500, 27864, 27863, 27861, 27860, 49493, 12739, 12742,\n",
       "         57271, 49471, 49490, 49486, 27845, 12762, 12763, 49474, 41762,\n",
       "         12768, 12769, 12770, 12771, 12773, 27831, 58851, 49489, 41742,\n",
       "         49445, 49444, 27757, 41818, 27754, 61704, 49411, 12892, 12894,\n",
       "         12898, 12901, 64756, 27735, 27733, 41828, 12880, 27731, 12915,\n",
       "         27725, 49400, 61709, 49398, 27723, 49391, 12930, 27715, 27713,\n",
       "         27712, 27710, 64749, 27726, 12829, 49418, 12877, 27792, 27791,\n",
       "         12835, 61695, 41798, 57283, 49439, 49437, 41802, 64766, 49434,\n",
       "         12851, 12852, 12878, 12854, 49431, 12858, 61698, 12862, 41807,\n",
       "         12865, 61700, 27763, 49425, 49424, 41817, 49421, 27758, 27776,\n",
       "         27708, 12721, 12717, 27992, 12562, 49579, 49578, 12568, 41671,\n",
       "         49574, 12574, 64822, 64821, 64820, 57261, 61641, 12557, 12581,\n",
       "         12583, 49572, 49570, 12586, 64816, 12592, 27967, 12595, 12596,\n",
       "         12597, 12598, 64814, 27963, 64819, 61646, 27994, 49586, 61629,\n",
       "         12510, 57251, 12512, 49606, 41655, 49605, 41658, 28018, 57252,\n",
       "         57254, 12527, 57256, 61637, 12530, 28013, 12534, 55978, 64833,\n",
       "         57257, 61632, 49590, 12544, 12546, 49588, 41664, 64831, 12550,\n",
       "         49594, 41741, 27958, 61647, 57266, 27908, 49532, 12675, 12676,\n",
       "         49529, 41729, 64797, 49526, 49524, 49523, 41731, 27891, 12667,\n",
       "         12693, 27883, 49516, 41738, 64792, 12707, 49511, 12710, 12711,\n",
       "         49509, 27877, 12714, 49508, 49507, 12696, 27957, 57265, 12663,\n",
       "         27955, 61648, 49560, 41694, 41695, 49558, 41697, 61650, 27946,\n",
       "         27937, 41703, 12633, 12634, 12664, 27931, 64806, 49549, 49548,\n",
       "         12644, 58865, 49546, 12653, 58859, 41718, 41719, 41722, 12661,\n",
       "         27910, 41706, 27707, 64748, 41832, 41929, 41932, 13201, 27516,\n",
       "         64699, 61751, 13209, 13214, 49241, 13217, 27506, 13219, 41935,\n",
       "         13193, 13221, 49235, 58814, 57325, 13233, 49226, 27486, 13243,\n",
       "         57329, 13247, 13249, 41949, 49219, 49216, 27500, 49215, 27527,\n",
       "         41922, 58820, 27557, 49272, 49271, 13146, 49269, 13148, 13149,\n",
       "         13151, 13154, 41908, 49263, 13160, 13190, 13161, 13167, 41913,\n",
       "         41914, 41916, 49255, 13173, 13176, 49254, 41919, 13183, 64704,\n",
       "         27535, 27531, 27548, 27561, 13255, 61762, 13311, 49181, 41971,\n",
       "         13317, 27439, 41973, 13322, 41976, 49174, 27431, 49173, 13328,\n",
       "         13329, 41970, 57339, 13333, 49168, 58809, 13338, 49164, 57341,\n",
       "         13344, 13345, 13347, 64668, 49160, 27417, 27413, 27430, 13259,\n",
       "         49182, 27449, 27471, 61765, 41962, 13269, 13271, 49202, 13273,\n",
       "         13274, 61766, 27464, 57334, 13280, 49196, 13307, 61767, 27459,\n",
       "         27458, 13288, 13290, 13292, 13293, 13295, 61771, 27451, 61772,\n",
       "         13301, 49186, 49185, 57336, 61742, 58821, 49281, 61717, 12987,\n",
       "         64737, 12989, 41850, 41851, 41853, 27676, 41856, 57301, 13002,\n",
       "         13003, 49350, 41848, 57303, 13014, 49340, 13016, 27658, 61724,\n",
       "         13020, 27656, 27653, 64730, 13028, 13029, 27650, 41867, 49345,\n",
       "         61727, 12983, 27686, 12943, 49383, 64747, 12947, 12948, 49378,\n",
       "         12951, 12952, 27703, 49377, 57297, 27701, 49374, 41847, 49373,\n",
       "         49369, 12964, 57299, 12969, 12970, 12971, 27693, 12973, 41843,\n",
       "         41844, 27688, 49362, 49360, 12960, 57305, 13037, 64728, 13096,\n",
       "         27593, 13098, 27591, 27590, 13101, 13103, 13106, 27586, 13108,\n",
       "         41896, 61737, 13112, 13095, 27582, 27581, 49291, 49290, 61739,\n",
       "         41897, 27576, 41898, 27573, 41899, 27571, 49284, 27568, 27567,\n",
       "         49294, 61735, 41887, 27605, 13040, 27641, 27638, 27637, 61729,\n",
       "         57306, 58827, 27631, 13052, 61730, 64725, 27625, 27624, 27621,\n",
       "         27620, 13065, 49315, 61733, 27616, 27612, 64721, 49309, 61734,\n",
       "         13079, 41884, 13081, 27607, 27606, 13084, 49609, 12506, 49610,\n",
       "         28026, 64964, 28473, 49931, 11922, 11923, 61545, 41416, 41419,\n",
       "         49923, 11931, 28452, 11939, 11940, 11914, 28450, 28447, 64956,\n",
       "         28445, 41429, 28441, 28439, 11952, 28436, 41432, 11959, 49901,\n",
       "         28429, 41436, 28448, 41440, 28476, 64967, 49973, 28521, 28520,\n",
       "         28519, 11861, 41389, 49960, 11874, 28504, 11876, 28501, 28500,\n",
       "         28498, 28478, 11882, 11885, 28494, 28493, 58919, 49948, 28487,\n",
       "         61537, 41406, 11902, 28482, 49941, 11906, 61538, 49954, 61528,\n",
       "         11968, 49897, 49865, 28388, 12029, 28383, 28382, 12033, 28378,\n",
       "         41455, 28374, 41457, 28371, 49856, 49855, 12022, 12045, 12047,\n",
       "         64928, 49854, 28370, 49851, 12056, 12059, 41465, 12062, 49847,\n",
       "         12064, 28361, 64920, 12046, 49898, 61559, 12015, 28421, 11975,\n",
       "         11976, 64948, 41441, 57188, 49891, 49890, 58915, 28416, 11984,\n",
       "         11985, 11987, 12017, 49885, 11994, 11995, 41444, 64943, 64941,\n",
       "         28408, 28407, 41448, 28398, 28397, 61557, 12013, 12014, 28410,\n",
       "         28525, 61527, 11850, 41337, 11699, 11700, 65001, 28624, 11704,\n",
       "         11706, 11707, 11708, 28622, 28621, 11711, 61507, 11696, 61508,\n",
       "         11722, 61510, 28605, 41346, 28602, 11731, 11733, 11734, 41347,\n",
       "         11736, 11737, 11738, 11739, 28612, 41349, 11695, 28634, 58933,\n",
       "         11647, 11649, 41321, 11651, 11653, 11656, 28649, 50062, 11659,\n",
       "         50060, 50058, 65012, 28630, 50055, 11669, 11672, 11673, 11676,\n",
       "         50049, 28642, 11679, 41331, 41333, 50046, 65005, 58928, 65004,\n",
       "         11668, 41351, 28595, 50024, 28552, 11809, 41375, 11811, 28548,\n",
       "         41376, 61522, 11817, 28544, 11821, 49988, 11826, 11827, 64984,\n",
       "         11828, 11830, 64981, 11832, 11834, 28537, 28536, 61525, 28534,\n",
       "         28530, 28529, 49978, 49976, 11848, 49985, 11806, 11805, 11804,\n",
       "         64997, 50021, 11749, 64996, 28592, 28589, 58925, 50016, 11758,\n",
       "         41360, 28583, 11765, 11766, 28580, 41361, 11777, 11779, 11781,\n",
       "         41365, 11784, 11785, 41369, 64988, 28562, 50000, 49999, 28558,\n",
       "         49994, 11802, 49837, 27409, 12075, 61563, 12356, 49691, 28128,\n",
       "         12362, 12363, 12365, 28126, 12367, 12368, 28124, 12372, 57237,\n",
       "         12374, 41593, 49686, 64866, 28117, 49679, 58884, 28114, 28113,\n",
       "         58882, 12390, 12391, 49678, 49677, 28109, 28108, 58885, 41614,\n",
       "         49696, 28136, 41580, 12313, 12315, 49713, 49712, 12318, 64874,\n",
       "         61601, 61602, 41582, 49708, 49707, 61603, 28135, 28150, 64872,\n",
       "         64871, 49703, 12338, 41584, 61607, 57232, 61608, 12344, 12346,\n",
       "         28140, 61611, 41591, 61604, 12308, 12404, 28097, 64845, 41628,\n",
       "         12459, 12460, 41631, 49642, 28064, 28063, 41634, 12468, 49639,\n",
       "         28056, 41638, 12454, 28051, 64840, 12484, 28042, 61627, 41649,\n",
       "         12490, 12491, 41650, 12494, 12495, 57247, 28034, 41653, 28047,\n",
       "         49668, 12452, 12448, 49667, 12411, 12412, 28093, 49666, 28091,\n",
       "         12418, 28088, 49661, 28085, 28084, 49654, 12428, 41626, 28082,\n",
       "         12431, 64850, 64849, 64847, 28080, 28079, 28078, 28076, 49649,\n",
       "         49648, 41624, 12446, 12447, 64851, 28167, 28173, 12297, 64908,\n",
       "         49796, 28299, 12142, 12143, 58907, 41509, 41515, 41516, 12158,\n",
       "         41520, 28274, 61578, 41503, 41523, 28265, 28264, 57218, 12178,\n",
       "         64900, 41530, 49771, 12184, 12186, 49768, 49767, 61579, 41533,\n",
       "         28267, 28248, 12134, 12132, 12079, 28350, 61565, 58914, 57208,\n",
       "         49825, 12087, 41474, 28341, 28337, 28333, 28331, 58912, 28304,\n",
       "         41485, 41486, 12106, 12108, 12109, 41487, 64914, 28316, 49809,\n",
       "         57209, 41494, 28310, 49803, 49800, 12104, 28247, 61582, 12198,\n",
       "         28208, 12251, 12252, 12253, 12254, 64888, 49742, 28207, 12258,\n",
       "         64887, 28205, 49739, 12267, 28209, 49732, 49729, 12279, 28188,\n",
       "         12283, 41565, 41566, 28182, 41572, 12292, 12293, 12294, 49725,\n",
       "         57230, 28191, 12247, 41558, 28213, 28241, 12202, 28240, 12205,\n",
       "         28238], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_instrument': {'feature_present_idx': array([35051, 18652, 19522, 19931, 46980, 20687, 63220,  6736, 45621,\n",
       "          5010,  4875,  4543,  7061, 27580, 29117, 24288, 39531, 43640,\n",
       "         16189, 17544, 54047, 37510, 52271, 19243, 30685, 51711, 30572,\n",
       "         20771, 21247, 46687, 22411, 22630, 56577, 28237, 41732, 23551,\n",
       "         24931, 41669, 56940, 19042, 57185, 13218, 64033,  1997,  9868,\n",
       "         64553, 11398,   971, 58656, 64911, 63338,   249, 12876, 67070,\n",
       "         36200, 63510, 24389, 24390, 38357, 43464, 39728, 41332, 27050,\n",
       "         64278,  5871,   287, 29016, 66067, 43105, 42370, 44370,  7674,\n",
       "         57462, 56264,  9671,  9148,  8866, 35318, 62793,  7962, 46533,\n",
       "         33648,  8375, 42227, 35607, 36844, 62868, 37801, 56192, 38366,\n",
       "         39340, 55654, 47232, 57593, 46965, 53755, 65926, 53709, 45360,\n",
       "         41708, 59374, 51921, 61381, 55550, 58338,   142, 33754, 26214,\n",
       "         25314, 23960, 23654, 23222, 21930, 21619, 19766, 19315, 12263,\n",
       "         11643,  8398,  7964,  4617,  4395,  1922,   262, 26322, 28824,\n",
       "         18637, 67238, 29637, 29893, 31699, 14993, 55684, 14263, 56440,\n",
       "         29174, 13400, 56682, 13396, 13025, 32114, 58050, 11770, 37461,\n",
       "         18290, 11068, 60580, 32125, 63130,  7493, 33634, 36057, 67201,\n",
       "          1859,  1315, 58561, 54664, 27961, 30034, 45919, 38291, 27095,\n",
       "         20737, 20142, 43320, 19896, 31181, 47735, 48718, 38906, 37719,\n",
       "         19057, 53185, 33915, 47801, 54069, 64268, 64407, 44345,  9860,\n",
       "          6318, 61221, 56501, 58896, 30713, 13006, 57083, 14969, 35604,\n",
       "         43092,   931,   557, 66223, 18299, 37401, 31836, 22763, 60615,\n",
       "         59816, 46692, 46857, 56919, 67044, 18961, 62911], dtype=int64),\n",
       "  'feature_absent_idx': array([52664, 57571, 57570, 12721, 12723, 57568, 45583, 57567, 57566,\n",
       "         28274, 45592, 45594, 28267, 12739, 12717, 28265, 12742, 45598,\n",
       "         45599, 57550, 45600, 45603, 57544, 28248, 28247, 45609, 12762,\n",
       "         12763, 28241, 28264, 28240, 12714, 12710, 12661, 12663, 12664,\n",
       "         57611, 45557, 12667, 57609, 28316, 57605, 12675, 12676, 28310,\n",
       "         57601, 12711, 45565, 57596, 28304, 57594, 57591, 45567, 12693,\n",
       "         12696, 28299, 45573, 57579, 57578, 12707, 45576, 57599, 45611,\n",
       "         28238, 12768, 57502, 57501, 28207, 57493, 28205, 12824, 12826,\n",
       "         12829, 45634, 45635, 12835, 28191, 28188, 12813, 45638, 57480,\n",
       "         28182, 45643, 57468, 12851, 12852, 45652, 12854, 28173, 12858,\n",
       "         12862, 28167, 12865, 45639, 12812, 12811, 28208, 12769, 12770,\n",
       "         12771, 12773, 28233, 12777, 28232, 45615, 45616, 12782, 57526,\n",
       "         57525, 57524, 45618, 45619, 28225, 57518, 28224, 57516, 57513,\n",
       "         57511, 12799, 28218, 45626, 28213, 12805, 45628, 12807, 28209,\n",
       "         45553, 57450, 45544, 57626, 57745, 28447, 57741, 12506, 28445,\n",
       "         45458, 57736, 12510, 57735, 12512, 28441, 57731, 57730, 28448,\n",
       "         45460, 57725, 28436, 57723, 45462, 12527, 57718, 12530, 57717,\n",
       "         57715, 12534, 28429, 45467, 45469, 28439, 28421, 45457, 57750,\n",
       "         28487, 45411, 12452, 57782, 12454, 45413, 45414, 28482, 12459,\n",
       "         12460, 45415, 28478, 28476, 28450, 57772, 28473, 57770, 57768,\n",
       "         57766, 57762, 45446, 12484, 12490, 12491, 28452, 12494, 12495,\n",
       "         57753, 12468, 12544, 45473, 12546, 12598, 57666, 57665, 28374,\n",
       "         45509, 28371, 28370, 57662, 45511, 57656, 28361], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 205\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 205\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 205\n",
       "    })}}},\n",
       " 'contains_location': {'feature_present_idx': array([   12, 36023, 15909, 56154, 35763, 16170, 56386, 35378, 36377,\n",
       "         56573, 35250,  5053, 35068, 57507, 34538, 17092, 17107, 16418,\n",
       "         34236, 15625, 37050, 54862, 39479, 14791, 54923, 54972, 38487,\n",
       "         15050, 15611,  5901, 15108, 55319, 55363, 55513,  5818, 38039,\n",
       "         15445, 55230, 39769, 17158,  4535,  3517, 60194, 60404, 31387,\n",
       "          3369, 30648, 30432, 31448, 30431, 61063, 19298, 19348, 19607,\n",
       "         29655,  2860, 19785, 19125, 33990, 60095, 18302, 58675, 33769,\n",
       "         33395, 33389, 17657,  4113, 32443, 18446, 59061, 17973, 32264,\n",
       "         18015,  3923, 18047, 32201, 18212,  4022, 19794, 39933, 40152,\n",
       "         45822, 49230, 49389, 45673, 49582, 45405, 10995,  9315, 45150,\n",
       "         49818, 11061, 45101, 45094,  8892, 50156,  8801, 45131, 11292,\n",
       "         45876, 49152, 47885,  9901,  9889, 10063, 47281, 48542, 48565,\n",
       "          9425, 48709, 46286, 46279, 46206, 46152, 10480, 49092, 45977,\n",
       "         46394, 54390, 44673, 44237, 41522, 41374,  7333, 13707, 13708,\n",
       "         13732, 13740, 52720, 53201,  7084, 13875, 53366, 13999, 53710,\n",
       "          6906, 53944, 53255,  8752, 41668, 52567, 44233,  8680, 44062,\n",
       "         50838, 51339, 12206, 43343, 41761, 51503, 51719, 12673, 52075,\n",
       "         52118, 42092, 52470, 52536, 51616, 61708,  9945, 26700, 62967,\n",
       "         62941,  2286,   479, 64284, 28096, 62889, 21300, 27826, 26122,\n",
       "         62783,   387, 64479, 66705,  1106, 66849, 26333, 21346, 20274,\n",
       "         65785, 24164, 21258, 28089, 66207,  2001, 27674, 20917, 25641,\n",
       "          2067, 27517, 63441, 63407, 27903, 66322, 63950, 20652, 27989,\n",
       "           563, 24830,  1795, 27428, 63096, 27375, 62694, 62796, 62583,\n",
       "         28988, 21566, 21568, 28975, 62413,  2613, 62422,  1400, 26599,\n",
       "         67302, 26412,  2596, 24133, 23585,   233, 66949, 26373, 66884,\n",
       "         62444, 62130, 43331, 13955, 13953, 42680, 26678, 40789, 25771,\n",
       "         13894, 42562, 12827, 42480, 40513, 25676, 12750, 43171, 42688,\n",
       "         42737, 12698, 40413, 12422, 42979, 25655, 43042, 43146, 43268,\n",
       "         43223, 25455, 40415, 40485, 22140, 42143, 42292, 41287, 13287,\n",
       "         26452, 41883, 41302, 26189, 26523, 26392, 13484, 41670, 41561,\n",
       "         26289, 41532, 13670, 41700, 42399, 41207, 26548, 13890, 12996,\n",
       "         13616, 40816, 42097, 13061, 41139, 25845, 22054, 42061, 41092,\n",
       "         13242, 26585, 26574, 42075, 25448, 19811, 43412, 24033, 46272,\n",
       "         24049, 24148, 10536, 10559, 10570, 45954, 10603, 24334, 10636,\n",
       "         24402, 24447, 45793, 24455, 45742, 45625, 45476, 10877, 23774,\n",
       "         24504, 10325, 23709,  9960, 23225, 47699, 23217, 47614, 23499,\n",
       "         47575, 10090, 47373, 47365, 46708, 10230, 10232, 46616, 23602,\n",
       "         23662, 46545, 46529, 46470, 23720, 43348, 45384, 24558, 44136,\n",
       "         11616, 44130, 40410, 25180, 44005, 43858, 43771, 43750, 11941,\n",
       "         43467, 25304, 43457, 43439, 43415, 12165, 12169, 12189, 25381,\n",
       "         22333, 45315, 44155, 11564, 22666, 11026, 24698, 22609, 22589,\n",
       "         24734, 44890, 44744, 11239, 44683, 24815, 11283, 24823, 22450,\n",
       "         44582, 44450, 22397, 11481, 11490, 25109, 44073, 39814, 26714,\n",
       "         33616, 17454, 33236, 20610, 33233, 17850, 32749, 32599, 32337,\n",
       "         32280, 20583, 20576, 32255, 28194, 32164, 32054, 18118, 20509,\n",
       "         31998, 33623, 31988, 33669, 17404, 34582, 34559, 27868, 34523,\n",
       "         34517, 34466, 27944, 17187, 34130, 34104, 17274, 34025, 33994,\n",
       "         17313, 33935, 33854, 33838, 33824, 20623, 20616, 16931, 18270,\n",
       "         18293, 30370, 20178, 30322, 20017, 19300, 29963, 19500, 29763,\n",
       "         29665, 19974, 19951, 29396, 19655, 29087, 29278, 29207, 29089,\n",
       "         19859, 19827, 19027, 18273, 30379, 30657, 31812, 28653, 18311,\n",
       "         18395, 31787, 31727, 31478, 20212, 28801, 31443, 28848, 18742,\n",
       "         18772, 31115, 31093, 31050, 18815, 30990, 30984, 18927, 34660,\n",
       "         16735, 34678, 39658, 39570, 21383, 39305, 21354, 38907, 38881,\n",
       "         27015, 14858, 14879, 38811, 38788, 14894, 38694, 38610, 27047,\n",
       "         38421, 21325, 38282, 39661, 27341, 26855, 14462, 40333, 40259,\n",
       "         26768, 40123, 14197, 40111, 14239, 14240, 40074, 14265, 40067,\n",
       "         14288, 21499, 14330, 26807, 39927, 39922, 19815, 26840, 14478,\n",
       "         21105, 27407, 37967, 35700, 35595, 35536, 27734, 35295, 35291,\n",
       "         27835, 20808, 16454, 35189, 27843, 16521, 16536, 47928, 34906,\n",
       "         16576, 34868, 34776, 34706, 16077, 35741, 27660, 15969, 37682,\n",
       "         15405, 37133, 37113, 36991, 15480, 15484, 36975, 36705, 14083,\n",
       "         27480, 27501, 36327, 15864, 15871, 27614, 15934, 15947, 27633,\n",
       "         35888, 36450, 34922, 45179, 56994,  2526, 62728,  6280,  6301,\n",
       "         54879,  6367, 54834,  6408, 54647, 54589, 54507,  6588,  6600,\n",
       "          6605, 62763, 54287, 54229, 54916,  6231, 54970, 55003,  5606,\n",
       "         55690, 55570, 61777,  2691,  5695, 55539, 55531,  6712,  2659,\n",
       "         62290, 55224,  5962,  2645,  6041,  6052,  6056, 62469, 55286,\n",
       "          5591,  2377, 54046,  1902,  1896, 63827, 52924,  1885, 63911,\n",
       "         64081, 64098,  7368,  1758, 52659, 52578, 64105,  7532, 64124,\n",
       "          1691,  7566,  7204, 63640, 63578, 53131, 53878, 53765,  6910,\n",
       "          6913, 63002, 53691, 53683, 59610,  6830, 53589, 63164, 63330,\n",
       "          2134, 53347, 63536,  2026,  1982, 63571, 53522,  5524, 55959,\n",
       "          5493, 58873,  4268, 60665,  3321, 58830, 58823, 58773,  4391,\n",
       "         58695, 58600, 58515,  4559, 58370,  4572,  4578, 58210,  3313,\n",
       "         58942, 58947, 58973, 60548, 59577, 59701, 59471, 59824, 59258,\n",
       "         59254, 59874,  3764,  4631, 60102,  4000,  4013,  4043, 59047,\n",
       "          4114,  4154, 60488,  4182, 59105,  4666, 57925, 57902, 61073,\n",
       "         56529, 56442, 56426,  5204, 61189, 56377, 56349, 60983,  5235,\n",
       "          3041,  5330,  2952, 56055, 56025,  5464, 61250,  5492, 56318,\n",
       "          1654, 56732,  3163, 57714, 57657,  4711, 57590, 60709, 60711,\n",
       "          4766, 57298, 56744,  4845,  4944, 57056, 57053, 60836, 60869,\n",
       "         56936,  3191, 56843, 57149,  7575, 63051,  1636,   362, 49557,\n",
       "         49672, 66615,   488,   534, 66513, 49716,  9033,  8987,   554,\n",
       "         50127,  8855,  8787, 50158,  8757, 50258, 65848, 50789, 65939,\n",
       "          8584, 50662, 66059,  9195,  8594, 50624, 50489, 66151, 50398,\n",
       "           696, 50324,  8595,  8527, 49402, 49313,  9923, 48063,    22,\n",
       "          9905, 48111, 48154, 48264, 48281, 48316, 48445, 48458, 67137,\n",
       "         48484, 48496, 48516, 67130, 67045, 66847,  9409,  9446, 49187,\n",
       "          9491, 49145, 66758, 49051,   229,   224,   207, 48855,  9684,\n",
       "          9723, 48986, 50994, 59652,  1123, 51401, 52182, 65671,  1506,\n",
       "         52319, 51462,  8088, 65566, 52235,  7791, 51496, 64740,  1510,\n",
       "         51497, 51663, 65534, 64595,  8193, 52042, 65680, 51386, 65361,\n",
       "         51217, 65060, 65709, 52531, 30613, 30445, 63552, 24155, 30998,\n",
       "         65195, 64898, 64854, 64812, 31046, 30441, 31041, 66877, 60682,\n",
       "         66845, 24337, 27813, 27825, 24333, 60691, 24234, 24407, 24210,\n",
       "         65045, 31047, 26607, 64961, 30866, 30522, 30895, 30466, 65018,\n",
       "         28234, 64014, 67034, 27372, 31439, 27008, 60380, 60133, 27230,\n",
       "         31501, 27151, 31544, 67232, 67282, 67294, 64286, 31746, 59712,\n",
       "         23400, 64372, 31795, 59689, 31424, 60455, 67204, 31348, 27505,\n",
       "         23911, 23870, 26814, 24482, 23868, 60679, 60561, 64681, 63883,\n",
       "         31130, 27377, 23665, 31221, 67173, 31261, 23618, 26978, 31285,\n",
       "         26985, 64619, 24492, 27982, 66655, 62811, 28952, 25513, 62341,\n",
       "         66126, 66131, 25414, 62906, 66267, 62283, 29000, 25268, 29023,\n",
       "         29078, 62254, 62214, 61904, 65595, 66315, 62378, 61642, 26259,\n",
       "         66008, 28315, 28332, 28434, 26069, 26057, 28459, 28532, 25938,\n",
       "         25925, 28607, 62749, 65889, 65928, 28669, 26194, 25755, 62515,\n",
       "         62784, 65980, 28164, 61624, 66328, 25101, 66385, 29999, 66387,\n",
       "         24799, 26453, 61110, 63294, 66510, 30091, 30113, 63325, 30135,\n",
       "         30181, 65515, 24731, 66590, 30336, 65358, 63331, 66363, 29978,\n",
       "         61194, 24850, 61619, 61581, 61500, 29362, 29363, 61367, 64582,\n",
       "         26383], dtype=int64),\n",
       "  'feature_absent_idx': array([39346, 25433, 54098, 10626, 31389, 18630, 10630, 31386, 10632,\n",
       "         10633, 10634, 49284, 45152, 25438, 49281, 10641, 10642, 31379,\n",
       "         10645, 10646, 45157, 10649, 18624, 18623, 59853, 10638, 18622,\n",
       "         59864, 10618, 59885, 31417, 10589, 31416, 59883, 31414, 18650,\n",
       "         18648, 59877, 54085, 54086, 45151, 54087, 54090, 25427, 18640,\n",
       "         59870, 25429, 10611, 31399, 45148, 59868, 54096, 59866, 10602,\n",
       "         10654, 18619, 59852, 49271, 31346, 59828, 10697, 59827, 10699,\n",
       "         25456, 59825, 25457, 45178, 49269, 49272, 59821, 10708, 10710,\n",
       "         10711, 59820, 45188, 10716, 10717, 59817, 18596, 10720, 10723,\n",
       "         10706, 25452, 45172, 31355, 10658, 10659, 18617, 18616, 59846,\n",
       "         10665, 10666, 45159, 59845, 31367, 45160, 59843, 10673, 54109,\n",
       "         10677, 59840, 10680, 31360, 18610, 54111, 45168, 59837, 10686,\n",
       "         10687, 54113, 31418, 31328, 45135, 49290, 59944, 59943, 31489,\n",
       "         59942, 54049, 25396, 10490, 31485, 59936, 49309, 45096, 54048,\n",
       "         59935, 59934, 59933, 18678, 31477, 10502, 10503, 59930, 54057,\n",
       "         10511, 31469, 59922, 10496, 10514, 31491, 31492, 31515, 45070,\n",
       "         54041, 18694, 10451, 59964, 59963, 45073, 59960, 59959, 59958,\n",
       "         59945, 59956, 45078, 59953, 25391, 18691, 59950, 10468, 54043,\n",
       "         54045, 10474, 45089, 10478, 31507, 59921, 25408, 31467, 59901,\n",
       "         31445, 59899, 25413, 18661, 10558, 31438, 18660, 31435, 45122,\n",
       "         10565, 45117, 49294, 54077, 18656, 31429, 45128, 31426, 10575,\n",
       "         10576, 49291, 10578, 10579, 25421, 59892, 59903, 10549, 45113,\n",
       "         10518, 18670, 59920, 54068, 10522, 18668, 59917, 54072, 59915,\n",
       "         10527, 59914, 18665, 59911, 45106, 45107, 59909, 45108, 31456,\n",
       "         10540, 31455, 31453, 10544, 45111, 59904, 10547, 10584, 54037,\n",
       "         54125, 49263, 45275, 45281, 10905, 59725, 45282, 31201, 18536,\n",
       "         10910, 10911, 18535, 10913, 25508, 31194, 45292, 59714, 10921,\n",
       "         10922, 18531, 25512, 59710, 18529, 45299, 10928, 25514, 25511,\n",
       "         54179, 10900, 31211, 54164, 45250, 59734, 31230, 31229, 31228,\n",
       "         10874, 45252, 45253, 31224, 10879, 31210, 45255, 10883, 45258,\n",
       "         18542, 49235, 31217, 54171, 10889, 45266, 10893, 10894, 45271,\n",
       "         10882, 10931, 10932, 45304, 10967, 31151, 59673, 54188, 31148,\n",
       "         59670, 18511, 59668, 10978, 31146, 59665, 45323, 10982, 45331,\n",
       "         10986, 10987, 25526, 45333, 31140, 10991, 45338, 49219, 54191,\n",
       "         45339, 31145, 59676, 10963, 18516, 31178, 31177, 45305, 59698,\n",
       "         10938, 25516, 59691, 10943, 25517, 31172, 10947, 25519, 45310,\n",
       "         18521, 18520, 49226, 18518, 54184, 59678, 31161, 45317, 10958,\n",
       "         45321, 10960, 31157, 10866, 18592, 59736, 59737, 49255, 10763,\n",
       "         59793, 10765, 31302, 10767, 31301, 25477, 59786, 10773, 45212,\n",
       "         59795, 54144, 59783, 31293, 31291, 10782, 31289, 45220, 10785,\n",
       "         45223, 10787, 59780, 10790, 49254, 59779, 59796, 10758, 59810,\n",
       "         10730, 18589, 54128, 59809, 10734, 10736, 10737, 59808, 45197,\n",
       "         10740, 59797, 25469, 54131, 45199, 18584, 10746, 31312, 54133,\n",
       "         54138, 59803, 18578, 25474, 59799, 10742, 59774, 31282, 54152,\n",
       "         45236, 31251, 10836, 31250, 10838, 10839, 18550, 45237, 45239,\n",
       "         10843, 59744, 59749, 54159, 31243, 31242, 10850, 10852, 31240,\n",
       "         59739, 59738, 45243, 45247, 25503, 45248, 10846, 18551, 31254,\n",
       "         59754, 31279, 59771, 10799, 25488, 10801, 31277, 10803, 59767,\n",
       "         31276, 10806, 31274, 59764, 45232, 31272, 54156, 45233, 25492,\n",
       "         59756, 59755, 10821, 10822, 49241, 54158, 31258, 31257, 45249,\n",
       "         31134, 45064, 10441, 10046, 18855, 60256, 31803, 31802, 25272,\n",
       "         44850, 53950, 10055, 60253, 18850, 60258, 60249, 10064, 31792,\n",
       "         25274, 53952, 18847, 60243, 53953, 10071, 10073, 60238, 31784,\n",
       "         60248, 44858, 60260, 10042, 10017, 44825, 10019, 53945, 53946,\n",
       "         60280, 44829, 10024, 60275, 18860, 60274, 10043, 44830, 44834,\n",
       "         25269, 49411, 10034, 31811, 18856, 31807, 10038, 31806, 10040,\n",
       "         10041, 60270, 44859, 10080, 60235, 53967, 10119, 49398, 31752,\n",
       "         31749, 10125, 10127, 60191, 53969, 10130, 10132, 44878, 60189,\n",
       "         53970, 10137, 49391, 10139, 31737, 60183, 31735, 60180, 60178,\n",
       "         44893, 18808, 60188, 60206, 60209, 60210, 10083, 44860, 10085,\n",
       "         18841, 10087, 53956, 44867, 53959, 60228, 25283, 49400, 10097,\n",
       "         18832, 10099, 31765, 53962, 10102, 18830, 10105, 10107, 10108,\n",
       "         53964, 18826, 53966, 31756, 18864, 10150, 10015, 31826, 31907,\n",
       "         25236, 31905, 31904, 53910, 31902, 31898, 31897,  9915, 53913,\n",
       "         53916, 31910,  9918, 49425, 60345, 60344, 60342, 44777, 60340,\n",
       "         31889, 31888, 60338, 18898, 31886, 44775, 49424,  9897, 18911,\n",
       "         31938, 31937, 44737, 60390, 60387, 31935,  9870, 31934, 60386,\n",
       "         44739, 53902, 49431, 60382, 44749, 25227, 25228, 60374, 60373,\n",
       "         25231, 31918,  9891, 60367, 44764, 18912, 18919, 31882, 18894,\n",
       "         49421,  9982, 53933, 31848,  9987,  9988, 31846, 31845, 44811,\n",
       "          9994, 44812, 60305, 18880, 53939, 53941, 10001, 60300, 10003,\n",
       "         10004, 53942, 18867, 60292, 53943, 31828, 60287, 31837,  9980,\n",
       "         25255,  9978, 60332,  9942, 25249, 60329, 18889, 31874, 31872,\n",
       "         31870, 44793,  9953, 18887, 31866, 44795, 53927, 25252, 44797,\n",
       "          9963,  9964, 31859, 53929, 44801, 49418, 31854,  9973,  9975,\n",
       "         44822, 10442, 31726, 53975, 10339, 31589, 60041, 10342, 10343,\n",
       "         60039, 31588, 10346, 60038, 10349, 18733, 60047, 18732, 25357,\n",
       "         10355, 60031, 10357, 45008, 60028, 25358, 31578, 10363, 18727,\n",
       "         10366, 45007, 60024, 54016, 31592, 54009, 44980, 10304, 44982,\n",
       "         44983, 18750, 10308, 10309, 54010, 60065, 44987, 10336, 31604,\n",
       "         10321, 44995, 44996, 60056, 10326, 54013, 10330, 25354, 54015,\n",
       "         60053, 49340, 44993, 31575, 10370, 31574, 31548, 18714, 59996,\n",
       "         31545, 59995, 25374, 59993, 59992, 18712, 54031, 31535, 10408,\n",
       "         45058, 54032, 31532, 18707, 59986, 25378, 59984, 31528, 18700,\n",
       "         45062, 49315, 59971, 59987, 18715, 31551, 18718, 25366, 60020,\n",
       "         10376, 10377, 25367, 60018, 60015, 10383, 60013, 45022, 31565,\n",
       "         10388, 31563, 10390, 10391, 10392, 45026, 10394, 10395, 60006,\n",
       "         45028, 31559, 54024, 45036, 10402, 31616, 10153, 10300, 44976,\n",
       "         10190, 10191, 60139, 60138, 18791, 49374, 31696, 31694, 53987,\n",
       "         10203, 53988, 10189, 10205, 60130, 44920, 44921, 60129, 44922,\n",
       "         10212, 60128, 53990, 60124, 31686, 25313, 49373, 10218, 60140,\n",
       "         60143, 31724, 44901, 25300, 44903, 60168, 31719, 25301, 31716,\n",
       "         60164, 60160, 49383, 10187, 31712, 60154, 49378, 25306, 10177,\n",
       "         31708, 44913, 18796, 31704, 49377, 18794, 31701, 31711, 10220,\n",
       "         44927, 18783, 31646, 18765, 44958, 10268, 18761, 10271, 44959,\n",
       "         60093, 49350, 31634, 44966, 60100, 44968, 10281, 10282, 31630,\n",
       "         60083, 60082, 31629, 31628, 10289, 31626, 49345, 60073, 10280,\n",
       "         49360, 60104, 31653, 25315, 10224, 49369, 31677, 10228, 18778,\n",
       "         10231, 31675, 31674, 60113, 44934, 31671, 10239, 53993, 53994,\n",
       "         10242, 18773, 31660, 31658, 10249, 10250, 31656, 49362, 60107,\n",
       "         10257, 10299, 45340, 59643, 31129, 30612, 49053, 30608, 25729,\n",
       "         45683, 18247, 11722, 30601, 30600, 25730, 59139, 30614, 49045,\n",
       "         59134, 11731, 11733, 11734, 11736, 11737, 11738, 11739, 18239,\n",
       "         59128, 18237, 49042, 30589, 45674, 45672, 30637, 30636, 30635,\n",
       "         59158, 30633, 59154, 25723, 30627, 45664, 11695, 11696, 11711,\n",
       "         18255, 11699, 11700, 30622, 18253, 25724, 11704, 45671, 11706,\n",
       "         11707, 11708, 59147, 18254, 18236, 54396, 59123, 18226, 11781,\n",
       "         59089, 11784, 11785, 59088, 59087, 49038, 18223, 45711, 30559,\n",
       "         11779, 30558, 25744, 25745, 25746, 30552, 45716, 59073, 45717,\n",
       "         11802, 11804, 11805, 11806, 45713, 54406, 11777, 59092, 45695,\n",
       "         11749, 30585, 54399, 45696, 30582, 30581, 54400, 45699, 11758,\n",
       "         30577], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_manner': {'feature_present_idx': array([36878, 64216,  8712, 24347, 24338, 45561, 58080, 45554, 24294,\n",
       "         40805,  8820, 24221,  8838, 24116, 24365, 24090, 40874,  8896,\n",
       "         49819, 64111,  8956, 45464,  8973, 64096, 23938, 23925,  9044,\n",
       "         23898, 40962, 40862, 23853, 24415, 57992, 64473, 25585,  8073,\n",
       "         57761, 64426, 25529, 25524, 64393, 25424, 45839, 25291, 40582,\n",
       "          8328, 24501, 25149,  8405, 25029, 40619, 49721,  8498, 49726,\n",
       "          8508,  8516,  8519, 24882, 64306, 24822, 40677,  8359,  9108,\n",
       "         23787, 49870, 22896, 58486,  9824,  9828, 45132, 22764, 41364,\n",
       "         63729, 58590,  9979, 63688,  9990, 58604, 22904, 63666, 63566,\n",
       "         45059, 63538, 22399, 22394, 63530, 51757, 22304, 22219, 51725,\n",
       "         10311, 63455, 45017, 10057, 22961, 63750, 23063, 23780, 64026,\n",
       "         41011,  9198, 23716, 23700, 41098,  9297,  9327,  9329,  9347,\n",
       "         23476, 23448, 45356, 23394, 58328, 23357, 23348, 23321, 23202,\n",
       "         45259, 45241, 63864, 41256,  9646,  9664, 23112, 23066, 49924,\n",
       "         25719, 58825, 45941, 49657, 28221, 56661, 28195,  6251, 28121,\n",
       "          6261, 65168, 49354, 56718, 46605, 46595, 65130, 46567,  6196,\n",
       "         56778,  6403, 65068, 56844, 27858, 65057, 39990, 56873,  6507,\n",
       "          6517, 46507, 52272, 56879, 56941, 65095, 56952, 56649,  6142,\n",
       "         39507,  5633, 29083,  5671, 29079, 65313, 29069, 29022, 39578,\n",
       "         52352, 56427, 28937, 28843,  6153, 46763, 39657, 28671,  5933,\n",
       "          5943, 28639, 28581, 28495,  6037,  6065, 56634, 28340, 52315,\n",
       "          6115, 56481, 27619, 27575, 27560, 26512, 49616, 26489, 57443,\n",
       "          7400,  7440, 40282, 40290, 57492, 26244, 26234, 26190, 26182,\n",
       "         40201, 57515, 26161,  7613,  7731, 46060, 25932, 40398, 25864,\n",
       "          7787,  7808,  7852,  7859, 57681, 45957,  7567, 26603, 26818,\n",
       "         26868, 27522,  6715, 27503, 64935, 27478, 64926, 27427,  6789,\n",
       "         27415, 57048,  6852, 27370,  6859, 27358, 64846, 27261,  6899,\n",
       "          6909, 57089, 57109, 40117, 52185, 27140, 57144, 27070, 46309,\n",
       "         26913,  7163,  7168, 40468, 58837, 10422, 10454, 44078, 17602,\n",
       "         13650, 17527, 13661, 51000, 13666, 42986, 50991, 13686, 50969,\n",
       "         17432, 13727, 17632, 50921, 17242, 17233, 62264, 17066, 43975,\n",
       "         13948, 61207, 43955, 16903, 14005, 14009, 14015, 50560, 43080,\n",
       "         62182, 50520, 13514, 51075, 62625, 12992, 18780, 13026, 18746,\n",
       "         13059, 18675, 62564, 13119, 62540, 50375, 42720, 13533, 60605,\n",
       "         18352, 44306, 42779, 60733, 42834, 13375, 13395, 13398, 60759,\n",
       "         44215, 13477, 60810, 60862, 60614, 61224, 16841, 50572, 16017,\n",
       "         14772, 14802, 15981, 15959, 61561, 50648, 14869, 15820, 15795,\n",
       "         61968, 15697, 14989, 61452, 43495, 15508, 15028, 15043, 15081,\n",
       "         15093, 43548, 15454, 15128, 61898, 15207, 43558, 43599, 15234,\n",
       "         61931, 14712, 16115, 43387, 43899, 16753, 43165, 16708, 61263,\n",
       "         16671, 14219, 16638, 62137, 61269, 14336, 14348, 14360, 43815,\n",
       "         61353, 61360, 43783, 14496, 61400, 16352, 61418, 14583, 16327,\n",
       "         43336, 50613, 43748, 16267, 14691, 16186, 60442, 60396, 60381,\n",
       "         18990, 21291, 42020, 11192, 11204, 51405, 59433, 11310, 59447,\n",
       "         20887, 59494, 59504, 59511, 20738, 21341, 20705, 20703, 50148,\n",
       "         11521, 59629, 59649, 51363, 11580, 20451, 20450, 42254, 59713,\n",
       "         11640, 20293, 11456, 11147, 59208, 21377, 58839, 51673, 22026,\n",
       "         10500, 21909, 21857, 41739, 50077, 58922, 21768, 63359, 10644,\n",
       "         41752, 44933, 63332, 10695, 10753, 21682, 51555, 10841, 10858,\n",
       "         44896, 21649, 21635, 10996, 21608, 41837, 59164, 59197, 59720,\n",
       "         29197, 20260, 11743, 12449, 19390, 42591, 12543, 60135, 50270,\n",
       "         19272, 50274, 60224, 12601, 19245, 12608, 19237, 12437, 62808,\n",
       "         50276, 62781, 62780, 60311, 60314, 42610, 42615, 19100, 19044,\n",
       "         19043, 19026, 12798, 60366, 12630, 62923, 12403, 62939, 11755,\n",
       "         44696, 63074, 59832, 20146, 11875, 20145, 59861, 20125, 11938,\n",
       "         59916, 20033, 20014, 19970, 63028, 44662, 19801, 59976, 19740,\n",
       "         19684, 60000, 42425, 12199, 12228, 19554, 19551, 60099, 50233,\n",
       "         19404, 20232, 29322, 15302, 33069, 66824, 47296, 38802, 35278,\n",
       "         54029, 55561, 54092,   762, 55565, 32949, 34268,  1772,   741,\n",
       "         35465, 31010,  3002, 32866, 37474,  4020, 34346, 31253,  4103,\n",
       "         66217,  4117, 32780,   889, 65910,  4125, 37718,  1708, 38772,\n",
       "         32809,  1717,  4293, 30931,  1782, 65730,   649, 30658, 30625,\n",
       "         39000, 37285, 35748,  1884, 35820,   597,  1890, 66434, 35852,\n",
       "         35861,  4577, 34081, 37293,  4012, 48960,  2847, 38867, 48367,\n",
       "         38885, 34266, 67101, 33009, 54844,  1823, 54449, 30743, 66396,\n",
       "         53965,  2850, 52582, 30675, 53948, 31265, 55499, 65971,  1433,\n",
       "          3629, 47420, 47404,  1189, 47395, 38620,  1464, 54176, 31555,\n",
       "         55394, 66927, 48230, 53202, 54141,  3622,  3276, 31697, 31740,\n",
       "         47481, 55204, 66118, 31958,  3469, 54254, 34614, 37619,  1234,\n",
       "         54215, 55299, 32248,  3535,  3319,  3540, 55355,  4588, 31529,\n",
       "         34925, 67066, 34432, 48903, 37518, 37708, 47313, 35136, 48300,\n",
       "          3178,  3151, 48161, 67067, 31297,  3119, 34407, 55035,  1527,\n",
       "         37663, 66901, 38685, 38422, 32436, 31462, 34954, 67009, 66058,\n",
       "         34505, 54123, 55426, 31436, 66006,  3917, 67053,  3234,  3920,\n",
       "         30481, 34656,  4601, 33371, 48520, 55973,  2042,  2354,  2536,\n",
       "         36277, 33510,  4999, 38167, 33839, 33294, 65458, 30065, 39226,\n",
       "         33837, 52398, 38172, 33997, 39427,  5349, 37148,  5363, 65494,\n",
       "         55921, 47078, 67156, 36368,  5083, 36635,  2416,  5240, 56105,\n",
       "         33851, 29747, 66592,   138, 38152, 37879, 52473, 36537, 53722,\n",
       "         65396, 47012, 47975, 53395,  5285,  2078, 47045, 65428, 29645,\n",
       "         29634, 37873, 37123,   200, 36387, 47052, 30197, 67153, 33441,\n",
       "          2631, 33155, 34067, 39118,   457,  4826,  5429, 67151, 47088,\n",
       "          2004, 56195, 56220, 38186,  4798,  4796, 56243, 36058, 30331,\n",
       "         46921, 30369, 48638,  5490, 36918,  2265, 39459, 30458, 55832,\n",
       "         37151, 36113, 66489, 53006,  4872, 36822,  4849, 49165, 67274,\n",
       "         47079, 34003, 34002, 29538, 54615, 33551, 34652, 59551, 21088,\n",
       "         19308, 19200, 42045, 60242, 51138, 53172, 52998, 33757, 33721,\n",
       "         34645, 20799, 20669, 60234, 54285, 33816, 19331, 53004, 19231,\n",
       "         37897, 54277, 34585, 20898, 53177, 37644, 20964, 19252, 42064,\n",
       "         37650, 42605, 33847, 20684, 20632, 59517, 20395, 20572, 20216,\n",
       "         42335, 20017, 20016, 34142, 53072, 42331, 19953, 19922, 59781,\n",
       "         53123, 20270, 19853, 34001, 19942, 19788, 19111, 20214, 20182,\n",
       "         42328, 20147, 34098, 20187, 53051, 34016, 51292, 37815, 54472,\n",
       "         34124, 20099, 20205, 37828, 42314, 54588, 19759, 19716, 33953,\n",
       "         34365, 42220, 34367, 42558, 33952, 20175, 20492, 37680, 20548,\n",
       "         19367, 37669, 60120, 59640, 19398, 20305, 19476, 19509, 59979,\n",
       "         20310, 34278, 34296, 34310, 42429, 37712, 42467, 19579, 19575,\n",
       "         42480, 20361, 37866, 60092, 51304, 29323, 18174, 19064, 36037,\n",
       "         16529, 16511, 37155, 16506, 43227, 16476, 16473, 16466, 37199,\n",
       "         36078, 36086, 16389, 61365, 36155, 37141, 16336, 36198, 53746,\n",
       "         36222, 43240, 16272, 16645, 43190, 43142, 16946, 16923, 53899,\n",
       "         16902, 61219, 35756, 35766, 53818, 16647, 16826, 16774, 37255,\n",
       "         16744, 37236, 35908, 53805, 37216, 16666, 16656, 16820, 53739,\n",
       "         53305, 43378, 53654, 61749, 36746, 43508, 36750, 43520, 15477,\n",
       "         36753, 36764, 43504, 36964, 53534, 61818, 36957, 61836, 15408,\n",
       "         15360, 15347, 36804, 53475, 61817, 36614, 43485, 15610, 36328,\n",
       "         16101, 16027, 37102, 50745, 36440, 50736, 53376, 36567, 43478,\n",
       "         15850, 61597, 36571, 36574, 15796, 36578, 37033, 15761, 61612,\n",
       "         61633, 15647, 43140, 19098, 61164, 35542, 34928, 60560, 18627,\n",
       "         34969, 18611, 34989, 18543, 60610, 34992, 60496, 60628, 54099,\n",
       "         18331, 51046, 35107, 18227, 18200, 42830, 42835, 18124, 51052,\n",
       "         18113], dtype=int64),\n",
       "  'feature_absent_idx': array([20091, 20701, 53312, 53316, 53317, 20694, 53320, 53323, 20685,\n",
       "         53326, 53328, 53331, 20664, 20663, 20659, 53341, 53310, 20650,\n",
       "         53309, 20712, 20768, 20767, 53265, 53266, 53279, 20746, 20744,\n",
       "         20743, 20739, 53285, 20731, 53288, 20729, 53290, 20720, 20707,\n",
       "         53261, 20646, 20639, 53401, 20577, 20575, 20559, 53411, 20552,\n",
       "         20551, 53414, 53415, 20540, 20538, 53417, 53418, 20533, 20530,\n",
       "         20584, 20641, 53393, 20597, 53356, 20635, 53358, 53359, 53360,\n",
       "         53365, 20622, 20620, 20608, 20606, 53382, 53383, 20601, 20599,\n",
       "         53389, 53391, 53260, 20773, 20776, 20939, 53137, 20933, 53142,\n",
       "         53143, 20929, 20927, 20926, 53145, 20922, 53147, 53148, 53149,\n",
       "         20916, 20914, 20945, 20911, 20947, 53132, 20990, 20988, 20985,\n",
       "         20984, 20983, 20981, 20979, 20977, 20972, 20965, 53119, 53121,\n",
       "         20959, 53124, 53128, 20948, 20909, 20907, 20891, 53224, 53227,\n",
       "         53229, 20812, 53230, 53231, 20803, 53234, 20795, 53244, 20792,\n",
       "         20787, 20785, 53249, 53258, 20819, 53218, 20829, 20831, 20888,\n",
       "         53175, 20879, 53176, 53178, 20874, 53181, 20525, 20871, 53190,\n",
       "         53198, 20851, 20845, 20840, 20839, 53212, 53182, 53426, 53429,\n",
       "         20520, 53595, 20219, 53597, 53600, 53601, 53602, 53606, 53613,\n",
       "         20197, 20196, 53617, 20191, 53619, 20181, 20179, 20221, 20176,\n",
       "         20222, 53592, 53566, 53568, 20261, 53570, 53571, 20252, 20249,\n",
       "         20248, 20246, 20244, 20242, 53582, 53584, 53590, 53591, 20224,\n",
       "         53626, 53627, 20167, 20108, 53662, 20103, 53664, 20090, 20084,\n",
       "         53679, 20079, 20077, 53684, 53687, 53688, 20066, 53694, 53700,\n",
       "         20109, 53660, 53657, 20116, 53636, 53638, 53639, 20152, 20150,\n",
       "         20149, 53641, 20267, 53643, 20135, 20134, 53652, 20128, 20122,\n",
       "         20121, 20118, 53645, 53106, 20268, 53562, 53462, 53464, 20456,\n",
       "         20454, 20452, 53469, 53480, 20439, 20430, 53484, 20426, 53489,\n",
       "         20423, 20420, 20419, 20465, 20418, 20469, 20472, 20519, 20518,\n",
       "         53438, 20508, 53443, 20501, 20488, 53453, 53455, 20482, 53456,\n",
       "         20478, 53457, 20475, 20474, 20471, 53492, 20412, 20411, 20316,\n",
       "         20315, 20313, 53547, 20302, 20301, 20300, 20299, 53552, 20294,\n",
       "         20290, 53556, 53560, 20281, 53561, 20317, 20321, 20327, 20331,\n",
       "         20409, 20403, 20396, 53502, 53508, 20374, 53511, 53565, 20372,\n",
       "         53515, 53516, 20352, 20350, 53523, 53526, 53529, 53513, 53103,\n",
       "         53100, 21011, 21623, 21610, 21607, 21603, 52695, 52698, 21593,\n",
       "         21584, 21579, 21578, 52714, 52718, 21571, 21564, 52721, 21626,\n",
       "         52725, 52680, 21632, 52661, 52662, 21663, 21660, 52664, 21656,\n",
       "         21654, 52669, 21648, 52671, 21641, 21640, 52676, 21636, 52679,\n",
       "         21631, 21561, 52728, 52733, 21496, 21491, 21490, 52780, 52785,\n",
       "         21479, 21478, 52786, 52790, 52791, 21473, 52795, 52798, 52810,\n",
       "         21459, 52774, 52767, 21503, 52766, 52734, 21543, 52738, 52740,\n",
       "         21528, 21526, 52751, 21668, 21524, 21522, 21518, 21514, 52761,\n",
       "         52764, 21507, 21505, 52753, 21458, 21684, 21691, 52543, 52544,\n",
       "         21848, 21846, 52547, 52548, 52556, 21834, 21832, 21829, 21826,\n",
       "         52562, 21821, 21816, 52580, 52541, 52581, 52539, 21863, 21922,\n",
       "         52493, 52501, 21906, 52503, 52508, 52518, 21897, 21894, 21880,\n",
       "         21879, 21878, 21874, 21866, 52535, 52537, 52585, 21808, 21807,\n",
       "         21741, 52619, 52620, 52623, 21726, 21724, 52627, 21720, 21718,\n",
       "         21710, 52635, 21702, 21700, 21697, 52637, 52616, 21747, 21757,\n",
       "         52604, 21804, 21801, 21798, 52591, 21796, 52595, 52596, 52640,\n",
       "         21787, 21783, 52599, 21781, 21780, 21773, 52603, 21767, 21784,\n",
       "         53703, 52813, 21455, 21175, 21171, 52996, 21165, 21164, 52997,\n",
       "         53008, 53012, 21149, 21148, 53013, 21146, 53019, 21137, 21135,\n",
       "         21178, 21134, 52991, 21188, 52961, 21221, 21220, 52963, 21218,\n",
       "         52965, 21215, 52966, 21209, 52975, 21202, 21200, 52977, 52979,\n",
       "         52982, 52990, 53020, 21129, 21128, 21071, 53055, 21068, 21066,\n",
       "         21064, 21060, 53074, 21036, 21030, 53087, 21026, 21020, 21019,\n",
       "         21016, 53092, 53049, 53047, 21083, 21084, 21125, 21124, 21123,\n",
       "         21122, 53027, 53028, 21116, 21227, 53030, 53036, 53039, 21100,\n",
       "         53040, 53042, 21086, 21085, 53033, 21456, 21228, 21234, 21392,\n",
       "         21389, 52859, 21381, 52864, 21372, 21370, 52868, 21367, 21365,\n",
       "         52869, 52871, 21353, 21349, 52884, 52855, 52885, 21400, 21405,\n",
       "         52814, 21451, 21448, 52821, 21441, 52831, 21430, 21424, 21421,\n",
       "         52840, 21418, 21415, 52842, 21411, 21410, 21403, 21345, 21343,\n",
       "         21342, 21275, 21271, 21269, 21266, 21264, 52938, 52939, 21251,\n",
       "         52942, 52946, 21244, 52947, 21242, 52958, 21235, 52933, 52919,\n",
       "         52914, 21305, 21340, 52888, 52892, 52893, 21333, 52895, 21330,\n",
       "         21231, 52898, 21323, 21322, 21321, 21319, 52905, 52906, 52909,\n",
       "         21324, 52492, 53705, 53708, 54519, 54520, 54525, 18867, 18864,\n",
       "         18860, 18856, 18855, 18850, 18847, 18841, 54542, 54546, 54547,\n",
       "         18832, 54518, 18830, 18880, 18887, 54483, 18919, 54485, 18912,\n",
       "         18911, 54490, 54491, 54493, 54495, 18898, 54497, 18894, 54499,\n",
       "         54503, 18889, 54509, 54480, 54550, 54558, 54614, 54616, 18733,\n",
       "         18732, 18727, 54623, 54625, 18718, 54629, 18715, 18714, 18712,\n",
       "         54632, 18707, 18700, 18750, 18826, 18761, 18765, 54559, 54560,\n",
       "         54562, 18808, 54564, 54566, 18796, 18794, 54568, 18791, 54571,\n",
       "         54573, 18783, 18778, 18773, 54587, 54477, 18938, 54476, 19088,\n",
       "         19087, 19086, 19085, 19084, 19083, 19080, 19079, 54379, 19074,\n",
       "         19052, 19051, 54396, 54399, 19045, 54372, 54400, 54369, 19103,\n",
       "         54318, 54319, 19159, 54337, 19149, 19135, 19132, 19127, 19124,\n",
       "         19123, 54350, 19119, 54351, 54354, 54361, 54365, 19040, 54402,\n",
       "         19038, 54445, 18973, 54452, 54457, 54465, 18960, 54470, 18954,\n",
       "         18953, 18952, 18951, 18948, 18947, 18946, 18942, 18977, 18979,\n",
       "         18980, 54438, 54404, 19036, 19031, 54406, 19021, 54412, 54413,\n",
       "         54639, 54418, 54430, 19001, 18998, 54433, 18993, 18992, 18989,\n",
       "         54419, 54641, 18694, 54646, 18392, 18391, 18389, 54849, 18383,\n",
       "         18376, 18371, 18370, 18369, 18361, 54868, 18355, 54870, 54871,\n",
       "         18344, 54842, 18343, 54840, 18400, 18451, 54809, 54811, 54814,\n",
       "         54816, 54820, 54822, 18426, 18423, 18422, 18420, 18412, 54831,\n",
       "         54837, 18402, 54838, 54878, 18337, 18336, 54943, 18255, 18254,\n",
       "         18253, 54952, 18247, 54962, 18239, 18237, 18236, 54966, 18232,\n",
       "         18226, 18223, 54975, 18267, 54940, 54935, 18283, 18334, 54880,\n",
       "         18332, 18330, 54882, 18324, 54890, 18469, 18315, 18304, 54907,\n",
       "         54909, 54912, 18294, 54915, 54922, 54892, 19173, 54795, 54781,\n",
       "         18640, 54688, 54694, 18630, 18624, 18623, 18622, 18619, 18617,\n",
       "         18616, 54700, 18610, 54702, 54705, 54712, 54678, 18596, 54675,\n",
       "         18650, 18691, 54650, 54651, 54653, 54655, 18678, 18670, 18668,\n",
       "         54665, 18665, 54666, 18661, 18660, 18656, 54670, 18648, 54715,\n",
       "         18592, 54718, 18531, 54755, 18529, 18521, 18520, 18518, 18516,\n",
       "         18511, 54767, 18501, 18494, 54775, 54776, 18487, 54780, 18535,\n",
       "         18536, 54753, 54752, 18589, 54719, 54723, 18584, 18578, 54730,\n",
       "         54734, 54789, 54735, 54738, 54741, 18551, 18550, 54746, 54748,\n",
       "         18542, 54736, 54306, 19181, 19184, 53939, 53941, 53942, 19750,\n",
       "         19748, 19745, 53943, 53945, 53946, 19739, 53950, 53952, 53953,\n",
       "         19726, 19725, 19758, 53956, 19763, 53933, 19825, 53892, 53893,\n",
       "         53896, 53900, 53902, 53910, 19802, 53913, 53916, 19791, 53927,\n",
       "         19779, 53929, 19770, 19765, 53959, 19719, 19717, 53993, 53994,\n",
       "         19663, 19661, 19660, 19654, 19651, 19646, 54009, 54010, 19640,\n",
       "         19639, 54013, 19636, 54015, 53990, 53988, 53987, 19677, 19714,\n",
       "         53962, 53964, 19709, 53966, 53967, 19706, 53891, 19701, 53970,\n",
       "         19697, 19696, 19695, 19691, 53975, 19687, 53969, 54016, 53890,\n",
       "         53885], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_medium': {'feature_present_idx': array([50340, 65807, 66354, 21024, 16925, 36408, 23463, 18349, 34965,\n",
       "         23487, 28616, 12674, 27125, 40128, 27669, 48808, 18188, 45350,\n",
       "         50226, 17380, 12055, 36228, 46260, 46303, 12954, 62389, 17207,\n",
       "         18450, 33863, 19482, 27769, 39511, 26833, 26515, 37662, 41476,\n",
       "         25253, 45156, 22619, 42570, 42868, 44142, 44164, 11908, 44951,\n",
       "         19498, 22600, 20208, 15240,  6275,  8608,  8325,  8213,  8053,\n",
       "         53347, 53594, 53021, 54078,  6449, 50869, 66587,  6216, 56281,\n",
       "          5295,  3343, 57238, 56184,  1206, 10173, 52994, 32733, 10520,\n",
       "         65071, 58219, 57653, 57477,  4597, 23046,  3361, 39964,  1039,\n",
       "          1736, 42477, 40642,  1920, 27068, 25113, 56969,  2864, 41223,\n",
       "         63328, 61015, 26975, 60463, 57002, 33661, 42279, 26014, 11216,\n",
       "         46771, 35962, 52100, 12119, 12486, 49972, 59650, 49351, 52197,\n",
       "         13530, 14570, 49086, 14872, 66738, 31318, 37288, 62303, 16399,\n",
       "         66390, 35920,  5958, 19627, 54598, 16076, 18725, 33050, 17434,\n",
       "         17051, 59329, 37001, 45661, 18683, 38031, 37075, 28252, 38994,\n",
       "         57416, 56908, 55300, 58977, 52033, 51388, 49212, 38483, 47226,\n",
       "         59961, 34697, 44013, 43479, 42762, 40801, 39451, 47127, 45510,\n",
       "         58456, 33828, 25046, 23849, 21211, 19711, 17919, 34494, 16045,\n",
       "         15616, 15375, 15339, 12521, 64799, 10728,  8746,  8223,  7891,\n",
       "          6865, 66279,  5370,  2420,  2018, 25545, 62574, 16643, 28845,\n",
       "         30355, 29626, 29122, 30890, 31286, 13684, 47141, 14761, 27397,\n",
       "         12628, 12626, 49893, 61970, 10694, 10648, 52329, 29796, 31732,\n",
       "         31946, 35960, 54325, 33326, 35407, 55493, 56027,  2551, 57862,\n",
       "         64863, 63508, 31472, 29794, 40145, 40453, 40491, 26592, 26225,\n",
       "         25373, 41490, 38990, 38821, 37641, 21369, 60157, 22533, 16492,\n",
       "         38256, 45548, 11049,  1054,  1076, 35298, 26843,  2980,  2983,\n",
       "          4230,  5187, 47062, 55253, 60644, 43383, 14805, 19465, 10929,\n",
       "         36877, 43120, 29340,  6708, 21046, 21236,  8954, 21013, 21010,\n",
       "         59234, 65525, 52849, 62460, 61781, 64414, 66981, 54014,  3620,\n",
       "          5275,  6656,  7658,  9224, 15424, 25728, 58314, 27255, 29586,\n",
       "         27137, 37667, 30410, 46429, 49773, 53189, 28960, 53444, 15497,\n",
       "         12016,  6935,  5518, 40418, 37289, 10495, 43054, 33339,   106],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([20533, 17163, 17162, 59749, 39306, 17161, 54144, 36549, 26987,\n",
       "         17159, 59744, 46588, 59754, 46589, 26982, 49978, 59739,  9942,\n",
       "         46591, 59738, 17156, 59737, 59736, 59734, 36548, 26983, 49976,\n",
       "         59755, 59756, 27013, 59774, 22612, 17177,  9897, 59771, 54131,\n",
       "         46572, 59767, 46573, 17173, 46582, 46575, 54133, 22616, 27000,\n",
       "         17169, 54138, 22617,  9915, 33892, 34554,  9918, 17165, 59764,\n",
       "         17179, 17154,  9953, 54156, 46617,  9987,  9988, 54158, 17139,\n",
       "         54159, 26948,  9994, 33904, 34552, 33903, 59698, 10001, 46632,\n",
       "         10003, 10004, 35371, 36538, 54164, 26940, 17132, 22634, 40884,\n",
       "         59691, 26974, 35369, 59710, 39311, 22624, 17152, 34553, 59725,\n",
       "         46602, 46603,  9963,  9964, 41376, 26965,  9982, 17148, 41375,\n",
       "         17146, 54152, 46609,  9973, 36544,  9975, 59714,  9978, 33902,\n",
       "          9980, 49973, 26936,  9891, 54128,  9795, 59852, 49999, 22590,\n",
       "         27066, 33878, 22591, 46530, 17209,  9804, 59846, 59853, 27061,\n",
       "          9808, 17208,  9811,  9812, 59843, 54109, 33880,  9816, 17204,\n",
       "         46536,  9820, 59845, 46538, 50000, 22586,  9766, 54098, 46518,\n",
       "         59870,  9770,  9771, 59868, 35358, 27076, 59866, 27075,  9792,\n",
       "          9777, 59864,  9780, 39298,  9782,  9784, 17216,  9786,  9787,\n",
       "         17215, 39299, 36565,  9778, 36556, 59840, 54111, 59808, 49985,\n",
       "         46558, 54125, 17184, 59803, 33887, 46563,  9870, 46564, 59799,\n",
       "         59809, 59797, 59795, 27022, 59793, 33888, 33889, 59786, 27018,\n",
       "         59783, 39303, 59780, 59779, 59796,  9823, 59810, 22604, 17201,\n",
       "          9826, 46542, 49994, 34556, 59837, 27046, 46546, 54113,  9835,\n",
       "         33883,  9856, 59828, 36561, 59825,  9845,  9846, 27037,  9848,\n",
       "         59821, 59820, 59817, 33885, 49988, 59827, 27080, 59678, 49960,\n",
       "         49923, 22681, 59529, 36505, 46712, 22682, 22683, 10187, 22684,\n",
       "         10189, 10190, 10177, 10191, 26831, 26829, 59519, 36502, 26826,\n",
       "         26825, 26824, 10203, 17056, 10205, 59515, 54223, 26822, 59537,\n",
       "         17070, 26863, 17080, 59565, 22671, 26860, 10150, 59564, 10153,\n",
       "         26858, 36510, 17077, 46703, 22673, 54213, 26854, 35380, 59555,\n",
       "         49931, 17072, 26850, 26848, 59547, 59544, 26847, 59560, 54209,\n",
       "         17055, 17053, 22699, 10249, 10250, 46729, 46730, 26794, 59479],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 288\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 288\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 288\n",
       "    })}}},\n",
       " 'contains_mod': {'feature_present_idx': array([30320, 13969, 56810, 45496, 45495, 56812, 28545, 28549, 13954,\n",
       "         45490, 28553, 28556, 13946, 56821, 13942, 13940, 28560, 56826,\n",
       "         28585, 56839, 28582, 28574, 28573, 13911, 13971, 13917, 56832,\n",
       "         13925, 13926, 13927, 28564, 45466, 28572, 56807, 13977, 56806,\n",
       "         45525, 14032, 28499, 14045, 56763, 28497, 14025, 14049, 14052,\n",
       "         45528, 56756, 56755, 56754, 14065, 56758, 13903, 14023, 14019,\n",
       "         13984, 56804, 13987, 56800, 45508, 56793, 45518, 45513, 14004,\n",
       "         56785, 14008, 45516, 14011, 28510, 14001, 14066, 13899, 13889,\n",
       "         56920, 13784, 56926, 45368, 56946, 45365, 56949, 13757, 13752,\n",
       "         13751, 28691, 28693, 28695, 28696, 28709, 28710, 13739, 57013,\n",
       "         57010, 45326, 57009, 45332, 28722, 28665, 13723, 56995, 45345,\n",
       "         13734, 45346, 28711, 13738, 28721, 13803, 56916, 13807, 45389,\n",
       "         28636, 56871, 28629, 45395, 13860, 13846, 56864, 56858, 45404,\n",
       "         45417, 28610, 13886, 45436, 28620, 56849, 45385, 56883, 56910,\n",
       "         45372, 13817, 56904, 56903, 56902, 28646, 28659, 13824, 28656,\n",
       "         56892, 45377, 45378, 13839, 13822, 56751, 56749, 56740, 28314,\n",
       "         14373, 56543, 45688, 14358, 56546, 56547, 45686, 14347, 45681,\n",
       "         28335, 45677, 14337, 45676, 14329, 45663, 45657, 14281, 56582,\n",
       "         56581, 28367, 14298, 14301, 14379, 56578, 45649, 28359, 28358,\n",
       "         14316, 45651, 56568, 28364, 14381, 28311, 56541, 28268, 14442,\n",
       "         14446, 45734, 14452, 28255, 56500, 14465, 56449, 28243, 14479,\n",
       "         56444, 56433, 14489, 14468, 56583, 14432, 56504, 14392, 14394,\n",
       "         28309, 56538, 56536, 28305, 56503, 56532, 45709, 45714, 28289,\n",
       "         14416, 28283, 28281, 14405, 28379, 14271, 14270, 14107, 28442,\n",
       "         45579, 56690, 14123, 56689, 28455, 28438, 14138, 56684, 14144,\n",
       "         14148, 56683, 56677, 28437, 45586, 45572, 28458, 14075, 28481,\n",
       "         45536, 56739, 56738, 28474, 56716, 28470, 45564, 14095, 56729,\n",
       "         14097, 14100, 28460, 14090, 13697, 14161, 28430, 28396, 14236,\n",
       "         28394, 14238, 45636, 28392, 56611, 56597, 45641, 28385, 14258,\n",
       "         28384, 28380, 14269, 14252, 56669, 56625, 45632, 14180, 56655,\n",
       "         28424, 28422, 14194, 14198, 14228, 56646, 45604, 14211, 14212,\n",
       "         28414, 56629, 45610, 14203, 28733, 57023, 13687, 57529, 13170,\n",
       "         13165, 57531, 29099, 29106, 45012, 57540, 29116, 29120, 13141,\n",
       "         45010, 29124, 44998, 57560, 13130, 44986, 29168, 57583, 44960,\n",
       "         29162, 29159, 13110, 13180, 57577, 13118, 44965, 29155, 29143,\n",
       "         13127, 44975, 57576, 45042, 29080, 13186, 13238, 57452, 45079,\n",
       "         29049, 13250, 45090, 29052, 45098, 45102, 57424, 13266, 57419,\n",
       "         57418, 57410, 13258, 57585, 13236, 29056, 57509, 45052, 13195,\n",
       "         45053, 13199, 13206, 29055, 29066, 13213, 57481, 57465, 13223,\n",
       "         29063, 29059, 57482, 29173, 13089, 44956, 29274, 44894, 29272,\n",
       "         57721, 29263, 12965, 29276, 29260, 44905, 12990, 44907, 12994,\n",
       "         57703, 57698, 12972, 57696, 57738, 44887, 57763, 12899, 29301,\n",
       "         12903, 12906, 12911, 12940, 57760, 29293, 44881, 57748, 12924,\n",
       "         29288, 12931, 29295, 45105, 13001, 57687, 29202, 57630, 57627,\n",
       "         57620, 13068, 13069, 44943, 57612, 44947, 57603, 29180, 13083,\n",
       "         44953, 13087, 29190, 29238, 57644, 13043, 29233, 57678, 57677,\n",
       "         57660, 29232, 44910, 29209, 44911, 29225, 29220, 13032, 57649,\n",
       "         29217, 13039, 13022, 56431, 45115, 29014, 57147, 28828, 28829,\n",
       "         13563, 28832, 13553, 13552, 57159, 45235, 57161, 57164, 57165,\n",
       "         28842, 45231, 57172, 28854, 13525, 57202, 45195, 13482, 45198,\n",
       "         45205, 13499, 45256, 13501, 57182, 28866, 28857, 13518, 57174,\n",
       "         13523, 28871, 57136, 13586, 13588, 13644, 13649, 28764, 13660,\n",
       "         28753, 57049, 28780, 45293, 45295, 28745, 13677, 57036, 13682,\n",
       "         28737, 13668, 13475, 28782, 13635, 13592, 13598, 28809, 13600,\n",
       "         57119, 13605, 57087, 57110, 45272, 57105, 57102, 28796, 28794,\n",
       "         13633, 13609, 28885, 57207, 13465, 28985, 45137, 13340, 13342,\n",
       "         13348, 57342, 13332, 28978, 57335, 57333, 13361, 57330, 45141,\n",
       "         28970, 57337, 45145, 45134, 57347, 57398, 57393, 29010, 29009,\n",
       "         13291, 13296, 45133, 13300, 13309, 45126, 13319, 57357, 28995,\n",
       "         13324, 45125, 13279, 28963, 45153, 57250, 57248, 28911, 13438,\n",
       "         57244, 28908, 13430, 57240, 13453, 28904, 57229, 28889, 45189,\n",
       "         28886, 57235, 45149, 13428, 28921, 45158, 45166, 57312, 57304,\n",
       "         45169, 57294, 28912, 57288, 28945, 28943, 57278, 28938, 13409,\n",
       "         13412, 45174, 28236, 28235, 14507, 15650, 15648, 46337, 27496,\n",
       "         15644, 15643, 55541, 15639, 27497, 55544, 46330, 15627, 27507,\n",
       "         15622, 15618, 27509, 27510, 46308, 46311, 55566, 15589, 15591,\n",
       "         15593, 27492, 15595, 15599, 46321, 46323, 15609, 15612, 55559,\n",
       "         15597, 15653, 55535, 15655, 27446, 46401, 55458, 55456, 27438,\n",
       "         55446, 55469, 15740, 46409, 27425, 27422, 55418, 15757, 27419,\n",
       "         46408, 55574, 46388, 15707, 46338, 15665, 27490, 27487, 55516,\n",
       "         55509, 27461, 55504, 55492, 46358, 27472, 55485, 46380, 15702,\n",
       "         55502, 46301, 46298, 15555, 46251, 55683, 27617, 27610, 46253,\n",
       "         46255, 46249, 27603, 27600, 15464, 55671, 55668, 55665, 15475,\n",
       "         27601, 27587, 55688, 55691, 46211, 15396, 27661, 15400, 55716,\n",
       "         55710, 15438, 55703, 15418, 46245, 15421, 55700, 15425, 46248,\n",
       "         27646, 55410, 55661, 15482, 27553, 46285, 27550, 27547, 27545,\n",
       "         55614, 15525, 46293, 15545, 55598, 27542, 46297, 55584, 27539,\n",
       "         55602, 15481, 27554, 15518, 15487, 46273, 55658, 27569, 46276,\n",
       "         55637, 27556, 46278, 55633, 15505, 55632, 55631, 55626, 15513,\n",
       "         15501, 15393, 27418, 15764, 55187, 46569, 55207, 27222, 46560,\n",
       "         16020, 16019, 27224, 46556, 55210, 27226, 46555, 55217, 16006,\n",
       "         46540, 55226, 27243, 15941, 15944, 46521, 55265, 55259, 15962,\n",
       "         46574, 46522, 46531, 15980, 15983, 55242, 27246, 55231, 55254,\n",
       "         46576, 16039, 27207, 16085, 16086, 16087, 16090, 27175, 55137,\n",
       "         27179, 55133, 46608, 46610, 55127, 16116, 55126, 16121, 55131,\n",
       "         15940, 16080, 27182, 27206, 27205, 16048, 27195, 55161, 16058,\n",
       "         55141, 55157, 55152, 55149, 46593, 55145, 16074, 27184, 27192,\n",
       "         27278, 27282, 46516, 15814, 15817, 15819, 46422, 46424, 15828,\n",
       "         55388, 27369, 55359, 55357, 55356, 55352, 27354, 55346, 15832,\n",
       "         46448, 46415, 27390, 27412, 15769, 15771, 15772, 15778, 15781,\n",
       "         27387, 15782, 15785, 15788, 55402, 46411, 27404, 46413, 55406,\n",
       "         27416, 15856, 27336, 15900, 46478, 55302, 15910, 55298, 27300,\n",
       "         46476, 15915, 46498, 46501, 27292, 46508, 46515, 55281, 27297,\n",
       "         55339, 55314, 55316, 27335, 46451, 46452, 15869, 15870, 27328,\n",
       "         15895, 27326, 15877, 15883, 46455, 46460, 27320, 15892, 55320,\n",
       "         12896, 15386, 55727, 28019, 56180, 28021, 56193, 14823, 28033,\n",
       "         14821, 56200, 56201, 28035, 14809, 28040, 45873, 56223, 56226,\n",
       "         28055, 45857, 45834, 14745, 14746, 28107, 45841, 45842, 45882,\n",
       "         28075, 56259, 45855, 56254, 14773, 28062, 14778, 56265, 28014,\n",
       "         14849, 56171, 56094, 45970, 56077, 56075, 56073, 56071, 45965,\n",
       "         45987, 14944, 14948, 27943, 56057, 56056, 56052, 27948, 14737,\n",
       "         27960, 56100, 14856, 14870, 27991, 45918, 56139, 14882, 56097,\n",
       "         27986, 27978, 45956, 56110, 45962, 14907, 56104, 45949, 45833,\n",
       "         56282, 45832, 28192, 56363, 28189, 56359, 45776, 14592, 28197,\n",
       "         45777, 14604, 14609, 28169, 56342, 14622, 14623, 45780, 14624,\n",
       "         56375, 56382, 14508, 45749, 56421, 45760, 56417, 56414, 28200,\n",
       "         14537, 28203, 56390, 56384, 28201, 14558, 14559, 45766, 56050,\n",
       "         28165, 14630, 14696, 14697, 14701, 56311, 14703, 56310, 45816,\n",
       "         45827, 14721, 14722, 14726, 56284, 14729, 56283, 14714, 45791,\n",
       "         14687, 14680, 28160, 45795, 14647, 28156, 56325, 28152, 56314,\n",
       "         56319, 14663, 28147, 14670, 14673, 56317, 45814, 45805, 55726,\n",
       "         56047], dtype=int64),\n",
       "  'feature_absent_idx': array([35509, 50885, 30543, 50883, 18176, 50882, 50877, 18180, 50872,\n",
       "         18185, 30542, 50862, 50861, 18195, 39969, 50853, 39972, 39973,\n",
       "         50849, 18202, 18204, 50848, 30535, 30534, 50887, 18213, 50892,\n",
       "         18156, 18112, 39942, 18115, 39952, 18119, 30552, 18126, 18127,\n",
       "         50911, 39954, 50907, 50906, 50905, 18137, 50904, 18143, 50900,\n",
       "         50898, 30546, 18149, 18151, 18152, 50896, 18160, 18218, 50843,\n",
       "         39974, 50799, 50797, 50796, 18294, 50795, 18304, 50792, 50790,\n",
       "         50788, 18315, 39995, 50781, 18324, 18330, 50773, 18332, 18334,\n",
       "         50771, 18336, 18337, 50769, 18343, 18344, 39984, 18283, 50806,\n",
       "         50807, 18223, 18226, 39975, 18232, 50835, 18236, 18237, 39977,\n",
       "         18239, 50829, 50828, 50923, 50824, 18247, 18253, 18254, 18255,\n",
       "         50821, 50819, 50816, 50815, 18267, 30524, 39979, 30527, 50768,\n",
       "         18110, 18108, 51098, 17932, 51091, 17934, 39890, 17936, 17940,\n",
       "         51086, 17947, 17948, 51079, 51068, 17958, 51066, 30589, 17971,\n",
       "         51059, 51055, 17977, 17978, 17984, 39902, 30585, 51101, 39907,\n",
       "         30600, 17924, 30622, 39879, 51159, 30614, 51151, 51148, 30612,\n",
       "         39882, 17888, 30608, 51136, 51135, 17899, 17905, 51127, 39886,\n",
       "         17911, 17912, 39888, 30601, 51112, 17921, 51108, 17928, 30582,\n",
       "         17996, 30581, 50966, 18067, 18073, 50962, 18077, 50961, 39938,\n",
       "         50953, 18084, 50949, 18086, 18088, 30559, 18090, 50943, 30558,\n",
       "         18096, 39940, 50938, 50934, 50930, 18105, 18107, 18061, 50972,\n",
       "         18056, 18054, 51033, 30577, 51021, 18006, 51018, 18010, 18011,\n",
       "         18012, 18013, 51017, 51004, 18109, 30576, 18023, 50999, 18031,\n",
       "         39919, 50988, 18037, 50986, 18042, 50980, 50978, 50976, 51001,\n",
       "         51167, 30513, 30511, 18660, 18661, 18665, 18668, 18670, 50515,\n",
       "         50512, 18678, 50507, 50506, 50498, 50496, 18691, 18694, 30414,\n",
       "         18700, 50493, 40093, 40095, 30404, 18707, 30403, 50479, 40088,\n",
       "         40109, 50523, 18656, 50558, 50555, 18616, 18617, 50554, 18619,\n",
       "         18622, 18623, 18624, 50553, 50552, 18630, 40083, 50541, 30429,\n",
       "         50535, 18640, 30428, 40086, 18648, 18650, 50527, 50526, 30420,\n",
       "         18712, 50476, 18714, 50432, 50430, 18783, 30387, 50427, 18791,\n",
       "         50424, 30385, 18794, 50422, 18796, 40129, 30383, 50406, 50405,\n",
       "         50403, 18808, 50400, 40139, 50393, 18826, 50392, 18830, 18778,\n",
       "         50434, 30389, 18773, 18715, 18718, 50475, 18727, 30398, 18732,\n",
       "         18733, 40119, 50465, 50463, 50462, 18610, 50460, 50458, 50457,\n",
       "         18750, 40127, 50452, 50450, 18761, 50448, 18765, 50446, 50442,\n",
       "         50459, 50764, 50561, 50566, 50722, 50719, 30489, 18420, 50711,\n",
       "         18422, 18423, 18426, 50709, 50706, 30488, 50704, 40011, 30483,\n",
       "         18451, 50696, 50689, 50688, 50677, 40023, 50672, 18469, 40028,\n",
       "         50723, 40033, 18412, 18402, 30510, 39998, 30508, 30506, 18355,\n",
       "         50750, 18361, 18369, 18370, 18371, 40001, 18376, 50747, 40002,\n",
       "         50742, 18383, 30499, 50738, 18389, 18391, 18392, 50737, 18400,\n",
       "         50728, 50652, 50650, 50649, 18550, 18551, 30446, 50596, 50594,\n",
       "         50593, 50592, 50591, 50588, 50585, 50581, 18578, 30442, 50578,\n",
       "         18584, 40077, 50575, 18589, 18592, 30438, 50571, 18596, 30436,\n",
       "         50600, 50601, 50603, 18542, 18487, 40044, 40047, 18494, 50644,\n",
       "         50642, 50640, 18501, 50635, 50629, 18511, 50564, 30460, 18518,\n",
       "         18520, 18521, 30459, 50616, 40058, 18529, 18531, 18535, 18536,\n",
       "         50606, 18516, 18832, 51177, 51183, 51791, 17293, 51788, 17296,\n",
       "         51785, 51784, 30816, 39711, 51770, 30810, 17318, 17319, 51767,\n",
       "         17321, 17322, 30804, 17324, 30803, 17330, 30801, 51753, 30797,\n",
       "         17338, 51793, 30796, 17288, 17286, 17241, 30837, 17244, 17247,\n",
       "         17248, 30834, 30826, 17252, 39703, 17254, 51820, 51819, 30823,\n",
       "         51810, 51809, 17265, 17266, 39706, 17278, 51807, 51806, 39708,\n",
       "         51799, 17287, 17343, 17344, 51747, 17402, 30778, 51685, 17408,\n",
       "         39757, 30776, 17415, 17417, 17420, 17421, 17423, 17424, 51675,\n",
       "         39768, 17428, 17429, 51671, 51669, 17435, 51665, 17437, 17438,\n",
       "         17439, 17401, 17399, 30780, 17396, 51743, 51742, 30795, 17353,\n",
       "         17355, 51731, 39735, 51727, 30792, 51721, 39736, 17240, 17367,\n",
       "         17369, 51718, 51712, 51709, 39748, 51705, 30786, 17384, 17389,\n",
       "         30784, 17392, 39739, 51661, 17235, 51853, 39666, 17072, 51987,\n",
       "         17077, 51978, 17080, 51977, 30865, 51972, 51968, 17090, 30861,\n",
       "         51958, 51957, 39674, 51954, 39685, 51945, 17105, 39690, 51943,\n",
       "         51941, 17111, 17070, 51937, 51992, 30872, 52050, 17006, 52048,\n",
       "         52047, 52046, 17019, 52043, 17027, 52037, 30881, 17037, 52023,\n",
       "         52016, 39663, 30875, 17050, 52011, 30874, 17053, 39665, 17055,\n",
       "         17056, 51998, 30871, 17113, 51935, 17116, 17179, 51895, 17184,\n",
       "         51886, 30844, 30843, 51878, 51877, 39696, 51868, 17201, 17204,\n",
       "         17208, 17209, 51867, 39700, 17215, 17216, 51859, 51856, 17227,\n",
       "         17228, 30840, 17177, 17173, 17169, 51900, 17118, 51933, 51928,\n",
       "         51924, 51922, 17125, 39692, 17132, 17139, 30851, 17146, 51848,\n",
       "         17148, 51914, 17152, 17154, 30849, 17156, 51909, 17159, 17161,\n",
       "         17162, 17163, 17165, 51915, 51180, 51660, 30768, 30668, 17708,\n",
       "         17710, 51358, 51356, 30664, 51352, 17721, 51351, 51348, 51344,\n",
       "         30663, 17731, 30661, 17735, 17737, 51337, 17740, 17742, 17743,\n",
       "         51333, 30660, 39843, 35513, 51317, 51370, 17698, 51428, 51427,\n",
       "         17659, 51425, 39835, 51419, 51415, 17667, 51411, 17671, 30670,\n",
       "         17679, 17680, 51403, 17683, 51402, 51392, 51391, 51389, 51384,\n",
       "         51382, 51377, 51376, 51375, 17758, 17759, 51303, 39856, 51264,\n",
       "         51262, 51260, 30643, 30642, 51248, 17828, 39865, 30637, 51234,\n",
       "         17838, 30636, 30635, 30633, 51199, 39875, 51195, 17856, 51190,\n",
       "         30627, 39877, 17862, 51267, 51268, 51269, 17800, 39849, 51300,\n",
       "         17769, 17772, 51299, 17774, 17775, 51295, 17779, 51286, 51280,\n",
       "         30678, 17782, 17784, 17785, 39850, 17788, 17790, 17792, 30651,\n",
       "         51275, 51274, 39851, 17799, 17783, 39771, 30679, 17648, 39787,\n",
       "         51585, 17512, 17513, 30742, 30737, 51578, 51572, 17519, 30735,\n",
       "         17521, 17522, 17523, 30734, 17525, 17526, 30732, 51558, 17530,\n",
       "         17532, 17533, 51557, 17540, 51593, 39791, 17502, 39783, 17449,\n",
       "         51646, 51638, 39775, 30762, 17458, 17462, 51632, 30760, 17465,\n",
       "         17466, 30759, 17469, 51620, 17471, 17475, 30756, 17478, 30755,\n",
       "         17491, 17492, 39781, 39782, 17497, 39799, 17545, 51552, 17608,\n",
       "         51489, 17614, 17615, 17616, 51485, 51484, 51482, 39816, 51474,\n",
       "         51473, 17627, 51469, 39817, 51463, 51459, 39818, 51453, 51452,\n",
       "         39823, 51446, 51440, 51439, 17606, 39813, 17603, 30698, 17549,\n",
       "         30719, 51540, 30716, 17558, 30706, 17563, 17564, 51526, 17570,\n",
       "         51523, 51436, 30705, 51513, 17581, 17583, 17584, 17587, 51508,\n",
       "         51506, 17592, 30700, 17596, 17600, 30701, 17001, 50391, 50389,\n",
       "         49235, 40475, 20066, 30007, 20077, 20079, 20084, 30005, 30004,\n",
       "         49226, 40481, 20090, 20091, 49219, 49216, 49215, 20103, 40484,\n",
       "         29997, 20108, 20109, 49202, 49196, 49241, 20116, 20052, 20038,\n",
       "         19994, 19996, 19999, 49294, 49291, 49290, 49284, 20011, 49281,\n",
       "         30024, 49272, 49271, 20019, 49269, 20022, 30023, 20026, 49263,\n",
       "         20028, 20029, 30020, 49255, 49254, 40470, 20118, 29988, 20121,\n",
       "         49131, 49130, 49125, 20191, 49124, 29971, 20196, 20197, 49111,\n",
       "         40519, 49108, 29969, 49102, 49094, 49091, 49089, 49088, 49087,\n",
       "         20219, 49084, 20221, 20222, 49082, 49133, 20181, 20179, 49140,\n",
       "         20122, 49186, 49185, 20128, 20134, 20135, 49182, 49181, 29987,\n",
       "         29986, 49174, 19989, 49173, 20150, 20152, 49168, 40498, 49164,\n",
       "         49160, 20167, 49153, 29979, 49143, 20176, 20149, 20224, 40463,\n",
       "         19983, 49466, 49463, 40402, 19802, 40404, 49456, 30087, 49450,\n",
       "         49446, 19825, 49445, 49444, 49439, 19831, 19832, 19833, 49437,\n",
       "         30086], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_mode': {'feature_present_idx': array([    0, 16218, 46190, 46178, 46167, 45950, 16323, 16375, 45947,\n",
       "         16535, 45931, 16577, 45893, 16831, 45571, 45361, 45303, 45093,\n",
       "         45091, 17121, 45000, 44988, 16202, 44935, 16169, 46471, 47906,\n",
       "         47893, 47855, 47818, 47787, 47727, 47700, 47439, 15526, 47318,\n",
       "         47212, 15752, 47105, 15793, 47021, 15874, 46937, 15924, 15938,\n",
       "         46590, 16105, 46346, 47908, 44842, 44788, 43512, 18713, 43189,\n",
       "         18813, 18863, 18874, 43108, 18949, 18975, 42832, 42673, 19122,\n",
       "         42507, 42303, 19311, 42285, 42250, 42148, 19357, 42056, 19392,\n",
       "         43540, 44818, 18528, 43609, 17548, 17561, 44619, 44545, 44504,\n",
       "         44289, 44223, 17840, 17893, 44110, 44044, 43964, 18181, 43932,\n",
       "         18197, 43906, 43870, 43809, 43808, 18259, 43643, 18523, 41821,\n",
       "         48051, 48054, 12002, 51645, 12066, 51561, 12096, 12124, 51501,\n",
       "         12150, 12219, 12220, 51476, 12304, 12312, 12336, 51410, 51399,\n",
       "         51342, 12590, 51328, 51100, 51015, 11942, 13297, 11918, 51849,\n",
       "         52425, 10805, 10950, 11007, 11031, 11034, 11060, 52196, 11090,\n",
       "         52179, 11316, 11345, 52135, 11552, 11577, 11604, 11631, 52061,\n",
       "         11690, 51892, 11728, 11859, 15208, 13303, 50868, 49788, 49763,\n",
       "         49697, 49612, 49599, 14460, 14538, 14595, 14639, 14725, 49285,\n",
       "         49064, 14758, 48941, 48827, 48773, 48724, 48593, 48209, 48107,\n",
       "         15169, 14196, 50870, 14155, 49914, 50772, 50697, 50549, 13439,\n",
       "         13447, 50510, 50472, 13528, 50332, 50321, 13691, 13700, 50272,\n",
       "         13714, 13733, 50063, 13847, 13928, 49945, 13979, 13994, 14153,\n",
       "         10794, 19471, 19605, 33213, 33210, 33113, 33033, 25911, 33008,\n",
       "         25926, 32873, 26012, 32837, 26055, 32646, 32441, 32418, 26196,\n",
       "         26255, 32207, 32155, 26336, 32102, 32073, 33245, 31769, 33272,\n",
       "         33319, 24606, 24706, 34961, 34934, 34876, 24958, 25077, 34419,\n",
       "         34257, 34211, 34167, 34010, 25278, 33719, 25365, 33651, 33477,\n",
       "         33410, 25505, 33357, 25594, 25661, 34993, 31717, 26587, 29812,\n",
       "         27964, 27976, 28001, 29714, 28028, 28130, 28143, 28186, 29546,\n",
       "         29415, 29409, 29267, 28511, 29172, 28611, 28662, 29081, 29070,\n",
       "         28755, 28802, 29973, 31625, 30056, 30260, 31600, 26834, 26944,\n",
       "         31154, 31080, 30970, 30933, 27139, 30587, 27193, 30548, 30422,\n",
       "         30351, 30310, 30302, 27302, 30301, 30294, 27481, 30261, 27485,\n",
       "         27566, 41579, 24493, 24296, 38974, 38894, 21162, 38545, 38430,\n",
       "         21318, 21336, 38416, 21555, 38179, 38109, 38007, 21799, 21822,\n",
       "         37737, 21856, 37688, 37658, 37589, 37564, 37512, 20956, 22063,\n",
       "         20955, 20868, 19703, 19718, 19772, 41316, 41152, 40927, 40880,\n",
       "         20137, 40668, 20235, 20241, 40555, 20329, 40412, 40234, 20511,\n",
       "         40037, 39812, 20678, 39468, 39316, 20892, 24396, 22086, 37205,\n",
       "         23180, 35907, 35890, 35823, 23435, 35761, 35721, 23682, 35621,\n",
       "         23739, 35609, 35570, 23844, 23947, 35516, 23987, 35389, 24182,\n",
       "         24240, 24269, 35287, 36036, 37250, 23059, 36246, 22220, 37169,\n",
       "         37166, 37052, 22276, 22332, 36969, 36871, 36776, 36727, 22575,\n",
       "         22613, 22618, 22659, 36514, 36480, 36426, 22770, 22911, 36271,\n",
       "         22978, 23017, 10741, 28958, 59983, 58326,  6544,  6561, 64563,\n",
       "          2200, 58077, 58025, 57987, 64685,  2062, 57886,  6725,  6748,\n",
       "         64876, 57877, 58362,  6780, 58368, 58453, 59136,  2669, 64067,\n",
       "         59049, 64190, 58927,  5867,  5869, 64234, 58732,  5982, 58640,\n",
       "          6095,  6248, 64424,  6475,  5619, 57608,  6970,  1374,  7686,\n",
       "         56730,  7724, 56662, 56642, 56609, 56475, 56412, 65417,  1286,\n",
       "         65442,  8024, 56389, 56339,  1380, 65006, 65259, 57104,  6977,\n",
       "         65010, 65080,  7124, 57372, 57326, 57324, 57307, 57273,  1605,\n",
       "          7363,  1579,  7387,  1507,  1482, 57033,  1235, 59148,  5479,\n",
       "          3732,  4374,  3644,  3605, 62157,  3584, 60620, 60593, 62324,\n",
       "         62340, 60583,  3521, 60519, 60483,  3479, 61951, 60471,  3760,\n",
       "          4357,  4092, 61148,  4007,  3959,  4163,  3957,  4189,  3930,\n",
       "          4214,  4228, 60948, 61383,  4285, 60925,  3794, 61831,  2709,\n",
       "         60416, 62573, 59461, 59438,  5055,  2841,  2840,  5121, 63623,\n",
       "         63680,  5255,  5286,  2803, 59341,  2754, 63725, 63782,  4968,\n",
       "          3437, 63440,  4941, 62688,  3248, 62785, 62887, 63050, 59905,\n",
       "          3140, 59835, 63196,  4860, 59715, 63208, 59653,  4938, 63428,\n",
       "          4947,  8061, 65135, 56330, 54407, 54534, 55361, 53505, 53467,\n",
       "         66260,  9644,  9643,  8971, 66275,  8538,   856,  8492,  8489,\n",
       "           865, 66051,   124, 66039, 53416,   520, 54103,  8655, 10175,\n",
       "          8676, 66939, 54979, 55045,  9748, 66838, 66842, 53789, 66181,\n",
       "         53546,   767, 53976, 54662, 66775, 53533,  8719, 66105, 66923,\n",
       "          9708, 55173,   801, 55285, 66094,  9933, 54110,  8456, 54328,\n",
       "         52865, 56031, 54142,  8222, 65764, 66433, 56161, 52737,    34,\n",
       "         56175, 52719,  9196, 65523, 67243,  1083,  8119,   396, 52555,\n",
       "         65449, 65925, 53043,  1020,   727, 67102, 55863, 55525,   925,\n",
       "         55875,   345, 53052, 54411, 53327,  9279, 55494, 10324,  9167,\n",
       "         10356, 55902, 67038, 36007, 63483, 36087, 62872, 36008, 66760,\n",
       "         35746, 66652, 35661, 35709, 29768, 35665, 29684, 35696, 35767,\n",
       "         29685, 29374, 36104, 29259, 67072, 29156, 37203, 61778, 61685,\n",
       "         61605, 37373, 36972, 29125, 67220, 29030, 37558, 61380, 37627,\n",
       "         29003, 37722, 61273, 67161, 62863, 61988, 36907, 62827, 66834,\n",
       "         29631, 29579, 29537, 36289, 36419, 36425, 36944, 29468, 62563,\n",
       "         36531, 62163, 36576, 29283, 66986, 36633, 62144, 36460, 35632,\n",
       "         35091, 66437, 65140, 65962, 31437, 31378, 33220, 66038, 37741,\n",
       "         65125, 65098, 31315, 31216, 31179, 67249, 64972, 33452, 64689,\n",
       "         66079, 33534, 33588, 33610, 30927, 33115, 64587, 65201, 31505,\n",
       "         32119, 65446, 32107, 32103, 65760, 32461, 32489, 32591, 65409,\n",
       "         31939, 31779, 32659, 65272, 32736, 65900, 32906, 32940, 65241,\n",
       "         31560, 31514, 33027, 31464, 30603, 33929, 33940, 35045, 35054,\n",
       "         64038, 35069, 32160, 63870, 30253, 63834, 30128, 30102, 30058,\n",
       "         35343, 66395, 30008, 30006, 66432, 29960, 35522, 35551, 63620,\n",
       "         35586, 66258, 66239, 64201, 34971, 66087, 64544, 34203, 30388,\n",
       "         64533, 64516, 34277, 34361, 64471, 30321, 63589, 66122, 64398,\n",
       "         66126, 34469, 34698, 34767, 64286, 34932, 64255, 64245, 66133,\n",
       "         34458, 37830, 52554, 37874, 48337, 48505, 48570, 48598, 48631,\n",
       "         48671, 56285, 48913, 56074, 56034, 49119, 56011, 55927, 48196,\n",
       "         29002, 49300, 49514, 49556, 55579, 55560, 55554, 55486, 49811,\n",
       "         49861, 49894, 49900, 49913, 55417, 55894, 48069, 56367, 48042,\n",
       "         45981, 46017, 46085, 57458, 57390, 46300, 57258, 46539, 46596,\n",
       "         46837, 57246, 57215, 57211, 46948, 46989, 56838, 47119, 56780,\n",
       "         56772, 47237, 47383, 47399, 47412, 56551, 56539, 47900, 56424,\n",
       "         47942, 48014, 55411, 57462, 50034, 50111, 51465, 54091, 51525,\n",
       "         53734, 51596, 53727, 53693, 51682, 51728, 51764, 51780, 53525,\n",
       "         51884, 51444, 53450, 53449, 52067, 53315, 52083, 53298, 52156,\n",
       "         52988, 52812, 52758, 52204, 52293, 52326, 52656, 51967, 54333,\n",
       "         51347, 54362, 50172, 50240, 55279, 50317, 55132, 50440, 55120,\n",
       "         50444, 55076, 55041, 54919, 50551, 54798, 50782, 54531, 54516,\n",
       "         50876, 50891, 50913, 50932, 50948, 51054, 51063, 51116, 51172,\n",
       "         51196, 51203, 51251, 51281, 55365, 57497, 57555, 45624, 39993,\n",
       "         60592, 40172, 40207, 60570, 40313, 40434, 40503, 40542, 60437,\n",
       "         40632, 40652, 60310, 39686, 40821, 60175, 60052, 40912, 40916,\n",
       "         52504, 40930, 40941, 59940, 41273, 41393, 41396, 41439, 41459,\n",
       "         40873, 39653, 39647, 39616, 37908, 61152, 37988, 38098, 61002,\n",
       "         60952, 38281, 38319, 38340, 38425, 38452, 38622, 38744, 38874,\n",
       "         38884, 60782, 38961, 39011, 39089, 39119, 39266, 60779, 39272,\n",
       "         60775, 39283, 60669, 60656, 39364, 60630, 41792, 41810, 41881,\n",
       "         41885], dtype=int64),\n",
       "  'feature_absent_idx': array([49087, 39601, 62592, 27845, 12892, 12894, 62589, 12898, 57015,\n",
       "         12901, 57017, 62588, 57019, 52599, 27831, 57020, 27828, 12915,\n",
       "         27820, 39611, 50696, 57027, 62582, 44687, 44686, 12930, 52596,\n",
       "         27811, 62593, 12880, 44705, 12878, 12835, 27883, 52603, 27877,\n",
       "         57004, 62612, 62611, 57005, 44725, 44724, 12851, 12852, 39597,\n",
       "         62579, 12854, 44719, 27864, 27863, 12862, 27861, 12865, 27860,\n",
       "         57008, 44714, 50688, 62600, 50689, 12877, 12858, 62578, 52595,\n",
       "         57031, 50706, 12983, 27776, 57043, 12987, 62551, 12989, 50709,\n",
       "         39628, 57044, 57046, 44663, 52591, 57042, 13002, 27763, 62544,\n",
       "         27758, 44659, 27757, 57052, 62539, 13014, 27754, 13016, 50711,\n",
       "         13020, 57054, 13003, 50677, 39625, 44671, 27805, 62576, 12943,\n",
       "         27801, 27799, 12947, 12948, 62568, 12951, 12952, 27796, 44679,\n",
       "         39620, 62560, 62566, 27791, 12960, 50704, 62562, 12964, 39621,\n",
       "         57038, 62561, 12969, 12970, 12971, 12973, 57040, 27792, 44730,\n",
       "         62615, 56991, 62671, 52619, 12667, 44793, 62669, 50644, 56942,\n",
       "         12675, 12676, 56943, 62668, 56944, 56945, 12664, 27994, 62664,\n",
       "         56947, 12693, 12696, 56951, 62662, 50649, 62657, 62656, 12707,\n",
       "         44777, 56953, 12710, 27992, 12711, 12663, 39543, 39528, 39529,\n",
       "         44812, 56931, 28042, 44811, 56934, 62693, 28034, 50640, 12633,\n",
       "         12634, 28026, 12661, 56937, 62684, 44801, 50642, 12644, 28018,\n",
       "         62680, 56939, 62678, 12653, 44797, 28013, 52620, 44795, 39538,\n",
       "         62536, 62655, 56955, 12773, 56971, 12777, 56972, 12782, 44749,\n",
       "         62629, 27910, 27908, 12799, 62624, 12805, 12807, 12771, 50672,\n",
       "         12812, 12813, 44739, 62621, 44737, 39586, 27891, 52604, 12824,\n",
       "         44734, 12826, 56989, 12829, 12811, 12714, 12770, 12768, 62654,\n",
       "         12717, 44775, 27967, 12721, 12723, 27963, 56956, 50650, 27958,\n",
       "         62650, 62649, 27957, 12769, 50652, 27955, 12739, 52616, 12742,\n",
       "         39564, 44764, 27946, 56968, 27937, 12762, 12763, 27931, 56970,\n",
       "         56958, 13028, 13029, 62535, 27567, 57107, 13280, 44565, 27561,\n",
       "         62435, 27557, 13288, 62431, 13290, 13292, 13293, 13295, 44567,\n",
       "         13301, 62427, 27548, 13307, 62426, 13311, 50737, 62423, 57112,\n",
       "         13317, 39703, 13322, 57117, 62418, 39700, 13328, 27568, 13274,\n",
       "         44587, 13233, 44586, 44585, 44583, 27586, 13243, 44580, 57101,\n",
       "         27582, 13247, 62456, 13249, 62442, 27581, 44577, 13255, 13259,\n",
       "         27576, 62452, 27573, 44571, 27571, 39696, 13269, 13271, 62443,\n",
       "         13273, 62454, 44588, 13329, 44553, 62395, 50747, 44531, 27500,\n",
       "         62393, 52562, 44525, 13399, 50750, 44521, 13405, 62387, 13410,\n",
       "         57133, 27486, 44514, 52556, 13422, 13423, 13425, 13426, 27471,\n",
       "         13429, 57156, 44510, 13435, 52548, 27464, 13415, 50738, 62398,\n",
       "         44537, 27535, 13333, 39706, 39708, 27531, 13338, 57120, 27527,\n",
       "         13344, 13345, 13347, 57121, 39711, 62399, 57124, 50742, 44543,\n",
       "         62410, 27516, 57126, 13362, 13364, 13365, 62406, 57130, 27506,\n",
       "         62400, 57131, 57125, 62696, 62461, 27591, 13084, 57071, 27693,\n",
       "         57072, 13095, 13096, 27688, 13098, 44635, 52581, 13101, 27686,\n",
       "         13103, 27701, 62510, 13108, 44634, 57076, 13112, 44632, 44630,\n",
       "         39663, 52580, 39665, 27676, 44628, 39666, 50719, 13106, 62500,\n",
       "         13081, 27703, 39638, 62534, 62532, 13037, 13040, 62530, 27735,\n",
       "         27733, 52585, 27731, 39646, 27726, 27725, 13079, 13052, 57062,\n",
       "         39651, 27715, 44645, 27713, 27712, 13065, 44642, 27710, 27708,\n",
       "         27707, 62517, 39652, 27723, 27590, 44621, 44616, 13183, 27624,\n",
       "         39685, 62479, 27621, 27620, 13190, 44600, 13193, 27616, 27612,\n",
       "         13201, 62475, 27625, 39690, 27607, 27606, 13209, 27605, 13214,\n",
       "         13217, 57095, 13219, 39692, 13221, 27593, 50728, 57098, 44597,\n",
       "         57080, 57091, 27631, 62497, 27658, 27656, 39674, 57082, 27653,\n",
       "         13146, 57084, 13148, 13149, 27650, 13151, 13154, 57090, 62490,\n",
       "         44610, 13160, 13161, 27641, 50722, 13167, 44607, 27638, 27637,\n",
       "         50723, 13173, 62483, 13176, 62489, 13441, 28047, 28056, 28452,\n",
       "         62903, 28450, 62902, 62901, 45008, 45007, 12045, 12046, 12047,\n",
       "         39382, 28448, 28447, 50571, 28445, 12056, 62896, 12059, 28441,\n",
       "         12062, 12064, 28439, 62894, 28436, 56801, 12075, 62888, 56797,\n",
       "         12033, 56795, 12029, 11987, 56786, 28478, 45026, 39375, 28476,\n",
       "         11994, 11995, 45022, 28473, 39377, 62917, 56790, 44996, 62916,\n",
       "         50561, 12013, 12014, 12015, 62914, 12017, 52680, 52679, 50564,\n",
       "         12022, 50566, 62909, 62908, 62915, 12079, 44995, 28429, 62865,\n",
       "         44976, 56813, 12142, 12143, 28388, 39399, 28383, 28382, 62859,\n",
       "         12158, 28378, 39401, 12134, 50585, 44968, 44966, 28374, 28371,\n",
       "         28370, 62856, 52669, 62855, 62854, 12178, 28361, 50588, 62848,\n",
       "         52671, 11985, 12132, 62866, 52676, 50575, 12087, 44993, 28421,\n",
       "         28416, 39394, 50578, 44987, 12104, 12106, 28410, 12108, 28397,\n",
       "         12109, 62879, 28408, 62878, 62877, 28407, 62875, 56808, 56811,\n",
       "         44983, 44982, 44980, 28398, 50581, 56805, 11984, 62927, 28482,\n",
       "         28595, 11830, 62994, 11832, 45073, 11834, 39346, 56746, 28592,\n",
       "         28589, 56747, 56748, 28583, 11828, 45070, 11850, 28580, 62988,\n",
       "         62986, 62985, 62984, 56750, 11861, 50535, 45064, 62976, 39351,\n",
       "         45062, 11848, 11874, 11827, 56742, 11779, 11781, 52695, 28624,\n",
       "         11784, 11785, 50526, 28622, 28621, 63008, 50527, 63005, 28612,\n",
       "         11826, 11802, 11805, 11806, 56734, 11809, 28605, 11811, 28602,\n",
       "         45078, 11817, 62999, 62998, 11821, 39344, 11804, 12184, 11876,\n",
       "         11882, 11940, 45036, 50553, 39367, 62944, 50554, 39368, 50555,\n",
       "         11952, 28504, 39370, 28501, 28500, 11939, 28498, 28494, 28493,\n",
       "         56775, 11968, 62937, 56782, 45028, 62934, 28487, 11975, 11976,\n",
       "         50558, 39374, 11959, 28562, 39363, 28519, 28558, 11885, 45058,\n",
       "         28552, 62965, 28548, 28544, 62961, 11902, 11906, 50541, 28537,\n",
       "         28536, 39362, 56765, 28534, 11914, 39358, 28530, 28529, 11922,\n",
       "         11923, 28525, 39360, 28521, 11931, 50552, 28520, 62957, 12186,\n",
       "         50591, 44959, 44867, 56895, 12468, 56897, 62754, 52637, 62752,\n",
       "         39497, 52635, 28140, 62750, 39499, 28136, 28150, 28135, 12490,\n",
       "         12491, 28128, 62747, 12494, 12495, 62745, 44860, 44859, 44858,\n",
       "         28126, 28124, 50616, 12484, 12506, 56893, 12459, 39478, 12411,\n",
       "         12412, 28191, 28188, 12418, 56877, 62768, 28182, 39481, 52640,\n",
       "         12428, 12431, 12460, 28173, 44878, 62761, 28167, 62758, 56884,\n",
       "         39489, 12446, 12447, 12448, 39493, 12452, 56891, 12454, 39485,\n",
       "         62776, 56905, 28117, 44834, 50629, 12568, 44830, 39516, 44829,\n",
       "         56917, 12574, 56918, 62709, 44825, 56921, 12581, 28076, 12583,\n",
       "         12586, 44822, 50635, 28063, 12592, 52627, 12595, 12596, 12597,\n",
       "         12598, 39521, 62699, 52623, 28064, 12510, 12562, 28078, 12512,\n",
       "         39504, 28114, 44850, 28113, 28109, 28108, 62730, 12527, 12530,\n",
       "         56912, 12534, 28097, 39515, 56913, 28091, 28088, 12544, 12546,\n",
       "         62723, 62722, 12550, 28085, 28084, 28082, 12557, 28080, 28079,\n",
       "         28093, 28051, 56872, 44893, 52661, 12247, 28316, 12251, 12252,\n",
       "         12253, 12254, 28310, 12258, 39429, 28304, 50596, 12267, 12243,\n",
       "         28299, 39431, 56847, 62810, 62809, 39433, 12279, 12283, 39437,\n",
       "         56851, 50600, 39439, 12292, 12293, 44934, 12294, 52662, 12239,\n",
       "         56822, 44958, 12198, 28350, 52664, 12202, 39411, 62840, 12205,\n",
       "         12207, 50592, 12212, 50593, 12240, 62837, 28341, 12218, 39416,\n",
       "         28337, 12224, 50594, 39417, 28333, 12230, 56833, 28331, 12234,\n",
       "         12236, 12215, 12404, 12297, 39442, 28238, 39460, 50606, 12362,\n",
       "         12363, 12365, 28233, 12367, 12368, 28232, 62790, 12372, 12374,\n",
       "         12356, 28225, 28224, 39470, 44901, 28218, 39474, 28213, 56870,\n",
       "         12390, 12391, 28209, 28208, 28207, 28205, 44903, 44927, 28240,\n",
       "         39458, 50601, 62805, 62804, 28274, 12308, 12313, 12315, 44922,\n",
       "         44921], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_name': {'feature_present_idx': array([35751, 40989, 31088, 17483, 17470, 17448,  6750, 64489, 17427,\n",
       "         31150,  6766, 17397,  6790, 64448,  6804, 64444, 31173, 50160,\n",
       "          6981, 31483, 54153, 50189, 31474, 31442, 40995, 40720, 31376,\n",
       "         31361, 40751, 54210, 54226, 17335,  6924, 17509, 17518, 41025,\n",
       "         64620, 17752, 41307,  6272, 17814, 17821,  6340, 17832, 30789,\n",
       "         30787,  6178, 30721, 59741,  6076, 30790, 31487,  6345, 17701,\n",
       "         17520, 50045, 54291, 64526, 17547, 41087, 30857,  6465, 50038,\n",
       "         41126, 17617, 64604,  6384, 17668, 50043, 31527,  7055, 60132,\n",
       "         32267, 60468, 16325, 60466, 63993, 60459, 40009, 53767,  7904,\n",
       "         16387, 16402,  7877, 64025, 60425, 64010,  7838, 32275,  8009,\n",
       "         39811, 60588, 15970, 53512, 60575,  8145, 16292, 39848, 16139,\n",
       "         39915, 63951, 39957, 50466,  8014, 16023, 17933, 32187, 60351,\n",
       "          7281, 60174, 50252, 31623, 31596,  7244, 40452, 60156,  7221,\n",
       "         17029, 64324, 64332,  7145, 40533,  7228, 16463, 60187, 60213,\n",
       "         60327, 16555, 16590, 40241, 53919, 40256, 60204,  7555,  7471,\n",
       "         60254, 16783, 31797, 40366, 60230, 16734, 30674, 17974, 41548,\n",
       "         19421, 29163, 65248, 19517, 29077, 29068, 42879, 58997, 58970,\n",
       "         43063, 29037, 19644, 49071, 49065, 54971,  4397, 42841, 49176,\n",
       "         54928, 29280, 19295,  4778,  4765,  4759, 65225, 59062, 19366,\n",
       "         59057, 42801,  4649, 54947, 42813, 42757, 29351, 19702, 65323,\n",
       "         28748, 20042, 58715, 58701, 58700, 48991,  4121, 65453, 20120,\n",
       "         20141, 48925, 58679, 20198, 20231, 43384, 54991,  4132, 43264,\n",
       "          4334, 19753, 28930, 43156,  4274, 43163, 43266, 58844,  4245,\n",
       "         58832, 43224, 58808, 43231,  4170, 49049, 39805,  4869,  4897,\n",
       "          5719, 30407,  5702, 18266, 41764, 30289, 41692, 18374, 30252,\n",
       "          5535,  5527, 18435, 41890, 30234, 18394, 41906, 54535, 59599,\n",
       "         41606,  5950, 30573, 18095,  5895, 30536, 30430, 30521, 41646,\n",
       "          5845,  5819, 54496, 18178, 49889,  5875, 19053, 30215, 41937,\n",
       "         29734, 49518, 18853, 54796, 18923, 29562, 18809, 49410, 49379,\n",
       "         49366, 65067, 29510, 29488,  4921, 49390, 30156, 18807, 29816,\n",
       "         18548, 41950, 41963, 59459, 18612, 64951, 54764, 42086, 29911,\n",
       "          5236, 49566, 29850, 49541, 29820, 29970, 28590,  8266, 32623,\n",
       "         34818, 10689, 10692, 34851, 52502, 61678, 13263, 13228, 61706,\n",
       "         10768, 13164, 10780, 36992, 34936, 52488, 36956, 13135, 62549,\n",
       "         62550, 12966, 11023, 35118, 51539, 34798, 13046, 13051, 13093,\n",
       "         36920, 10863, 52455, 13125, 35050, 51368, 34769, 52520, 13703,\n",
       "         10237, 34404, 61471, 37546, 37581, 10298, 61465, 34344, 62918,\n",
       "         34300, 51273, 34256, 13916, 13816, 12913, 10316, 61533, 13421,\n",
       "         10508, 13492, 10494, 13529, 10473, 62832, 34622, 34511, 61567,\n",
       "         13614, 10381, 34487, 13657, 34532, 35254, 62542, 12902, 62280,\n",
       "         12262, 11712, 12284, 52186, 12307, 35832, 12309, 36392, 24679,\n",
       "         11635, 51880, 36404, 35701, 36367, 11595, 62262, 36202, 52069,\n",
       "         36081, 62192, 12040, 35976, 62209, 36227, 52120, 11887, 62114,\n",
       "         11843, 11841, 11839, 11814, 11893, 51244, 11590, 36417, 51654,\n",
       "         62450, 11269, 35346, 11241, 12720, 51655, 11221, 61860, 35312,\n",
       "         52372, 36742, 52382, 12867, 36673, 11566, 35412, 35449, 36453,\n",
       "         61966, 35628, 12419, 61948, 61937, 52301, 36501, 36555, 11468,\n",
       "         11457, 11451, 12594, 11441, 12540, 37778, 61370, 62982, 50785,\n",
       "          8874, 50776, 39131, 60798, 33062, 39084,  8799, 39199, 39203,\n",
       "         39229, 53344, 15537, 33003, 60705, 63672, 53243, 60827, 15211,\n",
       "          9043, 15213, 60843, 39021,  9015, 63533, 63463,  9004, 50851,\n",
       "         39055, 39067, 39075, 53238, 39024, 63433, 32988, 63703, 32813,\n",
       "         39577,  8458, 15763, 15779, 39607, 32827, 50580, 50577, 15888,\n",
       "          8336, 50550, 15906, 53476, 32741, 63683, 50632, 50647, 60680,\n",
       "          8677, 63716, 63724, 53379,  8606, 39517, 32917,  8573, 39383,\n",
       "         32869, 53399,  8545, 39400, 15658, 63905, 63426, 53192, 14283,\n",
       "         14294,  9750,  9742,  9738, 33956, 14241, 33921,  9697,  9692,\n",
       "         38197, 14395, 61182, 61166, 33881, 38389, 38050, 14191, 62990,\n",
       "         52744, 51211,  9943, 37859, 14041, 61256, 52748, 51187, 51185,\n",
       "          9906, 52778, 38014, 38017, 37898, 63419, 38390, 38400, 38809,\n",
       "         15059,  9208, 53159, 15133,  9165, 15020, 38910,  9155, 33368,\n",
       "          9146, 63357, 38934,  9111, 53165, 38395, 50884, 53118, 61108,\n",
       "          9509, 38466, 33764, 14667, 33711, 33482, 50983, 14803, 53045,\n",
       "         53069, 33602, 33561,  9281, 38609,  3804, 41625, 52084,  2614,\n",
       "         25691, 66934, 48420, 23428, 21552, 25689, 27393, 27400, 27406,\n",
       "         25651, 66971, 55733,   942,  2673, 56470, 21391,   915, 55638,\n",
       "         21560,  2584, 66907, 55768,  2398, 21824, 25797, 27134,  2442,\n",
       "         66168, 23377,  1046, 27177, 25602, 46332, 27198, 44722, 21652,\n",
       "         44704, 55803, 21634, 55783, 66129, 46368, 66154, 23521,   886,\n",
       "         46551, 48551, 27798,  3015, 23737,   690, 44165, 55500,  3057,\n",
       "         67076,   730,   662, 44141, 46853,   637, 20998, 46892, 27898,\n",
       "         27909, 46895, 20975, 23835, 27109,  2988, 44188, 21263, 67007,\n",
       "          2788, 21253,  2799,  2802, 21222, 48532,  2838, 65842, 58235,\n",
       "         44287, 46680, 44274, 57169, 25478, 58281, 25462, 44228, 21121,\n",
       "         57177, 44099, 23303, 25868, 22563, 26538, 57704, 45442, 57724,\n",
       "         56048, 48075, 22873, 45752, 22874, 48164, 26136, 66479,  1956,\n",
       "         45820, 22381, 22360, 22349, 57826, 22857,  1847, 48082, 22825,\n",
       "         66562,  1699, 45602, 22709, 45640,  1725,  1750, 22644, 45577,\n",
       "         56016, 22760, 66575, 56117, 22599,  1791, 26506,  1603,  1601,\n",
       "         57701, 45667, 22777, 26731, 57554, 57843, 26972,  1178, 23155,\n",
       "         46056,  2245, 66334, 66890,  2258,  2260, 46038,  1156, 23185,\n",
       "          1151,  2291, 46086, 48297, 44879, 23244, 46099, 57431, 46065,\n",
       "         66269, 25995, 26930, 45207, 45921, 45940, 57863,  1363, 45966,\n",
       "         66740, 45971, 23048, 46031, 26916, 26923, 26924,  1261, 46004,\n",
       "         45067, 46005,  2161, 26005, 45039,  1276, 27927, 45613, 55415,\n",
       "         47323, 47094, 24139, 25062, 24066, 43877, 67254,  3287, 47239,\n",
       "           503, 28031,   508, 47336,  3690,   177, 43710, 47515, 24790,\n",
       "         24216, 48688, 43857, 24870, 28515, 28360, 58339, 47086,   478,\n",
       "         20453, 47272,  3312, 44015, 25111, 20479, 20766, 24111,  3633,\n",
       "         43995, 24112, 24825, 28125, 43649, 24801, 28355, 25176, 56929,\n",
       "         20696, 20807,  3660,  3402, 43620,  3407, 20353, 24805, 55447,\n",
       "         46935, 43796, 55434, 24297,   309, 25256, 58642, 28571, 20320,\n",
       "         28542, 44080, 67162, 47547, 58613, 43823, 28287, 24254, 55312,\n",
       "         28527, 20546, 24648, 57039, 25320, 65774, 28263, 53122, 60994,\n",
       "         15031, 33440, 56273, 33698, 52959, 33386, 57519, 26059, 15124,\n",
       "         15107, 60976, 14495, 60983, 53144, 14523, 15069, 56315, 33811,\n",
       "         56255, 24398, 52948, 15038, 35679, 33793, 56267, 33475, 33784,\n",
       "         12402, 14904, 56965, 14875, 61089, 61071, 61069, 33604, 33565,\n",
       "         14730, 14822, 56964, 25984, 57491, 33650, 61062, 14748, 12396,\n",
       "         61112, 23130, 14940, 24855, 56950, 12314, 24404, 60999, 12341,\n",
       "         52983, 25974, 24860, 33542, 14943, 56288, 14637, 56769, 33721,\n",
       "         52223, 61098, 61020, 23880, 35803, 57600, 60699, 26227, 24773,\n",
       "         35933, 15515, 26211, 15502, 35929, 15484, 26240, 24575, 15473,\n",
       "         52142, 60707, 26150, 15432, 24573, 60760, 60766, 15405, 33147,\n",
       "         15483, 24586, 33002, 56900, 24697, 36044, 32872, 26396, 62146,\n",
       "         36009, 32923, 15617, 56107, 12023, 22755, 15600, 24637, 32957,\n",
       "         53345, 12037, 56837, 24603, 62138, 32979, 56119, 15558, 56835,\n",
       "         52158, 23068, 12166, 60811, 15248, 22996, 24541, 56205, 26096,\n",
       "         23009, 60861, 24391, 15192, 57535, 62043, 23021, 26085, 60876,\n",
       "         33348, 35824, 53172, 15156, 26084, 57528, 12265, 53166, 35829,\n",
       "         57558, 56187, 33242, 35898, 33167, 33184, 33185, 22883, 22885,\n",
       "         22910], dtype=int64),\n",
       "  'feature_absent_idx': array([20922, 31355, 48180, 14511, 31346, 48191, 48195, 48200, 14530,\n",
       "         14531, 14533, 14534, 14535, 58389, 58388, 14541, 14542, 58385,\n",
       "         31328, 14545, 58380, 14549, 14550, 48208, 14552, 14553, 58373,\n",
       "         14561, 58411, 14504, 14503, 14501, 14449, 58443, 14457, 14458,\n",
       "         58442, 58439, 58438, 14463, 31379, 58434, 14474, 14477, 58429,\n",
       "         14562, 58428, 14484, 48174, 31367, 14488, 14490, 48175, 48176,\n",
       "         58416, 31360, 58415, 58413, 14499, 14500, 14482, 48213, 31312,\n",
       "         14573, 14626, 31274, 58340, 31272, 58337, 14634, 14635, 14636,\n",
       "         58333, 14645, 31258, 14651, 31257, 48240, 48247, 31251, 31250,\n",
       "         14659, 48249, 31243, 31242, 31240, 48253, 14675, 14677, 58318,\n",
       "         31230, 14681, 31254, 14448, 31276, 31279, 58367, 48220, 14577,\n",
       "         31302, 31301, 58364, 58363, 14584, 58361, 31293, 14593, 58360,\n",
       "         58358, 31277, 58357, 31291, 14600, 58354, 48229, 14603, 31289,\n",
       "         14605, 14610, 58349, 14615, 31282, 48236, 14619, 14598, 14447,\n",
       "         58444, 48165, 48096, 58553, 31515, 58548, 31507, 14285, 14286,\n",
       "         14287, 48103, 14291, 48106, 14293, 14295, 14268, 14296, 31492,\n",
       "         14304, 14305, 31491, 31489, 14310, 58538, 14312, 58537, 58536,\n",
       "         14317, 31485, 14319, 48109, 48115, 58559, 14262, 31574, 48055,\n",
       "         14215, 14216, 31565, 31563, 14220, 31559, 14225, 48065, 31551,\n",
       "         14232, 48070, 31528, 31548, 48079, 48080, 58573, 58572, 14249,\n",
       "         14251, 48083, 58571, 31535, 31532, 48087, 14260, 14261, 31545,\n",
       "         31229, 58526, 48117, 14387, 14388, 14390, 14393, 48150, 31418,\n",
       "         31417, 31416, 31414, 14402, 48157, 58476, 14414, 58488, 14417,\n",
       "         58465, 14422, 14424, 58460, 14426, 14427, 48162, 58450, 31389,\n",
       "         14439, 14441, 31386, 14443, 31399, 31477, 58489, 14383, 48118,\n",
       "         58519, 31469, 31467, 14340, 58513, 31456, 31455, 48123, 31453,\n",
       "         31445, 58506, 14362, 14384, 14363, 58502, 31438, 14369, 14371,\n",
       "         58496, 31435, 48143, 31429, 14378, 31426, 14380, 48146, 58491,\n",
       "         14365, 31228, 14684, 58316, 31039, 14953, 48401, 58132, 14958,\n",
       "         58130, 14960, 48403, 31034, 58122, 58118, 14966, 14967, 31040,\n",
       "         31028, 14973, 58112, 31021, 31020, 14983, 58110, 14986, 48413,\n",
       "         31013, 48415, 58106, 31007, 14999, 14971, 31005, 14947, 48388,\n",
       "         14888, 14889, 14890, 31078, 14892, 31076, 14897, 48370, 31069,\n",
       "         48374, 58163, 48375, 58158, 48400, 14914, 31060, 31059, 14921,\n",
       "         14922, 14925, 58152, 14927, 58151, 14929, 14930, 31055, 31051,\n",
       "         14937, 14917, 58178, 58092, 15008, 48461, 58060, 30949, 15066,\n",
       "         58057, 15071, 15075, 58052, 48471, 30941, 30939, 58049, 58046,\n",
       "         48459, 48475, 48477, 30930, 48478, 30926, 58039, 58037, 15106,\n",
       "         15109, 30917, 15112, 48494, 58036, 30907, 15092, 58090, 30953,\n",
       "         15057, 48424, 15010, 15013, 30997, 15015, 48431, 15018, 48433,\n",
       "         48438, 15026, 48441, 15029, 30983, 30955, 30979, 48444, 30976,\n",
       "         58072, 15040, 15042, 15046, 30968, 30967, 30966, 48455, 48456,\n",
       "         48457, 30957, 15034, 14207, 58179, 48364, 48295, 14740, 58286,\n",
       "         14744, 48299, 58285, 58283, 58277, 14753, 58274, 31178, 31177,\n",
       "         14760, 48292, 58267, 31172, 48303, 48304, 48310, 48315, 58254,\n",
       "         31161, 48319, 48320, 31157, 14780, 48321, 58246, 14764, 58243,\n",
       "         48291, 14733, 48262, 31224, 48265, 58311, 14694, 14695, 58310,\n",
       "         31217, 48271, 31211, 58305, 31210, 58301, 58292, 14707, 14710,\n",
       "         14711, 48280, 14716, 14717, 14718, 31201, 48282, 14723, 48286,\n",
       "         58294, 14727, 31194, 58297, 14883, 31151, 58242, 58207, 31117,\n",
       "         48340, 14842, 48342, 31112, 14845, 58203, 14847, 14848, 48345,\n",
       "         31109, 58200, 58208, 48346, 31106, 14857, 58195, 14859, 31103,\n",
       "         31101, 31092, 14871, 58191, 31090, 48359, 14877, 48361, 58197,\n",
       "         14788, 31120, 48339, 31148, 31146, 58240, 14794, 31145, 58239,\n",
       "         14797, 58237, 14799, 14800, 58236, 31140, 48329, 14833, 14811,\n",
       "         31134, 48333, 31129, 58221, 14820, 31128, 31127, 14824, 14825,\n",
       "         14826, 48338, 14829, 58215, 48332, 14206, 31575, 14204, 59037,\n",
       "         13541, 32077, 59032, 47748, 13551, 13557, 32063, 32061, 13564,\n",
       "         13565, 13566, 32057, 59038, 13568, 13571, 47759, 32051, 32050,\n",
       "         47760, 59006, 13577, 32047, 13579, 59003, 13582, 47762, 32040,\n",
       "         59016, 47767, 47744, 59040, 47721, 13494, 13495, 13498, 32106,\n",
       "         32105, 47728, 59058, 47730, 47732, 47733, 13507, 32098, 13536,\n",
       "         32096, 13513, 32093, 32091, 13519, 13520, 47738, 47740, 32086,\n",
       "         13524, 59045, 32082, 59043, 13532, 13511, 32113, 58992, 32032,\n",
       "         58951, 31973, 58950, 13671, 13672, 13675, 47810, 58941, 13688,\n",
       "         13689, 58937, 13692, 58935, 47797, 31954, 47814, 13698, 58933,\n",
       "         13701, 47816, 13705, 31948, 31944, 31943, 58928, 31938, 58925,\n",
       "         13718, 13696, 13595, 13659, 13654, 32030, 58987, 47770, 32024,\n",
       "         13606, 13608, 58982, 58981, 47772, 13615, 47773, 13620, 47774,\n",
       "         31982, 58974, 32010, 32008, 13631, 32005, 47785, 13637, 13638,\n",
       "         58966, 32000, 47786, 31994, 13647, 47794, 13626, 13719, 47719,\n",
       "         13485, 32232, 13317, 47645, 32230, 59179, 59178, 13322, 32228,\n",
       "         32227, 32226, 13328, 13329, 13333, 59183, 47646, 13338, 59168,\n",
       "         32215, 13344, 13345, 13347, 32209, 47659, 59163, 47664, 59158,\n",
       "         32203, 13362, 59170, 13364, 32235, 13307, 32270, 13259, 47634,\n",
       "         47635, 59212, 59211, 13269, 13271, 59210, 13273, 13274, 32262,\n",
       "         13280, 13311, 59206, 59199, 13288, 59198, 13290, 13292, 13293,\n",
       "         13295, 32251, 32245, 13301, 59195, 47641, 59191, 32254, 32115,\n",
       "         13365, 59154, 13429, 59106, 47694, 13435, 59104, 32146, 13441,\n",
       "         47695, 32142, 13446, 59093, 13448, 59092, 32154, 32141, 13454,\n",
       "         59088, 59087, 13463, 13466, 13467, 32130, 32126, 47710, 13476,\n",
       "         47715, 59073, 47717, 59089, 32199, 13426, 13423, 32195, 32194,\n",
       "         47669, 32186, 47671, 59147, 59139, 32179, 32177, 59134, 59128,\n",
       "         47680, 32170, 13425, 32169, 13399, 59123, 47682, 13405, 47684,\n",
       "         47687, 13410, 32158, 13415, 59112, 59110, 47691, 13422, 32167,\n",
       "         58034, 31937, 31934, 14028, 58708, 31694, 14033, 14034, 14035,\n",
       "         31686, 47988, 58697, 31677, 31675, 14054, 14056, 31696, 31674,\n",
       "         14059, 47993, 14062, 31671, 47995, 47996, 48000, 14073, 31660,\n",
       "         58687, 58684, 14078, 14079, 58694, 58680, 14026, 58712, 13974,\n",
       "         13975, 13976, 58747, 58746, 58744, 31737, 58741, 58740, 13986,\n",
       "         31735, 13988, 58739, 47976, 31726, 47965, 31719, 31716, 31712,\n",
       "         31711, 47970, 31708, 31704, 58718, 31701, 58714, 58713, 14021,\n",
       "         31724, 13973, 31658, 31656, 58635, 58632, 58631, 14157, 14158,\n",
       "         58628, 48037, 14162, 14163, 14164, 31604, 14169, 58621, 48034,\n",
       "         14176, 58615, 14181, 31589, 31588, 14187, 14189, 14190, 48049,\n",
       "         58601, 31578, 48053, 14200, 14201, 31592, 14085, 31616, 48030,\n",
       "         14091, 31653, 58672, 48009, 58671, 48011, 14099, 14102, 31646,\n",
       "         58666, 14110, 14111, 14113, 14146, 58657, 31634, 31630, 14127,\n",
       "         31629, 31628, 14131, 31626, 14134, 14135, 48027, 58643, 48029,\n",
       "         14143, 48022, 31935, 47956, 13964, 13788, 13791, 13794, 13795,\n",
       "         13796, 58885, 58884, 13799, 31889, 13801, 58882, 31888, 13804,\n",
       "         47852, 31886, 31882, 47860, 13815, 31874, 58865, 31872, 31870,\n",
       "         13823, 31866, 13825, 13829, 58859, 47870, 13808, 58851, 47850,\n",
       "         31898, 47823, 13725, 58919, 13729, 13731, 58915, 47830, 58914,\n",
       "         58912, 47831, 58907, 31918, 47841, 31897, 31910, 31907, 31905,\n",
       "         58897, 31904, 13767, 58894, 31902, 13772, 13773, 13774, 13776,\n",
       "         13778, 47848, 47845, 31749, 31859, 13840, 47918, 47922, 31792,\n",
       "         13920, 13921, 31784, 58781, 58780, 58779, 58776, 47931, 13933,\n",
       "         47933, 13908, 13936, 47937, 13941, 47939, 58770, 58769, 31765,\n",
       "         13950, 47947, 31756, 13958, 31752, 13961, 58754, 13937, 58842,\n",
       "         58796, 58797, 31854, 47876, 31848, 31846, 31845, 31837, 13864,\n",
       "         47883], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_ord': {'feature_present_idx': array([20211, 40808, 59138, 43308, 66276, 16247, 55605, 16870, 38847,\n",
       "         66969, 10466, 61050, 14115, 43976, 14313, 13938, 44063, 45155,\n",
       "         46587, 47725, 14551, 48815, 49447, 49873,  9299, 55063, 55188,\n",
       "          6922, 57198, 57340, 45729, 15002, 40660, 41091, 25277, 27420,\n",
       "         30607, 23414, 30902, 31004, 31431, 21606, 21457, 21243, 15274,\n",
       "         34537, 36940, 19642, 37702, 38478, 39252, 17989, 39312, 39548,\n",
       "         40115, 57747, 35491, 58087, 25403,  5054, 60717,  5748,  2691,\n",
       "         63014, 63199, 63303, 63358, 64591, 64829,  1528,   754, 66132,\n",
       "          5441, 60728,   250, 66966,  1785, 27844,  2148, 40097, 40099,\n",
       "          2185, 16906, 24900, 40174, 16684, 16630, 40322, 16307, 16276,\n",
       "         27493, 15974, 66335, 41348, 27150, 41473, 41713, 42862, 43083,\n",
       "         61474, 61427, 61295, 61237,  1738, 24791, 18443, 38785, 23156,\n",
       "         30522,   926, 66128, 31659, 31776, 22685, 21924, 65985, 21677,\n",
       "         65948, 34171,  1154, 34360,  1210, 65596, 65096, 23857, 36429,\n",
       "         29418, 19686, 64694, 37404, 14177, 27900, 38460, 64044, 18859,\n",
       "         18753, 30611,  5776, 15196,  9251, 10786, 59630, 10195, 59469,\n",
       "          5038, 50059,  9794, 50732, 50935, 51155, 52368, 53213,  8540,\n",
       "         53273, 10853, 53275, 54425, 54964, 59431,  7375,  5222, 55409,\n",
       "         55849,  6613,  6609, 56203, 56240, 58359, 57373,  5580, 53999,\n",
       "         11032, 67166, 11346, 48254, 46084, 45754, 60638, 60667, 46724,\n",
       "         12473, 47076, 13759, 60554, 14018, 47808, 47925, 44721, 55196,\n",
       "         61811, 42243, 42163, 58303, 42811, 32654, 32657, 58189, 32718,\n",
       "         32058, 30829, 55764, 27836, 30799, 30723, 45433, 33316, 30424,\n",
       "         55966, 44393, 43907, 56525, 27572, 59142, 59328, 54691, 54185,\n",
       "         45946, 48354, 60223, 39356, 48506, 39255, 48916, 40500, 47276,\n",
       "         62849, 38476, 62184, 37549, 51249, 37202, 44081, 51605, 40959,\n",
       "         54405, 54130, 34332, 53637, 62032, 46107, 33660, 35021, 41318,\n",
       "         35597, 35867, 36423, 26803, 52854, 35328, 61165, 33842, 15712,\n",
       "          9284, 15675,  2925,  3094, 23550, 23498,  9062, 23047,  3818,\n",
       "         13352,  3979, 15717,  4185, 22811, 15179, 16236,  8257, 22629,\n",
       "         22625,  4705,  5214, 21792,  7557, 18405, 21489, 21099,  5974,\n",
       "         19134,  7003, 20202,  8683,  9328,  6430,  1107, 11256, 11998,\n",
       "         24947, 13072,  1664, 25222, 25510, 10160, 39019,  7458, 39235,\n",
       "         13845,  7406,  7253, 44292, 18017,  7681, 17720, 44523, 15155,\n",
       "         13786, 38187, 55322, 37875, 19427, 37414, 55692, 13612, 56020,\n",
       "         19840, 36884, 36841,  6440, 13202,  7171, 55272, 39472, 12986,\n",
       "         41597, 41571, 41942, 50658, 15085, 10117, 42553, 49871, 42734,\n",
       "         41249, 51971, 48867, 51985, 48377, 14899, 11407, 15822, 47485,\n",
       "         12335, 53548, 40186, 12778, 16947, 16971, 17079,  7711, 14159,\n",
       "         14037, 41785, 39462, 25589, 36523, 20529, 28730, 28961, 62120,\n",
       "          2808, 24610, 29480, 29509, 61959, 30449, 36602, 22964,  4090,\n",
       "          4116, 60343, 31990, 28678, 28608, 28594, 28352, 66908, 66822,\n",
       "         26101, 66365, 26117, 26661, 25001, 32059,  1413, 27518,  1554,\n",
       "         24929, 24889, 27873,  1627, 63844, 24961, 32184, 23134, 32295,\n",
       "         56378, 36053, 20986, 21056, 60078, 58183, 58187,  5739, 34265,\n",
       "          5497, 58704, 34031, 45942, 22635, 59831, 59334, 59386, 55572,\n",
       "         64953, 12415, 46877,  6260, 46618,  7131,  1282,  6263,  5375,\n",
       "         57364, 46483, 60084,   617,  6591, 57115, 56911, 46074,  6387,\n",
       "          1066,  7160, 48007,  3181, 61106, 61973,  5469, 61077, 55057,\n",
       "          9364,  9374, 58322,  4623, 52093, 55269,  1898,  8040, 49573,\n",
       "          8170, 64402, 10318, 53162, 57396, 57388, 57589, 45056, 36077,\n",
       "         41740, 41267, 41155, 16318, 17556, 39149, 18657, 38704, 18922,\n",
       "         38069, 19344, 37494, 37082, 36173, 35749, 34704, 21782, 25639,\n",
       "         27170, 27747, 28115, 23673, 23562, 42000, 31226, 31434, 31536,\n",
       "         31919, 32261, 32622, 33032, 31329, 42630,    43, 43256, 14445,\n",
       "         14963, 43958, 14437, 13878, 43173, 43900, 43006,  4201, 59703,\n",
       "         59671, 33533, 34060, 21590,  4181, 49619, 34329, 21358, 34386,\n",
       "         57613, 35361, 20895, 20754, 57284,  5482, 46623, 49793, 60829,\n",
       "         45431,   936, 65920, 65812, 64777, 24639, 64329,  1663, 28162,\n",
       "         63755, 28318, 63339, 28523, 62484,  2654, 30129, 23784, 61592,\n",
       "         23483,  3565,  3711, 61140, 44166, 20547, 14423, 58624, 16733,\n",
       "         40188,  7820, 17725, 54812, 39164, 52944, 10379,  8699, 41097,\n",
       "         38551, 36403, 43077, 19592, 51129, 10192, 50762, 49592, 49487,\n",
       "         15084, 50530, 39618, 19598, 27488,    85, 46614, 41559,  8469,\n",
       "         25731, 23150, 16392, 26102,  3519,   136, 42452, 52527,  1622,\n",
       "         13163, 28967, 40664, 63722, 15497,  2415,  2371, 46457, 25351,\n",
       "         36195, 60603,  5806, 60615, 56919, 34189, 19000, 10811, 14935,\n",
       "         33949, 43658, 34781, 33573, 36625,  5983, 56701, 13248, 48690,\n",
       "         59695, 59816,  6869,  6241, 36942, 46692, 60358, 56090, 56618,\n",
       "         34716, 27483, 41819, 36744, 46093,  2391,   748, 29050, 52835,\n",
       "         18217, 22790, 22900, 39868, 47288, 37289, 10185, 42649, 42793,\n",
       "          8682,  8474, 11500, 26143, 55501, 45013, 59622, 31613, 27515,\n",
       "         45461, 22503], dtype=int64),\n",
       "  'feature_absent_idx': array([38261, 28450, 12807, 45711, 28448, 28447, 12811, 12812, 12813,\n",
       "         28445, 45713, 28441, 57611, 57609, 12805, 28439, 57605, 12826,\n",
       "         28436, 12829, 45716, 45717, 57601, 12835, 57599, 45722, 28429,\n",
       "         45725, 45726, 12824, 57596, 57626, 57628, 45683, 57662, 28482,\n",
       "         28478, 12762, 12763, 57656, 28476, 12768, 12769, 12770, 12771,\n",
       "         28473, 28452, 12773, 12777, 45696, 57650, 12782, 45699, 45701,\n",
       "         57643, 57642, 57641, 45704, 45705, 12799, 57629, 45695, 57594,\n",
       "         57591, 28421, 57550, 12898, 12901, 28378, 45758, 45761, 28374,\n",
       "         28371, 57544, 28370, 12915, 45769, 28361, 28382, 28350, 57525,\n",
       "         12930, 45779, 57524, 45786, 28341, 57518, 57516, 28337, 12943,\n",
       "         57513, 57511, 12947, 57526, 28383, 12894, 12892, 45731, 45732,\n",
       "         12851, 12852, 12854, 28416, 12858, 57579, 57578, 12862, 28410,\n",
       "         12865, 45736, 28408, 28407, 45740, 57571, 57570, 57568, 45743,\n",
       "         57567, 57566, 12877, 12878, 12880, 28398, 28397, 45747, 28388,\n",
       "         28487, 12948, 57665, 57667, 45611, 12595, 12596, 12597, 12598,\n",
       "         28605, 45615, 28602, 45616, 45618, 57782, 45619, 28595, 12592,\n",
       "         28592, 45626, 28583, 57772, 57770, 28580, 57768, 45628, 12633,\n",
       "         12634, 57766, 57762, 12644, 45634, 28589, 28562, 28612, 57795,\n",
       "         45594, 12546, 57840, 28642, 12550, 45598, 57835, 45599, 12557,\n",
       "         28634, 45600, 12562, 57825, 45609, 57821, 12568, 45603, 28624,\n",
       "         57811, 12574, 28622, 28621, 57807, 57801, 12581, 12583, 57796,\n",
       "         12586, 28630, 45635, 57753, 57750, 28525, 28521, 12707, 28520,\n",
       "         28519, 12710, 12711, 57699, 12714, 12717, 45664, 12721, 12723,\n",
       "         28529, 57688, 28504, 57683, 45672, 28501, 28500, 28498, 12739,\n",
       "         12742, 28494, 28493, 57676, 45674, 57670, 45671, 28530, 45652,\n",
       "         12696, 12653, 28558, 45638, 57745, 45639, 12661, 57741, 12663,\n",
       "         12664, 28552, 12667, 57736, 57735, 28548, 12675, 12676, 57731,\n",
       "         57730, 28544, 45643, 57725, 57723, 28537, 28536, 57718, 57717,\n",
       "         12693, 28534, 57715, 57666, 12544, 28333, 12952, 13217, 28136,\n",
       "         13219, 28135, 13221, 45953, 28128, 28126, 28124, 57283, 13233,\n",
       "         28117, 28114, 57297, 28113, 57271, 28109, 28108, 13247, 13249,\n",
       "         57266, 57265, 45968, 13255, 57261, 13259, 45969, 57257, 13243,\n",
       "         57256, 13214, 57299, 13160, 13161, 28182, 45904, 13167, 57329,\n",
       "         28173, 57325, 13173, 13176, 28167, 45923, 13183, 45948, 45927,\n",
       "         13190, 13193, 28150, 45935, 57306, 57305, 45939, 13201, 45945,\n",
       "         57303, 57301, 13209, 28140, 45929, 57254, 57252, 57251, 57218,\n",
       "         45986, 45990, 13317, 57209, 13322, 57208, 45993, 28064, 28063,\n",
       "         13328, 13329, 45994, 13311, 13333, 28051, 13338, 57188, 28047,\n",
       "         13344, 13345, 46006, 13347, 46007, 46008, 28042, 46013, 28034,\n",
       "         28056, 45984, 28076, 13307, 13269, 13271, 28097, 13273, 13274,\n",
       "         57247, 45976, 28093, 13280, 28091, 57237, 28088, 57232, 13288,\n",
       "         57230, 13290, 13292, 13293, 28085, 13295, 28084, 28082, 57227,\n",
       "         13301, 28080, 57224, 28079, 57221, 28078, 57334, 12951, 45903,\n",
       "         45900, 57447, 13020, 28274, 57442, 13028, 13029, 57441, 28267,\n",
       "         28265, 57437, 13037, 28264, 13040, 13016, 45843, 45846, 45847,\n",
       "         45849, 57430, 57429, 57428, 13052, 45856, 57427, 57425, 28248,\n",
       "         28247, 45863, 57433, 57423, 57450, 45828, 28331, 57502, 57501,\n",
       "         12960, 57493, 45800, 12964, 45803, 45807, 12969, 12970, 12971,\n",
       "         12973, 13014, 28316, 28310, 12983, 28304, 12987, 57480, 12989,\n",
       "         28299, 45823, 57468, 13002, 13003, 45824, 45826, 45809, 57422,\n",
       "         13065, 57420, 13112, 57386, 28213, 28209, 57381, 28208, 28207,\n",
       "         28205, 57367, 57366, 57365, 57362, 45892, 57389, 57359, 57352,\n",
       "         45895, 57350, 57344, 28188, 13146, 13148, 13149, 57341, 13151,\n",
       "         57339, 45899, 13154, 28191, 13108, 57391, 13106, 45864, 28241,\n",
       "         28240, 57415, 57413, 45865, 28238, 57405, 57403, 13079, 13081,\n",
       "         28233, 28232, 13084, 45872, 45874, 57401, 57399, 28225, 28224,\n",
       "         45879, 13095, 13096, 13098, 57395, 13101, 28218, 13103, 57392,\n",
       "         57336, 45592, 28649, 45583, 11984, 11985, 58274, 11987, 45255,\n",
       "         45258, 11994, 11995, 58267, 29071, 45266, 45271, 29058, 58277,\n",
       "         45275, 12014, 12015, 58254, 12017, 45281, 12022, 58246, 45282,\n",
       "         58243, 58242, 12029, 29042, 58240, 12013, 58239, 45253, 58285,\n",
       "         29107, 58311, 58310, 29105, 58305, 45236, 45237, 58301, 11952,\n",
       "         29098, 29097, 45239, 58297, 58283, 29094, 58294, 45243, 45247,\n",
       "         45248, 58292, 11968, 29086, 45249, 45250, 45252, 11975, 11976,\n",
       "         58286, 11959, 12033, 58237, 29041, 29004, 58195, 45317, 45321,\n",
       "         12087, 45323, 58191, 28994, 28993, 45331, 45333, 58179, 28986,\n",
       "         58197, 12104, 28983, 12108, 12109, 28982, 58178, 28981, 45338,\n",
       "         28976, 45339, 58163, 45340, 45342, 45343, 12106, 29007, 12079,\n",
       "         29008, 58236, 29040, 29039, 45292, 29035, 29033, 12045, 12046,\n",
       "         12047, 29032, 29029, 29028, 45299, 58221, 45304, 12056, 29020,\n",
       "         58215, 12059, 45305, 12062, 12064, 45310, 58208, 58207, 29012,\n",
       "         58203, 12075, 58200, 11940, 58158, 11939, 58316, 58439, 58438,\n",
       "         58434, 29214], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 650\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 650\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 650\n",
       "    })}}},\n",
       " 'contains_part': {'feature_present_idx': array([22578, 24581, 37486,  8252, 48880, 63551, 63386, 24632, 37048,\n",
       "         24664, 49234, 36568, 37590, 49317, 56494,  9451,  9472,  9479,\n",
       "          9536,  9582, 20123,  9783, 24953, 35699, 19982, 62491, 63607,\n",
       "         63634, 63661, 40649,  5711, 40567, 47878, 23374, 39961, 55699,\n",
       "         48004, 39842,  6133,  6207, 39702,  6535,  6550, 38882,  6892,\n",
       "          7040,  7212, 38361, 55995,  7499, 37911, 48719,  7837,  7885,\n",
       "         49794, 10479, 10613, 10643, 14640, 14860, 30205, 15214, 29514,\n",
       "         52636, 29006, 15821, 58677, 16054, 18238, 16232, 53992, 57561,\n",
       "         16377, 18161, 28166, 53056, 57614, 53897, 17326, 58258, 58213,\n",
       "         17524, 53849, 14620, 47689, 30418, 59540, 10745, 35228, 10974,\n",
       "         34919, 34853, 19457, 61307, 11185, 11243, 11301, 50153, 61229,\n",
       "         61006, 50396, 19453, 25356, 12080, 50702, 25392, 33095, 33024,\n",
       "         31767, 18970, 31235, 51521, 30729, 41255, 20227,  4746,  1585,\n",
       "         44559, 45595, 22880,  1535, 41902, 44637, 66551, 41991, 65919,\n",
       "         46746, 67223, 42119, 67109,   669,  3202, 42129, 55083, 45691,\n",
       "         44997,  3630, 66224, 22357, 46961, 55414,  4264, 42852,  4426,\n",
       "         43954,  4353,  1912, 45562, 45512, 66683, 45522, 54828, 21596,\n",
       "         51500, 51468, 11180,  2319, 22846, 13018, 51462, 31980, 57114,\n",
       "         51379, 32122, 19147, 51270, 34652, 61035, 11144, 14239, 14213,\n",
       "         14210, 52089, 46022, 18802, 51711,  2349, 34847, 22691, 51607,\n",
       "         13866, 51577,  1319, 32218, 59931, 30887, 25445, 12856, 22486,\n",
       "         56846, 50162, 11384, 34301, 66898, 25298, 34234, 60974, 11991,\n",
       "         56760, 66815, 61001, 50288, 44542, 34130, 33131, 34604, 12565,\n",
       "         44647, 60488, 34213, 51188, 50120, 32492, 56854, 12727, 32779,\n",
       "         32856, 12689, 12683, 11325, 32872, 14338, 22842, 60828, 12651,\n",
       "         41555, 14404, 27854, 53217, 27915,   273, 53034, 16888, 53011,\n",
       "         45397, 27850, 28194, 16403, 67176, 45234, 16238,   455, 45606,\n",
       "         45114, 22688, 16476, 28418, 53329, 27456,    22, 27006, 27021,\n",
       "         17611, 58038, 53824, 67265, 53818, 17075, 17881, 57873, 22450,\n",
       "           110, 67264, 26707, 17231, 26670, 17141, 53634, 28570, 28789,\n",
       "         58703, 26309, 52443, 52400, 57281, 30238, 54146, 14807, 30409,\n",
       "         29790, 18742, 46111, 45975, 52128, 52098, 59322, 18760, 30607,\n",
       "         25887, 59281, 52487, 15086, 15089, 52815,   554, 28884, 28919,\n",
       "           578, 58719, 26411, 52688, 22387, 52618, 15486, 52559, 57464,\n",
       "         18331, 26353, 29563, 54083, 29619, 52531, 30659,   753, 50029,\n",
       "         43968, 48722, 55450, 47069,  7678, 42156, 56007, 37964, 55495,\n",
       "         47067, 24292, 24217,  7308, 63809, 63853, 38368, 48504, 23832,\n",
       "         38600, 38128, 37787, 48864,  7977, 56292,  8504, 63347, 48945,\n",
       "         20708, 10975, 20713, 37320, 48885, 37338, 42800, 37369, 37391,\n",
       "         37419, 42663, 21772, 24392, 37653, 66221, 23709, 63298, 23499,\n",
       "         21306,  5825, 40355, 65331, 47301, 23305, 47872,  5486, 64973,\n",
       "         47989, 21474, 21485, 41202, 23344,  5080,  5007, 47355, 47577,\n",
       "         41544, 65070, 64524, 65370,  5896, 39128, 39195, 41944, 21339,\n",
       "         39547, 39553, 39643, 39670, 64133, 39682, 41811, 39802, 55604,\n",
       "         64204, 64261, 39814, 39923, 21667,  5909, 48217,  8583, 42814,\n",
       "         43181, 61974,  2777, 10030,  2782, 49603, 43359, 49602, 24931,\n",
       "         62287, 62386, 54395, 22069, 49395, 23071,  2939,  8650, 21941,\n",
       "         56577, 36226, 10124, 10133, 54387, 61878, 61550, 49844, 19647,\n",
       "          2549, 19788, 10727, 10701, 22193, 43598, 62429, 10557, 22137,\n",
       "         61649, 35394, 61807, 25052, 43467, 35511, 10180, 25019, 35366,\n",
       "          9352, 17853, 49246, 24698, 62864, 24796, 23158, 62825,  3219,\n",
       "         23141, 46736, 20324, 24663,  9033,  8912, 62763, 49313, 63275,\n",
       "          8660, 20322, 24682, 57995, 37034, 36281,  8768, 36530, 63224,\n",
       "         25072, 24627, 25753, 26691, 24025, 54208, 25812, 54585, 54371,\n",
       "         26784, 25080, 26814, 22863, 25759, 54198, 54168, 25736, 55011,\n",
       "         23974, 23290, 54533, 54644, 54686, 23525, 54284, 23491, 25496,\n",
       "         25550, 54263, 23296, 55029, 23237, 25694, 55114, 22692, 23212,\n",
       "         54819, 25840, 67325, 27020, 47631, 40770, 40684, 47882, 40252,\n",
       "         39949, 39220, 48211, 39109, 48328, 39048, 38883, 48473, 38556,\n",
       "         48505, 38217, 38135, 37025, 37056, 37070, 37073, 37180, 37276,\n",
       "         41678, 37281, 37572, 48871, 37916, 38005, 48717, 38048, 37309,\n",
       "         36973, 41693, 41794, 45435, 45658, 45048, 44967, 44762, 44742,\n",
       "         46055, 44655, 44551, 46095, 46096, 44084, 44076, 43865, 46630,\n",
       "         43329, 43307, 47119, 41892, 42019, 47115, 42120, 42346, 47124,\n",
       "         47005, 42693, 46931, 42949, 46838, 43137, 46660, 46985, 53825,\n",
       "         49210, 49287, 31216, 31089, 31041, 30951, 30895, 30866, 51855,\n",
       "         30628, 30569, 52104, 30417, 30271, 52211, 30122, 52460, 29595,\n",
       "         29559, 53761, 53603, 53525, 27249, 27327, 53425, 51519, 27440,\n",
       "         28234, 28332, 52875, 29023, 29491, 29545, 52981, 49224, 31330,\n",
       "         31816, 49381, 36337, 36309, 49393, 36224, 36213, 49461, 49498,\n",
       "         35732, 49613, 35608, 49646, 49801, 49805, 49811, 35313, 34997,\n",
       "         32001, 51308, 32210, 32260, 51107, 50834, 31501, 33165, 33761,\n",
       "         33872, 33912, 50410, 34674, 34733, 33366, 50056, 22209, 64577,\n",
       "         15443, 58836,  6525,  6615, 15160,  6633,  6673,  6695,  6743,\n",
       "         14942,  6835, 14819, 59204, 63922,  7030,  7048,  7271,  7345,\n",
       "         14607, 14514, 59332, 59351, 59437, 59451, 59476,  6454, 64076,\n",
       "         15444, 15556, 58008, 17697, 17649, 58101, 65733, 58276, 17310,\n",
       "         58398, 17145, 17091,  4504,  4771, 14122,  5143, 16489, 16330,\n",
       "         65003, 16005,  5833, 64513,  5885, 15747, 64496, 64452,  6011,\n",
       "          6173, 58531, 17746, 59485, 13968, 60879,  9091,  9098,  9166,\n",
       "         12384,  9244, 62388,  9595,  9603,  9614,  9843, 11504, 10169,\n",
       "         61210, 11349, 61275, 11284, 11172, 10306, 11074, 61310, 61320,\n",
       "         10972, 61761, 61613, 62640, 62695, 60755,  9002,  7520, 59692,\n",
       "          7551,  7736,  7887, 59912, 13724,  8016, 63576, 60133,  8174,\n",
       "         13320, 59531,  8187,  8199,  8303, 13225, 13063, 12976, 63363,\n",
       "          8473, 63294,  8708,  8732, 12786, 12665, 13302,  4086, 61562,\n",
       "         20455, 21287, 56792,   979, 19198,   899,  2872,  2884, 57037,\n",
       "          2832,  2962, 18902, 18871, 66474, 21525, 21534,   700, 66397,\n",
       "         66328, 56035, 21744,  2827, 19561, 55986, 20755, 55965,  2327,\n",
       "         57926, 66655, 21067, 20406,  2636, 20226, 66957, 20107,  1405,\n",
       "         21069, 19807, 21101, 19638,  1355,  2439, 18769,  2964, 67135,\n",
       "         22027, 21875,  3510,   103, 57332, 22194, 66004, 57331, 67166,\n",
       "         55178, 18706,  3627, 55212, 21835, 57320, 22346, 44688,   697,\n",
       "          1369, 35478, 49783, 63491, 63481,  8390,  8419, 37366,  8274,\n",
       "           173, 35406, 37721, 10744,  7964,    94, 10499, 37673, 35436,\n",
       "         44480,  8136,  8159, 37566, 37533, 66804,  1555, 63626, 37252,\n",
       "         44710, 48933, 49228,  8977, 44843, 62199, 35843, 44898, 44940,\n",
       "         62673,  9068, 49472, 45075,   735, 45778, 45043, 45703, 62088,\n",
       "         67128,  9974,  8963,  9322, 44713, 67008,  8529, 10275, 44757,\n",
       "         45637,   476,   518, 10141, 35668,  8802, 35678, 49126, 62849,\n",
       "         44831, 46078,  4010, 37864, 47628,  4980,  5122,  5123, 41110,\n",
       "         41108,  3460, 65088, 40754, 40726, 66313, 47859,  5618, 40658,\n",
       "         40628, 64731,  5788, 10820,  3266, 47582, 65094, 41469, 47432,\n",
       "         42028, 65926, 42036,  3925,  3896, 42192, 47117,  4098, 66178,\n",
       "         40180, 65840,  3652, 65501,  4292,  4325, 47257,  3589, 65278,\n",
       "          4735, 47361,  3670, 47930,  5848, 66493, 46313, 43863, 66568,\n",
       "          2462, 46236,  7360, 48555, 66677, 38053, 43797, 48569,  7425,\n",
       "          7435, 44134, 63723, 44145, 37968,  2158,  2127, 63708, 44118,\n",
       "          7864, 63947, 38668,  3037,  2999, 39759, 64184, 43188, 64182,\n",
       "         48139, 39482, 48171,  6844, 39219, 66554,  6667, 46391, 39079,\n",
       "         46360, 63958,  6843, 48363, 48436, 39215, 22579, 11716, 28731,\n",
       "         15810], dtype=int64),\n",
       "  'feature_absent_idx': array([59198, 57715, 45968, 28775, 45969, 28772, 13014, 28768, 13016,\n",
       "         28767, 13020, 28765, 45976, 57699, 13003, 13028, 28759, 45984,\n",
       "         45986, 28754, 57688, 13037, 45990, 13040, 57683, 45993, 45994,\n",
       "         28738, 13052, 13029, 57676, 13002, 57717, 45953, 28805, 28803,\n",
       "         12960, 57745, 57741, 12964, 12969, 12970, 12971, 12973, 57736,\n",
       "         57735, 28777, 57731, 28792, 28791, 12983, 28788, 57725, 12987,\n",
       "         12989, 57723, 28784, 28783, 28779, 28778, 57718, 57730, 28727,\n",
       "         57670, 57667, 28697, 13112, 46023, 57629, 46024, 57628, 28688,\n",
       "         57626, 46028, 28684, 46036, 57611, 57609, 28699, 28677, 28676,\n",
       "         57601, 57599, 57596, 13146, 46047, 13148, 13149, 57594, 13151,\n",
       "         57591, 13154, 28664, 57605, 13108, 57641, 13106, 57666, 13065,\n",
       "         57665, 46006, 28724, 46007, 57662, 46008, 57656, 46013, 13079,\n",
       "         28715, 13081, 28714, 28713, 13084, 57650, 46016, 46018, 13095,\n",
       "         13096, 28703, 13098, 28702, 13101, 28700, 13103, 57643, 57642,\n",
       "         57750, 46049, 12952, 57753, 28924, 45872, 12805, 12807, 57876,\n",
       "         45874, 12811, 12812, 12813, 45879, 57867, 57864, 12824, 28927,\n",
       "         57860, 28909, 12829, 28907, 57857, 57856, 28905, 12835, 28902,\n",
       "         28901, 28900, 28897, 28896, 28895, 12826, 28893, 28928, 28929,\n",
       "         45846, 28957, 45847, 57901, 12762, 12763, 57900, 57899, 45849,\n",
       "         28954, 12768, 12769, 12770, 12799, 12771, 45856, 12777, 57898,\n",
       "         12782, 28942, 28940, 45863, 57887, 45864, 57885, 45865, 28933,\n",
       "         28932, 12773, 57850, 57846, 28890, 12901, 28853, 28850, 45923,\n",
       "         45927, 28840, 12915, 57782, 28839, 45929, 45935, 57772, 57770,\n",
       "         12898, 28827, 45939, 28823, 57768, 57766, 45945, 28818, 28817,\n",
       "         57762, 45948, 12943, 28815, 12947, 12948, 12930, 28860, 12894,\n",
       "         12892, 12851, 12852, 12854, 28887, 57840, 12858, 45892, 12862,\n",
       "         57835, 12865, 28881, 28880, 57825, 57821, 45895, 45899, 45900,\n",
       "         45903, 12877, 12878, 57811, 12880, 45904, 57807, 57801, 28868,\n",
       "         28865, 57796, 57795, 12951, 57907, 13160, 57579, 13422, 13423,\n",
       "         13425, 13426, 28473, 46187, 13429, 57367, 13435, 57366, 57365,\n",
       "         57362, 13441, 28476, 57359, 13446, 13448, 46199, 57352, 13454,\n",
       "         57350, 28452, 57344, 28450, 57341, 28448, 28447, 13463, 46198,\n",
       "         57339, 46184, 46183, 57422, 28501, 57420, 28500, 57415, 57413,\n",
       "         28498, 57405, 57403, 57401, 57399, 28494, 57395, 28478, 28493,\n",
       "         46172, 57392, 13405, 57391, 57389, 28487, 46180, 13410, 57386,\n",
       "         28482, 13415, 46182, 57381, 13399, 13466, 13467, 28445, 57299,\n",
       "         13524, 57297, 13532, 28398, 28397, 13536, 57283, 46258, 13541,\n",
       "         28388, 57271, 28383, 13520, 28382, 57265, 13551, 28378, 13557,\n",
       "         46268, 28374, 46271, 57261, 28371, 28370, 13564, 13565, 13566,\n",
       "         57266, 13519, 28407, 57301, 46209, 57336, 57334, 28441, 13476,\n",
       "         28439, 57329, 28436, 46214, 13485, 57325, 28429, 46228, 13494,\n",
       "         13495, 46237, 13498, 28421, 46239, 28416, 46241, 13507, 57306,\n",
       "         13511, 57305, 13513, 28410, 28408, 57303, 57423, 13161, 46168,\n",
       "         28504, 13221, 28612, 46100, 57544, 28605, 13233, 28602, 46110,\n",
       "         28595, 46117, 28592, 13243, 28589, 13219, 13247, 46120, 57526,\n",
       "         57525, 57524, 13255, 28583, 13259, 57518, 57516, 57513, 28580,\n",
       "         46124, 57511, 13249, 13269, 57550, 13214, 13167, 57578, 46063,\n",
       "         13173, 28649, 46066, 13176, 46067, 28642, 46071, 57571, 13183,\n",
       "         57570, 13217, 46075, 57567, 57566, 13190, 13193, 28634, 28630,\n",
       "         46088, 13201, 46089, 28624, 28622, 28621, 13209, 57568, 13271,\n",
       "         13273, 13274, 13338, 28530, 28529, 57450, 13344, 13345, 13347,\n",
       "         28525, 57447, 28521, 28520, 57442, 28519, 28534, 57441, 46158,\n",
       "         46159, 13362, 13364, 13365, 46162, 57433, 46163, 57430, 57429,\n",
       "         46164, 57428, 57427, 57437, 13333, 46146, 28536, 57502, 13280,\n",
       "         57501, 57493, 46128, 46129, 13288, 46130, 13290, 13292, 13293,\n",
       "         13295, 28562, 28558, 46135, 13301, 28552, 13307, 13311, 57480,\n",
       "         28548, 46138, 13317, 28544, 13322, 57468, 13328, 13329, 28537,\n",
       "         57425, 57257, 57908, 57911, 29389, 12178, 58340, 29388, 58337,\n",
       "         29387, 12184, 12186, 58333, 29383, 29382, 29380, 29377, 45583,\n",
       "         45592, 29372, 12202, 45594, 29368, 12205, 12207, 45598, 45599,\n",
       "         58318, 12212, 58316, 45600, 12215, 12198, 58311, 29392, 45576,\n",
       "         29432, 29430, 58373, 45565, 12132, 45567, 12134, 29424, 29423,\n",
       "         29422, 58367, 12142, 12143, 29393, 29414, 29413, 58363, 58361,\n",
       "         45573, 29410, 58360, 58358, 29408, 12158, 58357, 29406, 58354,\n",
       "         58349, 58364, 58310, 12218, 58305, 58283, 12267, 45618, 58277,\n",
       "         58274, 45619, 29329, 29326, 58267, 12279, 12283, 29320, 29317,\n",
       "         45616, 45626, 12293, 12294, 12297, 45628, 29308, 58254, 29306,\n",
       "         29305, 29304, 29303, 58246, 12308, 12313, 12292, 29334, 58285,\n",
       "         29335, 29357, 12224, 58301, 45603, 29353, 12230, 29352, 58297,\n",
       "         12234, 58294, 12236, 29350, 29349, 12239, 12240, 29346, 29345,\n",
       "         12243, 45609, 58292, 12247, 12251, 12252, 12253, 12254, 45611,\n",
       "         12258, 45615, 58286, 58380, 58243, 29433, 29436, 29552, 11968,\n",
       "         45477, 58513, 29549, 29548, 29547, 29544, 11975, 11976, 29543,\n",
       "         58506, 45488, 45473, 11984, 58502, 11987, 45489, 58496, 29532,\n",
       "         11994, 11995, 29529, 58491, 29526, 58489, 58488, 29525, 11985,\n",
       "         29522, 29558, 58519, 29602, 29601, 29597, 11914, 45446, 58559,\n",
       "         58553, 11922, 11923, 58548, 45457, 45458, 11931, 11959, 29580,\n",
       "         45462, 58538, 11939, 11940, 58537, 58536, 29574, 29572, 58526,\n",
       "         29569, 45467, 11952, 45469, 45460, 29521, 45500, 29516, 45520,\n",
       "         58434, 58429, 58428, 12075, 29470, 12079, 29465, 58416, 58415,\n",
       "         12087, 58413, 58411, 58438, 29462, 45535, 29453, 45542, 12104,\n",
       "         45544, 12106, 29444, 12108, 12109, 58389, 58388, 45553, 58385,\n",
       "         29461, 12064, 58439, 12062, 12013, 12014, 12015, 12017, 29508,\n",
       "         58476, 12022, 29504, 12029, 45504, 58465, 12033, 29495, 45509,\n",
       "         58460, 29490, 45511, 12045, 12046, 12047, 58450, 29483, 58444,\n",
       "         12056, 29482, 58443, 12059, 29481, 58442, 45557, 45843, 12315,\n",
       "         12318, 12586, 58030, 58029, 29086, 12592, 12595, 12596, 12597,\n",
       "         12598, 58021, 45769, 29071, 58017, 58032, 45779, 58006, 58000,\n",
       "         57998, 45786, 12633, 12634, 29042, 29041, 29040, 29039, 57991,\n",
       "         57990, 57988, 29058, 12644, 12583, 45761, 58060, 29119, 29115,\n",
       "         29114, 12544, 58057, 12546, 29111, 12550, 58052, 29110, 29107,\n",
       "         58049, 12581, 12557, 45747, 12562, 58046, 29098, 29097, 12568,\n",
       "         45758, 29094, 12574, 58039, 58037, 58036, 58034, 29105, 29035,\n",
       "         29033, 29032, 45823, 12707, 45824, 45826, 12710, 12711, 12714,\n",
       "         28986, 57940, 12717, 57938, 12721, 28983, 28993, 12723, 28982,\n",
       "         28981, 45828, 57933, 57929, 28976, 57927, 57924, 12739, 12742,\n",
       "         57922, 57919, 28964, 57937, 28994, 57953, 12696, 57978, 12653,\n",
       "         29029, 57977, 57975, 57974, 57973, 57972, 29028, 12661, 57971,\n",
       "         12663, 12664, 45800, 12667, 45803, 57968, 29020, 45807, 12675,\n",
       "         12676, 45809, 29012, 29008, 29007, 57960, 29004, 12693, 57955,\n",
       "         45743, 58242, 12534, 45740, 58197, 58195, 45664, 45671, 12390,\n",
       "         12391, 29239, 58191, 45672, 45674, 29229, 12404, 58179, 29249,\n",
       "         58178, 12411, 12412, 45683, 29219, 12418, 58163, 29214, 29213,\n",
       "         58158, 12428, 45695, 58152, 12431, 29226, 58151, 29252, 58200,\n",
       "         58240, 58239, 58237, 58236, 45634, 45635, 29287, 45638, 29284,\n",
       "         45639, 12338, 58221, 12344, 12374, 45643, 58215, 58208, 12356,\n",
       "         58207, 45652, 12362, 12363, 12365, 58203, 12367, 12368, 29254,\n",
       "         12372, 12346, 45696, 29205, 29200, 12491, 45717, 12494, 12495,\n",
       "         45722, 58092, 58090, 45725, 29152, 45726, 12506, 29149, 29147,\n",
       "         12490, 29146, 12512, 45731, 29140, 29139, 45732, 58072, 29135,\n",
       "         29133, 29131, 45736, 12527, 29127, 12530, 12510, 29161, 45716,\n",
       "         12484], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_path': {'feature_present_idx': array([37800, 50562, 33176,  3269, 29994, 56376, 17503, 19240, 28068,\n",
       "         42607, 42185, 21975, 40725, 11169, 11937, 66963, 36941, 13099,\n",
       "         13188, 43003, 23334, 31413, 30238, 27380, 15244, 46565, 21542,\n",
       "         58943, 59772, 54230,  2868, 50196, 53141,  7152,  7559,  7729,\n",
       "           499, 59251, 66508, 23419, 24677, 22738, 25507, 64684, 26083,\n",
       "         26762, 64425, 60046, 29928, 47192, 47057, 57175, 53706, 34464,\n",
       "         36739, 53682, 37059, 52891, 40191, 49777, 41021, 47534, 31215,\n",
       "         41585, 67146,  4379, 10461, 10172,  4774,  8742, 13913, 17851,\n",
       "         21442, 53905, 53608, 49382, 48646, 47252, 53926, 45792, 43188,\n",
       "          9546, 12041, 36312, 48245,  4617, 54381, 56148, 66935, 66348,\n",
       "         65606, 65599, 63895, 63205, 61501, 36171, 61103,  1439, 59513,\n",
       "          2021, 58913, 57888, 57636, 56192, 60426, 13042, 47235,   330,\n",
       "         32171, 14836, 27785, 19141, 19568, 33089, 22192, 17382, 21551,\n",
       "         20381, 21432, 31099,  7420, 14170,  6754, 49995,  6303, 52246,\n",
       "         52491, 66558,  5060,  1082,  4681, 62501, 54325, 54649,  4511,\n",
       "         26284,  7752, 58602, 58710, 59631, 60123, 66232, 23012, 65717,\n",
       "         61526,  1198,  8620, 34499, 52295, 42379, 10094, 43070, 43078,\n",
       "         41310, 32748, 32836, 40489, 43131, 13960, 12794, 35561, 38723,\n",
       "         39498, 66891, 54055, 42040, 27004, 54450, 66850, 41557, 56647,\n",
       "         21926, 57847, 57982, 53954, 22393, 37637,  3377, 59361, 24329,\n",
       "         40221, 57834, 15447, 16497, 48611,  6666, 49915, 44150, 50770,\n",
       "         51219, 51230, 14297,  9955, 31773,  5863, 46219, 15009, 52566,\n",
       "         17889, 59775, 11413, 12732, 49225,  1288, 12679,  1393, 46893,\n",
       "         58392, 26484, 45439, 21177, 32494, 27063, 25572, 50373, 36963,\n",
       "         44827, 65944, 33119, 13314, 30250, 18171, 62919, 39937, 51932,\n",
       "         34049, 53472, 62974, 44718, 49273, 51745, 36485, 26922, 46506,\n",
       "         53876,  8682, 42649, 35310], dtype=int64),\n",
       "  'feature_absent_idx': array([61527, 18850, 46016, 18847, 46018, 18841, 63427, 46023, 46024,\n",
       "         46028, 18832, 18830, 18826, 63432, 46036, 18808, 46013, 63436,\n",
       "         18855, 18860, 45986, 18898, 45990, 18894, 45993, 45994, 18889,\n",
       "         18887, 57762, 18880, 46006, 46007, 46008, 18867, 18864, 18856,\n",
       "         18796, 18794, 18791, 18727, 63450, 63452, 18718, 18715, 18714,\n",
       "         18712, 18707, 46088, 46089, 18700, 57745, 18694, 18691, 46100,\n",
       "         63449, 46075, 18732, 18733, 46047, 46049, 63438, 18783, 18778,\n",
       "         18773, 18765, 45984, 57753, 46063, 46066, 46067, 18750, 63445,\n",
       "         46071, 57750, 18761, 63460, 18911, 18919, 19074, 45903, 45904,\n",
       "         63383, 57782, 63385, 19052, 19051, 19045, 19040, 19038, 19036,\n",
       "         19031, 45923, 19021, 45900, 45927, 63381, 19079, 19124, 19123,\n",
       "         19119, 63375, 45892, 19103, 63378, 45895, 19088, 19087, 19086,\n",
       "         19085, 19084, 19083, 19080, 45899, 45929, 45935, 63393, 18954,\n",
       "         18953, 18952, 18951, 18948, 18947, 18946, 63405, 18942, 45968,\n",
       "         18938, 45969, 63409, 63410, 45976, 57766, 18960, 57768, 45953,\n",
       "         57772, 19001, 45939, 63397, 18998, 63398, 18993, 18912, 18992,\n",
       "         45945, 57770, 45948, 18980, 18979, 18977, 18973, 18989, 19127,\n",
       "         18678, 46110, 18392, 18391, 18389, 46268, 18383, 46271, 63523,\n",
       "         18376, 46274, 18371, 18370, 18369, 18361, 46284, 18355, 46258,\n",
       "         63528, 18400, 18412, 18469, 57718, 57717, 46228, 57715, 18451,\n",
       "         46237, 46239, 63513, 63514, 46241, 18426, 18423, 18422, 18420,\n",
       "         18402, 46287, 18344, 18343, 46334, 18267, 46341, 46342, 46343,\n",
       "         46344, 63545, 18255, 18254, 18253, 18247, 46349, 18239, 18237,\n",
       "         18236, 18283, 63540, 18294, 46317, 18337, 18336, 18334, 46294,\n",
       "         18332, 18330, 46299, 46214, 18324, 46304, 46305, 18304, 46312,\n",
       "         57699, 46314, 46316, 18315, 57741, 63506, 46209, 46135, 18624,\n",
       "         18623, 18622, 46138, 18619], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 238\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 238\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 238\n",
       "    })}}},\n",
       " 'contains_polarity': {'feature_present_idx': array([46026, 38879, 36414, 17654, 23330, 37429, 57545, 48121, 19694,\n",
       "         57541,  2293, 14632, 66406, 36679, 35610, 53580, 24654,  2459,\n",
       "         48275, 46626, 19377, 34987, 49591, 51795, 53289, 53470, 54056,\n",
       "         16513, 49328, 17555, 25197, 45456, 36655, 36161, 35649, 34937,\n",
       "         34514, 33619, 36970, 37552, 23278, 31827, 38631, 39392, 39630,\n",
       "         39955, 40116, 40179, 26559, 54417, 38459, 16437, 36648, 64338,\n",
       "          8428,  2933,  7380,  2600,  6069,  2685,  1004, 10297, 60865,\n",
       "          8777,   922, 11872, 58691, 55445,  3360, 13634, 56069, 57672,\n",
       "         64994, 66745, 14544, 30186, 43941, 32231,  1979, 41783, 37699,\n",
       "          3165,  5555,  2855, 66371, 31518, 38023, 33442, 36929,  3791,\n",
       "         24869, 44326, 16314, 15689, 17281,   916, 17844, 52727, 57823,\n",
       "         18819, 12393, 48783, 24694, 61041, 20980,  1027, 22008, 22089,\n",
       "         22388, 23081, 36890, 45848,  9037, 45297, 61174, 32881, 55988,\n",
       "         64386, 39724, 40075, 64345, 40898, 41905, 64058, 45905, 62732,\n",
       "         60061, 57729, 56378, 65652, 52049,   157, 27244, 29154, 16326,\n",
       "         28490, 19411,  6030, 17773, 18476, 29187, 24666, 23474, 36508,\n",
       "         21348, 20969, 19328, 20515, 20039, 24382, 29772,  9262,  9426,\n",
       "         10918, 33603, 33481, 32055, 11246, 57155, 49394, 62689, 61786,\n",
       "          9368, 50080,  3788, 51864, 60783, 18657, 52459, 59549, 64589,\n",
       "         16972, 53844,  5554, 59404, 16348, 12352, 13094, 13905, 57456,\n",
       "         57364, 15696, 19152,  9175, 32788, 65185, 39446, 28734, 38371,\n",
       "         37986, 42101, 43557, 43652, 43824, 30237, 37028, 44824, 34073,\n",
       "         45723, 66863, 35521, 36296, 36459,  3657, 14631, 61085, 58402,\n",
       "         57872, 57720, 66564, 48561, 29990, 17110, 47421, 49850, 46668,\n",
       "         20779, 44779, 30146, 25473, 49298, 64358, 26320,  2917, 56445,\n",
       "          9141, 52031, 23425, 12864,   169, 15448, 31245, 14222, 36644,\n",
       "         54238, 16541, 53349, 51146, 19330, 38408, 60695, 30862, 67055,\n",
       "         16502, 25048, 26565,  1533], dtype=int64),\n",
       "  'feature_absent_idx': array([29788, 12717, 12721, 28310, 12723, 28304, 45609, 57579, 57578,\n",
       "         28299, 45611, 12739, 45615, 45616, 57591, 12742, 57570, 57568,\n",
       "         57567, 57566, 45618, 45619, 45626, 12762, 12763, 45628, 28274,\n",
       "         12768, 12769, 57571, 12770, 57594, 45603, 45576, 12675, 12676,\n",
       "         57629, 57628, 28341, 45583, 57626, 28337, 28333, 28331, 57611,\n",
       "         57609, 12714, 45592, 45594, 12696, 57605, 45598, 45599, 45600,\n",
       "         57601, 57599, 12707, 57596, 12710, 12711, 28316, 12693, 12771,\n",
       "         12773, 28267, 12826, 12829, 45664, 57502, 57501, 12835, 28225,\n",
       "         28224, 57493, 28218, 45671, 45672, 28213, 28232, 12851, 45674,\n",
       "         12854, 28209, 28208, 28207, 12858, 57480, 28205, 12862, 12865,\n",
       "         57468, 45683, 12877, 12852, 12824, 28233, 57511, 12777, 57550,\n",
       "         28265, 28264, 12782, 57544, 45634, 45635, 45638, 45639, 45643,\n",
       "         28248, 12799, 57526, 57525, 57524, 28247, 12805, 12807, 28241,\n",
       "         12811, 12812, 12813, 57518, 57516, 28240, 45652, 57513, 28238,\n",
       "         45573, 12878, 28350, 12664, 12506, 28473, 45488, 45489, 12510,\n",
       "         12512, 57753, 57750, 57745, 45500, 57741, 12527, 28452, 57762,\n",
       "         12530, 57735, 12534, 28450, 45504, 57731, 28448, 28447, 28445,\n",
       "         57730, 12544, 12546, 28441, 57725, 57736, 45509, 28476, 57768,\n",
       "         12460, 45458, 57796, 57795, 45460, 45462, 12468, 28504, 45467,\n",
       "         28501, 28500, 28498, 57782, 57766, 28494, 12484, 45469, 28487,\n",
       "         45473, 12490, 12491, 45477, 28482, 12494, 12495, 57772, 57770,\n",
       "         28478, 28493, 12550, 57723, 28439, 57676, 28383, 28382, 57670,\n",
       "         57667, 57666, 57665, 28378, 45553, 45557, 12633, 12634, 28374,\n",
       "         28388, 28371, 28370, 57656, 12644, 45565, 57650, 45567, 28361,\n",
       "         12653, 57643, 57642, 57641, 12661, 12663, 57662, 45544, 45542,\n",
       "         28397, 28436, 45511, 12557, 12562, 57718, 57717, 57715, 28429,\n",
       "         12568, 12574, 45520, 28421, 28416, 12581, 57699, 12583, 12586,\n",
       "         57688, 28410, 12592, 28408], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 247\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 247\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 247\n",
       "    })}}},\n",
       " 'contains_polite': {'feature_present_idx': array([62414,  2806, 44269, 59069, 35535, 49762, 52887, 57711, 66405,\n",
       "         66599], dtype=int64),\n",
       "  'feature_absent_idx': array([18992, 57567, 57566, 28225, 28224, 45542, 28218, 12693, 45544,\n",
       "         12696], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 10\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 10\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 10\n",
       "    })}}},\n",
       " 'contains_poss': {'feature_present_idx': array([67343, 10631, 10675, 10714, 10840, 10888, 49179, 49144, 49109,\n",
       "         10961, 48988, 50102, 11091, 48805, 11280, 48670, 11449, 48556,\n",
       "         48553, 48409, 48347, 11654, 48228, 48839, 11692, 50210, 50305,\n",
       "          9134, 52112, 52045,  9269,  9334,  9373,  9477, 51825, 51699,\n",
       "          9581, 50302,  9645, 51105, 51037,  9871, 50945, 50886, 10013,\n",
       "         50716, 10066, 50569, 10186, 51309,  9130, 48149, 11878, 13354,\n",
       "         45630, 45550, 45208, 45087, 45066, 13667, 45034, 13746, 13766,\n",
       "         13343, 44783, 13895, 44638, 13980, 44555, 13998, 14003, 44444,\n",
       "         44190, 14119, 14184, 44776, 48101, 45773, 45898, 11880, 11890,\n",
       "         47946, 12012, 47822, 47722, 12177, 47591, 12231, 47379, 45878,\n",
       "         47339, 12514, 12613, 46719, 46579, 46543, 46491, 46479, 13005,\n",
       "         13030, 46010, 47280, 44089,  9060, 52286, 58493, 58218,  5234,\n",
       "          5259, 58128,  5333,  5394,  5454, 57993, 57894, 58574, 57879,\n",
       "         57616, 57582, 57470,  5723, 57075, 56818, 56796, 56794,  6212,\n",
       "         56638, 57695,  6315, 58591, 58879, 60938, 60757,  3905, 60609,\n",
       "         60467, 60406, 60375, 60233, 60193, 60114,  4900, 59886, 59758,\n",
       "         59740,  4536, 59445, 59252, 59166,  4702,  4725,  4762, 59076,\n",
       "         59765, 52217,  6352,  6406,  7971,  8065, 53531,  8153,  8179,\n",
       "         53521, 53259, 53222, 53191, 53107, 53906, 53075,  8548,  8618,\n",
       "          8657, 52828, 52706, 52642,  8805, 52397, 52393, 52379, 53010,\n",
       "         56303, 53909, 53971, 56209, 56116, 56051, 55791,  6862, 55558,\n",
       "         55515, 55246, 55048, 54949,  7882, 54917, 54872,  7313,  7614,\n",
       "          7671, 54300,  7727,  7734, 54040,  7830,  7869, 54904, 44087,\n",
       "         14309, 43642, 32258, 32246, 32157, 32147, 32085, 21313, 32045,\n",
       "         31953, 31850, 21444, 32289, 31818, 21494, 31597, 21612, 31249,\n",
       "         21888, 31196, 21999, 30911, 30882, 30854, 31791, 30638, 20992,\n",
       "         32595, 19858, 34017, 19971, 33992, 33894, 33812, 33750, 20230,\n",
       "         20238, 20289, 32479, 33586, 33406, 20398, 33349, 33175, 20648,\n",
       "         20697, 33110, 20769, 33015, 32817, 33564, 19828, 30631, 22280,\n",
       "         27760, 24242, 24276, 27378, 27338, 27267, 27167, 24629, 27003,\n",
       "         26921, 27874, 24732, 24819, 24999, 26352, 25198, 25211, 26071,\n",
       "         25266, 25999, 25878, 25844, 26866, 30588, 23846, 23531, 30544,\n",
       "         30476, 30357, 22498, 22581, 30198, 30150, 22762, 29819, 22891,\n",
       "         28211, 22915, 22944, 29623, 23055, 29292, 29271, 29201, 23375,\n",
       "         29144, 29088, 28882, 29718, 34351, 34403, 19712, 15607, 41539,\n",
       "         41502, 15855, 41470, 41404, 41386, 15961, 41280, 16150, 41863,\n",
       "         16171, 16235, 40901, 40625, 16491, 40479, 40243, 40010, 39989,\n",
       "         39867, 39784, 41103, 39751, 42266, 15388, 14471, 43553, 43490,\n",
       "         14576, 14641, 14671, 14840, 43091, 14886, 42981, 15394, 14976,\n",
       "         15111, 42648, 42589, 15199, 42436, 15317, 15319, 15321, 15322,\n",
       "         42402, 15033, 16980, 39561, 39404, 18421, 18659, 18702, 36378,\n",
       "         36375, 18722, 36203, 18907, 18924, 18925, 36869, 35707, 35554,\n",
       "         35410, 35397, 35360, 35270, 19360, 34814, 34787, 34736, 34734,\n",
       "         35578, 18316, 37032, 37037, 39386, 39314, 39217, 39165, 38950,\n",
       "         38909, 17366, 17398, 38328, 38313, 38200, 17660, 37966, 17744,\n",
       "         17761, 37876, 17878, 37623, 37594, 37492, 18057, 18205, 37094,\n",
       "          3727,  3726, 25484, 65822,  2543, 64627, 61845, 65092, 63283,\n",
       "          2087,  2684, 62203, 66349, 63938, 64987, 64413,  3274,   434,\n",
       "         62374, 65627, 66345,  2330,  1798, 66482,  3126, 66657, 64109,\n",
       "          2513, 67267, 62724,  2250,   315, 61186, 65688, 62210,  3428,\n",
       "          3549, 62956, 65347, 62207, 63308, 64875, 62741, 67051, 67219,\n",
       "         66189, 64873,  2110,  3572, 66794, 66872, 66470, 63966, 62060,\n",
       "           567,  1740, 63847,   261, 65573,  1608, 64817, 63229, 63910,\n",
       "         62635,  2921, 65642,  3251, 66643,  2815, 65435,  1091,  1983,\n",
       "         66713,  2914, 64273, 61589, 63925, 13632,  1948, 13669,  1940,\n",
       "         32044, 44944, 45057, 45040, 13706, 45038, 13715, 44979, 45029,\n",
       "         63942, 13764, 44873,  1929, 66567, 45119, 31813, 45728, 45742,\n",
       "         45746, 13356, 45753, 63893, 21488, 45724, 13299, 45813, 45854,\n",
       "         13276, 63855, 21504, 13218, 31715, 45920, 31781, 13624, 31814,\n",
       "         45574, 31924, 13590, 31900, 13567, 31871, 45284, 31861, 66550,\n",
       "         45622, 13534,   609, 45441, 45447, 45491, 21454, 45543,  1963,\n",
       "         45570, 31833, 44862, 46407, 32122, 43480, 64257, 14568, 20921,\n",
       "         32651, 14526, 32625, 32605, 43460, 66215, 43637, 64222, 43680,\n",
       "         43717, 43760, 32414, 43817, 43832, 32488, 43943, 43403, 32678,\n",
       "         14867, 64312, 33055,  1770, 43178, 32999, 43199, 43209, 14594,\n",
       "         43219, 43250, 32948, 32897, 43303, 32858, 32828,  3663, 43346,\n",
       "         14749, 32064, 43969, 14328,  1873, 66416, 64103, 64047, 44592,\n",
       "         13967, 21169, 13197, 44522, 13935, 21176, 44678, 32191, 44738,\n",
       "         13866, 32159, 64011, 13834, 21170, 14332, 44506, 44471, 21038,\n",
       "         32298, 44019, 14213, 14195, 32272, 32266, 44121, 44485, 44126,\n",
       "         21118,  1863, 21119, 44218, 44264, 44265, 44413, 44423, 44146,\n",
       "          1905, 12958, 13166, 63349, 30773, 30741, 48250, 48272, 11622,\n",
       "         22241, 48335, 48343, 48355, 30610, 30605, 11528, 11527, 11516,\n",
       "         30568, 35941, 11490, 63276, 22122, 63275, 48122, 48089, 12049,\n",
       "         21975, 63456,   544, 47837, 47838, 47853, 47857, 47877, 47880,\n",
       "         11935, 22001, 30950,   538,  2190, 63376, 30848, 30842, 48088,\n",
       "         63353, 47779, 48568, 48571, 48889, 11097,  2339, 48902, 48909,\n",
       "         30433, 48993, 11056, 22405, 30393, 30374, 63248, 49101,  2367,\n",
       "         10920, 22478, 49155, 30333,  2375, 22389, 11389, 22387,  2338,\n",
       "         30555,  2313, 48683, 48705, 30530, 30529, 48721, 48742, 30507,\n",
       "         11278, 30500, 30495, 48791,  2337, 11238, 11187, 30468, 22366,\n",
       "         22370, 30448, 45928, 47747, 31014, 63744, 12847, 46519, 12820,\n",
       "         21664, 46570, 46690, 31508, 46736, 46782, 12760, 12753, 12733,\n",
       "         46836, 46845, 46847, 12678, 31482, 21701,  2071, 46870, 46444,\n",
       "         31543, 45995, 63805, 31666, 31633, 46116, 46121, 46169, 46193,\n",
       "           577, 63791, 46261, 46289, 46320, 43075, 46348, 46351, 31570,\n",
       "         46385, 12909, 21628, 21963, 46880, 21723, 63640, 47301, 63578,\n",
       "         47365, 47371, 47382, 12278, 47478, 31193, 31171, 47588,  2137,\n",
       "         12191, 47601, 12164, 12151, 47647, 47668, 47713, 47270, 46914,\n",
       "         31231,   568, 46933, 31457, 31440, 21772, 47003, 47022, 47041,\n",
       "         63645, 21813, 31420, 31368, 47123, 12464, 12444, 31256, 47224,\n",
       "         12424, 47236, 12399, 47247,  1753, 14994, 43003, 17612, 38062,\n",
       "         38087, 38128, 19409, 38143, 34944, 65009, 38262, 38276, 17553,\n",
       "         38299, 19444, 64998, 38320, 17517, 38360, 38387, 17480, 35007,\n",
       "         17630, 35012, 38009, 35134, 37733, 19323, 35089, 37771, 35037,\n",
       "         17845, 35035, 37852, 38407, 37872, 17755, 19365, 65033, 17713,\n",
       "         19373, 17687, 65027, 65020, 37985, 35030, 37605, 38426, 38477,\n",
       "         17135, 39214, 64945, 39279, 17096, 39357, 34676,  1367, 34616,\n",
       "         39558, 17009, 16988,  1386, 19673, 16968, 34615, 39610, 39617,\n",
       "         39643, 19643, 39210, 34708,  1344, 34910, 34897,  1326, 19542,\n",
       "         17359, 38778,   946, 19594, 38907, 38461, 34771, 38941, 17259,\n",
       "          1342, 38970, 38971, 65680, 17205, 39045, 17170, 17283, 34559,\n",
       "         37603, 18001, 35760, 65479, 35736, 65620, 18968, 18996, 18663,\n",
       "         18997, 36519, 35652, 36530, 35596,   988, 18595, 36577, 36578,\n",
       "         18562, 35543, 35529, 35764, 18748, 36329, 36323, 18908, 65537,\n",
       "         36009, 18901, 36015, 18873, 35857, 36045, 36106, 19022, 36117,\n",
       "         36194, 35834, 36207, 18828, 36226, 35780, 36264, 36300, 36320,\n",
       "         65577, 37595, 36646, 36700, 35323, 18221, 37219, 37233, 37277,\n",
       "         37300, 19191, 35248, 37412, 37419, 18100, 18097, 18089, 35194,\n",
       "         65154, 18052, 65152, 37519, 65120, 19148, 35332, 35334, 18234,\n",
       "         36719, 19042, 36786, 36831, 65363, 18414, 18387, 36897, 36908,\n",
       "         65628], dtype=int64),\n",
       "  'feature_absent_idx': array([33693, 53657, 53660, 21100, 53662, 53664, 21086, 21085, 21084,\n",
       "         21083, 21071, 53679, 21068, 53684, 21066, 21064, 53652, 53687,\n",
       "         21116, 21123, 21149, 21148, 53638, 21146, 53639, 53641, 21137,\n",
       "         21135, 21134, 53643, 53645, 21129, 21128, 21125, 21124, 21122,\n",
       "         21060, 53688, 53694, 20985, 20984, 20983, 20981, 53743, 20979,\n",
       "         20977, 20972, 53754, 20965, 20959, 53771, 53772, 20948, 20947,\n",
       "         53741, 20988, 20990, 53735, 53700, 53703, 53705, 21036, 53708,\n",
       "         21030, 53712, 53636, 21026, 21019, 21016, 53718, 53719, 21011,\n",
       "         53726, 53730, 21020, 20945, 53627, 21164, 21322, 21321, 21319,\n",
       "         21305, 53547, 53552, 53556, 53560, 53561, 21275, 53562, 21271,\n",
       "         53565, 21269, 53566, 21323, 21266, 21324, 21330, 53502, 53508,\n",
       "         53511, 21353, 21349, 53513, 53515, 21345, 53516, 21343, 21342,\n",
       "         21340, 53523, 53526, 21333, 53529, 21264, 53568, 53570, 53600,\n",
       "         53601, 21209, 53602, 53606, 21202, 21200, 53613, 21188, 53617,\n",
       "         53619, 21178, 21175, 21171, 21165, 21215, 53597, 53595, 21218,\n",
       "         53571, 21251, 21244, 53582, 21242, 53584, 21235, 53626, 21234,\n",
       "         21231, 21228, 21227, 53591, 53592, 21221, 21220, 53590, 21365,\n",
       "         20939, 53780, 53956, 20650, 53959, 20646, 53962, 20641, 20639,\n",
       "         53964, 20635, 53966, 53967, 53969, 53970, 20622, 20620, 53953,\n",
       "         53975, 53952, 20663, 53927, 20707, 53929, 20701, 53933, 20694,\n",
       "         20685, 53939, 53941, 53942, 53943, 53945, 53946, 53950, 20664,\n",
       "         20659, 53987, 53988, 53990, 54024, 20533, 20530, 20525, 54031,\n",
       "         54032, 20520, 20519, 20518, 54037, 54041, 20508, 54043, 54045,\n",
       "         20501, 20538, 20540, 20551, 20552, 20608, 20606, 53993, 20601,\n",
       "         53994, 20599, 20597, 20712, 20584, 20577, 54010, 20575, 54013,\n",
       "         54015, 20559, 54016, 54009, 53777, 20720, 20729, 53811, 20891,\n",
       "         20888, 53814, 53816, 20879, 53820, 20874, 20871, 53829, 53831,\n",
       "         53832, 53837, 53839, 20851, 53810, 20845, 53809, 53800, 20933,\n",
       "         53783, 53786, 20929, 20927, 20926, 20922, 53788, 53792, 20916,\n",
       "         20914, 53795, 20911, 20909, 20907, 53808, 20840, 20839, 53850,\n",
       "         53893, 20776, 53896, 20773, 20768, 20767, 53900, 53902, 53910,\n",
       "         20746, 20744, 20743, 20739, 20731, 53913, 53892, 53891, 53890,\n",
       "         53886, 53851, 53853, 53854, 20831, 20829, 53857, 20819, 53916,\n",
       "         53868, 20803, 20795, 20792, 53880, 20787, 20785, 53885, 20812,\n",
       "         54048, 21367, 21372, 22031, 22025, 53055, 22022, 22018, 22006,\n",
       "         21998, 53074, 21992, 53087, 21988, 21987, 21976, 53092, 21967,\n",
       "         22035, 21964, 53049, 53047, 53019, 53020, 22074, 53027, 53028,\n",
       "         53030, 53033, 22061, 22060, 53036, 53039, 53040, 22051, 53042,\n",
       "         22043, 22037, 21960, 21959, 53100, 53148, 21880, 21879, 21878,\n",
       "         53149, 21874, 21866, 21863, 53175, 21848, 53176, 21846, 53178,\n",
       "         53181, 53182, 53147, 53145, 53143, 21894, 21954, 53103, 53106,\n",
       "         21944, 53119, 21929, 21928, 22082, 53121, 53124, 53128, 53132,\n",
       "         21906, 53137, 53142, 21897, 21922, 53190, 22084, 22088, 22228,\n",
       "         52933, 22217, 22215, 52938, 52939, 22210, 22207, 52942, 52946,\n",
       "         52947, 22201, 22195, 52958, 52961, 22231, 22188, 22232, 22234,\n",
       "         22289, 52898, 52905, 22272, 52906, 52909, 22264, 22259, 52914,\n",
       "         22255, 22250, 52919, 22245, 22243, 22237, 22233, 52963, 22184,\n",
       "         52965, 22132, 52997, 22125, 22124, 22123, 22121, 22118, 22117,\n",
       "         22116, 22113, 53008, 22101, 53012, 22097, 53013, 52996, 22139,\n",
       "         52991, 22143, 22178, 52966, 22174, 22171, 22168, 52975, 52977,\n",
       "         22087, 22160, 22156, 52979, 52982, 22153, 22150, 52990, 22145,\n",
       "         22158, 21370, 21834, 21829, 21526, 53411, 21524, 21522, 21518,\n",
       "         53414, 53415, 21514, 53417, 53418, 21507, 21505, 21503, 21496,\n",
       "         21491, 21528, 21490, 53401, 53393, 53356, 53358, 53359, 53360,\n",
       "         21584, 53365, 21579, 21578, 21571, 21564, 21561, 53382, 53383,\n",
       "         53389, 53391, 21543, 53426, 21479, 21478, 21418, 21415, 53469,\n",
       "         21411, 21410, 21405, 21403, 53480, 21400, 53484, 21392, 21389,\n",
       "         53489, 21381, 53492, 21421, 21424, 53464, 53462, 53429, 21473,\n",
       "         53438, 53443, 21459, 21458, 21456, 21593, 21455, 53453, 21448,\n",
       "         21441, 53455, 53456, 53457, 21430, 21451, 21832, 21603, 21610,\n",
       "         53229, 53230, 53231, 21773, 21767, 53234, 21757, 53244, 53249,\n",
       "         21747, 21741, 53258, 53260, 53261, 21726, 21780, 21724, 21781,\n",
       "         21784, 53198, 21826, 21821, 21816, 21808, 21807, 53212, 21804,\n",
       "         21801, 21798, 53218, 21796, 53224, 21787, 53227, 21783, 53265,\n",
       "         53266, 21720, 53320, 21654, 53323, 21648, 53326, 53328, 21641,\n",
       "         21640, 53331, 21636, 21632, 21631, 21626, 21623, 53341, 21656,\n",
       "         53317, 53316, 53312, 21718, 21710, 53279, 21702, 21700, 21697,\n",
       "         53285, 21607, 21691, 53290, 21684, 21668, 53309, 53310, 21663,\n",
       "         21660, 53288, 52895, 54049, 54057, 19234, 19228, 54890, 54892,\n",
       "         19221, 19216, 19211, 54907, 19209, 19207, 54909, 19201, 54912,\n",
       "         19199, 19197, 54882, 54915, 54880, 54878, 19294, 19293, 19290,\n",
       "         54849, 19288, 19287, 19273, 19271, 19266, 54868, 54870, 19257,\n",
       "         19256, 54871, 19251, 19248, 19194, 19192, 54922, 54975, 54988,\n",
       "         19088, 19087, 19086, 19085, 19084, 19083, 19080, 19079, 19074,\n",
       "         54999, 19052, 19051, 19045, 19103, 54966, 54962, 19119, 19189,\n",
       "         19187, 19184, 19181, 19173, 54935, 54940, 19297, 19159, 19149,\n",
       "         54952, 19135, 19132, 19127, 19124, 19123, 54943, 19040, 54842,\n",
       "         54840, 54734, 19475, 54735, 54736, 19466, 54738, 54741, 19459,\n",
       "         54746, 19454, 54748, 54752, 54753, 54755, 19445, 19477, 19439,\n",
       "         19479, 54723, 54700, 19523, 19521, 54702, 54705, 19512, 19511,\n",
       "         19507, 19506, 19505, 19502, 54712, 54715, 54718, 54719, 54730,\n",
       "         19431, 19430, 54767, 19355, 19350, 54809, 54811, 54814, 19339,\n",
       "         54816, 19335, 54820, 54822, 54831, 19319, 19318, 54837, 54838,\n",
       "         54795, 19362, 19369, 19379, 19423, 19422, 19420, 19419, 54775,\n",
       "         54776, 19410, 19310, 54780, 19402, 54781, 19400, 19396, 19386,\n",
       "         19385, 54789, 19405, 19537, 19038, 19031, 18712, 18707, 18700,\n",
       "         55214, 18694, 55222, 18691, 55235, 18678, 55237, 55239, 55241,\n",
       "         18670, 18668, 18665, 18714, 18661, 18715, 18718, 55180, 18761,\n",
       "         55185, 18750, 55192, 55194, 55195, 18733, 18732, 55197, 55199,\n",
       "         18727, 55200, 55201, 55202, 55206, 18660, 55249, 18656, 55305,\n",
       "         55306, 18592, 18589, 55311, 18584, 18578, 55317, 55324, 55326,\n",
       "         55332, 55333, 18551, 18550, 55334, 18596, 55295, 55294, 18610,\n",
       "         55250, 55251, 18650, 18648, 55261, 18640, 55266, 18765, 55268,\n",
       "         18630, 18624, 18623, 18622, 18619, 18617, 18616, 55278, 19036,\n",
       "         55179, 18773, 18973, 55060, 18960, 18954, 18953, 18952, 18951,\n",
       "         55066, 55068, 18948, 18947, 18946, 18942, 18938, 55075, 55054,\n",
       "         55077, 55052, 18977, 55016, 19021, 55020, 55032, 55033, 19001,\n",
       "         18998, 55036, 55037, 18993, 18992, 18989, 55043, 18980, 18979,\n",
       "         55050, 55078, 55079, 55081, 18832, 18830, 18826, 55148, 55154,\n",
       "         18808, 18796, 18794, 18791, 55167, 55168, 55169, 18783, 18778,\n",
       "         55175, 55138, 18841, 18847, 18850, 18919, 55082, 18912, 18911,\n",
       "         55091, 18898, 18894, 55176, 18889, 18880, 55124, 18867, 18864,\n",
       "         18860, 18856, 18855, 18887, 20488, 19538, 19540, 54260, 20179,\n",
       "         54261, 20176, 54266, 20167, 54270, 54273, 54276, 20152, 20150,\n",
       "         20149, 54280, 54282, 20135, 20181, 20134, 54256, 54251, 20244,\n",
       "         20242, 54213, 20224, 20222, 20221, 54223, 20219, 54235, 54239,\n",
       "         54241, 54244, 54245, 20197, 20196, 20191, 20128, 54290, 20122,\n",
       "         54350, 54351, 54354, 20038, 20029, 20028, 20026, 54361, 20022,\n",
       "         20019, 54365, 54369, 54372, 20011, 54379, 20052, 54337, 20066,\n",
       "         54319, 20121, 20118, 20116, 54297, 20109, 20108, 54299, 54209,\n",
       "         20103, 20091, 20090, 54306, 20084, 20079, 54318, 20077, 54302,\n",
       "         19999], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_purpose': {'feature_present_idx': array([20875, 28735, 62518, 28635, 28554, 47214, 53656, 62590,  5432,\n",
       "          5949,  5997,  6137, 48060,  6520,  6539,  6548, 26040, 27936,\n",
       "         25038,  5418, 56270, 33977,  4450, 61884, 32468, 32193, 45934,\n",
       "         32023, 29183, 31654, 45988,  4924, 31184, 59292,  4952, 46585,\n",
       "         46973, 31647, 48962, 24207,  7117, 15682, 15430, 15194, 14586,\n",
       "         54237, 14502, 13403, 54645, 10713, 13191, 10808, 11137, 12524,\n",
       "         53544, 53659, 58269, 10769, 51134, 18417, 18734, 24171, 49162,\n",
       "          7349, 22510,  7597, 58068,  7726, 58676, 21698, 20828, 20727,\n",
       "         66040,  8316, 64727, 50231, 50323, 19113, 56717, 34058, 53653,\n",
       "         57277,   778,   349, 43605, 40587, 34765, 41787,   482,  2945,\n",
       "         40511, 61022, 41769, 36014, 42051, 35653, 36123,  3695, 66695,\n",
       "         42512,  1465, 44205,  2558,  2115, 39622, 60250, 34222, 17642,\n",
       "         51160, 18089, 41224, 51472, 41060, 18601, 17845, 58557, 19742,\n",
       "         40796, 64202, 22176, 21918, 50110, 42667, 64501, 39840, 58655,\n",
       "         40056, 19848, 19824, 19760, 51475, 40774, 50543, 18789, 16574,\n",
       "         45374, 58509, 52489, 13277, 41836, 52494, 41893, 42098, 13189,\n",
       "         13041, 12975, 42786, 12802, 12729, 42447, 42504, 42728, 13502,\n",
       "         58284, 13722, 13802, 16246, 16110, 51946, 15701, 43249, 38769,\n",
       "         52032, 51500, 14891, 58404, 41510, 14512, 14244, 65211, 14080,\n",
       "         13983, 14732, 41434, 23109, 22411, 46173, 46552, 35072, 59127,\n",
       "         30377, 30249, 57693, 31071, 45177, 35304, 28931, 35452, 35540,\n",
       "         35641, 28347, 36488, 35289, 34885, 34865, 34756, 61503, 61512,\n",
       "         33415, 33087, 61614, 32945, 32703, 61219, 45366, 45884, 61150,\n",
       "         32143, 45296, 45273, 34686, 31610, 59318, 36631, 47604, 60834,\n",
       "         44746, 37815, 44506, 24504, 24362, 37960, 37964, 24175, 24046,\n",
       "         59620, 24003, 38247, 49286, 34090, 49651, 49765, 44308, 38442,\n",
       "         48540, 59707, 25435, 63439, 36939, 47799, 27534, 63067, 27265,\n",
       "         47927, 26951, 37066, 44617, 37553, 26695, 37577, 48241, 26249,\n",
       "         26144, 37697, 25957, 25603, 28266,    28,  5045,  1982, 53912,\n",
       "         65861, 67122, 56225, 10593,  5608,  2080, 10561,  9017,  6724,\n",
       "          6709, 57536,  4507,   995,  2315, 57961, 55343,  8381, 10155,\n",
       "         56940,  2911, 56881,  3103,   791, 56719,  3241, 56856, 54149,\n",
       "          4524, 56820,  7062,  4829, 57281,  9398,  7979,  7195,  4915,\n",
       "         58064,   354,  1469, 58143,  6911,  7631,  7482,  9277,  9485,\n",
       "         56552,  1435,  7958, 55399, 10835,  4775,  1976,  5310, 66988,\n",
       "         60278, 40724, 40956, 27770, 46403,  5288, 40684,  5762,  5945,\n",
       "         28229, 30206, 43656, 47176, 28513, 46718,  5661, 46791,   990,\n",
       "         29011, 29251, 29328, 62480, 62640, 28858, 11483, 27695, 58868,\n",
       "         55854, 58766, 63625, 55801, 48666, 48769, 48869,  7249, 41421,\n",
       "         55625,  7299, 23855, 23545, 49233, 23453, 23296, 23186, 60221,\n",
       "         63515, 43525,  6798, 25687,  6336, 58998, 47907, 58020, 55967,\n",
       "         27092, 46290, 48032, 55965, 26903, 48064,  6540, 48072, 26530,\n",
       "          1033, 48243, 25840, 66184, 25734, 25645, 27053, 60414, 31000,\n",
       "         37257, 37096, 60692, 44649,  2020, 44974,  2060, 36681, 44999,\n",
       "         36664, 36634, 36528, 60586, 59496, 36025,  2172, 35994, 35977,\n",
       "         59489,  1831, 37324, 37529, 57370,  1058, 39512, 59948, 39225,\n",
       "         59888, 38580, 57231, 59692,  1278, 35854, 38107, 37922,  1634,\n",
       "         37870, 57175, 60607, 44527,  1650, 44551, 37602, 38024, 35686,\n",
       "         66977, 35507, 40147,  4295, 32989, 59382, 32913, 44034, 45790,\n",
       "         32849, 32616, 33179, 57814,  4590, 32103, 31983,  4814, 31611,\n",
       "         40408, 31188, 56344, 31058, 45883, 30994, 59465, 33409, 60932,\n",
       "         57068, 35272,  2668,  2753,  2883, 59477, 34374, 34373, 45443,\n",
       "         66832,  3508, 34180,  3776, 34038,  3961,  4186, 33872, 33627,\n",
       "          4279, 34290, 49718, 25933,   266, 65056, 54315, 14572, 55090,\n",
       "         64907, 10314, 58288,  8860, 52244,  8858, 41975, 19160, 50293,\n",
       "         64795, 65193, 19455, 19501, 14137, 19561, 14000, 65541,  8511,\n",
       "         64622, 65889,  8414, 19776, 10515, 20218, 57740, 14813, 51024,\n",
       "         18307, 18297, 16275,  9508, 42320, 51869, 58499, 15945, 57659,\n",
       "         16951, 15824, 17043, 17086, 17202, 58470, 17450, 13457, 51242,\n",
       "         15549, 17629, 17633, 65716, 17714,  9992, 17803, 17887, 52132,\n",
       "         18026,  9131, 51093, 18211, 54397, 51996, 65472, 54554, 53078,\n",
       "         12328, 12567, 12493, 12887,  7733, 12882, 52953, 50096, 53729,\n",
       "         49965, 53723, 52980, 11262, 41691, 58275,  8012, 64377, 21756,\n",
       "         21830, 50025, 53135, 11115, 22395,    79, 11271,  8118, 49817,\n",
       "         11920,  8188, 20904, 64496, 52804, 42557, 12221,   165, 34251,\n",
       "          4292, 33084,  1452, 38828, 60590, 45337, 10068, 16225, 15072,\n",
       "         38119, 15067,  9610, 51756,  4312, 15414, 52052, 52020, 33122,\n",
       "         12276, 15805, 61541, 38649, 39196,  4249, 45409, 45400, 54521,\n",
       "         54405, 33361, 61575, 12433,  1368, 15499, 34146, 39482, 44338,\n",
       "          9934, 45269, 13389,  3046, 35786, 37496, 13035, 10919, 65310,\n",
       "         52832, 10467, 10793, 13216, 39917, 52383, 37045, 45045, 36206,\n",
       "         36357, 42545, 13690, 13683, 45035, 53852,  2072, 57669, 13535,\n",
       "         13349, 52476, 42836, 34489, 35759, 35719, 53095, 66987, 34657,\n",
       "         36827, 52203, 37912, 34835, 54252, 45201, 12703, 37812,  2556,\n",
       "         35238, 10397,  2410,  2395, 35485, 60657, 35510, 42487,  1698,\n",
       "         14327, 57145, 54206, 12934, 35740, 22674, 51372, 61714, 63367,\n",
       "          6679,  8245,  6717,  8159, 20971, 26358, 50119, 48251, 21199,\n",
       "         25437,  6877, 21292, 63541, 21127, 48421,  6624, 57532, 62943,\n",
       "         11807, 64788, 27484, 27477, 66321,   338, 27385, 20021,   681,\n",
       "         20081, 43147, 26724, 20264, 50216,   536, 21416, 25059,  7392,\n",
       "         22383, 23385, 23313, 43200, 23277, 49274, 49791,  7398,  7510,\n",
       "          7502, 49749, 22779, 22766, 49502, 58126, 49209, 57559, 21445,\n",
       "         21453, 50061, 63694, 21580, 24683, 63865, 21616, 64456, 48977,\n",
       "          7003, 64412, 24146, 49070, 49993, 16435, 19383, 62884, 57404,\n",
       "         30693, 30775, 30788, 17797, 30863, 54619, 40486,  4961, 17485,\n",
       "         56525, 46080, 51249, 17257, 22598,  4779, 45946, 56644, 64957,\n",
       "         45848, 43941, 32665, 43914,  9507, 50242, 16639, 32243, 51487,\n",
       "         16713, 59343, 16910, 61939, 32450, 66532,  5046, 46615, 18582,\n",
       "         66459, 67099, 40605, 18688, 55101,  5733, 64902, 19105, 47315,\n",
       "         28138, 28007, 47522, 57996,  5985,  5174, 28878, 47143,   209,\n",
       "         30340, 30264, 30151, 46677, 42192,  5319, 56261, 39639,   981,\n",
       "          5338,  5399, 29031, 18415, 44186, 43025, 57615, 43854, 42712,\n",
       "         42964, 59015, 45037, 49440, 49483, 49979, 50129, 50138, 50171,\n",
       "         55398, 50285, 55160, 55104, 58650, 51082, 55042, 54605, 51490,\n",
       "         51624, 54442, 58448, 52258, 52404, 58214, 53845, 53153, 53278,\n",
       "         53446, 58735, 55596, 49043, 58789, 57160, 56774, 45527, 45645,\n",
       "         45771, 56695, 59359, 56657, 46042, 46082, 46114, 46805, 57162,\n",
       "         46993, 47170, 47246, 47436, 47506, 47556, 59017, 47720, 47743,\n",
       "         56070, 55877, 58954, 48194, 47046, 42639, 29187, 21536, 64581,\n",
       "         19432, 19343, 19328, 64823, 18314, 17456, 17130, 16603, 16571,\n",
       "         21449, 16334, 65000, 15564, 15468, 15280, 15003, 14817, 14481,\n",
       "         14425, 13593, 65408, 16032, 13267, 60059, 22532, 27764, 27528,\n",
       "         63022, 63134, 26917, 26637, 26519, 26483, 25850, 25286, 64199,\n",
       "         63605, 24798, 24486, 24154, 24004, 23791, 63995, 23179, 23110,\n",
       "         22925, 64114, 63653, 27918, 13140, 12792,  7334,  6926,  6443,\n",
       "          6423, 66418, 66439,  5889,  5494,  5425,  4934,  7652,  4931,\n",
       "          4693,  4464,  4418, 66737,  2179,  1713,   996,   611,   348,\n",
       "         67118,  4723, 12873,  7836,  8701, 12701, 12652, 12585, 12564,\n",
       "         12320, 12094, 12068, 11853, 11376, 10760,  8277, 10685, 10433,\n",
       "         10259, 65623, 10094, 10072, 65717, 65747,  9263,  9237,  9171,\n",
       "         10629, 28176, 57694, 60700, 33806, 36150, 41969, 33225, 41877,\n",
       "         31539], dtype=int64),\n",
       "  'feature_absent_idx': array([19257, 12930, 28642, 45879, 28634, 28630, 12943, 57676, 12947,\n",
       "         12948, 57670, 57667, 12951, 12952, 57683, 57666, 28624, 57662,\n",
       "         28622, 12960, 28621, 57656, 12964, 45892, 12969, 12970, 12971,\n",
       "         12973, 57650, 57665, 28612, 45874, 28649, 28688, 57725, 12877,\n",
       "         12878, 12880, 57723, 28684, 57718, 57717, 57715, 12892, 12894,\n",
       "         28677, 45872, 12898, 45843, 12901, 45846, 45847, 45849, 28664,\n",
       "         45856, 12915, 57699, 45863, 45864, 45865, 57688, 28676, 45895,\n",
       "         57643, 57642, 13037, 45935, 13040, 57596, 57594, 28562, 57591,\n",
       "         45939, 28558, 13052, 28552, 28548, 45945, 57599, 57579, 13065,\n",
       "         28544, 45948, 57571, 57570, 57568, 57567, 28537, 57566, 13079,\n",
       "         28536, 13081, 28534, 57578, 57601, 45929, 13029, 12983, 45899,\n",
       "         45900, 57641, 12987, 12989, 28605, 45903, 28602, 45904, 28595,\n",
       "         28592, 57629, 13002, 13003, 57628, 28589, 57626, 45923, 28583,\n",
       "         57611, 13014, 57609, 13016, 28580, 13020, 45927, 57605, 13028,\n",
       "         57730, 45953, 57731, 45828, 57857, 57856, 12721, 28805, 12723,\n",
       "         28803, 45758, 45761, 57850, 57846, 28792, 28791, 28788, 12717,\n",
       "         12739, 12742, 28784, 28783, 57840, 28779, 28778, 57835, 28777,\n",
       "         28775, 57825, 57821, 28772, 12762, 45769, 12763, 12714, 12711,\n",
       "         45722, 28850, 45725, 45726, 12675, 12676, 57887, 28840, 57885,\n",
       "         28839, 45731, 45732, 45736, 57860, 28827, 12693, 45740, 28823,\n",
       "         12696, 45743, 28818, 28817, 28815, 57867, 45747, 57864, 12707,\n",
       "         12710, 57876, 28768, 28767, 45779, 12826, 57768, 57766, 12829,\n",
       "         28715, 57762, 12835, 28714, 28713, 45823, 45824, 28703, 57753,\n",
       "         12824, 57750, 45826, 12851, 12852, 28700, 12854, 28699, 57745,\n",
       "         12858, 57741, 28697, 12862, 57736, 12865, 28702, 57770, 57772,\n",
       "         28724, 28765, 12768, 12769, 12770, 12771, 12773, 12777, 57811,\n",
       "         28759, 45786, 12782, 57807, 57801, 28754, 57796, 57795, 45800,\n",
       "         45803, 12799, 45807, 57782, 28738, 12805, 12807, 45809, 12811,\n",
       "         12812, 12813, 28727, 57735, 12667, 13084, 28529, 13345, 57362,\n",
       "         13347, 28341, 57359, 46088, 28337, 46089, 57352, 57350, 13362,\n",
       "         28333, 13364, 13344, 13365, 57344, 57341, 57339, 46100, 57336,\n",
       "         46110, 57334, 28316, 57329, 57325, 28310, 46117, 28304, 28331,\n",
       "         57306, 46075, 57365, 28378, 57401, 13301, 57399, 28374, 57395,\n",
       "         28371, 13307, 28370, 13311, 57392, 57391, 57389, 46071, 57386,\n",
       "         46063, 13322, 46066, 28361, 57381, 13328, 13329, 46067, 13333,\n",
       "         57367, 13338, 57366, 28350, 13317, 13399, 57305, 57303, 57257,\n",
       "         57256, 46146, 13463, 57254, 13466, 13467, 57252, 57251, 57247,\n",
       "         13476, 46158, 46159, 28264, 28248, 46162, 13485, 57237, 46163,\n",
       "         28241, 57232, 28240, 57230, 13494, 13495, 46164, 28238, 13498,\n",
       "         28247, 57261, 28265, 13454, 57301, 13405, 57299, 28299, 46120,\n",
       "         13410, 57297, 46124, 13415, 13422, 13423, 46128, 13425, 13426,\n",
       "         46129, 13429, 46130, 57283, 13435, 46135, 46138, 57271, 13441,\n",
       "         28274, 13446, 57266, 13448, 57265, 28267, 13295, 28530, 13293,\n",
       "         46049, 57513, 13146, 13148, 13149, 57511, 13151, 28478, 45990,\n",
       "         13154, 28476, 28473, 13160, 13161, 57516, 57502, 45993, 45994,\n",
       "         13167, 57493, 13173, 13176, 46006, 28452, 13183, 28450, 46007,\n",
       "         28448, 28447, 57501, 13190, 57518, 45986, 28525, 28521, 28520,\n",
       "         13095, 13096, 28519, 13098, 13101, 13103, 13106, 13108, 57550,\n",
       "         13112, 28482, 45968, 57544, 28504, 28501, 28500, 28498, 28494,\n",
       "         28493, 45976, 57526, 28487, 57525, 57524, 45984, 45969, 13193,\n",
       "         28445, 46008, 28398, 57433, 28397, 13255, 57430, 13259, 57429,\n",
       "         57428, 57427, 57425, 46047, 28388, 13269, 13249, 13271, 13273,\n",
       "         13274, 57422, 57420, 13280, 57415, 57413, 28383, 28382, 57405,\n",
       "         13288, 57403, 13290, 57423, 57437, 13247, 46036, 57480, 28441,\n",
       "         28439, 13201, 28436, 46013, 46016, 13209, 57468, 28429, 46018,\n",
       "         13214, 13217, 13219, 13221, 46023, 28421, 46024, 46028, 28416,\n",
       "         57450, 13233, 57447, 28410, 28408, 28407, 57442, 57441, 13243,\n",
       "         13292, 57227, 28853, 12663, 58333, 45446, 45457, 12104, 45458,\n",
       "         12106, 12108, 12109, 45460, 45462, 58318, 58316, 29254, 12087,\n",
       "         58311, 58310, 29249, 45467, 58305, 58301, 45469, 12132, 58297,\n",
       "         12134, 45473, 45477, 58294, 58292, 29252, 29239, 58337, 29287,\n",
       "         45411, 45413, 45414, 58367, 29308, 12045, 12046, 12047, 58364,\n",
       "         58363, 29306, 58361, 29305, 29284, 58360, 12056, 29304, 58357,\n",
       "         12059, 29303, 45415, 12062, 58354, 12064, 58349, 12075, 58340,\n",
       "         12079, 58358, 12142, 12143, 29229, 12202, 58239, 12205, 12207,\n",
       "         58237, 58236, 12212, 29177, 12215, 29175, 12218, 12224, 29170,\n",
       "         29184, 45520, 12230, 12234, 58215, 12236, 29161, 12239, 12240,\n",
       "         12243, 12247, 58208, 29152, 12251, 12252, 58221, 12198, 45511,\n",
       "         58240, 58286, 58285, 29226, 58283, 45488, 45489, 12158, 58277,\n",
       "         58274, 29219, 58267, 29214, 29213, 45500, 29205, 12178, 29200,\n",
       "         29199, 58254, 12184, 29196, 12186, 45504, 29194, 58246, 58243,\n",
       "         29191, 58242, 45509, 58373, 12253, 12033, 12029, 45348, 45349,\n",
       "         29424, 29423, 29422, 58506, 45351, 58502, 58496, 45354, 11902,\n",
       "         29414, 29413, 29430, 11906, 58491, 58489, 29408, 58488, 11914,\n",
       "         29406, 45357, 11922, 11923, 45364, 58476, 29393, 11931, 29410,\n",
       "         29392, 11885, 58513, 45317, 29465, 29462, 29461, 45321, 45323,\n",
       "         11848, 11850, 29453, 58538, 58537, 58536, 45331, 29432, 11861,\n",
       "         45333, 45338, 29444, 58519, 45339, 11874, 45340, 11876, 29436,\n",
       "         45342, 45343, 29433, 11882, 58526, 29389, 58465, 29388, 29350,\n",
       "         29349, 45390, 45391, 58416, 58415, 11994, 11995, 58413, 58411,\n",
       "         29346, 29345, 45393, 11987, 29335, 29329, 12013, 12014, 12015,\n",
       "         29326, 12017, 58389, 58388, 12022, 58385, 45410, 58380, 29320,\n",
       "         29334, 11985, 11984, 29352, 29387, 11939, 11940, 29383, 58460,\n",
       "         29382, 29380, 58450, 29377, 11952, 29372, 29368, 11959, 58444,\n",
       "         45382, 45383, 58443, 58442, 11968, 58439, 58438, 29357, 45388,\n",
       "         11975, 11976, 58434, 58429, 58428, 29353, 29317, 12664, 12254,\n",
       "         29149, 57991, 57990, 57988, 12527, 45664, 12530, 12534, 28942,\n",
       "         57978, 57977, 28940, 57975, 12544, 28954, 57974, 57973, 57972,\n",
       "         57971, 12550, 45671, 28933, 57968, 28932, 12557, 28929, 28928,\n",
       "         28927, 12562, 12546, 45672, 28957, 45652, 58039, 28982, 28981,\n",
       "         58037, 58036, 58034, 45634, 58032, 45635, 12484, 28976, 58030,\n",
       "         58029, 57998, 12490, 45638, 12494, 12495, 45639, 58021, 58017,\n",
       "         45643, 12506, 28964, 58006, 12510, 12512, 58000, 12491, 28924,\n",
       "         12568, 45674, 57927, 28881, 57924, 28880, 45701, 57922, 45704,\n",
       "         45705, 12633, 12634, 45711, 28868, 57919, 45699, 45713, 12644,\n",
       "         57911, 57908, 57907, 28860, 45716, 12653, 45717, 57901, 57900,\n",
       "         57899, 57898, 12661, 28865, 57929, 28887, 28890, 57960, 12574,\n",
       "         57955, 45683, 12581, 57953, 12583, 12586, 28909, 28907, 28905,\n",
       "         12592, 12595, 12596, 12597, 12598, 28902, 28901, 28900, 28897,\n",
       "         28896, 28895, 57940, 45695, 28893, 57938, 45696, 57937, 57933,\n",
       "         28983, 58207, 28986, 28993, 12308, 29111, 29110, 12313, 29107,\n",
       "         12315, 58163, 12318, 29105, 45565, 45567, 58158, 29098, 29114,\n",
       "         29097, 58151, 29094, 12338, 45573, 29086, 12344, 45576, 12346,\n",
       "         58132, 58130, 12356, 45583, 29071, 58152, 12362, 29115, 58178,\n",
       "         12258, 29147, 29146, 58203, 45535, 58200, 12267, 29140, 29139,\n",
       "         58197, 58195, 29135, 12279, 45557, 29133, 45542, 12283, 29131,\n",
       "         45544, 29127, 29123, 45553, 12292, 12293, 12294, 12297, 58179,\n",
       "         29119, 58191, 12363, 58122, 12365, 12418, 29020, 45615, 45616,\n",
       "         58072, 12428, 45618, 45619, 12431, 29012, 29008, 58060, 29007,\n",
       "         45611, 58057, 12446, 12447, 12448, 45626, 12452, 58052, 12454,\n",
       "         58049, 45628, 12459, 12460, 28994, 58046, 29004, 45609, 29028,\n",
       "         29029], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_quant': {'feature_present_idx': array([25404, 59847, 23689,  8991, 23860, 23876, 60012, 46762,  8911,\n",
       "         60284, 60285, 24086,  8850, 60458,  8706, 46559, 24249, 46387,\n",
       "         24393, 46318, 24495, 46291, 60825, 24585, 60839,  8338, 46165,\n",
       "         24692, 59706, 59581, 23478, 23475, 22196, 10164, 22244, 10123,\n",
       "         47686, 58706, 47673, 58785, 22560, 47663, 47619, 22601, 22650,\n",
       "          8235, 58876, 47444, 23024, 59129, 59133, 59186,  9765, 23171,\n",
       "         23281,  9462, 23285,  9400, 59522, 47194, 22794, 22149, 24852,\n",
       "          8005, 26669, 44636, 44613, 61531, 44575, 61615, 61667, 26931,\n",
       "         26945, 27048, 27149, 61787,  6596,  6541, 27209, 44149, 27357,\n",
       "         27467, 27555, 27635, 43756, 27666, 27768, 43653, 28540, 28661,\n",
       "          5566,  6937, 26638,  6992, 26424, 45811, 25348, 25395, 14792,\n",
       "         25411,  7816, 25443,  7757, 61074, 45532,  7738, 61169, 45486,\n",
       "         60929, 61177,  7589, 45449,  7508, 45309, 45285, 26193, 45193,\n",
       "         61316,  7287, 26324, 26345, 61426,  7069,  7623, 62639, 10209,\n",
       "         10240, 16011, 53221, 53210, 16119, 55384, 53111, 53090, 55585,\n",
       "         52935, 52686, 16557, 52421, 13452, 16842, 51637, 56054, 56142,\n",
       "         12910, 51422, 17411, 17447, 17842, 17965, 18022, 51125, 18262,\n",
       "         56632, 55331, 13768, 53304, 13841, 14742, 54434, 14692, 54334,\n",
       "         54473, 54331, 14515, 54189, 15032, 54631, 54115, 53907, 14418,\n",
       "         51083, 54807, 14320, 14231, 55000, 15588, 55096, 15596, 14136,\n",
       "         53672, 15681, 14024, 15713, 53578, 15744, 14343, 22021, 51053,\n",
       "         18464, 11435, 11395, 11197, 48982, 21079, 21107, 48828, 11109,\n",
       "         11047, 57845, 57966, 58109, 10926, 21371, 48591, 21521, 58271,\n",
       "         48358, 21790, 48205, 48202, 58400, 21883, 21912, 58427, 58505,\n",
       "         10243, 49357, 57633, 49430, 49436, 50894, 18587, 18597, 50831,\n",
       "         18849, 50628, 12167, 57099, 12102, 19029, 19046, 12083, 19060,\n",
       "         18459, 19062, 50416, 19264, 19463, 50033, 49930, 49867, 19777,\n",
       "         49689, 57478, 49635, 11678, 57510, 49454, 50433, 42614, 54382,\n",
       "          2996,  1570,  3904, 31930, 41134,  1602, 40938, 34880, 38638,\n",
       "         64155, 40891, 32247,  1746, 38674,  1846,  3591, 34723,  3561,\n",
       "         38497, 40700, 41292,  1437, 35577, 41750, 63420,  4531, 35395,\n",
       "         63482, 38110,  4481,  4382, 66140, 38286, 31400,  4199, 63851,\n",
       "         31554, 63869, 31571,  4124, 66380, 40670, 40595,  2918,  2888,\n",
       "          2882, 34088, 39801, 39764,  2360, 65169, 33758,  2376,  2774,\n",
       "         33768, 65161, 39445, 65155, 65102,  2640, 33461,  1899, 40063,\n",
       "         40220,  3459, 34578, 65673, 32684, 64522,  2135, 34447, 40473,\n",
       "         40467, 32908,  3294, 40465,  3272, 39222, 40314, 33094,  3158,\n",
       "         33342, 63131, 65111,   415, 66702,  5052, 66717, 36085, 42084,\n",
       "           654, 36462, 29977, 35961, 35915, 36240, 42270, 62841, 30047,\n",
       "          5138, 30254, 67048, 35782, 29648,   547, 29858,  5264, 36189,\n",
       "         42501, 42018, 37325, 37514, 36091, 29528, 36761,   783, 36798,\n",
       "         30592, 20093, 39187, 20209, 39060, 19374, 50149, 50258, 15533,\n",
       "         36191, 37119, 53835, 39183, 37220, 15465, 20008, 15442, 15456,\n",
       "         49651, 39145, 15521, 19862, 20212, 19848, 15472, 19780, 39087,\n",
       "         34506, 15483, 19440, 53044, 20405, 53898, 20973, 36911, 14998,\n",
       "         54264, 36902, 36818, 14905, 36557, 36587, 48868, 21239, 14862,\n",
       "         54380, 21265, 34068, 48714, 34061, 34052, 48707, 15006, 36466,\n",
       "         49048, 36464, 34242, 39282, 36998, 15200, 20417, 34202, 54046,\n",
       "         49363, 34175, 20234, 36913, 34142, 39347, 20628, 20656, 49256,\n",
       "         20865, 49057, 20961, 49051, 20615, 34580, 15645, 19236, 35367,\n",
       "         51589, 17168, 17213, 35275, 51451, 38282, 51243, 35768, 17590,\n",
       "         35806, 17770, 51236, 38287, 15946, 17869, 51217, 35179, 53299,\n",
       "         17999, 17112, 17060, 53022, 16351, 35662, 37962, 16431, 35641,\n",
       "         35582, 16272, 37849, 16612, 52322, 38087, 16885, 52028, 52013,\n",
       "         51768, 35682, 16994, 37953, 50388, 15880, 35056, 50786, 50661,\n",
       "         50657, 15666, 18956, 34868, 18958, 18964, 15698, 50604, 38719,\n",
       "         34708, 38960, 34586, 37381, 19183, 19215, 37335, 38662, 51184,\n",
       "         53594, 34906, 15871, 51123, 15864, 48683, 51119, 53481, 18292,\n",
       "         51094, 38581, 37802, 18350, 51058, 34991, 34916, 18484, 34914,\n",
       "         18493, 18505, 38522, 18128, 42581, 39396, 41900, 30708, 30655,\n",
       "         45177, 41997, 45171, 26380, 45072, 26560, 30579, 41893, 30574,\n",
       "         30551, 42029, 30493, 42061, 26729, 26767, 30379, 30333, 26939,\n",
       "         42211, 44754, 30813, 41804, 30867, 41537, 45788, 25221, 45654,\n",
       "         41621, 25415, 45644, 31256, 25540, 31126, 31110, 31087, 31032,\n",
       "         45530, 30991, 25701, 25704, 41728, 25710, 25973, 45440, 26049,\n",
       "         41774, 44452, 42225, 27098, 44314, 28116, 43385, 43348, 28172,\n",
       "         43324, 28231, 28245, 28251, 28324, 28391, 43250, 43178, 43101,\n",
       "         29636, 43026, 28771, 42837, 42358, 42825, 42754, 42706, 29186,\n",
       "         29356, 43412, 45853, 43429, 28065, 27186, 30112, 44175, 30041,\n",
       "         44130, 27342, 43923, 29963, 27475, 43778, 27501, 43775, 29779,\n",
       "         27639, 42333, 27672, 27737, 27803, 27894, 29715, 27970, 43637,\n",
       "         43585, 28072, 24948, 24945, 45868, 22428, 33211, 33185, 40262,\n",
       "         22639, 47575, 40387, 47519, 22791, 22817, 22867, 22869, 47311,\n",
       "         32852, 23057, 47263, 47260, 32795, 23190, 23225, 23255, 40508,\n",
       "         40518, 33338, 32704, 22365, 22301, 33980, 33948, 21499, 48516,\n",
       "         48507, 21513, 21533, 21621, 48324, 39589, 21828, 48145, 21868,\n",
       "         39828, 48125, 22020, 33448, 48086, 40089, 42563, 33377, 33346,\n",
       "         22246, 22308, 21337, 40520, 47106, 46651, 46642, 32043, 46625,\n",
       "         24202, 46604, 32041, 41117, 24283, 46431, 46355, 41209, 31893,\n",
       "         24541, 41277, 46259, 31819, 31768, 46243, 41302, 31714, 45955,\n",
       "         24815, 24144, 47164, 24110, 32205, 23380, 23402, 47053, 46926,\n",
       "         40637, 46864, 23567, 23608, 23655, 23713, 23781, 23834, 40769,\n",
       "         32420, 32337, 46821, 40823, 23896, 23917, 23951, 46706, 24043,\n",
       "         40890, 24099,    14, 50973, 14828, 11452, 62987, 62993, 57580,\n",
       "         11562,  4910, 11585, 63078, 63235,  4775, 63330, 11655, 63415,\n",
       "          4523,  7949, 63598, 11857, 11339, 62975, 57746,  5099, 62648,\n",
       "          5437,  5378, 10937, 62770,  5208, 57818, 57800, 57387, 62867,\n",
       "         11173,  5161, 57775, 11298, 11323, 57758, 62899,  5113, 57783,\n",
       "         63890,  4099, 11960, 64509, 56987, 56979, 12316,  3456,  3427,\n",
       "         12327,  3401, 12211, 12373, 56760,  3313, 64625, 12456, 64656,\n",
       "         56626, 56533, 64714, 56798, 58287, 12185, 57079,  3878,  3857,\n",
       "          3849, 64152,  3809, 12050,  3808, 57267, 57056, 64183, 64228,\n",
       "         64301,  3599, 57168, 64462,  3557,  3506, 12127, 64195, 64738,\n",
       "         62627, 10570, 60171, 60121,  6967, 61503,  6936,  8987, 59989,\n",
       "         61505,  9038,  6895, 59931, 59867, 59776,  9151, 59562, 61688,\n",
       "          6644,  8922,  7041,  7082, 61482, 60957, 60904,  7817,  8160,\n",
       "         60868, 60845,  8301,  7662,  6600, 60831, 60818,  7648,  7642,\n",
       "         60706,  8648,  7181, 61438, 60439,  7655, 59478, 59396,  6515,\n",
       "          6092, 62211, 58725,  5984, 58692, 62330,  5924,  5904,  9950,\n",
       "         58630, 62356, 10183,  5683, 10235, 62469, 58404, 62523, 10525,\n",
       "         10136, 62577,  6156,  6198,  6495, 59251,  9613,  6451,  9704,\n",
       "         61894, 61961,  9810, 58870, 59072,  9840,  6383,  9851, 59047,\n",
       "         58946,  6276, 62030,  6239,  9836, 12605, 11833, 13377,  2547,\n",
       "           167, 65121,  1700,  1197,  1695, 67073, 65744,  2630, 65951,\n",
       "         65732, 55955, 54977, 65974, 55209, 65134, 55929, 12876,   175,\n",
       "         14315, 66856, 66893, 56185,   930, 66921, 12939, 55771, 66469,\n",
       "         55182,  1827, 54742, 65845, 66819, 66384, 55816, 66174, 55368,\n",
       "         65624,  1900, 14223,  2128, 13623, 66582, 13996, 54437, 56388,\n",
       "          3039, 13312, 54422,  2252,   598, 65547, 14076, 55147, 65593,\n",
       "         54484,   332, 12606,  2920, 13761,    52, 55382, 56337, 54565,\n",
       "            59, 55397,  1974, 67106, 65629,  2830, 61981,  6400, 66610,\n",
       "         37941], dtype=int64),\n",
       "  'feature_absent_idx': array([49500, 19288, 19287, 42831, 60410, 19273, 19271, 19266, 42840,\n",
       "         19257, 19256, 42843, 19251, 19248, 42847, 19234, 19290, 60420,\n",
       "         19293, 19297, 42821, 60386, 19339, 60387, 60390, 19335, 42824,\n",
       "         60394, 19319, 19318, 42827, 60401, 42828, 19310, 42829, 19294,\n",
       "         42820, 42850, 19228, 19184, 19181, 51819, 42867, 42869, 42871,\n",
       "         19173, 60435, 60436, 42875, 60438, 19159, 42877, 60440, 19149,\n",
       "         19187, 60421, 19189, 19192, 19221, 42853, 19216, 19211, 19209,\n",
       "         42857, 19207, 60428, 19201, 42859, 19199, 19197, 42861, 19194,\n",
       "         60430, 51820, 42880, 60382, 19350, 19502, 60329, 51848, 42764,\n",
       "         60332, 42765, 42766, 42767, 42769, 42770, 19479, 19477, 19475,\n",
       "         42776, 60338, 19505, 42778, 19506, 42761, 19552, 19550, 19549,\n",
       "         19541, 19540, 19539, 19538, 19537, 19523, 19521, 42758, 42759,\n",
       "         42760, 19512, 19511, 19507, 42817, 19466, 60342, 42804, 19396,\n",
       "         60367, 42807, 42808, 19386, 19385, 19379, 60373, 19369, 42810,\n",
       "         60374, 19362, 19355, 42815, 19400, 60340, 19402, 19410, 19459,\n",
       "         60344, 60345, 19454, 42782, 19445, 19439, 19431, 19430, 19423,\n",
       "         19422, 19420, 19419, 42798, 42799, 19405, 51853, 42881, 19135,\n",
       "         18867, 60523, 18864, 60524, 60526, 18860, 60529, 18856, 18855,\n",
       "         18850, 18847, 60531, 60533, 18841, 60535, 42973, 18832, 42972,\n",
       "         18880, 51785, 42953, 18919, 18912, 18911, 51784, 42958, 42960,\n",
       "         18898, 60515, 18894, 18889, 18887, 60517, 42968, 42971, 18938,\n",
       "         18830, 60547, 18761, 60571, 18750, 60572, 60574, 60577, 18733,\n",
       "         18732, 60579, 18727, 43024, 60587, 18718, 18715, 18714, 18765,\n",
       "         18826, 43012, 18773, 42987, 42990, 42991, 60551, 60552, 18808,\n",
       "         18796, 18794, 60558, 18791, 60559, 51770, 18783, 18778, 43009,\n",
       "         51767, 42883, 18942, 18947, 19085, 19084, 19083, 19080, 19079,\n",
       "         19074, 60464, 60469, 19052, 19051, 42911, 60472, 19045, 51799,\n",
       "         19040, 19086, 60475, 19087, 51806, 19132, 42885, 19127, 19124,\n",
       "         19123, 51810, 19119, 42888, 51809, 42890, 42891, 60453, 19103,\n",
       "         51807, 42897, 19088, 18946, 19038, 19036, 18980, 18979, 60495,\n",
       "         18977, 42933, 18973, 51791, 60498, 18960, 51788, 18954, 18953,\n",
       "         18952, 18951, 18948, 42932, 51793, 42931, 18989, 19031, 42919,\n",
       "         60477, 60478, 42920, 19021, 42924, 42925, 60489, 19001, 18998,\n",
       "         42928, 60492, 18993, 18992, 60494, 19555, 19560, 42745, 42536,\n",
       "         20135, 20134, 42537, 60104, 20128, 42541, 20122, 20121, 20118,\n",
       "         20116, 51924, 20109, 20108, 60107, 60100, 20103, 20149, 20152,\n",
       "         20197, 20196, 42511, 20191, 51933, 20181, 20179, 42521, 60093,\n",
       "         20176, 42522, 42524, 42525, 20167, 51928, 20150, 60083, 51922,\n",
       "         20090, 60139, 60140, 20038, 20029, 20028, 20026, 42576, 60143,\n",
       "         20022, 20019, 51909, 42582, 42584, 42585, 20011, 60138, 20091,\n",
       "         42573, 20052, 42554, 20084, 60113, 20079, 20077, 42559, 42560,\n",
       "         60124, 20066, 60128, 60129, 42564, 42565, 60130, 51915, 51914,\n",
       "         42586, 60082, 51935, 60031, 42459, 42460, 42462, 20331, 20327,\n",
       "         60038, 51941, 60039, 20321, 60041, 20317, 20316, 20315, 20313,\n",
       "         20350, 42470, 20352, 42454, 20409, 42439, 20403, 60013, 20396,\n",
       "         42440, 60015, 51945, 60018, 60020, 20374, 20372, 42450, 60024,\n",
       "         51943, 60028, 42509, 42472, 20302, 20246, 42492, 20244, 20242,\n",
       "         42493, 42495, 42496, 42497, 60073, 20224, 20222, 20221, 20219,\n",
       "         42500, 51937, 20248, 60047, 20249, 42490, 20301, 20300, 20299,\n",
       "         42475, 20294, 20290, 60053, 20281, 60056, 42483, 20268, 20267,\n",
       "         20261, 60065, 42489, 20252, 60154, 19999, 19996, 60258, 19697,\n",
       "         19696, 19695, 19691, 42696, 60260, 19687, 42699, 19677, 60270,\n",
       "         19663, 19661, 19660, 60274, 19701, 60275, 51877, 60256, 19739,\n",
       "         42682, 42684, 60248, 60249, 19726, 19725, 42686, 60253, 19719,\n",
       "         42687, 19717, 19714, 42690, 19709, 19706, 51878, 42707, 51868,\n",
       "         51859, 60305, 42735, 19590, 19584, 19581, 19578, 19577, 19576,\n",
       "         19570, 51856, 19566, 19565, 19564, 19562, 19602, 19654, 19606,\n",
       "         42726, 19651, 60280, 51867, 19646, 42715, 19640, 19639, 42717,\n",
       "         60287, 19636, 19630, 60292, 19621, 42723, 19615, 60300, 42679,\n",
       "         19745, 60243, 42618, 60180, 60183, 19915, 51895, 42624, 19902,\n",
       "         19899, 60188, 19893, 60189, 42631, 42632, 19889, 19886, 19928,\n",
       "         19885, 19930, 42612, 19994, 19989, 60160, 42592, 19983, 60164,\n",
       "         42597, 19972, 42600, 19956, 51900, 60168, 42604, 19943, 60178,\n",
       "         19933, 19882, 19880, 60191, 42659, 19802, 42666, 19791, 60228,\n",
       "         19779, 42674, 19770, 60235, 19765, 19763, 19758, 60238, 19750,\n",
       "         19748, 42658, 42656, 42654, 42653, 19875, 19868, 19866, 60206,\n",
       "         42644, 51886, 19841, 43029, 60209, 60210, 42646, 19833, 19832,\n",
       "         19831, 19825, 42652, 19839, 20411, 18712, 43034, 17533, 17532,\n",
       "         43475, 17530, 43476, 17526, 17525, 17523, 17522, 17521, 17519,\n",
       "         17513, 17512, 61026, 61027, 17540, 61028, 43472, 43470, 43454,\n",
       "         17592, 17587, 43456, 17584, 17583, 17581, 17570, 61011, 17564,\n",
       "         17563, 51620, 17558, 61016, 17549, 17545, 17596, 43481, 17497,\n",
       "         17438, 17437, 17435, 17429, 17428, 61060, 17424, 17423, 61061,\n",
       "         17421, 17420, 17417, 17415, 17408, 61064, 17439, 17502, 61056,\n",
       "         17449, 17492, 17491, 43486, 17478, 17475, 17471, 17469, 17466,\n",
       "         17465, 61046, 17462, 17458, 43497, 43498, 43499, 61055, 17402,\n",
       "         17600, 17606, 17783, 17782, 17779, 17775, 17774, 17772, 17769,\n",
       "         43380, 17759, 17758, 43386, 60937, 60939, 17743, 17742, 17784,\n",
       "         17740, 17785, 17790, 43360, 43362, 17828, 43364, 51661, 60920,\n",
       "         60921, 43368, 60924, 43370, 17800, 17799, 51660, 43372, 17792,\n",
       "         17788, 17603, 17737, 17731, 17659, 51638, 17648, 51632, 43433,\n",
       "         43435, 43437, 17627, 60982, 17616, 17615, 17614, 60986, 60991,\n",
       "         17608, 60968, 17735, 43418, 17671, 43393, 43395, 43397, 17721,\n",
       "         51646, 60953, 17710, 17708, 17698, 60961, 17683, 17680, 17679,\n",
       "         60965, 43416, 17667, 17838, 17401, 17396, 17118, 17116, 17113,\n",
       "         17111, 17105, 43611, 61171, 17090, 61176, 61178, 43617, 17080,\n",
       "         17077, 17072, 61180, 61161, 17070, 17125, 17132, 17165, 17163,\n",
       "         17162, 17161, 17159, 17156, 51572, 17154, 61151, 17152, 17148,\n",
       "         17146, 61154, 17139, 61157, 43601, 17169, 43621, 17056, 61200,\n",
       "         16996, 16991, 16989, 16986, 43647, 16981, 61208, 16973, 61211,\n",
       "         61213, 16970, 61215, 61216, 51558, 43644, 43623, 17001, 17019,\n",
       "         17055, 17053, 17050, 43627, 61190, 61191, 61192, 43629, 17037,\n",
       "         43630, 43631, 43632, 17027, 43634, 61195, 17006, 17399, 17173,\n",
       "         17179, 17324, 17322, 17321, 17319, 17318, 43542, 61101, 17296,\n",
       "         51593, 17293, 43551, 17288, 17287, 17286, 17278, 17330, 61115,\n",
       "         61087, 17338, 43515, 17392, 17389, 17384, 43521, 43522, 17369,\n",
       "         17367, 61078, 17355, 17353, 17344, 17343, 43531, 43533, 61084,\n",
       "         17177, 43556, 17266, 43569, 61138, 61139, 17216, 17215, 17209,\n",
       "         17208, 17204, 43575, 61144, 17201, 43576, 43578, 51578, 17184,\n",
       "         43567, 61116, 17227, 43566, 17265, 43560, 43561, 61123, 17254,\n",
       "         51585, 17252, 17248, 17247, 17244, 17241, 17240, 61128, 17235,\n",
       "         61129, 17228, 43357, 43355, 60913, 60697, 43139, 60698, 18426,\n",
       "         18423, 18422, 18420, 18412, 43144, 51727, 18402, 18400, 43149,\n",
       "         18392, 18391, 43138, 18389, 60694, 18451, 18511, 43112, 43114,\n",
       "         18501, 43115, 18494, 60672, 43116, 60673, 43117, 18487, 43118,\n",
       "         18469, 51731, 43132, 43133, 18516, 43157, 51721, 18332, 51712,\n",
       "         18330, 43177, 18324, 60731, 18315, 18304, 51709, 60739, 43192,\n",
       "         18294, 60743, 18283, 60747, 18334, 18383, 18336, 18343, 43159,\n",
       "         43161, 18376, 18371, 18370, 18369, 60716, 43164, 18361, 51718,\n",
       "         60718, 18355, 60723, 60725, 18344, 18337, 43197, 43107, 18520,\n",
       "         60613, 18656, 18650, 60619, 18648, 43051, 43053, 60625, 43055,\n",
       "         18640], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_range': {'feature_present_idx': array([ 1413, 15155,  9374, 43256, 20547, 50530,  8469], dtype=int64),\n",
       "  'feature_absent_idx': array([37992, 53975, 17252, 17248, 17247, 35242, 17244], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 7\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 7\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 7\n",
       "    })}}},\n",
       " 'contains_scale': {'feature_present_idx': array([41196], dtype=int64),\n",
       "  'feature_absent_idx': array([18993], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1\n",
       "    })}}},\n",
       " 'contains_source': {'feature_present_idx': array([56465, 57962, 50414, 60713, 20941, 33645, 63027, 43335, 33509,\n",
       "         47475, 22270, 64558, 50239, 10399, 17768, 51109, 51318, 33205,\n",
       "         52262,  9361, 52708, 32921, 18166, 53661, 32384, 55511, 51589,\n",
       "         50095, 19180, 31430, 14616, 36529, 14505, 14466, 38443, 38552,\n",
       "         39290, 13685, 13674, 47552, 36332, 41727, 12795, 12520, 34988,\n",
       "         12355, 11883, 34626, 34533, 46553, 35612, 34293, 37065, 19525,\n",
       "          2550, 26510,  2479, 21854, 62617, 25888,  1835, 25280, 64241,\n",
       "         27985, 65328, 65965, 24278, 66481, 23962, 66541, 66854, 66989,\n",
       "           419,   206, 65511, 28763, 26609, 58863, 58667,  5981,  3682,\n",
       "          5779, 30617,  5389,  6912,  6300, 28969, 59664, 20509, 20605,\n",
       "         20946, 29027, 32849, 31261, 23807, 31341, 32370, 34275, 30946,\n",
       "         35507, 29725, 29429, 34911, 36739, 24210,   103, 48468, 38303,\n",
       "         59018, 59101, 59169, 59410, 59607, 59819, 59926, 60637, 61500,\n",
       "         61513, 61562, 61785, 62586, 62613, 63287, 64214, 64893, 66085,\n",
       "         66462, 66510, 66829, 58801, 37431, 57055, 56590, 38386, 39824,\n",
       "         41112, 41372, 43013, 45454, 46053, 46175, 46654, 23706, 50431,\n",
       "         50439, 51855, 52245, 52717, 53071, 53972, 54310, 55859, 56035,\n",
       "         56329, 56671, 23186, 32291, 16184,  4668,  9885, 11856, 18246,\n",
       "          7136,  7238, 11393, 21394, 11349, 11087, 21288, 20132,  8856,\n",
       "          9649, 19681, 21544, 11983, 10455, 22835,  3180, 22664, 17327,\n",
       "          2548, 22531, 13472, 15409,  2936, 16465, 49201, 15884, 49745,\n",
       "         48613, 50303, 35910, 48541, 48124, 50309, 36444, 41493, 38526,\n",
       "         14017, 46223, 11612, 22912, 45116, 44941, 40978, 43366, 41196,\n",
       "         43176, 42917, 41583, 14774, 44421, 23098, 51478,  4193, 60882,\n",
       "         61137,  3638, 61877, 62520, 62552, 60597,  2217,  1452, 65611,\n",
       "         65691,   873,   809,   779,   564, 63152,  4604,  4961, 59468,\n",
       "         51600, 51688,  9772, 51974, 35859, 54007,  8349, 55620,  8117,\n",
       "          8090, 56401, 57564, 57752,  6333,  5887, 59201,  5068, 10291,\n",
       "          9260, 45932, 27345, 25820, 22052, 26476, 32470, 21470, 26681,\n",
       "         26800, 33435, 33869, 19731, 17711, 28157, 28110, 33526, 17897,\n",
       "         27786, 28363, 18379, 22254, 29360, 16237, 22866, 34986, 23239,\n",
       "         30904, 31844, 35104, 22567, 34318, 30894, 20277, 55644, 10196,\n",
       "         19932, 20087,  9064, 53431, 53798, 54924,  8748, 54129, 50865,\n",
       "          7836, 52512, 57624, 23471,   815,  1220, 66060,  1279, 65834,\n",
       "          1317,  1859, 63264, 24666, 27753,  1897,  2364, 24765, 61865,\n",
       "         25401, 25615,  4251,  5134, 58344, 57979, 27474, 62743, 10813,\n",
       "         67306, 32288, 45003, 10935, 12405, 42551, 13000, 34150, 17386,\n",
       "         45756, 17314, 16962, 46059, 48816, 14817, 48194, 31651, 14900,\n",
       "         27779, 45221, 34629, 44116,  6404, 58075, 33557,  5594,  1243,\n",
       "         27245, 64163, 60202, 60451, 65859, 34188, 24128, 22421, 62239,\n",
       "         25151, 14346, 14464,  1351, 19014, 33775, 35139,  9228, 52405,\n",
       "         30330, 30615, 51334, 10147, 32438, 51335, 10970, 51041, 52426,\n",
       "         10488, 24428, 26320, 34019, 28762, 34801,  3738, 13357, 34746,\n",
       "         29753, 19162, 24994, 24668, 50378, 19808, 14563, 33983,  1719,\n",
       "          1707,  1565, 32153, 39426, 61302, 47729, 17994, 17925, 46179,\n",
       "         45584, 54487, 18844, 26481, 27247,  5244, 43381, 41589, 47705,\n",
       "         26988,  4419, 55135, 14935,  8034, 37407, 11973, 55752, 13642,\n",
       "         46457, 57661, 27116, 36427, 41559, 34982, 30640, 16012,  9014,\n",
       "          6219, 38653, 52403, 67044,  9586, 46857,   969, 27689, 52787,\n",
       "         53840, 11134, 30862,  6608, 47561], dtype=int64),\n",
       "  'feature_absent_idx': array([19083, 52503, 52508, 19369, 52518, 19362, 19355, 19350, 52535,\n",
       "         52537, 52539, 19339, 52541, 19335, 52543, 52544, 19379, 52547,\n",
       "         19385, 52501, 19430, 19423, 19422, 19420, 19419, 52480, 52481,\n",
       "         19410, 52486, 19405, 19402, 19400, 52492, 19396, 52493, 19386,\n",
       "         52548, 52556, 19319, 52604, 19257, 19256, 19251, 19248, 52616,\n",
       "         52619, 52620, 19234, 52623, 52627, 19228, 52635, 52637, 19221,\n",
       "         52603, 19266, 52599, 52596, 19318, 52562, 19310, 52580, 52581,\n",
       "         19297, 19294, 19431, 19293, 52585, 19288, 19287, 52591, 52595,\n",
       "         19273, 19271, 19290, 19439, 52468, 52465, 52349, 19590, 19584,\n",
       "         19581, 52364, 19578, 19577, 19576, 52369, 19570, 52376, 19566,\n",
       "         19565, 19564, 19562, 52346, 52345, 19602, 52342, 52305, 19646,\n",
       "         52310, 52312, 19640, 19639, 52318, 19560, 19636, 19630, 52331,\n",
       "         19621, 19615, 52335, 52341, 19606, 52323, 52640, 19555, 19550,\n",
       "         52418, 52429, 19479, 19477, 19475, 19466, 52444, 52445, 52450,\n",
       "         19459, 52452, 19454, 52461, 52462, 19445, 52414, 52409, 52408,\n",
       "         19502, 19549, 52385, 19541, 19540, 19539, 19538, 19537, 19552,\n",
       "         52396, 19521, 19512, 19511, 19507, 19506, 19505, 52406, 19523,\n",
       "         19651, 19216, 19209, 18919, 52864, 18912, 18911, 52868, 52869,\n",
       "         52871, 18898, 18894, 18889, 52884, 18887, 52885, 52888, 52892,\n",
       "         52859, 52893, 52855, 18942, 18979, 18977, 18973, 52821, 52831,\n",
       "         18960, 18954, 18953, 18952, 18951, 52840, 52842, 18948, 18947,\n",
       "         18946, 18938, 18880, 52895, 52898, 52946, 52947, 18808, 52958,\n",
       "         18796, 18794, 52961, 18791, 52963, 52965, 52966, 18783, 18778,\n",
       "         52975, 18773, 52942, 52939, 52938, 18826, 18867, 52905, 18864,\n",
       "         52906, 52909, 18860, 18856, 18980, 18855, 18850, 18847, 52919,\n",
       "         18841, 18832, 18830, 52933, 52914, 52814, 52813, 52810, 19149,\n",
       "         52695, 52698, 19135, 19132, 19127, 19124, 19123, 19119, 52714,\n",
       "         52718, 52721, 19103, 52725, 52728, 19159, 52680, 52679, 52676,\n",
       "         19207, 19201, 19199, 19197, 19194, 19192, 19189, 52733, 19187,\n",
       "         52661, 52662, 19181, 52664, 52669, 19173, 52671, 19184, 19211,\n",
       "         52734, 19087, 52767, 52774, 19021, 52780, 52785, 52786, 52790,\n",
       "         52791, 19001, 52795, 18998, 52798, 18993, 18992, 18989, 52766,\n",
       "         19031, 19036, 19038, 19086, 19085, 19084, 19080, 19079, 52738,\n",
       "         19074, 19088, 52740, 52753, 19052, 19051, 52761, 19045, 19040,\n",
       "         52764, 52751, 52303, 19654, 19660, 51807, 20294, 20290, 51809,\n",
       "         51810, 20281, 51819, 51820, 20268, 20267, 20261, 20252, 20249,\n",
       "         20248, 20246, 51806, 20244, 20299, 20301, 51770, 20331, 20327,\n",
       "         51784, 51785, 20321, 51788, 20317, 20316, 20315, 20313, 51791,\n",
       "         51793, 51799, 20302, 20300, 20242, 51848, 51853, 51909, 51914,\n",
       "         51915, 20152, 51922, 20150, 20149, 51924, 51928, 51933, 20135,\n",
       "         20134, 51935, 51937, 20128, 20167, 51900, 20176, 20179, 51856,\n",
       "         20224, 51859, 20222, 20221, 20219, 51867, 51767, 51868, 51878,\n",
       "         51886, 20197, 20196, 20191, 20181, 51895, 51877, 20350, 20352,\n",
       "         51753, 20538, 51638, 20533, 20530, 51646, 20525, 20520, 20519,\n",
       "         20518, 51660, 51661, 20508, 51665, 20501, 51669, 20540, 51632,\n",
       "         20551, 20552, 20622, 51572, 20620, 51578, 51585, 20608, 20606,\n",
       "         51671, 20601, 20599, 20597, 20584, 20577, 20575, 51620, 20559,\n",
       "         51593, 20122, 20488, 20482, 20418, 51718, 20412, 20411, 20409,\n",
       "         51721, 20403, 20396, 51727, 51731, 51742, 20374, 51743, 20372,\n",
       "         51747, 20419, 20420, 20423, 51712], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 446\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 446\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 446\n",
       "    })}}},\n",
       " 'contains_subevent': {'feature_present_idx': array([ 2363, 61201, 38576, 17453, 14264, 34681, 60247, 57530, 19481,\n",
       "         60711, 62337, 14125, 33171, 33343, 34148, 11888, 19981,  1165,\n",
       "         50354, 47224,  7121,  6701, 65479,  5775, 47189, 57472, 41022,\n",
       "         59422, 31035, 53436, 50199, 66462, 40173, 29909, 33566, 19681,\n",
       "          3217,  4562, 16479, 62341, 12567, 12497, 12233, 65791,  7767,\n",
       "         65054,  7777,  4019, 47914, 33869, 19937, 11933, 56291, 29487,\n",
       "         42464, 34882,  2316, 62397, 44152,   580,  2537, 42336, 42324,\n",
       "          9862, 11120, 35023, 17461, 19301, 19442, 29674, 44255, 14086,\n",
       "         43383, 66648, 55072, 53954, 51533, 26547, 17741, 37388, 66456,\n",
       "         20878, 20101, 32497, 51380, 35769, 46663, 57503, 11500],\n",
       "        dtype=int64),\n",
       "  'feature_absent_idx': array([50294, 22562, 59734, 39218, 26920, 26918, 54111, 26915, 54113,\n",
       "          9915, 49931, 59725, 59736,  9918, 41321, 22570, 22571, 26906,\n",
       "         39223, 59714, 26905, 59710, 34468, 17090, 36473, 26910, 26899,\n",
       "         59737, 54109, 26940, 36484, 46538, 22555, 49941, 59756, 59755,\n",
       "         26936, 59754, 17113, 17111, 17105, 59749, 36482, 36481, 22559,\n",
       "         59744,  9891, 46542, 33808, 46546,  9897, 59739, 59738, 26932,\n",
       "         17116, 26897, 46558, 59668,  9975, 54133, 59665,  9978, 17072,\n",
       "          9980, 26870,  9982, 46575, 22586,  9973, 17070,  9987,  9988,\n",
       "         26865, 26863, 39232,  9994, 41309, 26860, 22590, 26858, 22591,\n",
       "         54138, 59698, 40829, 54131,  9942, 59691, 41315, 46563],\n",
       "        dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 89\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 89\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 89\n",
       "    })}}},\n",
       " 'contains_time': {'feature_present_idx': array([43315, 61010, 61017, 19816, 34444, 11881,  8279, 61118,  4009,\n",
       "         32360,  3976, 29833, 61305, 54561, 54537, 22377, 61327, 41644,\n",
       "         15139, 29848, 61384, 27344, 41600,  3822, 23990,  3782,  3743,\n",
       "         61484, 23916, 48181, 27396,  4236, 42530,  4560, 60315,  4512,\n",
       "         29588, 42361, 27751, 47442,  8035, 21103, 42201, 42131,  4387,\n",
       "         47572, 23804, 60508,  4324, 60581, 60606, 14855, 23809, 47683,\n",
       "         14909,  4265, 47749,  8196, 34401,  4197, 42556, 41480, 61588,\n",
       "          3104,  3096, 62439,  3087, 11289, 62482, 62512, 32035,  2966,\n",
       "         15950, 27032, 19559, 26902, 48639, 19547, 32011, 53555, 53483,\n",
       "         16109, 62813, 30240,  2694, 40090, 40062, 48824, 21295,  2625,\n",
       "         40710, 41477,  3114, 40781, 15382, 41362, 22343, 61683, 48223,\n",
       "         48252,  3575, 34558,  3522, 11620, 48270, 61903, 22315, 15575,\n",
       "         61935, 61947, 15636,  3365, 48416, 27097, 24113, 62083, 40870,\n",
       "          3268, 62127, 62279, 48515, 19667, 60211, 60205, 42634, 56098,\n",
       "         20634, 58058, 44928,  6033, 23182,  6025, 44872,  6004, 20859,\n",
       "         58295, 44806, 22753, 58320, 46425,  5820, 28508, 46441, 33423,\n",
       "         44579,  5734, 12560, 58544, 12541,  5687, 44430, 55708, 12748,\n",
       "         33490, 45147,  7147, 12985,  6758, 45642, 45620, 56594,  6900,\n",
       "         45515,  6971, 45381, 57222, 12840, 23029,  7007, 29090, 56466,\n",
       "         12839, 20786, 28728, 12806, 57466, 57475, 57489, 45229, 57539,\n",
       "         46029, 45190, 45184, 29141, 32772, 55676, 58788, 12171, 21733,\n",
       "         14218, 47104, 23605, 32612, 59576, 14335, 43258, 55158, 27919,\n",
       "         43229, 55112, 55110, 33725, 55103,  4793, 59887, 23657, 23676,\n",
       "         59913, 42938, 14467, 54987, 54974, 33843, 14510, 55318, 20970,\n",
       "         32634, 12183, 58795, 46689, 44128, 58815, 22700, 33496, 28300,\n",
       "         58833, 46702, 13856, 46711, 43965, 29443, 39996, 55611, 43655,\n",
       "          5350, 28206, 28174, 28154,  5256, 28133, 28092, 28066, 33597,\n",
       "         33657, 59300, 47065, 12354, 21320, 53881, 31941, 30746, 17413,\n",
       "         37869, 35305, 37840, 18965, 65584,  9637, 51622, 49781, 25785,\n",
       "         25747, 65653, 17379,   941, 65674, 37743,   902, 49799, 49857,\n",
       "         51466, 37622, 65786, 31526, 65793, 17656, 37542, 37516, 65663,\n",
       "         51450, 37937,  1146,  1501, 52166, 64889, 19145, 10709, 52058,\n",
       "         49530, 52009, 26073, 35255, 17087, 51993,  1312, 51774,  1283,\n",
       "         22005, 38325, 10681, 51964, 30652, 49643,  9471, 49665, 51841,\n",
       "         38074, 37987, 25860, 53096, 19121, 35230,   733, 35837, 36752,\n",
       "         36275, 51085, 50248, 36715, 50267, 66816, 36290, 31317, 25389,\n",
       "         31137, 50940, 18448, 25073, 18704, 25170, 36591, 36511,    95,\n",
       "         36491, 50615, 67253, 50753, 31208,    42,    41, 50668, 67315,\n",
       "           164, 25632, 66645, 51197, 35847, 37390, 18803, 37357, 37353,\n",
       "         37347, 50051, 66123,  9806,  9821, 37217, 37118, 18756, 18737,\n",
       "           550, 50066, 18749, 37008, 24979, 18068, 18083, 51259, 24993,\n",
       "           443, 30982, 36888, 50206, 66454, 51332,  9306, 49733, 49513,\n",
       "         63999, 39302,  2038, 30464, 49310, 64093, 64143, 21417, 52524,\n",
       "         39037, 49403, 64258, 22055, 16707, 26500, 52478, 38978,  1777,\n",
       "          9185,  1749, 38902, 22080, 63799, 63769, 24346, 16265, 39873,\n",
       "         39826,  2414, 63150, 63192, 34930, 49013, 34933, 26612, 52343,\n",
       "         39723, 39524, 63446, 10976, 63511, 26576, 30412, 63585, 49170,\n",
       "         63624,  2170, 16361, 16809, 45730, 64632, 16852, 38853, 52227,\n",
       "         38652, 22047, 64476, 64423, 10830, 52282, 26280,  1523, 64718,\n",
       "         38752,  9276, 64483, 10188, 46153, 11228, 12734, 32886, 46169,\n",
       "         12729, 47994, 11904, 12715, 31610, 12733, 48559, 21513, 46303,\n",
       "         46481, 21151, 50075, 31373, 12572, 11921, 10279, 32818, 11013,\n",
       "         50157, 49141, 10693, 32852, 46351, 21354, 10235, 46348, 50217,\n",
       "         32066, 32961, 50271, 49096, 32966, 48808, 12850, 48956, 32977,\n",
       "         31863, 32980, 12871, 50607, 45888, 12891, 45765, 32372, 45753,\n",
       "         48927, 45744, 10030, 11078, 31969, 10725, 32394, 50587, 46040,\n",
       "         25233, 49057, 10761, 11151, 21675, 48694, 48723, 47764, 50367,\n",
       "         12797, 50417, 48729, 47866, 48749, 45975, 45954, 31847, 50567,\n",
       "         46102, 31564, 47640, 49178, 48076, 47435, 31561, 47177, 11658,\n",
       "         11639, 49789, 47155, 11730, 47465, 49614, 11572, 49807, 49848,\n",
       "         21401, 47540, 32217, 12208, 12168, 49341, 48217, 47359, 49722,\n",
       "         21158, 11813, 47297, 10617, 21180, 47342, 11762, 12011, 10557,\n",
       "         47287, 21058, 49420, 47348, 32556, 49737, 47202, 47178, 31557,\n",
       "         32683, 46910, 11560, 31473, 49306, 32100, 31466, 49301, 21155,\n",
       "         49491, 11452, 46706, 11418, 48507, 46683, 47611, 21267, 46642,\n",
       "         12501, 12051, 46570, 49259, 11960, 49926, 45735, 48059, 46822,\n",
       "         11553, 21214, 11526, 32704, 32724, 32753, 12269, 10775, 49905,\n",
       "         10414, 12296, 47792, 12317, 12345, 32144, 46728, 32132, 11375,\n",
       "         12302,    11, 12978, 16568, 16552, 35154, 16524, 39373, 35117,\n",
       "         16499, 19222, 35064, 39391, 39395, 39511, 39730, 16342, 39743,\n",
       "         39770, 16484, 16291, 19217, 39134, 16926, 38694, 38715, 16880,\n",
       "         38765, 19167, 38807, 16624, 38827, 38895, 35222, 16740, 16722,\n",
       "         19175, 35178, 39039, 16811, 19155, 34872, 39945, 40663, 34758,\n",
       "         15880, 15842, 40782, 40820, 40843, 40601, 15799, 40909, 15783,\n",
       "         40911, 15742, 41006, 41019, 41031, 40885, 39936, 40443, 40301,\n",
       "         16220, 39970, 16199, 40034, 19416, 34839, 40064, 34776, 16132,\n",
       "         19458, 34836, 40142, 16021, 40161, 19480, 15987, 19451, 41038,\n",
       "         16952, 17000, 36263, 36222, 36843, 18169, 36891, 36913, 36924,\n",
       "         36756, 36054, 37049, 17993, 37221, 37282, 18788, 37339, 35863,\n",
       "         36993, 17880, 18264, 18711, 18614, 18609, 18588, 18580, 36371,\n",
       "         18666, 18564, 18303, 36327, 18450, 18442, 18438, 36612, 36632,\n",
       "         18341, 18335, 18455, 38544, 37443, 17754, 35281, 38178, 17258,\n",
       "         35268, 19118, 17218, 38311, 38090, 17191, 17100, 17097, 38421,\n",
       "         17048, 35234, 38473, 17008, 38333, 17798, 38065, 37976, 37579,\n",
       "         37659, 18890, 37693, 37702, 35662, 18930, 37980, 37766, 35531,\n",
       "         35417, 37899, 17400, 37925, 17371, 35300, 35587, 34695, 34644,\n",
       "         41072, 44375, 20521, 20524, 33484, 44536, 20541, 13711, 13779,\n",
       "         44651, 33323, 33318, 13617, 13611, 44798, 44838, 44840, 44690,\n",
       "         20596, 44343, 44175, 14076, 20282, 43597, 43635, 43664, 33548,\n",
       "         13978, 44179, 43769, 43790, 13929, 13892, 13877, 33511, 20449,\n",
       "         44163, 43787, 43572, 13521, 33243, 13171, 45375, 13157, 45438,\n",
       "         20698, 45503, 13117, 45322, 13111, 45587, 13078, 45593, 45607,\n",
       "         13009, 45680, 12979, 33141, 33251, 45296, 13234, 45002, 33224,\n",
       "         45080, 13414, 13411, 45119, 13339, 45284, 13334, 13287, 45183,\n",
       "         45210, 45238, 20676, 45265, 13237, 20670, 20272, 20215, 43455,\n",
       "         41789, 15027, 15025, 19773, 41804, 41816, 34449, 15047, 14992,\n",
       "         41836, 34436, 34409, 14941, 41965, 14912, 42032, 14965, 34296,\n",
       "         41753, 41627, 15543, 41114, 41167, 41235, 41261, 41263, 15428,\n",
       "         41681, 34540, 15347, 41489, 19760, 41524, 41544, 15210, 41616,\n",
       "         19743, 19849, 14839, 34252, 43000, 43030, 43049, 43246, 43249,\n",
       "         33717, 14322, 14419, 14307, 14209, 43321, 14193, 43356, 43392,\n",
       "         33687, 14142, 33701, 33735, 42975, 42942, 42117, 34213, 14769,\n",
       "         42321, 34061, 42353, 42358, 42448, 42469, 42498, 14616, 42510,\n",
       "         14606, 33920, 42893, 33818, 14455, 45697, 10029, 30657, 10014,\n",
       "         61278,  3974,  3971, 61319,  3892, 23929, 23936,  3861,  3852,\n",
       "         61343, 27350, 61413,  3803, 61477,  3713, 23994, 61511, 61119,\n",
       "         61547,  4021,  4048,  4391, 27639,  4380, 60567, 27634, 60589,\n",
       "         60621,  4271, 23822, 27562, 27546, 27410, 61003,  4097,  4071,\n",
       "          4064, 61071, 61107, 61606, 24033, 61634, 62147, 62301, 62330,\n",
       "         62379,  3127, 62389, 62445, 62453, 62516,  2923, 62531, 24184,\n",
       "         62628, 62641,  2836, 62715, 62717,  3285,  3300,  3330, 24095,\n",
       "          3621], dtype=int64),\n",
       "  'feature_absent_idx': array([40416, 10982, 19294, 19293, 10986, 10987, 49856, 60006, 19290,\n",
       "         10991, 32215, 19288, 32226, 19287, 32209, 26186, 59996, 59995,\n",
       "         45895, 54433, 45899, 59993, 11006, 59992, 32203, 45892, 45900,\n",
       "         60013, 60015, 10943, 45874, 10947, 32245, 60031, 60028, 26173,\n",
       "         45879, 60024, 10958, 26178, 10978, 10960, 10963, 32235, 26180,\n",
       "         10967, 19297, 32232, 60020, 60018, 32230, 32228, 32227, 54430,\n",
       "         60038, 11010, 49854, 59963, 11052, 11053, 11055, 32169, 45929,\n",
       "         32167, 11059, 59960, 59959, 59958, 59964, 11065, 11069, 11071,\n",
       "         26203, 59953, 54445, 59950, 45935, 32158, 11080, 19266, 59945,\n",
       "         59956, 49855, 32170, 45927, 32199, 45903, 45904, 11018, 59987,\n",
       "         59986, 32195, 32194, 59984, 49851, 49847, 19271, 32186, 32179,\n",
       "         19273, 11036, 11037, 32177, 45923, 59971, 11042, 26200, 11044,\n",
       "         11045, 54438, 59944, 60039, 60041, 49885, 10838, 10839, 45824,\n",
       "         45826, 60083, 10843, 60082, 26148, 10846, 32316, 10836, 10850,\n",
       "         10852, 32312, 32311, 32309, 32306, 19339, 54396, 54399, 60073,\n",
       "         19335, 54400, 45828, 10866, 45823, 60093, 49901, 10803, 45809,\n",
       "         60107, 10806, 32351, 49898, 60104, 32348, 54379, 60100, 32328,\n",
       "         26135, 19355, 32340, 26138, 32338, 10821, 10822, 26139, 49891,\n",
       "         19350, 26141, 49890, 49897, 32251, 32297, 32293, 10911, 19318,\n",
       "         10913, 45863, 49865, 60056, 54412, 45864, 60053, 32262, 10921,\n",
       "         10910, 10922, 54413, 45872, 54418, 10928, 10931, 10932, 32254,\n",
       "         60047, 54419, 19310, 10938, 45865, 45843, 19319, 10905, 10874,\n",
       "         45846, 26159, 54402, 45847, 10879, 32287, 32286, 10882, 10883,\n",
       "         45849, 32270, 32284, 54406, 10889, 32278, 10893, 10894, 32276,\n",
       "         60065, 26162, 10900, 26163, 45856, 54404, 32154, 59943, 45939,\n",
       "         59837, 54490, 19197, 46016, 32024, 54491, 46018, 19194, 19192,\n",
       "         11274, 26254, 19199, 11276, 59828, 59827, 19189, 11281, 46023,\n",
       "         59825, 46024, 11285, 32010, 11287, 59821, 54493, 32008, 32030,\n",
       "         59840, 11230, 32057, 26246, 11233, 32051, 59853, 59852, 32050,\n",
       "         32047, 49800, 59846, 11259, 11244, 46007, 11248, 59845, 32040,\n",
       "         46008, 19201, 59843, 11254, 49796, 32032, 46013, 46006, 19207,\n",
       "         46028, 59817, 59797, 59796, 59795, 11331, 46049, 26268, 59793,\n",
       "         31973, 59786, 11340, 54509, 26266, 26273, 19159, 59783, 59780,\n",
       "         11350, 59779, 11352, 11353, 11354, 11355, 54518, 46066, 46063,\n",
       "         59820, 26265, 19173, 32005, 19187, 32000, 19184, 59810, 11303,\n",
       "         46036, 54495, 11306, 11307, 59809, 59799, 19181, 54497, 59808,\n",
       "         11314, 54499, 54503, 26262, 26263, 46047, 11321, 59803, 31982,\n",
       "         31994, 54485, 11226, 32061, 11124, 59922, 45948, 59921, 59920,\n",
       "         26216, 59917, 32126, 19248, 59915, 45953, 11123, 26218, 11139,\n",
       "         59911, 11142, 59909, 54470, 32115, 11150, 32113, 59904, 59903,\n",
       "         59901, 59914, 11159, 32130, 11119, 59942, 11094, 26208, 49837,\n",
       "         54452, 26210, 32146, 54457, 19257, 59936, 32142, 54465, 32141,\n",
       "         59935, 59934, 45945, 11110, 49831, 59933, 49825, 59930, 11116,\n",
       "         26215, 19251, 19256, 59899, 26233, 11164, 32077, 49803, 45986,\n",
       "         11202, 26242, 19216, 54483, 59870, 45990, 59868, 59866, 45984,\n",
       "         11211, 11214, 19211, 59864, 11217, 19209, 11219, 11220, 45993,\n",
       "         32063, 11223, 45994, 26245, 11196, 11194, 19221, 32106, 32105,\n",
       "         45968, 45969, 19234, 59892, 32098, 32096, 54476, 11176, 11177,\n",
       "         32093, 59885, 54477, 32091, 45976, 19228, 26237, 59883, 49809,\n",
       "         32086, 59877, 54480, 11191, 32082, 10801, 19362, 10799, 60113,\n",
       "         10402, 45611, 19502, 54276, 32653, 10408, 32652, 45615, 45616,\n",
       "         26013, 45618, 49994, 45619, 32640, 54280, 45628, 60345, 32632,\n",
       "         60344, 60342, 32630, 60340, 32629, 60338, 45626, 54282, 54273,\n",
       "         45609, 32676, 32675, 10370, 60382, 19511, 10376, 10377, 26009,\n",
       "         60374, 26010, 10383, 19505, 60373, 32669, 45603, 10388, 10390,\n",
       "         10391, 10392, 19507, 10394, 10395, 19506, 60367, 32670, 19512,\n",
       "         49988, 10442, 10478, 19466, 60305, 32585, 60300, 32578, 32577,\n",
       "         10490, 45664, 32575, 10496, 54302, 32572, 19459, 10502, 10503,\n",
       "         26042, 54306, 32567, 60287, 45671, 45672, 26043, 10511, 60292,\n",
       "         10441, 32590, 26033, 54290, 45634, 45635, 60332, 49985, 45638,\n",
       "         10451, 45639, 60329, 26027, 32614, 10474, 32611, 19477, 45643,\n",
       "         54297, 19475, 26029, 32601, 32600, 10468, 54299, 32597, 45652,\n",
       "         19479, 10366, 10363, 60386, 60453, 32757, 19552, 45553, 45557,\n",
       "         19550, 19549, 10268, 45565, 10271, 45567, 32760, 32744, 60440,\n",
       "         54256, 10280, 10281, 10282, 32739, 60438, 60436, 60435, 19541,\n",
       "         10289, 32743, 19540, 10257, 19555, 25971, 19566, 10228, 19565,\n",
       "         60464, 10231, 19564, 32782, 54244, 19562, 54245, 54251, 45535,\n",
       "         32775, 19560, 10242, 25972, 25976, 32770, 45542, 32767, 10249,\n",
       "         10250, 45544, 10239, 60430, 32734, 45573, 45594, 19521, 10336,\n",
       "         60401, 32697, 10339, 32696, 50000, 10342, 10343, 45598, 45592,\n",
       "         10346, 45599, 10349, 32686, 60394, 45600, 10355, 49999, 10357,\n",
       "         60390, 54270, 60387, 32689, 10330, 19523, 25998, 60428, 32731,\n",
       "         19539, 19538, 10299, 10300, 19537, 32726, 45576, 10304, 25988,\n",
       "         60421, 32722, 10308, 10309, 60420, 54260, 54261, 32716, 10321,\n",
       "         45583, 60410, 54266, 10326, 32707, 19454, 46067, 10514, 26044,\n",
       "         26097, 32427, 45761, 32424, 10697, 10699, 32423, 54351, 26098,\n",
       "         60168, 10706, 19396, 54354, 10710, 10711, 32417, 32415, 45769,\n",
       "         10716, 10717, 60164, 32412, 10720, 32411, 10708, 60160, 32430,\n",
       "         10687, 10659, 45743, 60191, 26087, 60189, 60188, 10665, 10666,\n",
       "         45747, 19405, 19402, 32431, 32440, 19400, 45758, 60183, 10677,\n",
       "         49941, 54350, 10680, 60180, 60178, 32435, 10686, 10673, 10658,\n",
       "         10723, 49931, 54361, 10767, 54365, 26125, 10773, 60130, 60129,\n",
       "         60128, 19369, 32371, 10782, 10765, 54369, 10785, 10787, 60124,\n",
       "         32365, 10790, 32364, 32362, 45800, 45803, 54372, 45807, 26129,\n",
       "         26104, 45786, 10758, 32404, 10730, 19386, 32401, 60154, 10734,\n",
       "         32400, 10736, 10737, 32399, 10740, 10763, 19385, 10746, 45779,\n",
       "         32392, 49923, 26115, 19379, 60143, 32388, 60140, 60139, 60138,\n",
       "         10742, 49948, 10654, 19410, 26060, 32532, 19439, 60253, 26061,\n",
       "         10558, 60249, 60248, 32525, 32524, 26063, 10549, 10565, 32518,\n",
       "         60243, 45695, 45696, 32515, 32514, 10575, 10576, 54337, 10578,\n",
       "         10579, 49960, 45699, 10547, 49973, 10518, 45674, 49978, 10522,\n",
       "         60280, 54318, 60275, 10527, 60274, 54319, 45683, 60256, 60270,\n",
       "         32547, 32546, 49976, 19445, 32543, 60260, 10540, 32539, 60258,\n",
       "         32538, 10544, 32548, 60238, 32511, 10584, 45726, 26076, 10626,\n",
       "         32472, 45731, 60210, 10630, 45732, 10632, 10633, 10634, 45725,\n",
       "         26077, 60206, 10638, 10641, 10642, 32464, 10645, 10646, 45736,\n",
       "         10649, 45740, 32459, 60209, 19419, 10618, 19420, 45701, 32509,\n",
       "         60235, 19431, 10589, 19430, 32506, 45704, 45705, 60228, 49954,\n",
       "         45711, 32495, 10602, 32493, 45713, 19423, 45716, 45717, 19422,\n",
       "         32486, 10611, 26075, 32483, 45722, 32562, 32790, 59774, 11363,\n",
       "         18887, 31418, 31417, 31416, 31414, 59274, 59273, 26473, 59270,\n",
       "         59268, 46417, 18889, 12132, 12134, 54700, 18880, 59265, 59264,\n",
       "         59262, 12142, 12143, 26478, 49639, 59261, 26474, 54702, 59283,\n",
       "         59286, 31445, 46390, 26464, 49648, 12087, 59301, 18898, 46393,\n",
       "         59299, 31438, 59293, 26470, 31435, 18894, 49642, 46402, 12104,\n",
       "         31429, 12106, 46406, 12108, 12109, 31426, 54694, 46399, 46389,\n",
       "         26482, 31399, 18855, 54723, 12198, 26492, 26493, 31367, 12202,\n",
       "         12205, 46439, 12207, 18850, 18856, 26496, 31360, 46442, 12215,\n",
       "         12218, 59212, 59211, 59210, 12224, 18847, 31355, 26502, 12212,\n",
       "         54705, 26491, 46434, 54712, 46426, 12158, 46427, 26487, 18867,\n",
       "         59249, 31389, 18864, 54715, 31386, 54719, 46428, 54718, 18860,\n",
       "         12178], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_topic': {'feature_present_idx': array([25854, 15416, 65202, 15488, 54259, 17955, 26017, 25980, 25917,\n",
       "         46122, 46396, 63781,  3983, 46981, 65142, 65108, 59663, 37537,\n",
       "         25697, 59646, 59523, 54539,  8262, 42094, 43127, 17929, 56540,\n",
       "         37544, 54160, 46423, 49736, 20928, 45837, 10054, 37384, 48961,\n",
       "         50002, 49975, 46972, 35135, 53454,  3035, 27494, 53557, 14865,\n",
       "         35265, 56836, 27088, 27001,  6634, 53847, 21189,  9900, 53923,\n",
       "         41874, 21191,  3503, 15355,  6266, 24892, 17900,  4368, 17588,\n",
       "         55392, 39500,  8811, 61291, 49203, 23392, 16930, 23216, 55600,\n",
       "         23188, 56099,  5412, 43536, 55660, 42258, 17047, 64160, 46319,\n",
       "         17093, 63978, 22828, 22120, 43436, 48500, 55901,  5757, 17702,\n",
       "         34945, 55349, 36792,  4381, 21694, 36503, 36536,  4497, 36553,\n",
       "         24609, 24551,  9223,  8331, 48521,  9168, 16270, 42125,  6123,\n",
       "         42170,  9021,  9019, 24031, 23944, 39244, 43633,  8904, 39335,\n",
       "         16651,  5064, 23590, 55341, 44477, 14589, 53093, 31852, 19618,\n",
       "         51491, 19665, 50492, 34000, 61558, 31465, 12375, 38127, 44948,\n",
       "         50483, 31239, 10871, 66700, 10824,  7746, 38678,  1225, 42833,\n",
       "         61756, 34115, 38081, 58372, 20113,  1358, 30571, 31891,  1381,\n",
       "         61469, 46673, 32985, 50854, 11657,  7483, 19296, 50922, 32667,\n",
       "         61233, 51002, 11763, 11825, 32454, 32336, 32331, 51044, 57842,\n",
       "         38295, 47621, 12060, 61440, 32140, 51164, 38183, 51263, 12157,\n",
       "         31993, 50626, 11098, 60821, 57488, 61800, 40306, 30494,  2002,\n",
       "         29498,  2091, 14147,  6976,  2116, 20283, 44697, 63032, 29234,\n",
       "         29198, 50130, 52805, 52872, 50126, 28833, 52940, 60359, 48033,\n",
       "         28411, 65770, 50048, 41702, 40389, 34397, 29560, 58618, 52499,\n",
       "         52525, 66465, 44752, 18502, 29948, 30182, 66408, 13326, 30211,\n",
       "         47871, 29710,  7929,  7956, 52673, 40596, 13092, 29821, 19131,\n",
       "         18186, 58520, 18263, 58446, 48578, 19049, 38945, 18102, 18378,\n",
       "         58564, 17781, 39343, 18921, 18004, 48525, 18386, 18790, 48534,\n",
       "         17793, 17728, 57905, 39210, 18381, 38957, 18926, 23203, 39357,\n",
       "         12978, 40529, 13334, 13390, 60686, 47903, 13610, 14166, 60408,\n",
       "         14352, 60384, 14386, 60319, 14498, 14546, 14582, 48120, 60834,\n",
       "         14757, 47839, 12795, 11562, 11674, 61238, 47533, 61227, 40993,\n",
       "         40905, 61184, 40877, 12160, 12166, 12271, 12347, 61036, 12623,\n",
       "         12683, 47811, 12870, 14807, 14862, 48122, 16192, 39633, 39619,\n",
       "         59325, 59229, 39576, 16524, 39525, 16604, 16652, 48445, 16872,\n",
       "         59063, 17034, 17112, 58976, 17433, 59419, 16083, 59450, 39675,\n",
       "         14959, 60182, 15295, 40042, 15362, 40036, 15377, 15452, 17517,\n",
       "         39968, 15544, 59875, 39840, 59655, 15966, 16004, 48343, 16024,\n",
       "         19208, 19213, 56225, 19247, 27914, 35019, 53215, 50004, 28009,\n",
       "         53086, 28431, 28463, 28641, 52995, 50091, 29266, 50181, 29411,\n",
       "         50183, 34412, 29593, 50196, 29715, 53267, 53406, 27675, 53445,\n",
       "         36107, 54368, 36040, 25830, 54262, 35950, 35928, 26158, 49700,\n",
       "         34370, 26290, 26465, 54005, 26507, 26693, 26714, 26876, 35542,\n",
       "         35273, 27305, 54099, 25675, 34330, 30014, 31945, 51366, 32014,\n",
       "         33811, 32163, 50645, 33728, 32205, 33716, 33686, 33681, 51014,\n",
       "         32512, 50657, 33620, 50899, 32958, 33604, 33408, 31933, 31772,\n",
       "         31695, 51608, 52456, 30169, 52431, 30316, 30491, 34187, 30609,\n",
       "         52321, 50268, 29946, 52193, 52032, 31045, 31108, 51832, 31227,\n",
       "         31362, 31383, 31447, 31466, 52146, 54385, 36148, 54565, 37628,\n",
       "         21000, 56699, 37579, 21279, 21301, 21360, 48993, 56591, 21574,\n",
       "         56522, 37422, 56462, 56458, 56437, 21920, 49030, 49050, 56381,\n",
       "         56927, 20920, 37756, 57157, 48848, 19282, 57707, 48899, 19487,\n",
       "         38289, 19671, 19798, 19924, 21996, 20037, 20115, 20127, 20143,\n",
       "         38071, 20171, 48927, 48929, 57233, 20363, 57486, 56290, 37385,\n",
       "         56165, 24078, 24082, 55244, 24246, 55146, 55142, 24327, 24328,\n",
       "         24331, 24043, 24398, 36554, 24528, 54927, 49416, 36272, 36269,\n",
       "         25090, 25121, 54582, 24418, 48833, 23905, 36781, 49113, 49147,\n",
       "         55997, 55944, 49157, 22720, 22878, 49190, 22963, 49205, 37021,\n",
       "         23364, 23408, 23424, 36917, 36908, 23542, 55386, 23615, 55291,\n",
       "         36988, 61303, 59121, 33313,  8429, 44505, 65739,  8506,  8539,\n",
       "          8565,  8399,  2512,  8776,  8782, 65853, 42181, 62412,  2375,\n",
       "          2407,  8869,  2830, 62622, 63037,  7922, 63034, 63010, 44213,\n",
       "          3173,  8368, 65416, 62727,  2970,  8155, 42366, 44264, 44301,\n",
       "          8091,  2341,  8939,  2333,  1741, 47255, 62236,  1705,  1607,\n",
       "         44782,  1783,  1517, 66496, 41964, 44819,  9800,  9857,  1415,\n",
       "         42003,  1830,  1887,  9520, 45770, 62362, 44678,  2210,  9128,\n",
       "          9145, 62307, 66155, 62277, 66166,  9314, 62274, 45751,  9409,\n",
       "         66174, 44183, 63043,  7739,  3454, 64474, 43743, 46359, 64608,\n",
       "         43755,  6320, 46289,  6323,  6491, 43037,  4726,  4716,  4660,\n",
       "         43875, 43790,  6163, 64427,  6104,  5465, 46325, 64079, 43583,\n",
       "          5707, 43403, 64312,  5220,  5218,  5203, 46326, 63912,  5994,\n",
       "          5147,  6085, 46532,  1398,  4619, 43887,  3777, 63190,  7436,\n",
       "          3752,  7466,  3717,  3848,  7480,  3707,  7540, 42613,  3602,\n",
       "          3455, 63116, 65266,  3974,  3995,  7305,  4550, 42910, 43893,\n",
       "          4402, 64880,  6911, 46562,  6949, 46222,  4178, 65020, 63503,\n",
       "          7179, 65030, 65033, 63590, 41926,  5546,  1237, 62030, 10802,\n",
       "           344,   590, 11255, 10776, 67137, 10232, 10362, 45109,   281,\n",
       "         61388,  1127,   999, 67272, 10039, 67168, 61998, 41633, 44945,\n",
       "            38, 41287, 45287, 41636, 11113, 45521, 61890, 41641, 10166,\n",
       "         44964, 45444, 61773, 44977, 10401, 47368, 45425,  1281,   868,\n",
       "           276, 10624, 10652, 10529, 67079, 10440, 11403, 61570, 47528,\n",
       "         41186,  1297, 61377, 10411,   203, 36212, 54863, 54553, 51006,\n",
       "         49539, 54839, 32447, 32374, 46242, 36340, 36330, 64950, 64958,\n",
       "         64965, 25230, 25295, 54590, 25268, 54801, 44820, 45422, 54533,\n",
       "         54274,  3799, 26094,   388,   394, 51128, 26020, 32172, 26220,\n",
       "         35879, 26241, 35869,  3672, 33786, 67061, 25379,  3846, 46176,\n",
       "         32367,   289, 54526, 33646, 25466, 49545, 54286, 25646,  4077,\n",
       "          4056, 25736, 36049, 25796, 45222, 45225, 24708, 32745,  4476,\n",
       "         33190, 55567, 33180, 55556,  5194, 33165, 33543, 64328, 64372,\n",
       "         33085, 43612, 36817, 23577, 33072, 33558, 64291, 64396, 64280,\n",
       "         23252, 33257, 43530, 64191, 23046, 55655, 23099, 23107, 55651,\n",
       "          5392, 33321,     4, 43606, 45327,  5301, 33206, 36970, 33050,\n",
       "         33045,  5050, 32857,  4706, 32785, 67034,  4622, 50942, 36655,\n",
       "         55039, 32650, 32620, 67197,  4529, 24567, 43892,  4501, 49337,\n",
       "         24250, 32904,  4727, 55337, 23703, 33040, 23800,  5012, 23980,\n",
       "         45416, 54954, 50875, 49233, 67276, 43799, 24103, 55276,  4733,\n",
       "         33617,  4844, 26357, 26575, 26425, 51771,  2257, 29136, 34510,\n",
       "         50174, 29206,  2224, 52816, 52772, 67332, 29344, 31296, 66735,\n",
       "         52710, 31200, 51805, 44925, 66684, 31411, 34689, 44984, 51634,\n",
       "         45787, 28462,   984, 28491, 28492, 50113, 28575, 44544, 34011,\n",
       "         28669, 28675,  2384, 34744, 34731, 28598, 34796, 31094,  1971,\n",
       "         66484, 34117, 50298, 44800, 30219, 34306, 30286, 30029, 30806,\n",
       "         30665, 52387, 66636, 52378, 52371, 66556, 45533, 34247,  1221,\n",
       "         29981, 52574, 44726, 51916, 66308, 29698, 66339,  1805, 52631,\n",
       "         52569, 66357, 29905, 52054, 66668, 30883, 44845, 29953, 52575,\n",
       "         34071, 28334, 53001, 64153,  3366, 26956, 67029, 49829, 66868,\n",
       "         35580, 49845, 26869,  3332, 33813,   614, 65362, 35314, 66858,\n",
       "         33861, 27442, 53673,  3084, 26849, 26784,  3573, 65273, 26524,\n",
       "         53984, 26543,  3438, 49758, 35673, 50631, 26675, 35691, 26708,\n",
       "         53882, 46025, 26753, 26756, 50214, 35161, 27489, 65485, 45041,\n",
       "         44456, 50517, 31648,  2662, 28043, 28050, 33900, 34893, 51530,\n",
       "         51554], dtype=int64),\n",
       "  'feature_absent_idx': array([53212, 13219, 57825, 13221, 29097, 57821, 29094, 46294, 13233,\n",
       "         57811, 29086, 46299, 57807, 57801, 29098, 13243, 57795, 13247,\n",
       "         13249, 46304, 46305, 13255, 29071, 13259, 57782, 46312, 46314,\n",
       "         13269, 13271, 57796, 57772, 13217, 13214, 13167, 57860, 29133,\n",
       "         46274, 29131, 13173, 57857, 13176, 29127, 57856, 29123, 13183,\n",
       "         29119, 57835, 57850, 13193, 29115, 29114, 57846, 29111, 13201,\n",
       "         29110, 29107, 29105, 57840, 13209, 46284, 46287, 13190, 29135,\n",
       "         13273, 57770, 57735, 13328, 13329, 57731, 57730, 46341, 13333,\n",
       "         57725, 13338, 29020, 46342, 57723, 46343, 13322, 46344, 13345,\n",
       "         13347, 29012, 57718, 57717, 29008, 57715, 29007, 46349, 29004,\n",
       "         46350, 46353, 13362, 13344, 13274, 57736, 29029, 29058, 57768,\n",
       "         13280, 57766, 46316, 57762, 46317, 13288, 13290, 13292, 13293,\n",
       "         13295, 29042, 29028, 29041, 29040, 13301, 57750, 29039, 13307,\n",
       "         29035, 13311, 29033, 57745, 29032, 57741, 13317, 46334, 57753,\n",
       "         57864, 29139, 13161, 57975, 57974, 57973, 13014, 57972, 13016,\n",
       "         29252, 57971, 46183, 13020, 29249, 46184, 46187, 57977, 57968,\n",
       "         13029, 29239, 46198, 13037, 57960, 46199, 13040, 29229, 29226,\n",
       "         57955, 57953, 29219, 13052, 13028, 46209, 57978, 29254, 58029,\n",
       "         58021, 12960, 46162, 58017, 12964, 29287, 46163, 46164, 29284,\n",
       "         12969, 12970, 12971, 46182, 12973, 58000, 46168, 12983, 57998,\n",
       "         12987, 12989, 46172, 57991, 57990, 57988, 13002, 13003, 46180,\n",
       "         58006, 29214, 29213, 46214, 29175, 57911, 57908, 57907, 57901,\n",
       "         57900, 57899, 29170, 57898, 29161, 57887, 57885, 46258, 13112,\n",
       "         29152, 29147, 13146, 29146, 13148, 13149, 46268, 13151, 57876,\n",
       "         13154, 46271, 29140, 57867, 13160, 29149, 29177, 13108, 13106,\n",
       "         13065, 29205, 46228, 57940, 29200, 57938, 57937, 57933, 29199,\n",
       "         29196, 57929, 13079, 13081, 29194, 13084, 46237, 29191, 57927,\n",
       "         46239, 57924, 13095, 13096, 29184, 13098, 46241, 13101, 57922,\n",
       "         13103, 57919, 13364, 13365, 28994, 28993, 46480, 28805, 28803,\n",
       "         46482, 46486, 13637, 13638, 46487, 46488, 57480, 46489, 13647,\n",
       "         46490, 13631, 28792, 46493, 13654, 28788, 57468, 46494, 13659,\n",
       "         28784, 28783, 46495, 28779, 28778, 28777, 13671, 28791, 13672,\n",
       "         13626, 57501, 13577, 13579, 13582, 28840, 57526, 28839, 57525,\n",
       "         46458, 57524, 46462, 57518, 57516, 13595, 57493, 57513, 28827,\n",
       "         46472, 13606, 28823, 13608, 46473, 46475, 28818, 28817, 13615,\n",
       "         57502, 28815, 13620, 57511, 28775, 13675, 28772, 57423, 13731,\n",
       "         28738, 57422, 57420, 46538, 57415, 57413, 46542, 57405, 57403,\n",
       "         28727, 28724, 13729, 57401, 46546, 57395, 28715, 57392, 57391,\n",
       "         57389, 28714, 28713, 13767, 57386, 13772, 13773, 13774, 57399,\n",
       "         46536, 57425, 13725, 57450, 28768, 28767, 57447, 28765, 13688,\n",
       "         13689, 57442, 57441, 13692, 46510, 46511, 13696, 28759, 13698,\n",
       "         46513, 13701, 46518, 13705, 57437, 28754, 57433, 57430, 57429,\n",
       "         57428, 13718, 13719, 46530, 57427, 46449, 58030, 13571, 13568,\n",
       "         46383, 13429, 57643, 57642, 57641, 13435, 28942, 46389, 13441,\n",
       "         28940, 46390, 13446, 13448, 13426, 57629, 46393, 13454, 28933,\n",
       "         57626, 28932, 28929, 28928, 13463, 28927, 46399, 13466, 13467,\n",
       "         57611, 57628, 57609, 13425, 13423, 57699, 46361, 28986, 57688,\n",
       "         28983, 57683, 28982, 28981, 28976, 57676, 57670, 57667, 57666,\n",
       "         46382, 13399, 46372, 57662, 13405, 28964, 46374, 13410, 57656,\n",
       "         46377, 13415, 57650, 28957, 28954, 13422, 57665, 28924, 46402,\n",
       "         57605, 28880, 57571, 57570, 13532, 46426, 57568, 57567, 13536,\n",
       "         57566, 46427, 46428, 13541, 46434, 28881, 46439, 28865, 46442,\n",
       "         13551, 57550, 28860, 13557, 46446, 28853, 57544, 13564, 13565,\n",
       "         13566, 46447, 28868, 13524, 28887, 13520, 13476, 46406, 57601,\n",
       "         13485, 57599, 28909, 57596, 28907, 57594, 13494, 13495, 46417,\n",
       "         57591, 13498, 28905, 28902, 28901, 28900, 28897, 13507, 28896,\n",
       "         28895, 28893, 13511, 13513, 28890, 57579, 57578, 13519, 28850,\n",
       "         12952, 12951, 58032, 58476, 12367, 12368, 29727, 12372, 29726,\n",
       "         12374, 58465, 29720, 45892, 58460, 29717, 45895, 12365, 12390,\n",
       "         29709, 29708, 29705, 29703, 45899, 58450, 29701, 29700, 45900,\n",
       "         12404, 29696, 58444, 58443, 12391, 58442, 12363, 29731, 12315,\n",
       "         58513, 12318, 29771, 45863, 45864, 45865, 29765, 45872, 58506,\n",
       "         45874, 58502, 29758, 12362, 29757, 29754, 29751, 12338, 58491,\n",
       "         29750, 58489, 12344, 58488, 12346, 29745, 45879, 12356, 29735,\n",
       "         58496, 58439, 12411, 12412, 12468, 58388, 58385, 58380, 45935,\n",
       "         12484, 29640, 58373, 45939, 12490, 12491, 12494, 12495, 58389,\n",
       "         29635, 45945, 45948, 58364, 58363, 12506, 58361, 58360, 12510,\n",
       "         58358, 12512, 58357, 29628, 58354, 58367, 29654, 29656, 29658,\n",
       "         58438, 29693, 29692, 12418, 45903, 58434, 58429, 58428, 45904,\n",
       "         12428, 12431, 29683, 58416, 58415, 58413, 58411, 29675, 45923,\n",
       "         12446, 12447, 12448, 12452, 29666, 12454, 45927, 29661, 12459,\n",
       "         12460, 45929, 12313, 29624, 29776, 12308, 29903, 29899, 58635,\n",
       "         45779, 58632, 58631, 12158, 29891, 58628, 45786, 29887, 58621,\n",
       "         29883, 12143, 29882, 58615, 29879, 12178, 29876, 29875, 12184,\n",
       "         29870, 12186, 29867, 58601, 45800, 45803, 12198, 29880, 29857,\n",
       "         12142, 29907, 12087, 45726, 45731, 45732, 29957, 29956, 58672,\n",
       "         58671, 29950, 12104, 12106, 29943, 12108, 45769, 12109, 58666,\n",
       "         45740, 45743, 58657, 29929, 45747, 45758, 29920, 45761, 29915,\n",
       "         12132, 12134, 58643, 45736, 29856, 12202, 45807, 29817, 58553,\n",
       "         29815, 29814, 45826, 58548, 12267, 29811, 29808, 45828, 12279,\n",
       "         58538, 29799, 12258, 12283, 58536, 45843, 12292, 12293, 12294,\n",
       "         45846, 45847, 12297, 45849, 29788, 58526, 58519, 29782, 58537,\n",
       "         29822, 12254, 12253, 12205, 45809, 12207, 29851, 29849, 12212,\n",
       "         12215, 29845, 12218, 58573, 12224, 58572, 58571, 12230, 29834,\n",
       "         12234, 12236, 12239, 12240, 29831, 29830, 12243, 45823, 12247,\n",
       "         29825, 58559, 45824, 12251, 12252, 45856, 13776, 29622, 45953,\n",
       "         58151, 29410, 12799, 29408, 29406, 12805, 12807, 12811, 12812,\n",
       "         12813, 46100, 29393, 29392, 58152, 58132, 29389, 29388, 12824,\n",
       "         29387, 12826, 46110, 12829, 29383, 58122, 29382, 58118, 12835,\n",
       "         29380, 58130, 29377, 29413, 58158, 29453, 46066, 58191, 46067,\n",
       "         29444, 58179, 58178, 46071, 12762, 12763, 29436, 29433, 29432,\n",
       "         29414, 12768, 12770, 12771, 46075, 12773, 29430, 12777, 29424,\n",
       "         29423, 29422, 46088, 12782, 58163, 46089, 12769, 58112, 29372,\n",
       "         58110, 12898, 29329, 12901, 29326, 46146, 58060, 29320, 58057,\n",
       "         29317, 12915, 58052, 58049, 58046, 46138, 29308, 12930, 29305,\n",
       "         29304, 29303, 58039, 46158, 58037, 46159, 58036, 12943, 58034,\n",
       "         12947, 12948, 29306, 12894, 29334, 12892, 46117, 58106, 29368,\n",
       "         12851, 12852, 12854, 12858, 46120, 46124, 12862, 58092, 58090,\n",
       "         12865, 29357, 46128, 29353, 29352, 29350, 12877, 12878, 29349,\n",
       "         12880, 46129, 46130, 29346, 58072, 29345, 46135, 29335, 58195,\n",
       "         58349, 12742, 58197, 29572, 12586, 58305, 58301, 29569, 12592,\n",
       "         45990, 12595, 12596, 12597, 12598, 58297, 45993, 45986, 58294,\n",
       "         58292, 29558, 29552, 58286, 29549, 29548, 58285, 29547, 29544,\n",
       "         29543, 58283, 58277, 58274, 45994, 46006, 12583, 12581, 29615,\n",
       "         12527, 12530, 58340, 12534, 58337, 29608, 29605, 29602, 12544,\n",
       "         29601, 12546, 58333, 58310, 12550, 29597, 45969, 12557, 12562,\n",
       "         45976, 12568, 29580, 58318, 12574, 58316, 45984, 58311, 29574,\n",
       "         45968, 46007, 12633, 12634, 29495, 12693, 29490, 12696, 46036,\n",
       "         29483, 58221, 29482, 29481, 12707, 58215, 12710, 12711, 58236,\n",
       "         46047, 12717, 58208, 58207, 46049, 12721, 29470, 12723, 29465,\n",
       "         58203, 29462, 58200, 29461, 46063, 12714, 58237, 58239, 46028,\n",
       "         46008], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_unit': {'feature_present_idx': array([29630, 20592, 12539, 32352, 13114, 57773, 34635, 57448, 12499,\n",
       "         56206, 11928, 55774, 55453, 37268, 11568, 34157, 46502, 33544,\n",
       "          4913, 58748, 32868, 59306, 32565,  3347, 32176, 32020, 60738,\n",
       "         60792, 31422, 30364, 15064, 29912,  3849, 39088, 39280, 39317,\n",
       "          7936,  7771, 45605, 48044, 48104,  8578, 48373, 49008, 44383,\n",
       "         44270, 49161,  6946, 49482, 49559, 43594, 20044, 50090, 53223,\n",
       "         11171, 53154, 40812, 52195, 52029, 15585, 51604, 41387,  5858,\n",
       "         51535,  6126, 41958,  6215, 51595, 29454, 33907, 24281, 63592,\n",
       "         23280, 62567, 66201, 66114,  2120, 23036,   319, 65970, 22637,\n",
       "         65952, 17021, 18893, 23668, 24888, 65145, 25668, 66642, 63628,\n",
       "         23977, 64225, 27005, 63796, 28111, 17664, 18147, 28387,  2386,\n",
       "         61669, 28039, 22499, 41841, 41525, 39767, 39858, 10344, 41422,\n",
       "         40322, 18475, 18654, 41078, 40850, 42506, 18385, 40940, 40230,\n",
       "         42539,  9229, 42701, 20112, 20276, 45757,  8101,  8151, 19826,\n",
       "          8261,  8306, 45418, 45182, 20306, 21061, 45047, 19484, 22475,\n",
       "         44520, 21666, 21885, 44199, 44043, 22367,  9023, 43864, 22452,\n",
       "         43145,  9387, 22462, 43018, 42941, 42874, 44396, 39483, 15739,\n",
       "         11174, 13353, 16969, 33549, 13539, 33145, 25784, 33133, 32682,\n",
       "         25944, 32551, 26021, 32528, 14129, 32344, 32327, 26105, 26620,\n",
       "         31516, 27023, 27313, 14621, 14625, 14926, 27767, 30228, 27949,\n",
       "         15604, 29513, 29366, 13281, 23779, 13275, 34039, 39425, 39334,\n",
       "         23799, 23971, 38584, 11648, 17357, 11727, 36740, 36718, 11993,\n",
       "         24833, 12073, 36129, 35949, 12161, 35854, 12471, 24920, 35084,\n",
       "         24985, 25079, 34575, 12779, 25317, 34531, 13033, 17073, 17071,\n",
       "         34012,  7863,  9181, 20012,  3855, 52936, 58278, 58406,  5472,\n",
       "         52657,  1412, 64132, 52550, 52440, 51680, 51628, 51568,  5661,\n",
       "          5785,  6018,  1229, 51162, 50984,  3705, 50977,  2455, 61530,\n",
       "          5317, 58114, 57259, 57572, 57074,  4537, 62636, 56962, 56664,\n",
       "         56392, 62762,  4614, 61462, 62803, 55472,  1941, 55238, 57810,\n",
       "         63136,  1595, 54150, 60863, 53957, 53915, 56014, 59109,  1265,\n",
       "           558,  3031,  2883, 66073, 49449, 49106,  7006, 49072,  7165,\n",
       "         47213,  7198, 61363, 48141, 61124, 47357, 47602,  2793, 60835,\n",
       "         46751,  2628, 66776, 49817,    44,  7796, 49977,  2568,  6394,\n",
       "         49911,  7783, 65933,  1022, 60288, 49611, 67257, 59732, 65097,\n",
       "         59548, 65196, 61960, 61038, 27657, 60943, 27645, 30519, 30290,\n",
       "         27228, 61840, 27466, 60947, 61317, 61752, 61175, 29355, 29065,\n",
       "         29031, 62085, 28892, 61134, 29530, 28750, 27759, 28720, 28486,\n",
       "         28187, 29781, 61736, 29995, 30088, 28029, 27954, 61740, 28615,\n",
       "         26892, 24750, 26338, 64598, 64745, 23269, 64855, 64952, 22665,\n",
       "         22566, 22538, 65389, 65831, 22447, 22414, 22048, 21673, 66320,\n",
       "         21659, 21540, 66579, 21087, 66687, 20872, 20866, 66917, 67275,\n",
       "         20220, 23329, 64532, 23503, 23530, 62349, 62405, 62772, 25530,\n",
       "         25476, 25399, 62954, 63097, 63230, 63403, 63425, 63541, 62176,\n",
       "         24848, 24519, 24476, 63635, 24322, 63895, 64003, 24268, 24143,\n",
       "         24127, 23999, 64104, 64403, 24707, 30793, 46640, 31030, 50895,\n",
       "         42866, 42811, 42768, 42660, 42163, 41995, 51168, 51194, 40906,\n",
       "         40794, 40743, 50544, 40351, 40072, 40003, 39980, 52854, 39688,\n",
       "         39636, 53188, 53197, 53596, 39315, 54066, 38893, 40283, 50155,\n",
       "         43038, 43441, 46503, 46244, 46235, 46232, 45936, 45715, 46831,\n",
       "         45556, 47390, 45421, 47535, 45419, 45242, 45194, 47813, 45001,\n",
       "         44899, 44168, 44134, 49479, 43983, 43891, 43883, 49749, 43719,\n",
       "         49808, 43505, 38892, 38728, 54498, 38398, 58209, 58238, 33884,\n",
       "         33778, 58730, 33474, 33473, 46707, 33201, 59023, 33011, 32718,\n",
       "         59203, 59375, 59380, 32458, 32368, 59919, 32285, 60091, 60268,\n",
       "         31879, 31364, 31170, 31084, 31068, 31056, 58115, 30923, 57996,\n",
       "         57910, 37423, 54596, 54817, 55459, 55773, 36455, 56143, 36423,\n",
       "         36331, 36278, 56256, 35629, 35606, 35566, 35448, 35391, 35126,\n",
       "         57416, 57702, 57759, 57787, 34489, 34414, 34389, 34317, 57888,\n",
       "         34233, 34086, 33275, 67331, 16990, 10864, 10946,  9101,  8529,\n",
       "         14345,  6287, 11242,  3490,  9892, 14217, 15868,  9682, 14182,\n",
       "         15249,  8245, 13376,  2925, 14140,  8036, 16526,  6602, 14030,\n",
       "          2718,  3889, 16674, 15380, 18044, 15616,  5585,  4708, 14790,\n",
       "          4675, 15460,  5658,  8854, 17797,  4567, 16225,  2671, 17806,\n",
       "          8857,  4742, 17871,  6019, 10437,  6145,  4348, 10728,  6170,\n",
       "          4101, 10793, 15714, 14771,  2555, 13922,  1298,  5354,  7800,\n",
       "         13683,  1094, 13680,   981,  7698,  7392,  4971, 16372, 12518,\n",
       "         12691,   756,   716,  7690,  9259, 16262,  7624,   186, 12918,\n",
       "         13139, 16234,   109,   841, 16047,  1345, 11998,  2410, 19023,\n",
       "          6689, 19114,  9656,  6769, 11750,  7970, 13805, 19312,  2103,\n",
       "         16409,  5562,  4806,  7009,  2005, 12031,  9480,  1626,  7892,\n",
       "          1446,  1429, 19317,  9154, 43657, 19964, 43328, 43532, 19896,\n",
       "          8767, 47009, 46752, 46691, 46644,  7920, 46015, 45942, 45926,\n",
       "          8773, 45897, 45082, 45081, 45019,  8542, 44627, 44611, 44516,\n",
       "          8704, 45165, 45244, 10263, 43052, 38297, 37957, 37945, 37875,\n",
       "         37457, 37414, 11665, 37041, 11747, 36602, 36434, 36394, 36297,\n",
       "         36059, 36046, 12141, 35934, 12466, 35246, 35120, 12685, 34920,\n",
       "         34871, 34717, 12778, 12801, 34443, 12863, 34084, 38566, 43096,\n",
       "         38676, 11376, 42873, 42661, 42175, 42161, 42151, 42111, 41767,\n",
       "         41734, 41688, 41679, 41571, 10072, 10076, 10104, 41308, 10117,\n",
       "         10352, 40837, 10393, 10434, 10572, 10754, 40098, 10812, 11033,\n",
       "         11127, 39603, 39462, 11208, 11477,  7661,  6530, 47360,  2848,\n",
       "         60823, 60693, 60622, 60512, 60110, 60059, 59967, 59947, 59831,\n",
       "         59342,  3416, 59272,  3578, 58975, 58800,  3778, 57154,  4464,\n",
       "          4445, 57543,  4126, 57862, 61205,  4039, 58131, 58336, 58409,\n",
       "         58528, 58602, 58710, 58117,  4519,  2503, 62066, 67205,   172,\n",
       "         66789,   279, 66439,   359, 66287,   867, 65616, 65374, 65175,\n",
       "         65151,  1040, 64706, 64597,  1174, 64333, 62191, 62206, 62299,\n",
       "          2138, 62660,  2084, 61864,  2068,  1837, 63234,  1470, 63914,\n",
       "          1418,  1330, 62935, 57003, 56990,  4571, 51667,  5589, 51517,\n",
       "         51490, 51390, 51350, 50780, 50666,  6255, 50532, 50511, 50097,\n",
       "          6326, 50003,  6348,  6472,  6543,  7568,  7506,  7334, 48279,\n",
       "          7178, 48399, 52053, 48718,  7111,  6952, 49375,  6839,  6696,\n",
       "         49615, 48846, 52199, 52258, 52354, 55416,  4776,  4758, 55546,\n",
       "         55596, 55647, 55340, 55662, 55677, 55720, 55729, 55840, 56217,\n",
       "         56379, 55663, 47346, 55232, 55059,  5540,  5526, 52590, 52703,\n",
       "         52745, 53057, 55123,  5374, 53889, 54320, 54391,  4824, 55017,\n",
       "         55042,  5299, 33626,     8, 24293, 23808, 23920, 31999, 23939,\n",
       "         32013, 17824, 27928, 19448, 27822, 32279, 21567, 67321, 16495,\n",
       "         24473, 21531, 13949, 21361, 21206, 16554, 21142, 32673, 17223,\n",
       "         26740, 24896, 24903, 31794, 13790, 31759, 14403, 29884, 15385,\n",
       "         15241, 29486, 29473, 22964, 29469, 30295, 30347, 29390, 23106,\n",
       "         29082, 14874, 18460, 31033, 14747, 28730, 19210, 28670, 14433,\n",
       "         23580, 31472, 16007, 28401, 28272, 28176, 20877, 29919, 19625,\n",
       "         20136, 33012, 26568, 13517, 26542, 20494, 16992, 16796, 19818,\n",
       "         26137, 20155, 19835, 17192, 13550, 26579, 25286, 13594, 16866,\n",
       "         25284, 25531, 24917, 32951, 20856, 16920, 32939, 32947, 13785,\n",
       "         15905, 23493, 45670,  8905,  8170, 22935, 26095,  8938,  8879,\n",
       "         58353,  2943, 45563, 46074,  3832,  9099, 58250, 25559, 18168,\n",
       "         15343, 43723, 46483, 46583, 46612,  4830, 18189,  3594, 52214,\n",
       "         54076,  8739, 53844, 53894, 44487, 44491,  2961, 60040,  5180,\n",
       "         29583, 15736, 15786,  5356, 44971, 58761, 29091,  3261, 59503,\n",
       "         51781], dtype=int64),\n",
       "  'feature_absent_idx': array([53040, 59783, 53945, 10308, 10309, 53946, 44663, 59780, 59779,\n",
       "         48952, 30881, 48951, 10304, 48950, 10321, 18204, 30875, 59771,\n",
       "         30874, 10326, 48946, 30872, 59767, 10330, 30871, 59774, 44671,\n",
       "         30889, 44659, 44642, 53939, 53941, 48955, 44645, 10280, 10281,\n",
       "         10282, 30901, 18218, 59803, 59786, 30898, 59797, 10289, 59796,\n",
       "         59795, 53942, 24951, 59793, 53943, 18213, 10299, 10300, 59799,\n",
       "         18202, 53950, 59764, 30843, 59744, 53959, 24971, 30840, 10376,\n",
       "         10377, 48940, 59739, 59738, 30837, 10370, 59737, 59736, 59734,\n",
       "         18185, 10388, 30834, 10390, 10391, 10392, 10394, 10395, 53962,\n",
       "         10383, 30844, 24966, 10366, 10336, 30865, 44679, 10339, 30861,\n",
       "         44686, 10342, 10343, 24962, 10346, 44687, 53952, 10349, 59756,\n",
       "         59755, 59754, 10355, 53953, 10357, 30851, 18195, 59749, 30849,\n",
       "         10363, 53956, 30907, 24974, 59808, 10271, 44597, 10177, 59870,\n",
       "         18255, 59868, 18254, 44600, 59866, 18253, 59864, 30968, 53913,\n",
       "         10187, 10189, 10190, 10191, 30966, 53916, 48973, 44607, 24930,\n",
       "         59853, 59852, 44610, 30967, 30957, 30976, 48978, 18267, 48983,\n",
       "         44571, 10150, 30997, 24913, 10153, 24914, 59892, 44577, 24916,\n",
       "         24924, 44580, 44583, 44585, 59885, 44586, 44587, 59883, 30983,\n",
       "         53910, 59877, 44588, 30979, 24918, 30955, 10203, 30953, 10239,\n",
       "         48963, 44628, 10242, 30926, 53929, 18232, 44630, 44632, 10249,\n",
       "         10250, 30930, 59825, 30917, 44635, 59821, 10257, 59820, 59817,\n",
       "         53933, 18226, 18223, 10268, 59810, 44634, 53927, 59827, 59828,\n",
       "         10205, 18247, 30949, 24933, 59846, 44616, 10212, 59845, 59843,\n",
       "         10218, 30941, 10220, 59840, 30939, 10224, 48965, 48964, 59837,\n",
       "         10228, 44621, 18239, 10231, 24940, 18237, 18236, 59809, 44705,\n",
       "         59725, 53964, 10565, 44793, 18110, 18109, 18108, 18107, 44795,\n",
       "         44797, 10575, 10576, 18105, 25031, 10578, 44801, 25033, 48893,\n",
       "         48891, 10584, 25037, 30679, 59573, 30678, 10589, 54024, 10579,\n",
       "         59570, 30698, 30700, 30719, 25023, 59603, 25024, 30716, 54013,\n",
       "         10540, 18119, 54015, 10544, 54016, 18112, 10547, 10549, 59594,\n",
       "         30706, 30705, 59593, 59592, 59590, 59587, 10558, 48896, 30701,\n",
       "         18115, 48888, 18096, 48886, 25049, 10630, 44829, 10632, 10633,\n",
       "         10634, 30643, 30642, 10638, 44830, 10641, 18084, 10642, 10645,\n",
       "         10646, 30637, 59537, 10649, 30636, 30635, 30633, 10654, 18077,\n",
       "         59529, 44834, 10626, 59544, 59547, 44811, 30670, 25042, 30668,\n",
       "         59565, 10602, 59564, 25043, 44812, 59560, 30664, 30663, 54031,\n",
       "         10611, 30661, 30660, 18090, 59555, 54032, 44822, 10618, 18088,\n",
       "         30651, 44825, 18086, 44777, 54010, 59609, 54009, 30796, 30795,\n",
       "         24986, 30792, 10441, 10442, 44737, 53975, 24991, 30786, 44739,\n",
       "         30797, 30784, 10451, 59678, 30780, 59676, 18160, 59673, 30778,\n",
       "         59670, 59668, 59665, 30776, 24992, 59691, 48930, 59698, 10402,\n",
       "         44714, 30826, 18180, 30823, 10408, 24978, 18176, 48936, 44719,\n",
       "         30816, 53966, 59714, 53967, 59710, 30810, 44724, 53969, 44725,\n",
       "         53970, 44730, 30804, 30803, 30801, 44734, 44749, 24910, 24998,\n",
       "         10468, 10502, 10503, 59635, 18137, 48908, 25013, 30737, 48906,\n",
       "         10511, 30735, 30734, 59636, 10514, 30732, 25016, 10518, 10522,\n",
       "         25022, 59618, 18127, 59612, 10527, 18126, 44775, 48905, 30742,\n",
       "         48911, 59638, 30768, 53987, 53988, 18152, 10474, 18151, 30762,\n",
       "         30760, 10478, 30759, 53990, 18149, 30756, 30755, 48919, 53993,\n",
       "         18143, 59643, 10490, 59641, 53994, 44764, 59639, 10496, 25005,\n",
       "         18156, 10658, 31005, 31007,  9786,  9787, 49029, 18389, 53800,\n",
       "          9792, 24827,  9795, 60168, 18383, 31258, 18391, 31257, 60164,\n",
       "         60160, 31254,  9804, 53808, 44372, 31251,  9808, 31250, 53809,\n",
       "          9811, 24828,  9812,  9784,  9782,  9755, 60191, 31282, 44361,\n",
       "          9759, 60189, 60188, 31279, 31277,  9766, 31276, 18392, 53792,\n",
       "          9770,  9771, 31272, 60183, 53795, 44363,  9777,  9778, 60180,\n",
       "          9780, 60178, 31274, 60154, 53810, 44376,  9848, 60128, 24835,\n",
       "         60124, 24838, 53820, 31217,  9856, 44405, 44410, 31211, 53816,\n",
       "         31210, 18361, 44411, 53829, 49021,  9870, 31201, 60107, 53831,\n",
       "         60104, 18355, 44418, 60113,  9846,  9845, 60129,  9816, 53811,\n",
       "         31243, 31242,  9820, 44380, 31240,  9823, 18376,  9826, 53814,\n",
       "         24834, 18371, 60143, 60140, 60139,  9835, 60138, 31230, 31229,\n",
       "         31228, 18370, 31224, 18369, 60130, 53788, 60100,  9753, 18400,\n",
       "         60275, 60274, 60270, 44303, 31355, 44305, 49045,  9666,  9667,\n",
       "         49042, 24797, 31360, 31346,  9672, 60258, 44311, 60256, 44312,\n",
       "         44313, 24800, 60253, 44317, 60249, 60248, 60260, 18426, 60280,\n",
       "         24786, 31386, 53741,  9623, 53743, 60300, 49059,  9628, 18451,\n",
       "         31379, 44295, 24774, 53754, 60292, 24776, 24777, 24778, 24779,\n",
       "         60287,  9640,  9641, 24780, 49053, 24784, 31367,  9634, 53771,\n",
       "          9689, 44320,  9724, 44339, 49037,  9727, 44340, 24814, 31302,\n",
       "         31301, 44347, 53780, 60210, 44337, 60209, 60206, 18402, 53786,\n",
       "         31293,  9743, 44350,  9745, 31291, 31289, 44353,  9749, 53783,\n",
       "         53777,  9721, 49038, 60243, 24803, 18423, 31328, 18422, 24804,\n",
       "         18420, 60238, 53772, 60235,  9702, 44331, 44333, 24808,  9709,\n",
       "          9710, 60228, 44335, 24810,  9714,  9715, 18412, 31312, 24811,\n",
       "          9719, 24820, 53832, 24846, 31194, 59963, 31055, 53885, 31051,\n",
       "         10055, 59960, 53886, 59959, 59958, 59956, 53890, 59964, 44531,\n",
       "         10064, 24893, 59953, 53891, 59950, 44543, 10071, 10073, 31040,\n",
       "         31039, 59945, 44537, 10080, 44525, 18294, 18304, 31076, 10015,\n",
       "         59987, 10017, 59986, 10019, 59984, 10024, 44514, 31069, 10046,\n",
       "         48990, 48989, 53880, 10034, 31060, 31059, 10038, 59971, 10040,\n",
       "         10041, 10042, 10043, 44521, 59944, 59943, 10083, 24901, 59917,\n",
       "         24904, 10119, 59915, 24906, 59914, 53900, 31013, 10125, 59911,\n",
       "         59920, 10127, 59909, 10130, 10132, 53902, 44567, 24908, 59904,\n",
       "         10137, 59903, 10139, 59901, 44565, 59921, 31020, 59922, 59942,\n",
       "         10085, 31034, 10087, 53892, 18283, 31028, 59936, 59935, 44553,\n",
       "         59934, 59933, 53893, 10097, 24897, 10099, 59930, 53896, 10102,\n",
       "         24898, 10105, 24899, 10107, 10108, 31021, 31078, 44510, 24880,\n",
       "         24879, 31161,  9918, 31157, 60065, 18332, 31151, 18330, 60056,\n",
       "         31148, 53850, 31146, 18334, 60053, 53851, 53853, 44459, 31140,\n",
       "         60047, 44461, 53854, 60041, 60039,  9942, 18324, 31145,  9915,\n",
       "         18336, 18337, 24849, 44425, 60093, 24853, 49017, 44431,  9891,\n",
       "         53837, 60083, 60082,  9897, 44432, 18344, 44438, 31178, 31177,\n",
       "         44439, 18343, 49016, 53839, 31172, 60073, 24856, 24857, 24858,\n",
       "         60038, 59899, 44464, 44465,  9982, 31109, 44484, 60006,  9987,\n",
       "          9988, 31106, 49005, 31103, 44488, 31101, 44481,  9994, 31092,\n",
       "         31090, 53868, 10001, 59996, 10003, 10004, 59995, 24877, 59993,\n",
       "         59992, 49000,  9980, 31112,  9978, 60031, 49010, 31129,  9953,\n",
       "         60028, 31128, 31127, 53857, 44472, 60024, 24868,  9963,  9964,\n",
       "         60020, 31120, 44475, 60018, 31117, 44476, 18315,  9973, 60015,\n",
       "          9975, 60013, 24871, 31134, 10659, 54037, 30627, 45243, 17792,\n",
       "         59006, 11390, 30071, 11392, 45247, 59003, 45248, 45249, 11397,\n",
       "         25269, 30067, 11400, 17790, 30064, 45250, 45252, 45253, 25272,\n",
       "         58992, 45255, 11409, 11410, 54251, 17788, 45239, 59016, 54239,\n",
       "         11350, 11352, 11353, 11354, 11355, 48740, 59032, 30097, 11361,\n",
       "         45232, 45237, 11363, 11366, 45233, 54244, 54245, 11371, 30087,\n",
       "         30086, 17800, 17799, 45236, 11378, 54241, 45258, 25274, 58987,\n",
       "         11447, 30033, 17779, 48731, 48730, 58974, 48728, 17775, 11455,\n",
       "         45292, 30024, 45282, 30023, 17774, 54260, 11462, 30020, 17772,\n",
       "         11465, 54261, 48727, 45299, 17769, 25283, 11459, 30035, 30036,\n",
       "         45281, 30054, 11417, 11419, 30052, 45266, 11422, 11423, 17785,\n",
       "         45271], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 1000\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 1000\n",
       "    })}}},\n",
       " 'contains_wiki': {'feature_present_idx': [],\n",
       "  'feature_absent_idx': array([], dtype=int64),\n",
       "  'feature_present_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 0\n",
       "  }),\n",
       "  'feature_absent_dataset': Dataset({\n",
       "      features: ['text', 'label', 'idx'],\n",
       "      num_rows: 0\n",
       "  }),\n",
       "  'transformed_datasets': {'ExpandContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'ContractContractions': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'AddNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RemoveNeutralEmoji': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'ChangeLocation': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'ChangeName': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RandomInsertion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'InsertPunctuationMarks': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RandomCharDel': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RandomCharInsert': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RandomCharSubst': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RandomCharSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RandomSwapQwerty': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'ChangeNumber': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'ChangeSynonym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'ChangeHyponym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'ChangeHypernym': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'WordDeletion': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'HomoglyphSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })},\n",
       "   'RandomSwap': {'feature_present_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    }),\n",
       "    'feature_absent_aug_dataset': Dataset({\n",
       "        features: ['text', 'label', 'idx'],\n",
       "        num_rows: 0\n",
       "    })}}}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6a512352",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using distilbert-base-uncased-finetuned-sst-2-english to support evaluation.\n",
      "contains_imperative ExpandContractions\n",
      "contains_imperative ContractContractions\n",
      "contains_imperative AddNeutralEmoji\n",
      "contains_imperative RemoveNeutralEmoji\n",
      "contains_imperative ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_imperative RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_exlamation RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_negation RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_conjunctions RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_interrogative_clause RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_question RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_coreferences RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_number RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_accompanier RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_age RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_beneficiary RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_concession RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_condition RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_consist_of RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_degree RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_destination RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_direction RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_domain RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_duration RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_example RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_extent RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_frequency RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_instrument RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_location RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_manner RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_medium RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mod RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_mode RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_name RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_ord RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_part RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_path RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polarity RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite ExpandContractions\n",
      "contains_polite ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite AddNeutralEmoji\n",
      "contains_polite RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite ChangeLocation\n",
      "contains_polite ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite RandomInsertion\n",
      "contains_polite InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite RandomCharDel\n",
      "contains_polite RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite RandomCharSubst\n",
      "contains_polite RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite RandomSwapQwerty\n",
      "contains_polite ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite ChangeSynonym\n",
      "contains_polite ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite ChangeHypernym\n",
      "contains_polite WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_polite RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_poss RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_purpose RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_quant RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range ExpandContractions\n",
      "contains_range ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range AddNeutralEmoji\n",
      "contains_range RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range ChangeLocation\n",
      "contains_range ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range RandomInsertion\n",
      "contains_range InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range RandomCharDel\n",
      "contains_range RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range RandomCharSubst\n",
      "contains_range RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range RandomSwapQwerty\n",
      "contains_range ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range ChangeSynonym\n",
      "contains_range ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range ChangeHypernym\n",
      "contains_range WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_range HomoglyphSwap\n",
      "contains_range RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_scale ExpandContractions\n",
      "contains_scale ContractContractions\n",
      "contains_scale AddNeutralEmoji\n",
      "contains_scale RemoveNeutralEmoji\n",
      "contains_scale ChangeLocation\n",
      "contains_scale ChangeName\n",
      "contains_scale RandomInsertion\n",
      "contains_scale InsertPunctuationMarks\n",
      "contains_scale RandomCharDel\n",
      "contains_scale RandomCharInsert\n",
      "contains_scale RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_scale RandomCharSwap\n",
      "contains_scale RandomSwapQwerty\n",
      "contains_scale ChangeNumber\n",
      "contains_scale ChangeSynonym\n",
      "contains_scale ChangeHyponym\n",
      "contains_scale ChangeHypernym\n",
      "contains_scale WordDeletion\n",
      "contains_scale HomoglyphSwap\n",
      "contains_scale RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_source RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_subevent RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_time RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_topic RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ExpandContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ContractContractions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit AddNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RemoveNeutralEmoji\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ChangeLocation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ChangeName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RandomInsertion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit InsertPunctuationMarks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RandomCharDel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RandomCharInsert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RandomCharSubst\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RandomCharSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RandomSwapQwerty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ChangeNumber\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ChangeSynonym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ChangeHyponym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit ChangeHypernym\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit WordDeletion\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit HomoglyphSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contains_unit RandomSwap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "C:\\Users\\Fabrice\\anaconda3\\envs\\fada\\lib\\site-packages\\transformers\\pipelines\\base.py:1043: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pipe = EvalPipeline()\n",
    "pipe.find_model_for_dataset(\"sst2\")\n",
    "\n",
    "eval_results = []\n",
    "for f_name, f_data in feature_datasets.items():\n",
    "    \n",
    "    if f_data[\"feature_present_dataset\"].num_rows == 0:\n",
    "        continue\n",
    "    \n",
    "    orig_T_acc = pipe.calculate_accuracy(f_data[\"feature_present_dataset\"])\n",
    "    orig_F_acc = pipe.calculate_accuracy(f_data[\"feature_absent_dataset\"])\n",
    "    \n",
    "    orig_out = {\n",
    "        \"transform\": \"original\",\n",
    "        \"featurizer\": f_name,\n",
    "        \"num_samples\": f_data[\"feature_present_dataset\"].num_rows,\n",
    "        \"T_orig_acc\": orig_T_acc,\n",
    "        \"F_orig_acc\": orig_F_acc,\n",
    "        \"T_tran_acc\": 0,\n",
    "        \"F_tran_acc\": 0,\n",
    "        \"pct_T_changed\": 0,\n",
    "        \"pct_F_changed\": 0\n",
    "    }\n",
    "    \n",
    "    eval_results.append(orig_out)\n",
    "    \n",
    "    for t_name, t_data in f_data[\"transformed_datasets\"].items():\n",
    "        print(f_name, t_name)\n",
    "        \n",
    "        tran_T_acc = pipe.calculate_accuracy(t_data[\"feature_present_aug_dataset\"])\n",
    "        tran_F_acc = pipe.calculate_accuracy(t_data[\"feature_absent_aug_dataset\"])\n",
    "        \n",
    "        pct_T_changed = percent_dataset_changed(f_data[\"feature_present_dataset\"], t_data[\"feature_present_aug_dataset\"])\n",
    "        pct_F_changed = percent_dataset_changed(f_data[\"feature_absent_dataset\"],  t_data[\"feature_absent_aug_dataset\"])\n",
    "        \n",
    "        tran_out = {\n",
    "            \"transform\": t_name,\n",
    "            \"featurizer\": f_name,\n",
    "            \"num_samples\": f_data[\"feature_present_dataset\"].num_rows,\n",
    "            \"T_orig_acc\": orig_T_acc,\n",
    "            \"F_orig_acc\": orig_F_acc,\n",
    "            \"T_tran_acc\": tran_T_acc,\n",
    "            \"F_tran_acc\": tran_F_acc,\n",
    "            \"pct_T_changed\": pct_T_changed,\n",
    "            \"pct_F_changed\": pct_F_changed\n",
    "        }\n",
    "        \n",
    "        eval_results.append(tran_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04dbb0e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9058e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5c5ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"transform_feature_analysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0031e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
