
{'loss': 0.6696, 'learning_rate': 1.1883541295306003e-08, 'epoch': 0.0}
  0%|                                                                                       | 0/168372 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.























































